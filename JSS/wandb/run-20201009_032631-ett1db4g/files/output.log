2020-10-09 03:26:33,552	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_3bc00_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=81273)[0m 2020-10-09 03:26:36,624	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=81202)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81202)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81160)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81160)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81196)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81196)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81241)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81154)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81154)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81142)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81142)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81194)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81136)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81136)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81213)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81213)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81246)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81246)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81133)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81133)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81244)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81244)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81247)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81247)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81222)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81222)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81201)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81201)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81271)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81149)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81149)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81216)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81216)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81208)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81208)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81210)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81210)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81203)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81203)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81268)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81268)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81130)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81130)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81231)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81214)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81214)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81212)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81212)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81131)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81131)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81143)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81143)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81117)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81117)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81124)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81124)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81243)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81243)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81135)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81135)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81224)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81224)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81139)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81139)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81236)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81236)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81218)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81218)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81126)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81126)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81195)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81195)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81134)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=81148)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=81148)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-09_03-27-23
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.158928430080414
        entropy_coeff: 0.0
        kl: 0.00829014196060598
        model: {}
        policy_loss: -0.03108331940602511
        total_loss: 478.28696670532224
        vf_explained_var: 0.5854242444038391
        vf_loss: 478.31639556884767
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.583333333333332
    gpu_util_percent0: 0.29
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00020833333333333335
    ram_util_percent: 9.6
    vram_util_percent0: 0.2524188258445392
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17625916478957024
    mean_env_wait_ms: 1.6538563463635636
    mean_inference_ms: 5.617717844205493
    mean_raw_obs_processing_ms: 0.4744412539070791
  time_since_restore: 40.715906620025635
  time_this_iter_s: 40.715906620025635
  time_total_s: 40.715906620025635
  timers:
    learn_throughput: 5160.512
    learn_time_ms: 31351.925
    sample_throughput: 17406.552
    sample_time_ms: 9294.891
    update_time_ms: 28.216
  timestamp: 1602214043
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |      1 |          40.7159 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3207.0
  date: 2020-10-09_03-28-02
  done: false
  episode_len_mean: 876.3639240506329
  episode_reward_max: 278.6666666666666
  episode_reward_mean: 224.34621531773408
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.130819946527481
        entropy_coeff: 0.0
        kl: 0.008118597941938787
        model: {}
        policy_loss: -0.03645027284510434
        total_loss: 112.73407955169678
        vf_explained_var: 0.8625796437263489
        vf_loss: 112.76890621185302
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.326086956521745
    gpu_util_percent0: 0.2763043478260869
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765217391304349
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17143538555300927
    mean_env_wait_ms: 1.6467466128437034
    mean_inference_ms: 5.3693147227815246
    mean_raw_obs_processing_ms: 0.4623327809019236
  time_since_restore: 80.10207104682922
  time_this_iter_s: 39.38616442680359
  time_total_s: 80.10207104682922
  timers:
    learn_throughput: 5181.89
    learn_time_ms: 31222.582
    sample_throughput: 18490.329
    sample_time_ms: 8750.088
    update_time_ms: 33.041
  timestamp: 1602214082
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |      2 |          80.1021 | 323584 |  224.346 |              278.667 |              115.788 |            876.364 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3207.0
  date: 2020-10-09_03-28-42
  done: false
  episode_len_mean: 874.2130801687764
  episode_reward_max: 278.6666666666666
  episode_reward_mean: 225.9117120572815
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1192828208208083
        entropy_coeff: 0.0
        kl: 0.008574296371079981
        model: {}
        policy_loss: -0.04417881453409791
        total_loss: 19.457225465774535
        vf_explained_var: 0.968469500541687
        vf_loss: 19.499689626693726
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.084782608695654
    gpu_util_percent0: 0.27565217391304353
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.776086956521741
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16845600271131947
    mean_env_wait_ms: 1.6418058221950433
    mean_inference_ms: 5.235402446506455
    mean_raw_obs_processing_ms: 0.45318009010238486
  time_since_restore: 119.44758701324463
  time_this_iter_s: 39.345515966415405
  time_total_s: 119.44758701324463
  timers:
    learn_throughput: 5193.641
    learn_time_ms: 31151.942
    sample_throughput: 18855.897
    sample_time_ms: 8580.445
    update_time_ms: 36.204
  timestamp: 1602214122
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |      3 |          119.448 | 485376 |  225.912 |              278.667 |              115.788 |            874.213 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3207.0
  date: 2020-10-09_03-29-21
  done: false
  episode_len_mean: 872.256329113924
  episode_reward_max: 278.6666666666666
  episode_reward_mean: 227.0226633422834
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0977963536977768
        entropy_coeff: 0.0
        kl: 0.008727845503017306
        model: {}
        policy_loss: -0.04461192605085671
        total_loss: 11.030840396881104
        vf_explained_var: 0.9791488647460938
        vf_loss: 11.07370684146881
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.059999999999995
    gpu_util_percent0: 0.32711111111111113
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.780000000000001
    vram_util_percent0: 0.257051492292555
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16640550536556753
    mean_env_wait_ms: 1.6395611548033753
    mean_inference_ms: 5.137217954114339
    mean_raw_obs_processing_ms: 0.44695050120635726
  time_since_restore: 158.37326765060425
  time_this_iter_s: 38.92568063735962
  time_total_s: 158.37326765060425
  timers:
    learn_throughput: 5198.422
    learn_time_ms: 31123.291
    sample_throughput: 19292.271
    sample_time_ms: 8386.363
    update_time_ms: 35.765
  timestamp: 1602214161
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |      4 |          158.373 | 647168 |  227.023 |              278.667 |              115.788 |            872.256 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3207.0
  date: 2020-10-09_03-30-00
  done: false
  episode_len_mean: 870.2721518987341
  episode_reward_max: 284.5656565656567
  episode_reward_mean: 227.6732003580103
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0730338513851165
        entropy_coeff: 0.0
        kl: 0.008331259805709123
        model: {}
        policy_loss: -0.044995613815262916
        total_loss: 11.763849139213562
        vf_explained_var: 0.9812986254692078
        vf_loss: 11.807178640365601
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.584782608695654
    gpu_util_percent0: 0.3006521739130435
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771739130434785
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1648903562863284
    mean_env_wait_ms: 1.6390377143135895
    mean_inference_ms: 5.062933977407832
    mean_raw_obs_processing_ms: 0.4423128491246189
  time_since_restore: 197.81553888320923
  time_this_iter_s: 39.44227123260498
  time_total_s: 197.81553888320923
  timers:
    learn_throughput: 5197.2
    learn_time_ms: 31130.609
    sample_throughput: 19381.758
    sample_time_ms: 8347.643
    update_time_ms: 36.573
  timestamp: 1602214200
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |      5 |          197.816 | 808960 |  227.673 |              284.566 |              115.788 |            870.272 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3207.0
  date: 2020-10-09_03-30-39
  done: false
  episode_len_mean: 865.0506329113924
  episode_reward_max: 284.5656565656567
  episode_reward_mean: 229.7547719509743
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 1106
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0824410229921342
        entropy_coeff: 0.0
        kl: 0.00855303502175957
        model: {}
        policy_loss: -0.043681182933505626
        total_loss: 15.426239228248596
        vf_explained_var: 0.9801578521728516
        vf_loss: 15.468209743499756
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.156521739130437
    gpu_util_percent0: 0.266304347826087
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.769565217391307
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16284827377715752
    mean_env_wait_ms: 1.640586029833267
    mean_inference_ms: 4.963768050341638
    mean_raw_obs_processing_ms: 0.43632083303361385
  time_since_restore: 237.1507387161255
  time_this_iter_s: 39.33519983291626
  time_total_s: 237.1507387161255
  timers:
    learn_throughput: 5195.924
    learn_time_ms: 31138.255
    sample_throughput: 19491.788
    sample_time_ms: 8300.521
    update_time_ms: 37.695
  timestamp: 1602214239
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |      6 |          237.151 | 970752 |  229.755 |              284.566 |              115.788 |            865.051 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3207.0
  date: 2020-10-09_03-31-19
  done: false
  episode_len_mean: 860.8283227848101
  episode_reward_max: 284.5656565656567
  episode_reward_mean: 230.86438754634938
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.074987816810608
        entropy_coeff: 0.0
        kl: 0.008904261398129165
        model: {}
        policy_loss: -0.048669024789705875
        total_loss: 8.609347367286682
        vf_explained_var: 0.9842785596847534
        vf_loss: 8.656235563755036
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.851111111111116
    gpu_util_percent0: 0.27555555555555555
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.782222222222224
    vram_util_percent0: 0.257051492292555
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16214891417883098
    mean_env_wait_ms: 1.641663796693067
    mean_inference_ms: 4.928328280899789
    mean_raw_obs_processing_ms: 0.43429815081742745
  time_since_restore: 276.19263672828674
  time_this_iter_s: 39.041898012161255
  time_total_s: 276.19263672828674
  timers:
    learn_throughput: 5199.834
    learn_time_ms: 31114.838
    sample_throughput: 19602.576
    sample_time_ms: 8253.609
    update_time_ms: 37.917
  timestamp: 1602214279
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |      7 |          276.193 | 1132544 |  230.864 |              284.566 |              115.788 |            860.828 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3180.0
  date: 2020-10-09_03-31-58
  done: false
  episode_len_mean: 857.4535864978903
  episode_reward_max: 284.5656565656567
  episode_reward_mean: 232.33350381451632
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0624489307403564
        entropy_coeff: 0.0
        kl: 0.008878427697345615
        model: {}
        policy_loss: -0.05232571037486196
        total_loss: 7.265978908538818
        vf_explained_var: 0.9859078526496887
        vf_loss: 7.316528940200806
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.47608695652174
    gpu_util_percent0: 0.3010869565217391
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.77608695652174
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16152713081865833
    mean_env_wait_ms: 1.6428620958802098
    mean_inference_ms: 4.897876774559466
    mean_raw_obs_processing_ms: 0.43255507629482204
  time_since_restore: 315.7793674468994
  time_this_iter_s: 39.58673071861267
  time_total_s: 315.7793674468994
  timers:
    learn_throughput: 5193.656
    learn_time_ms: 31151.851
    sample_throughput: 19656.475
    sample_time_ms: 8230.977
    update_time_ms: 38.037
  timestamp: 1602214318
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |      8 |          315.779 | 1294336 |  232.334 |              284.566 |              115.788 |            857.454 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3167.0
  date: 2020-10-09_03-32-38
  done: false
  episode_len_mean: 854.4835443037974
  episode_reward_max: 284.5656565656567
  episode_reward_mean: 233.21836082342392
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0344813823699952
        entropy_coeff: 0.0
        kl: 0.008747104532085359
        model: {}
        policy_loss: -0.05044250464998186
        total_loss: 9.96943565607071
        vf_explained_var: 0.9814743995666504
        vf_loss: 10.018128657341004
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.134782608695648
    gpu_util_percent0: 0.3239130434782609
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.784782608695652
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16097651445195507
    mean_env_wait_ms: 1.6440796611343467
    mean_inference_ms: 4.871390194904086
    mean_raw_obs_processing_ms: 0.43099023622622606
  time_since_restore: 355.00750207901
  time_this_iter_s: 39.228134632110596
  time_total_s: 355.00750207901
  timers:
    learn_throughput: 5197.679
    learn_time_ms: 31127.742
    sample_throughput: 19661.46
    sample_time_ms: 8228.89
    update_time_ms: 36.256
  timestamp: 1602214358
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |      9 |          355.008 | 1456128 |  233.218 |              284.566 |              115.788 |            854.484 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3102.0
  date: 2020-10-09_03-33-17
  done: false
  episode_len_mean: 849.7737459978655
  episode_reward_max: 295.0101010101007
  episode_reward_mean: 234.61935254357866
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 294
  episodes_total: 1874
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0147421836853028
        entropy_coeff: 0.0
        kl: 0.00859500195365399
        model: {}
        policy_loss: -0.048124726163223386
        total_loss: 16.001771402359008
        vf_explained_var: 0.980965256690979
        vf_loss: 16.048176717758178
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.039130434782606
    gpu_util_percent0: 0.3006521739130435
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.769565217391307
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16013840462335757
    mean_env_wait_ms: 1.6464353108683303
    mean_inference_ms: 4.829850951230376
    mean_raw_obs_processing_ms: 0.42843357945063343
  time_since_restore: 394.5277771949768
  time_this_iter_s: 39.5202751159668
  time_total_s: 394.5277771949768
  timers:
    learn_throughput: 5193.115
    learn_time_ms: 31155.097
    sample_throughput: 19707.356
    sample_time_ms: 8209.726
    update_time_ms: 34.821
  timestamp: 1602214397
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |     10 |          394.528 | 1617920 |  234.619 |               295.01 |              115.788 |            849.774 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3102.0
  date: 2020-10-09_03-33-57
  done: false
  episode_len_mean: 846.9975657254138
  episode_reward_max: 295.0101010101007
  episode_reward_mean: 235.5273474767144
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 180
  episodes_total: 2054
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0241745322942735
        entropy_coeff: 0.0
        kl: 0.009053133870474994
        model: {}
        policy_loss: -0.055191726749762894
        total_loss: 6.824292528629303
        vf_explained_var: 0.9873965978622437
        vf_loss: 6.877673649787903
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.06739130434783
    gpu_util_percent0: 0.28369565217391307
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.786956521739132
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15977011909225072
    mean_env_wait_ms: 1.6481914313690198
    mean_inference_ms: 4.811060822319285
    mean_raw_obs_processing_ms: 0.42741385429639894
  time_since_restore: 433.7375421524048
  time_this_iter_s: 39.20976495742798
  time_total_s: 433.7375421524048
  timers:
    learn_throughput: 5199.322
    learn_time_ms: 31117.901
    sample_throughput: 19989.106
    sample_time_ms: 8094.009
    update_time_ms: 34.801
  timestamp: 1602214437
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |     11 |          433.738 | 1779712 |  235.527 |               295.01 |              115.788 |            846.998 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3102.0
  date: 2020-10-09_03-34-36
  done: false
  episode_len_mean: 844.877034358047
  episode_reward_max: 295.0101010101007
  episode_reward_mean: 236.2166785394632
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0074565917253495
        entropy_coeff: 0.0
        kl: 0.00913192555308342
        model: {}
        policy_loss: -0.05469669704325497
        total_loss: 7.0812937140464784
        vf_explained_var: 0.9873186349868774
        vf_loss: 7.134163975715637
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.154347826086955
    gpu_util_percent0: 0.3
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.773913043478263
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15946599655941618
    mean_env_wait_ms: 1.6495148480388035
    mean_inference_ms: 4.795314983034624
    mean_raw_obs_processing_ms: 0.42648657880757074
  time_since_restore: 473.060706615448
  time_this_iter_s: 39.32316446304321
  time_total_s: 473.060706615448
  timers:
    learn_throughput: 5196.51
    learn_time_ms: 31134.743
    sample_throughput: 20047.154
    sample_time_ms: 8070.572
    update_time_ms: 33.701
  timestamp: 1602214476
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |     12 |          473.061 | 1941504 |  236.217 |               295.01 |              115.788 |            844.877 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3102.0
  date: 2020-10-09_03-35-15
  done: false
  episode_len_mean: 843.25611814346
  episode_reward_max: 295.0101010101007
  episode_reward_mean: 236.92674423560484
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9807028263807297
        entropy_coeff: 0.0
        kl: 0.00932330433279276
        model: {}
        policy_loss: -0.056191819906234744
        total_loss: 6.953820466995239
        vf_explained_var: 0.9873665571212769
        vf_loss: 7.00814768075943
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.062222222222218
    gpu_util_percent0: 0.2864444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.782222222222224
    vram_util_percent0: 0.257051492292555
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1591933977963927
    mean_env_wait_ms: 1.6507179352890908
    mean_inference_ms: 4.781070351596221
    mean_raw_obs_processing_ms: 0.4256390569371623
  time_since_restore: 511.8553442955017
  time_this_iter_s: 38.79463768005371
  time_total_s: 511.8553442955017
  timers:
    learn_throughput: 5198.958
    learn_time_ms: 31120.082
    sample_throughput: 20145.559
    sample_time_ms: 8031.15
    update_time_ms: 31.881
  timestamp: 1602214515
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |     13 |          511.855 | 2103296 |  236.927 |               295.01 |              115.788 |            843.256 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3102.0
  date: 2020-10-09_03-35-55
  done: false
  episode_len_mean: 840.6839534009771
  episode_reward_max: 295.0101010101007
  episode_reward_mean: 237.8999123136664
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 291
  episodes_total: 2661
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9628608703613282
        entropy_coeff: 0.0
        kl: 0.00944374967366457
        model: {}
        policy_loss: -0.0517474836204201
        total_loss: 12.322264218330384
        vf_explained_var: 0.9849732518196106
        vf_loss: 12.372122955322265
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.868085106382974
    gpu_util_percent0: 0.2961702127659575
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.772340425531917
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15875607703825007
    mean_env_wait_ms: 1.652855176735783
    mean_inference_ms: 4.758292121803892
    mean_raw_obs_processing_ms: 0.424283863817499
  time_since_restore: 551.5243587493896
  time_this_iter_s: 39.66901445388794
  time_total_s: 551.5243587493896
  timers:
    learn_throughput: 5192.005
    learn_time_ms: 31161.756
    sample_throughput: 20068.065
    sample_time_ms: 8062.163
    update_time_ms: 30.822
  timestamp: 1602214555
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |     14 |          551.524 | 2265088 |    237.9 |               295.01 |              115.788 |            840.684 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3102.0
  date: 2020-10-09_03-36-34
  done: false
  episode_len_mean: 839.0900140646976
  episode_reward_max: 295.0101010101007
  episode_reward_mean: 238.56729034366154
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 183
  episodes_total: 2844
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9716890662908554
        entropy_coeff: 0.0
        kl: 0.00940763547550887
        model: {}
        policy_loss: -0.055779772950336336
        total_loss: 6.302498698234558
        vf_explained_var: 0.9891624450683594
        vf_loss: 6.356396949291229
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.919999999999998
    gpu_util_percent0: 0.3026666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.786666666666669
    vram_util_percent0: 0.257051492292555
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15852748048022325
    mean_env_wait_ms: 1.654089616929115
    mean_inference_ms: 4.746112405479173
    mean_raw_obs_processing_ms: 0.42359326277172343
  time_since_restore: 590.7616744041443
  time_this_iter_s: 39.23731565475464
  time_total_s: 590.7616744041443
  timers:
    learn_throughput: 5193.002
    learn_time_ms: 31155.773
    sample_throughput: 20102.924
    sample_time_ms: 8048.182
    update_time_ms: 28.776
  timestamp: 1602214594
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | RUNNING  | 172.17.0.4:81273 |     15 |          590.762 | 2426880 |  238.567 |               295.01 |              115.788 |             839.09 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_3bc00_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3102.0
  date: 2020-10-09_03-37-13
  done: true
  episode_len_mean: 837.7974683544304
  episode_reward_max: 295.0101010101007
  episode_reward_mean: 239.0943108634646
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 1042317d377e4c9fa0b5a3784906ee8a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9543144658207894
        entropy_coeff: 0.0
        kl: 0.009510073624551297
        model: {}
        policy_loss: -0.056130451941862704
        total_loss: 5.834118592739105
        vf_explained_var: 0.9894415140151978
        vf_loss: 5.888347089290619
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.6891304347826
    gpu_util_percent0: 0.2941304347826087
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.784782608695654
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 81273
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15834329661220392
    mean_env_wait_ms: 1.6550841548468855
    mean_inference_ms: 4.7363021647852
    mean_raw_obs_processing_ms: 0.42303282644774753
  time_since_restore: 629.8967399597168
  time_this_iter_s: 39.13506555557251
  time_total_s: 629.8967399597168
  timers:
    learn_throughput: 5196.706
    learn_time_ms: 31133.568
    sample_throughput: 20096.328
    sample_time_ms: 8050.824
    update_time_ms: 27.029
  timestamp: 1602214633
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 3bc00_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | TERMINATED |       |     16 |          629.897 | 2588672 |  239.094 |               295.01 |              115.788 |            837.797 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_3bc00_00000 | TERMINATED |       |     16 |          629.897 | 2588672 |  239.094 |               295.01 |              115.788 |            837.797 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


