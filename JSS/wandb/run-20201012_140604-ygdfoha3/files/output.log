2020-10-12 14:06:08,103	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_13eef_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=44079)[0m 2020-10-12 14:06:10,896	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=44063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44023)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44023)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44070)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44056)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44056)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44077)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44077)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44085)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44085)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44041)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44041)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44040)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44040)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44045)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44045)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43959)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43959)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43969)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43969)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43980)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43980)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43981)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43981)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44028)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44028)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43948)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43948)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43952)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43952)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43975)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43975)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43968)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43968)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44037)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44037)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43947)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43947)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43966)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43966)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43946)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43946)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43972)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43972)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44024)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44024)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43956)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43956)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43957)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43957)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43949)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43949)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43977)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43977)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44025)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44025)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=43953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=43953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=44053)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=44053)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3691
    time_step_mean: 3418.869230769231
    time_step_min: 3176
  date: 2020-10-12_14-06-44
  done: false
  episode_len_mean: 886.753164556962
  episode_reward_max: 282.343434343434
  episode_reward_mean: 241.94642628819824
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.181686669588089
        entropy_coeff: 0.0005000000000000001
        kl: 0.008099652904396256
        model: {}
        policy_loss: -0.010050435809413708
        total_loss: 488.36756642659503
        vf_explained_var: 0.49538537859916687
        vf_loss: 488.3765920003255
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.731250000000003
    gpu_util_percent0: 0.38625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.559375
    vram_util_percent0: 0.08698036241390619
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1704005482536144
    mean_env_wait_ms: 1.1551441782674292
    mean_inference_ms: 5.618200272680543
    mean_raw_obs_processing_ms: 0.45608256694231925
  time_since_restore: 27.704949140548706
  time_this_iter_s: 27.704949140548706
  time_total_s: 27.704949140548706
  timers:
    learn_throughput: 8631.762
    learn_time_ms: 18743.797
    sample_throughput: 18219.542
    sample_time_ms: 8880.135
    update_time_ms: 41.085
  timestamp: 1602511604
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |      1 |          27.7049 | 161792 |  241.946 |              282.343 |              165.677 |            886.753 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3725
    time_step_mean: 3428.4930555555557
    time_step_min: 3146
  date: 2020-10-12_14-07-10
  done: false
  episode_len_mean: 885.5886075949367
  episode_reward_max: 286.888888888889
  episode_reward_mean: 241.6016813706685
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1505032777786255
        entropy_coeff: 0.0005000000000000001
        kl: 0.010289580250779787
        model: {}
        policy_loss: -0.012145594131046286
        total_loss: 124.70166714986165
        vf_explained_var: 0.7999549508094788
        vf_loss: 124.71233304341634
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.822580645161295
    gpu_util_percent0: 0.3590322580645161
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7548387096774185
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1665892572171075
    mean_env_wait_ms: 1.1518552601987708
    mean_inference_ms: 5.474978825524569
    mean_raw_obs_processing_ms: 0.4455542931541077
  time_since_restore: 54.166749238967896
  time_this_iter_s: 26.46180009841919
  time_total_s: 54.166749238967896
  timers:
    learn_throughput: 8704.233
    learn_time_ms: 18587.737
    sample_throughput: 19302.746
    sample_time_ms: 8381.812
    update_time_ms: 67.568
  timestamp: 1602511630
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |      2 |          54.1667 | 323584 |  241.602 |              286.889 |              165.677 |            885.589 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3422.0695067264573
    time_step_min: 3065
  date: 2020-10-12_14-07-36
  done: false
  episode_len_mean: 879.1434599156119
  episode_reward_max: 299.1616161616161
  episode_reward_mean: 242.28525763968784
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1428071856498718
        entropy_coeff: 0.0005000000000000001
        kl: 0.011125149205327034
        model: {}
        policy_loss: -0.014299175255776694
        total_loss: 53.069172859191895
        vf_explained_var: 0.8840799331665039
        vf_loss: 53.0818198521932
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.303333333333338
    gpu_util_percent0: 0.33666666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16371942496876926
    mean_env_wait_ms: 1.1516061229174201
    mean_inference_ms: 5.327354119440595
    mean_raw_obs_processing_ms: 0.4368399295015944
  time_since_restore: 80.19539070129395
  time_this_iter_s: 26.02864146232605
  time_total_s: 80.19539070129395
  timers:
    learn_throughput: 8695.516
    learn_time_ms: 18606.372
    sample_throughput: 20170.486
    sample_time_ms: 8021.225
    update_time_ms: 56.956
  timestamp: 1602511656
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |      3 |          80.1954 | 485376 |  242.285 |              299.162 |              165.677 |            879.143 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3419.968543046358
    time_step_min: 3065
  date: 2020-10-12_14-08-02
  done: false
  episode_len_mean: 874.631329113924
  episode_reward_max: 299.1616161616161
  episode_reward_mean: 243.58144738524462
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1184191803137462
        entropy_coeff: 0.0005000000000000001
        kl: 0.010854517264912525
        model: {}
        policy_loss: -0.012112133124901447
        total_loss: 39.76910273234049
        vf_explained_var: 0.9120087027549744
        vf_loss: 39.77960236867269
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.21379310344828
    gpu_util_percent0: 0.3624137931034483
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.772413793103448
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16158215465709228
    mean_env_wait_ms: 1.1521823144178869
    mean_inference_ms: 5.208423302413325
    mean_raw_obs_processing_ms: 0.4299263727288745
  time_since_restore: 105.84470534324646
  time_this_iter_s: 25.649314641952515
  time_total_s: 105.84470534324646
  timers:
    learn_throughput: 8701.439
    learn_time_ms: 18593.707
    sample_throughput: 20827.743
    sample_time_ms: 7768.101
    update_time_ms: 51.962
  timestamp: 1602511682
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |      4 |          105.845 | 647168 |  243.581 |              299.162 |              165.677 |            874.631 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3417.150326797386
    time_step_min: 3065
  date: 2020-10-12_14-08-28
  done: false
  episode_len_mean: 869.7578814627994
  episode_reward_max: 299.1616161616161
  episode_reward_mean: 244.71264982740374
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 161
  episodes_total: 793
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0705191393693287
        entropy_coeff: 0.0005000000000000001
        kl: 0.009381224634125829
        model: {}
        policy_loss: -0.012345630559138954
        total_loss: 32.00433397293091
        vf_explained_var: 0.9435035586357117
        vf_loss: 32.01533921559652
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.633333333333333
    gpu_util_percent0: 0.3606666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7566666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15990720154857732
    mean_env_wait_ms: 1.1537499578250656
    mean_inference_ms: 5.112668341913279
    mean_raw_obs_processing_ms: 0.4241683074223537
  time_since_restore: 131.46836495399475
  time_this_iter_s: 25.62365961074829
  time_total_s: 131.46836495399475
  timers:
    learn_throughput: 8694.412
    learn_time_ms: 18608.735
    sample_throughput: 21325.745
    sample_time_ms: 7586.699
    update_time_ms: 50.206
  timestamp: 1602511708
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |      5 |          131.468 | 808960 |  244.713 |              299.162 |              165.677 |            869.758 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3406.7105751391464
    time_step_min: 3065
  date: 2020-10-12_14-08-53
  done: false
  episode_len_mean: 858.7224231464738
  episode_reward_max: 299.1616161616161
  episode_reward_mean: 246.86149012731275
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 313
  episodes_total: 1106
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0766534904638927
        entropy_coeff: 0.0005000000000000001
        kl: 0.011351613095030189
        model: {}
        policy_loss: -0.012353125610388815
        total_loss: 29.243800004323322
        vf_explained_var: 0.9566076397895813
        vf_loss: 29.25442123413086
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.83333333333334
    gpu_util_percent0: 0.301
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15767551923515746
    mean_env_wait_ms: 1.1571892464333768
    mean_inference_ms: 4.981930423160491
    mean_raw_obs_processing_ms: 0.4167827964111531
  time_since_restore: 157.1452145576477
  time_this_iter_s: 25.676849603652954
  time_total_s: 157.1452145576477
  timers:
    learn_throughput: 8683.067
    learn_time_ms: 18633.047
    sample_throughput: 21678.599
    sample_time_ms: 7463.213
    update_time_ms: 46.007
  timestamp: 1602511733
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |      6 |          157.145 | 970752 |  246.861 |              299.162 |              165.677 |            858.722 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3399.7815533980583
    time_step_min: 3047
  date: 2020-10-12_14-09-19
  done: false
  episode_len_mean: 854.2587025316456
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 247.93355229510274
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.057701011498769
        entropy_coeff: 0.0005000000000000001
        kl: 0.01204177108593285
        model: {}
        policy_loss: -0.014811604594190916
        total_loss: 18.43994601567586
        vf_explained_var: 0.9618549346923828
        vf_loss: 18.45287831624349
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.165517241379312
    gpu_util_percent0: 0.41275862068965513
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.772413793103448
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15686894165245396
    mean_env_wait_ms: 1.1586424066661227
    mean_inference_ms: 4.933618642010888
    mean_raw_obs_processing_ms: 0.4140755404135275
  time_since_restore: 182.68809819221497
  time_this_iter_s: 25.54288363456726
  time_total_s: 182.68809819221497
  timers:
    learn_throughput: 8682.585
    learn_time_ms: 18634.083
    sample_throughput: 21944.271
    sample_time_ms: 7372.858
    update_time_ms: 42.623
  timestamp: 1602511759
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |      7 |          182.688 | 1132544 |  247.934 |              301.889 |              165.677 |            854.259 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3393.161406025825
    time_step_min: 3047
  date: 2020-10-12_14-09-45
  done: false
  episode_len_mean: 849.7918424753868
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 248.97152964241553
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.033039261897405
        entropy_coeff: 0.0005000000000000001
        kl: 0.009977903760348758
        model: {}
        policy_loss: -0.01296484963192294
        total_loss: 18.63370672861735
        vf_explained_var: 0.959089994430542
        vf_loss: 18.645193099975586
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.94333333333333
    gpu_util_percent0: 0.311
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15617180944591652
    mean_env_wait_ms: 1.160094480111183
    mean_inference_ms: 4.891305221407189
    mean_raw_obs_processing_ms: 0.41166594007835616
  time_since_restore: 208.51183438301086
  time_this_iter_s: 25.8237361907959
  time_total_s: 208.51183438301086
  timers:
    learn_throughput: 8673.026
    learn_time_ms: 18654.619
    sample_throughput: 22110.117
    sample_time_ms: 7317.555
    update_time_ms: 42.559
  timestamp: 1602511785
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |      8 |          208.512 | 1294336 |  248.972 |              301.889 |              165.677 |            849.792 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3387.9049138481173
    time_step_min: 3047
  date: 2020-10-12_14-10-11
  done: false
  episode_len_mean: 845.8796238244514
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 249.87872454957082
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 173
  episodes_total: 1595
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9825452218453089
        entropy_coeff: 0.0005000000000000001
        kl: 0.010728327247003714
        model: {}
        policy_loss: -0.01404063228983432
        total_loss: 19.975447177886963
        vf_explained_var: 0.965771496295929
        vf_loss: 19.987833817799885
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.603333333333335
    gpu_util_percent0: 0.31333333333333335
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15550605452047406
    mean_env_wait_ms: 1.1619024189710259
    mean_inference_ms: 4.851025940021453
    mean_raw_obs_processing_ms: 0.409312908629528
  time_since_restore: 234.33727955818176
  time_this_iter_s: 25.8254451751709
  time_total_s: 234.33727955818176
  timers:
    learn_throughput: 8673.326
    learn_time_ms: 18653.974
    sample_throughput: 22191.326
    sample_time_ms: 7290.777
    update_time_ms: 42.424
  timestamp: 1602511811
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |      9 |          234.337 | 1456128 |  249.879 |              301.889 |              165.677 |             845.88 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3380.900910551687
    time_step_min: 3047
  date: 2020-10-12_14-10-36
  done: false
  episode_len_mean: 840.1166226912928
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 251.08533887689546
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 300
  episodes_total: 1895
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.98941237727801
        entropy_coeff: 0.0005000000000000001
        kl: 0.009727250474194685
        model: {}
        policy_loss: -0.012255423605286827
        total_loss: 18.099432786305744
        vf_explained_var: 0.9724103808403015
        vf_loss: 18.11023743947347
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.543333333333333
    gpu_util_percent0: 0.3499999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15457911845175035
    mean_env_wait_ms: 1.1646781231971142
    mean_inference_ms: 4.793846786620028
    mean_raw_obs_processing_ms: 0.40612625596854024
  time_since_restore: 259.9123742580414
  time_this_iter_s: 25.57509469985962
  time_total_s: 259.9123742580414
  timers:
    learn_throughput: 8672.326
    learn_time_ms: 18656.125
    sample_throughput: 22339.825
    sample_time_ms: 7242.313
    update_time_ms: 41.981
  timestamp: 1602511836
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |     10 |          259.912 | 1617920 |  251.085 |              301.889 |              165.677 |            840.117 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3375.59526159921
    time_step_min: 3047
  date: 2020-10-12_14-11-02
  done: false
  episode_len_mean: 837.4615384615385
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 251.87605362288895
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 159
  episodes_total: 2054
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9606113036473592
        entropy_coeff: 0.0005000000000000001
        kl: 0.010380143610139688
        model: {}
        policy_loss: -0.014458406483754516
        total_loss: 11.629551649093628
        vf_explained_var: 0.9753599166870117
        vf_loss: 11.642414410909018
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.3
    gpu_util_percent0: 0.3463333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15416844468630067
    mean_env_wait_ms: 1.165971507129399
    mean_inference_ms: 4.768615233504089
    mean_raw_obs_processing_ms: 0.40470202556859414
  time_since_restore: 285.8492224216461
  time_this_iter_s: 25.936848163604736
  time_total_s: 285.8492224216461
  timers:
    learn_throughput: 8663.536
    learn_time_ms: 18675.054
    sample_throughput: 22963.416
    sample_time_ms: 7045.642
    update_time_ms: 41.695
  timestamp: 1602511862
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |     11 |          285.849 | 1779712 |  251.876 |              301.889 |              165.677 |            837.462 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3370.434065934066
    time_step_min: 3047
  date: 2020-10-12_14-11-28
  done: false
  episode_len_mean: 834.9773960216999
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 252.63454618517895
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9407158493995667
        entropy_coeff: 0.0005000000000000001
        kl: 0.009515416420375308
        model: {}
        policy_loss: -0.015060299386580786
        total_loss: 12.72461231549581
        vf_explained_var: 0.971533477306366
        vf_loss: 12.738239765167236
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.826666666666664
    gpu_util_percent0: 0.33566666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15379881906077505
    mean_env_wait_ms: 1.1672314292301211
    mean_inference_ms: 4.745908112118808
    mean_raw_obs_processing_ms: 0.403394736380204
  time_since_restore: 311.7340588569641
  time_this_iter_s: 25.884836435317993
  time_total_s: 311.7340588569641
  timers:
    learn_throughput: 8651.134
    learn_time_ms: 18701.825
    sample_throughput: 23223.621
    sample_time_ms: 6966.7
    update_time_ms: 36.13
  timestamp: 1602511888
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |     12 |          311.734 | 1941504 |  252.635 |              301.889 |              165.677 |            834.977 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3363.268362741075
    time_step_min: 3047
  date: 2020-10-12_14-11-54
  done: false
  episode_len_mean: 831.9367139959433
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 253.8727231749543
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 253
  episodes_total: 2465
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8869793117046356
        entropy_coeff: 0.0005000000000000001
        kl: 0.010103590476016203
        model: {}
        policy_loss: -0.012116741800127784
        total_loss: 15.375253995259603
        vf_explained_var: 0.9764304161071777
        vf_loss: 15.385793447494507
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.356666666666673
    gpu_util_percent0: 0.3863333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15327253118535442
    mean_env_wait_ms: 1.1692008289445472
    mean_inference_ms: 4.713950090208219
    mean_raw_obs_processing_ms: 0.4015630666899864
  time_since_restore: 337.41235089302063
  time_this_iter_s: 25.67829203605652
  time_total_s: 337.41235089302063
  timers:
    learn_throughput: 8650.745
    learn_time_ms: 18702.668
    sample_throughput: 23374.121
    sample_time_ms: 6921.843
    update_time_ms: 43.7
  timestamp: 1602511914
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |     13 |          337.412 | 2103296 |  253.873 |              301.889 |              165.677 |            831.937 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3358.1930748964996
    time_step_min: 3047
  date: 2020-10-12_14-12-20
  done: false
  episode_len_mean: 829.7351955307263
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 254.66474803904958
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 220
  episodes_total: 2685
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8933351288239161
        entropy_coeff: 0.0005000000000000001
        kl: 0.009528630956386527
        model: {}
        policy_loss: -0.013485383552809557
        total_loss: 12.938791195551554
        vf_explained_var: 0.9763757586479187
        vf_loss: 12.950817505518595
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.880000000000003
    gpu_util_percent0: 0.332
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15289491658472806
    mean_env_wait_ms: 1.170625213253418
    mean_inference_ms: 4.690039093401507
    mean_raw_obs_processing_ms: 0.4002131451177881
  time_since_restore: 363.29252314567566
  time_this_iter_s: 25.88017225265503
  time_total_s: 363.29252314567566
  timers:
    learn_throughput: 8633.155
    learn_time_ms: 18740.773
    sample_throughput: 23428.711
    sample_time_ms: 6905.715
    update_time_ms: 43.86
  timestamp: 1602511940
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |     14 |          363.293 | 2265088 |  254.665 |              301.889 |              165.677 |            829.735 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3354.75
    time_step_min: 3047
  date: 2020-10-12_14-12-46
  done: false
  episode_len_mean: 828.5991561181435
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 255.28130460725387
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 159
  episodes_total: 2844
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8770750214656194
        entropy_coeff: 0.0005000000000000001
        kl: 0.009454072685912251
        model: {}
        policy_loss: -0.014890211925376207
        total_loss: 11.094911495844523
        vf_explained_var: 0.9763807654380798
        vf_loss: 11.108349561691284
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.673333333333336
    gpu_util_percent0: 0.314
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333325
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15264301833141164
    mean_env_wait_ms: 1.171557346622379
    mean_inference_ms: 4.674365935187824
    mean_raw_obs_processing_ms: 0.39932520061291904
  time_since_restore: 389.01137471199036
  time_this_iter_s: 25.718851566314697
  time_total_s: 389.01137471199036
  timers:
    learn_throughput: 8634.135
    learn_time_ms: 18738.646
    sample_throughput: 23417.06
    sample_time_ms: 6909.151
    update_time_ms: 49.873
  timestamp: 1602511966
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |     15 |          389.011 | 2426880 |  255.281 |              301.889 |              165.677 |            828.599 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3351.4091367148135
    time_step_min: 3047
  date: 2020-10-12_14-13-12
  done: false
  episode_len_mean: 827.8941763727122
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 255.84623270979338
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 161
  episodes_total: 3005
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8388787458340327
        entropy_coeff: 0.0005000000000000001
        kl: 0.008798193652182817
        model: {}
        policy_loss: -0.015330687902557353
        total_loss: 10.322221120198568
        vf_explained_var: 0.9793751239776611
        vf_loss: 10.336211522420248
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.23793103448276
    gpu_util_percent0: 0.31724137931034485
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7689655172413787
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15240759807683324
    mean_env_wait_ms: 1.1724336148073986
    mean_inference_ms: 4.659780024575088
    mean_raw_obs_processing_ms: 0.3984822397657091
  time_since_restore: 414.59560990333557
  time_this_iter_s: 25.584235191345215
  time_total_s: 414.59560990333557
  timers:
    learn_throughput: 8638.706
    learn_time_ms: 18728.732
    sample_throughput: 23419.591
    sample_time_ms: 6908.404
    update_time_ms: 50.74
  timestamp: 1602511992
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |     16 |          414.596 | 2588672 |  255.846 |              301.889 |              165.677 |            827.894 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3345.956668715427
    time_step_min: 3047
  date: 2020-10-12_14-13-37
  done: false
  episode_len_mean: 826.342169408897
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 256.7268941702213
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 277
  episodes_total: 3282
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7954489588737488
        entropy_coeff: 0.0005000000000000001
        kl: 0.009277041807460288
        model: {}
        policy_loss: -0.011573745675074557
        total_loss: 12.387669245402018
        vf_explained_var: 0.9815254807472229
        vf_loss: 12.397785584131876
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.030000000000005
    gpu_util_percent0: 0.35433333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1520472770507237
    mean_env_wait_ms: 1.1738631010512635
    mean_inference_ms: 4.637114097057463
    mean_raw_obs_processing_ms: 0.39720475410331524
  time_since_restore: 440.2890133857727
  time_this_iter_s: 25.693403482437134
  time_total_s: 440.2890133857727
  timers:
    learn_throughput: 8636.928
    learn_time_ms: 18732.587
    sample_throughput: 23391.538
    sample_time_ms: 6916.689
    update_time_ms: 52.184
  timestamp: 1602512017
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |     17 |          440.289 | 2750464 |  256.727 |              301.889 |              165.677 |            826.342 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3342.633594429939
    time_step_min: 3047
  date: 2020-10-12_14-14-03
  done: false
  episode_len_mean: 825.6486330935252
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 257.1824576702274
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 193
  episodes_total: 3475
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.803479810555776
        entropy_coeff: 0.0005000000000000001
        kl: 0.008956277277320623
        model: {}
        policy_loss: -0.01159922820321905
        total_loss: 9.924300193786621
        vf_explained_var: 0.981436014175415
        vf_loss: 9.934509674708048
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.986666666666665
    gpu_util_percent0: 0.318
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7733333333333334
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1518205032672236
    mean_env_wait_ms: 1.1746844473708289
    mean_inference_ms: 4.6229375171865055
    mean_raw_obs_processing_ms: 0.39639924619071143
  time_since_restore: 465.8649387359619
  time_this_iter_s: 25.57592535018921
  time_total_s: 465.8649387359619
  timers:
    learn_throughput: 8649.226
    learn_time_ms: 18705.951
    sample_throughput: 23386.935
    sample_time_ms: 6918.051
    update_time_ms: 51.901
  timestamp: 1602512043
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |     18 |          465.865 | 2912256 |  257.182 |              301.889 |              165.677 |            825.649 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3339.781198003328
    time_step_min: 3047
  date: 2020-10-12_14-14-29
  done: false
  episode_len_mean: 825.1150247660979
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 257.567121406692
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 159
  episodes_total: 3634
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7916842351357142
        entropy_coeff: 0.0005000000000000001
        kl: 0.007591636502183974
        model: {}
        policy_loss: -0.011824032485795518
        total_loss: 10.266473849614462
        vf_explained_var: 0.978585958480835
        vf_loss: 10.277175505956015
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.493333333333336
    gpu_util_percent0: 0.3406666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1516477462873639
    mean_env_wait_ms: 1.1753254219557387
    mean_inference_ms: 4.612133832762887
    mean_raw_obs_processing_ms: 0.39579264195975034
  time_since_restore: 491.521297454834
  time_this_iter_s: 25.65635871887207
  time_total_s: 491.521297454834
  timers:
    learn_throughput: 8649.331
    learn_time_ms: 18705.725
    sample_throughput: 23446.12
    sample_time_ms: 6900.587
    update_time_ms: 51.991
  timestamp: 1602512069
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |     19 |          491.521 | 3074048 |  257.567 |              301.889 |              165.677 |            825.115 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3337.649615690432
    time_step_min: 3047
  date: 2020-10-12_14-14-55
  done: false
  episode_len_mean: 824.861089187056
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 257.9054873916752
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 167
  episodes_total: 3801
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7505128681659698
        entropy_coeff: 0.0005000000000000001
        kl: 0.009044605928162733
        model: {}
        policy_loss: -0.013028348078175137
        total_loss: 11.484949032465616
        vf_explained_var: 0.9785370230674744
        vf_loss: 11.496543884277344
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.730000000000004
    gpu_util_percent0: 0.3360000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15148396411470919
    mean_env_wait_ms: 1.1759692814343685
    mean_inference_ms: 4.601716897841987
    mean_raw_obs_processing_ms: 0.39519236051741485
  time_since_restore: 517.3095438480377
  time_this_iter_s: 25.788246393203735
  time_total_s: 517.3095438480377
  timers:
    learn_throughput: 8644.495
    learn_time_ms: 18716.189
    sample_throughput: 23416.001
    sample_time_ms: 6909.463
    update_time_ms: 52.153
  timestamp: 1602512095
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |     20 |           517.31 | 3235840 |  257.905 |              301.889 |              165.677 |            824.861 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3333.4971639950677
    time_step_min: 3047
  date: 2020-10-12_14-15-21
  done: false
  episode_len_mean: 824.0955180014695
  episode_reward_max: 301.88888888888846
  episode_reward_mean: 258.5557782082396
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 282
  episodes_total: 4083
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.720697874824206
        entropy_coeff: 0.0005000000000000001
        kl: 0.008268185541965067
        model: {}
        policy_loss: -0.011076441519738486
        total_loss: 13.213833014170328
        vf_explained_var: 0.9804973006248474
        vf_loss: 13.223615884780884
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.71
    gpu_util_percent0: 0.3299999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15121778673447292
    mean_env_wait_ms: 1.1769489651967273
    mean_inference_ms: 4.585240274221184
    mean_raw_obs_processing_ms: 0.3942759871306293
  time_since_restore: 543.0672423839569
  time_this_iter_s: 25.75769853591919
  time_total_s: 543.0672423839569
  timers:
    learn_throughput: 8656.659
    learn_time_ms: 18689.89
    sample_throughput: 23392.815
    sample_time_ms: 6916.312
    update_time_ms: 52.892
  timestamp: 1602512121
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |     21 |          543.067 | 3397632 |  258.556 |              301.889 |              165.677 |            824.096 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3330.2985603021007
    time_step_min: 3045
  date: 2020-10-12_14-15-47
  done: false
  episode_len_mean: 823.8490035169988
  episode_reward_max: 302.1919191919193
  episode_reward_mean: 259.0058735064596
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 182
  episodes_total: 4265
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7301539381345113
        entropy_coeff: 0.0005000000000000001
        kl: 0.007949572056531906
        model: {}
        policy_loss: -0.012289915311460694
        total_loss: 8.747600555419922
        vf_explained_var: 0.9833554625511169
        vf_loss: 8.758665720621744
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.756666666666668
    gpu_util_percent0: 0.3126666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1510658071817537
    mean_env_wait_ms: 1.1774985888411695
    mean_inference_ms: 4.575593249851521
    mean_raw_obs_processing_ms: 0.39373608011196193
  time_since_restore: 568.849782705307
  time_this_iter_s: 25.782540321350098
  time_total_s: 568.849782705307
  timers:
    learn_throughput: 8653.447
    learn_time_ms: 18696.828
    sample_throughput: 23456.91
    sample_time_ms: 6897.413
    update_time_ms: 53.542
  timestamp: 1602512147
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |     22 |           568.85 | 3559424 |  259.006 |              302.192 |              165.677 |            823.849 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3327.835532302093
    time_step_min: 3045
  date: 2020-10-12_14-16-12
  done: false
  episode_len_mean: 823.3917269439421
  episode_reward_max: 302.1919191919193
  episode_reward_mean: 259.38950536102425
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 159
  episodes_total: 4424
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7250782748063406
        entropy_coeff: 0.0005000000000000001
        kl: 0.008360287950684627
        model: {}
        policy_loss: -0.01233038526455251
        total_loss: 8.545097351074219
        vf_explained_var: 0.9814481735229492
        vf_loss: 8.556117932001749
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.76206896551724
    gpu_util_percent0: 0.3151724137931034
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7793103448275853
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15093929900785172
    mean_env_wait_ms: 1.1779581839699014
    mean_inference_ms: 4.5676535912217835
    mean_raw_obs_processing_ms: 0.39329636227288195
  time_since_restore: 594.3703906536102
  time_this_iter_s: 25.520607948303223
  time_total_s: 594.3703906536102
  timers:
    learn_throughput: 8655.364
    learn_time_ms: 18692.686
    sample_throughput: 23466.888
    sample_time_ms: 6894.48
    update_time_ms: 44.571
  timestamp: 1602512172
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | RUNNING  | 172.17.0.4:44079 |     23 |           594.37 | 3721216 |   259.39 |              302.192 |              165.677 |            823.392 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_13eef_00000:
  custom_metrics:
    time_step_max: 3907
    time_step_mean: 3324.979921431689
    time_step_min: 3045
  date: 2020-10-12_14-16-38
  done: true
  episode_len_mean: 822.7694143167029
  episode_reward_max: 302.1919191919193
  episode_reward_mean: 259.806130721532
  episode_reward_min: 165.67676767676747
  episodes_this_iter: 186
  episodes_total: 4610
  experiment_id: 0084b6b863c84d7895d01dcae5ecd80d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6813372472922007
        entropy_coeff: 0.0005000000000000001
        kl: 0.008548903744667768
        model: {}
        policy_loss: -0.014106738187062243
        total_loss: 9.803930679957071
        vf_explained_var: 0.9822199940681458
        vf_loss: 9.816668430964151
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.425806451612903
    gpu_util_percent0: 0.345483870967742
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 44079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15080549056771184
    mean_env_wait_ms: 1.1785198086865734
    mean_inference_ms: 4.5591267395012265
    mean_raw_obs_processing_ms: 0.39282423417507073
  time_since_restore: 620.3549063205719
  time_this_iter_s: 25.98451566696167
  time_total_s: 620.3549063205719
  timers:
    learn_throughput: 8656.557
    learn_time_ms: 18690.109
    sample_throughput: 23431.94
    sample_time_ms: 6904.763
    update_time_ms: 45.15
  timestamp: 1602512198
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 13eef_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | TERMINATED |       |     24 |          620.355 | 3883008 |  259.806 |              302.192 |              165.677 |            822.769 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.57 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_13eef_00000 | TERMINATED |       |     24 |          620.355 | 3883008 |  259.806 |              302.192 |              165.677 |            822.769 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


