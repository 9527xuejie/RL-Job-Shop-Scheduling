2020-10-12 09:31:00,668	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_a4b10_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=69901)[0m 2020-10-12 09:31:03,338	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=69783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69776)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69776)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69884)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69884)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69864)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69864)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69894)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69871)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69871)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69886)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69886)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69797)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69786)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69786)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69782)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69782)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69857)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69857)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69842)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69842)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69835)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69835)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69778)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69845)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69845)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69822)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69861)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69861)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69780)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69780)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69868)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69868)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=69875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=69875)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_09-31-37
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1823383669058483
        entropy_coeff: 0.0005000000000000001
        kl: 0.006917016425480445
        model: {}
        policy_loss: -0.009157503198366612
        total_loss: 507.07493591308594
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.741176470588236
    gpu_util_percent0: 0.27999999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5676470588235296
    vram_util_percent0: 0.08659541218914593
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1706032312810697
    mean_env_wait_ms: 1.1820741125226353
    mean_inference_ms: 5.6304426390508615
    mean_raw_obs_processing_ms: 0.4503037628475329
  time_since_restore: 28.269787549972534
  time_this_iter_s: 28.269787549972534
  time_total_s: 28.269787549972534
  timers:
    learn_throughput: 8296.701
    learn_time_ms: 19500.762
    sample_throughput: 18600.765
    sample_time_ms: 8698.137
    update_time_ms: 41.837
  timestamp: 1602495097
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 27.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      1 |          28.2698 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3614.2256944444443
    time_step_min: 3379
  date: 2020-10-12_09-32-03
  done: false
  episode_len_mean: 892.4873417721519
  episode_reward_max: 264.3535353535352
  episode_reward_mean: 217.54734049354283
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.149937113126119
        entropy_coeff: 0.0005000000000000001
        kl: 0.007523950111741821
        model: {}
        policy_loss: -0.00998671705989788
        total_loss: 126.33550771077473
        vf_explained_var: 0.8110877871513367
        vf_loss: 126.34455998738606
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.690624999999997
    gpu_util_percent0: 0.33218749999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.753125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16582102436586446
    mean_env_wait_ms: 1.1757634400756574
    mean_inference_ms: 5.40283045650808
    mean_raw_obs_processing_ms: 0.438719071797137
  time_since_restore: 54.7525577545166
  time_this_iter_s: 26.482770204544067
  time_total_s: 54.7525577545166
  timers:
    learn_throughput: 8414.328
    learn_time_ms: 19228.155
    sample_throughput: 20028.496
    sample_time_ms: 8078.09
    update_time_ms: 32.139
  timestamp: 1602495123
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      2 |          54.7526 | 323584 |  217.547 |              264.354 |              133.899 |            892.487 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3605.479820627803
    time_step_min: 3310
  date: 2020-10-12_09-32-30
  done: false
  episode_len_mean: 888.5801687763714
  episode_reward_max: 264.50505050505006
  episode_reward_mean: 219.20585602864062
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1411352157592773
        entropy_coeff: 0.0005000000000000001
        kl: 0.010440803055341044
        model: {}
        policy_loss: -0.013970387983135879
        total_loss: 54.93683338165283
        vf_explained_var: 0.8966913819313049
        vf_loss: 54.94928582509359
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.384375
    gpu_util_percent0: 0.2896875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16280803946873557
    mean_env_wait_ms: 1.1738148708567302
    mean_inference_ms: 5.235817334700198
    mean_raw_obs_processing_ms: 0.4307773715856723
  time_since_restore: 81.17681360244751
  time_this_iter_s: 26.424255847930908
  time_total_s: 81.17681360244751
  timers:
    learn_throughput: 8410.61
    learn_time_ms: 19236.655
    sample_throughput: 20871.622
    sample_time_ms: 7751.769
    update_time_ms: 28.37
  timestamp: 1602495150
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      3 |          81.1768 | 485376 |  219.206 |              264.505 |              133.899 |             888.58 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3591.1639072847684
    time_step_min: 3227
  date: 2020-10-12_09-32-56
  done: false
  episode_len_mean: 885.4873417721519
  episode_reward_max: 277.0808080808083
  episode_reward_mean: 221.420326684567
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1191200812657673
        entropy_coeff: 0.0005000000000000001
        kl: 0.011468215147033334
        model: {}
        policy_loss: -0.013862663588952273
        total_loss: 39.326786041259766
        vf_explained_var: 0.9241357445716858
        vf_loss: 39.33891359965006
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.103125
    gpu_util_percent0: 0.3578125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16076016041517052
    mean_env_wait_ms: 1.1730123640074046
    mean_inference_ms: 5.115626480000997
    mean_raw_obs_processing_ms: 0.4246610408231483
  time_since_restore: 107.39726638793945
  time_this_iter_s: 26.220452785491943
  time_total_s: 107.39726638793945
  timers:
    learn_throughput: 8444.124
    learn_time_ms: 19160.307
    sample_throughput: 21289.165
    sample_time_ms: 7599.735
    update_time_ms: 30.529
  timestamp: 1602495176
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      4 |          107.397 | 647168 |   221.42 |              277.081 |              133.899 |            885.487 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3577.469816272966
    time_step_min: 3227
  date: 2020-10-12_09-33-22
  done: false
  episode_len_mean: 882.6164556962025
  episode_reward_max: 277.0808080808083
  episode_reward_mean: 223.37348165196246
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0904998779296875
        entropy_coeff: 0.0005000000000000001
        kl: 0.010465693194419146
        model: {}
        policy_loss: -0.013936646308138734
        total_loss: 29.070746898651123
        vf_explained_var: 0.9454066157341003
        vf_loss: 29.0831356048584
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.73225806451613
    gpu_util_percent0: 0.31580645161290327
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15921377221334443
    mean_env_wait_ms: 1.1729646717527076
    mean_inference_ms: 5.0246544027543685
    mean_raw_obs_processing_ms: 0.4197779138191918
  time_since_restore: 133.44354581832886
  time_this_iter_s: 26.046279430389404
  time_total_s: 133.44354581832886
  timers:
    learn_throughput: 8460.765
    learn_time_ms: 19122.62
    sample_throughput: 21637.895
    sample_time_ms: 7477.252
    update_time_ms: 32.096
  timestamp: 1602495202
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      5 |          133.444 | 808960 |  223.373 |              277.081 |              133.899 |            882.616 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3562.2380487804876
    time_step_min: 3215
  date: 2020-10-12_09-33-48
  done: false
  episode_len_mean: 875.4055080721747
  episode_reward_max: 278.89898989898927
  episode_reward_mean: 225.90998302109395
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 263
  episodes_total: 1053
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0669801433881123
        entropy_coeff: 0.0005000000000000001
        kl: 0.010119187956055006
        model: {}
        policy_loss: -0.014624884177464992
        total_loss: 30.67037757237752
        vf_explained_var: 0.9617660641670227
        vf_loss: 30.683512210845947
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.19375
    gpu_util_percent0: 0.43093750000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15738681973338306
    mean_env_wait_ms: 1.17444902530319
    mean_inference_ms: 4.917084374849647
    mean_raw_obs_processing_ms: 0.4140822595710767
  time_since_restore: 159.70570516586304
  time_this_iter_s: 26.26215934753418
  time_total_s: 159.70570516586304
  timers:
    learn_throughput: 8454.515
    learn_time_ms: 19136.758
    sample_throughput: 21915.619
    sample_time_ms: 7382.498
    update_time_ms: 42.043
  timestamp: 1602495228
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      6 |          159.706 | 970752 |   225.91 |              278.899 |              133.899 |            875.406 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3547.7540453074434
    time_step_min: 3215
  date: 2020-10-12_09-34-15
  done: false
  episode_len_mean: 868.5514240506329
  episode_reward_max: 278.89898989898927
  episode_reward_mean: 228.15807601329732
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 211
  episodes_total: 1264
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0668786863485973
        entropy_coeff: 0.0005000000000000001
        kl: 0.012256689059237639
        model: {}
        policy_loss: -0.01610318278350557
        total_loss: 20.370780150095623
        vf_explained_var: 0.963979959487915
        vf_loss: 20.384966214497883
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.951612903225808
    gpu_util_percent0: 0.39806451612903226
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15631439565107336
    mean_env_wait_ms: 1.175829711355721
    mean_inference_ms: 4.855880701336491
    mean_raw_obs_processing_ms: 0.410889061224067
  time_since_restore: 186.14849662780762
  time_this_iter_s: 26.44279146194458
  time_total_s: 186.14849662780762
  timers:
    learn_throughput: 8449.54
    learn_time_ms: 19148.025
    sample_throughput: 22019.601
    sample_time_ms: 7347.635
    update_time_ms: 41.121
  timestamp: 1602495255
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      7 |          186.148 | 1132544 |  228.158 |              278.899 |              133.899 |            868.551 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3536.647776183644
    time_step_min: 3215
  date: 2020-10-12_09-34-41
  done: false
  episode_len_mean: 862.704641350211
  episode_reward_max: 278.89898989898927
  episode_reward_mean: 229.98016025231198
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0334690809249878
        entropy_coeff: 0.0005000000000000001
        kl: 0.010793289790550867
        model: {}
        policy_loss: -0.015747709141578525
        total_loss: 15.715624650319418
        vf_explained_var: 0.969296395778656
        vf_loss: 15.729730685551962
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.361290322580643
    gpu_util_percent0: 0.3574193548387097
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.780645161290322
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15567327988933125
    mean_env_wait_ms: 1.1770876489003141
    mean_inference_ms: 4.8179954108961445
    mean_raw_obs_processing_ms: 0.4088420134598298
  time_since_restore: 211.94712591171265
  time_this_iter_s: 25.79862928390503
  time_total_s: 211.94712591171265
  timers:
    learn_throughput: 8468.927
    learn_time_ms: 19104.192
    sample_throughput: 22175.584
    sample_time_ms: 7295.952
    update_time_ms: 38.011
  timestamp: 1602495281
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      8 |          211.947 | 1294336 |   229.98 |              278.899 |              133.899 |            862.705 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3525.568943298969
    time_step_min: 3215
  date: 2020-10-12_09-35-07
  done: false
  episode_len_mean: 857.1208860759493
  episode_reward_max: 279.3535353535359
  episode_reward_mean: 231.70662319396482
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0033017992973328
        entropy_coeff: 0.0005000000000000001
        kl: 0.010770521514738599
        model: {}
        policy_loss: -0.015525121105990062
        total_loss: 16.273523728052776
        vf_explained_var: 0.9674468040466309
        vf_loss: 16.28739635149638
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.090625000000003
    gpu_util_percent0: 0.3553125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.155116540595777
    mean_env_wait_ms: 1.1784839514372694
    mean_inference_ms: 4.784972930701284
    mean_raw_obs_processing_ms: 0.4069818494819767
  time_since_restore: 237.8651885986328
  time_this_iter_s: 25.918062686920166
  time_total_s: 237.8651885986328
  timers:
    learn_throughput: 8479.955
    learn_time_ms: 19079.347
    sample_throughput: 22292.428
    sample_time_ms: 7257.711
    update_time_ms: 36.017
  timestamp: 1602495307
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |      9 |          237.865 | 1456128 |  231.707 |              279.354 |              133.899 |            857.121 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3504.7218934911243
    time_step_min: 3186
  date: 2020-10-12_09-35-33
  done: false
  episode_len_mean: 847.3826179120297
  episode_reward_max: 284.0505050505049
  episode_reward_mean: 234.9192882722293
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 307
  episodes_total: 1887
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9698180854320526
        entropy_coeff: 0.0005000000000000001
        kl: 0.008762541770314177
        model: {}
        policy_loss: -0.011754670903125467
        total_loss: 22.15676514307658
        vf_explained_var: 0.9699413776397705
        vf_loss: 22.167253017425537
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.82258064516129
    gpu_util_percent0: 0.3303225806451613
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1542483860669258
    mean_env_wait_ms: 1.181754387642914
    mean_inference_ms: 4.73275266033599
    mean_raw_obs_processing_ms: 0.4041681313374543
  time_since_restore: 263.87894344329834
  time_this_iter_s: 26.013754844665527
  time_total_s: 263.87894344329834
  timers:
    learn_throughput: 8483.789
    learn_time_ms: 19070.725
    sample_throughput: 22393.486
    sample_time_ms: 7224.958
    update_time_ms: 35.818
  timestamp: 1602495333
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     10 |          263.879 | 1617920 |  234.919 |              284.051 |              133.899 |            847.383 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3494.990128331688
    time_step_min: 3159
  date: 2020-10-12_09-35-59
  done: false
  episode_len_mean: 842.626582278481
  episode_reward_max: 287.38383838383817
  episode_reward_mean: 236.53693212553955
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 167
  episodes_total: 2054
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.959399938583374
        entropy_coeff: 0.0005000000000000001
        kl: 0.009050344349816442
        model: {}
        policy_loss: -0.014448691198291877
        total_loss: 14.143741130828857
        vf_explained_var: 0.9704552292823792
        vf_loss: 14.156859795252482
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.72258064516129
    gpu_util_percent0: 0.3361290322580645
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15385116156127512
    mean_env_wait_ms: 1.1834246683300518
    mean_inference_ms: 4.709276635922973
    mean_raw_obs_processing_ms: 0.40286794856730274
  time_since_restore: 289.79921793937683
  time_this_iter_s: 25.92027449607849
  time_total_s: 289.79921793937683
  timers:
    learn_throughput: 8509.034
    learn_time_ms: 19014.145
    sample_throughput: 22962.238
    sample_time_ms: 7046.003
    update_time_ms: 33.835
  timestamp: 1602495359
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     11 |          289.799 | 1779712 |  236.537 |              287.384 |              133.899 |            842.627 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3486.236721611722
    time_step_min: 3147
  date: 2020-10-12_09-36-25
  done: false
  episode_len_mean: 839.50226039783
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 237.80845069136197
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9463174144426981
        entropy_coeff: 0.0005000000000000001
        kl: 0.009074758971109986
        model: {}
        policy_loss: -0.014368217787705362
        total_loss: 10.841783205668131
        vf_explained_var: 0.9763579368591309
        vf_loss: 10.854809761047363
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.564516129032253
    gpu_util_percent0: 0.30129032258064514
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903227
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15352615558692534
    mean_env_wait_ms: 1.18493950428817
    mean_inference_ms: 4.689246037556198
    mean_raw_obs_processing_ms: 0.40173597296905394
  time_since_restore: 315.95725440979004
  time_this_iter_s: 26.158036470413208
  time_total_s: 315.95725440979004
  timers:
    learn_throughput: 8496.29
    learn_time_ms: 19042.665
    sample_throughput: 23169.192
    sample_time_ms: 6983.066
    update_time_ms: 35.087
  timestamp: 1602495385
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     12 |          315.957 | 1941504 |  237.808 |              289.202 |              133.899 |            839.502 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3477.1867900715188
    time_step_min: 3147
  date: 2020-10-12_09-36-51
  done: false
  episode_len_mean: 836.276923076923
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 239.12358512358495
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 193
  episodes_total: 2405
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9069925745328268
        entropy_coeff: 0.0005000000000000001
        kl: 0.009530291194096208
        model: {}
        policy_loss: -0.014515867456793785
        total_loss: 15.319237470626831
        vf_explained_var: 0.9747470021247864
        vf_loss: 15.332300901412964
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.335483870967746
    gpu_util_percent0: 0.3419354838709677
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15318451301500233
    mean_env_wait_ms: 1.1868007730600614
    mean_inference_ms: 4.667199300470967
    mean_raw_obs_processing_ms: 0.4004844786802626
  time_since_restore: 341.68492245674133
  time_this_iter_s: 25.727668046951294
  time_total_s: 341.68492245674133
  timers:
    learn_throughput: 8515.012
    learn_time_ms: 19000.796
    sample_throughput: 23264.32
    sample_time_ms: 6954.512
    update_time_ms: 35.027
  timestamp: 1602495411
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     13 |          341.685 | 2103296 |  239.124 |              289.202 |              133.899 |            836.277 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3465.9672686230247
    time_step_min: 3147
  date: 2020-10-12_09-37-17
  done: false
  episode_len_mean: 832.3082650781831
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 240.80178553968565
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 281
  episodes_total: 2686
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9011691262324651
        entropy_coeff: 0.0005000000000000001
        kl: 0.010886709050585827
        model: {}
        policy_loss: -0.01605825025762897
        total_loss: 13.799258867899576
        vf_explained_var: 0.9779562950134277
        vf_loss: 13.813590288162231
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.28064516129032
    gpu_util_percent0: 0.3680645161290322
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15272069323343457
    mean_env_wait_ms: 1.1891189732666108
    mean_inference_ms: 4.639373399553593
    mean_raw_obs_processing_ms: 0.39890077522278816
  time_since_restore: 367.5613408088684
  time_this_iter_s: 25.876418352127075
  time_total_s: 367.5613408088684
  timers:
    learn_throughput: 8511.704
    learn_time_ms: 19008.179
    sample_throughput: 23386.097
    sample_time_ms: 6918.298
    update_time_ms: 34.621
  timestamp: 1602495437
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     14 |          367.561 | 2265088 |  240.802 |              289.202 |              133.899 |            832.308 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3459.754971590909
    time_step_min: 3147
  date: 2020-10-12_09-37-43
  done: false
  episode_len_mean: 830.3291139240506
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 241.694508374888
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8705271085103353
        entropy_coeff: 0.0005000000000000001
        kl: 0.010132285223032037
        model: {}
        policy_loss: -0.01209646585630253
        total_loss: 9.354986588160196
        vf_explained_var: 0.9806396961212158
        vf_loss: 9.36549154917399
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.243333333333336
    gpu_util_percent0: 0.378
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15249740481549917
    mean_env_wait_ms: 1.1903172938011715
    mean_inference_ms: 4.62561428432916
    mean_raw_obs_processing_ms: 0.3981163619264575
  time_since_restore: 393.3409516811371
  time_this_iter_s: 25.779610872268677
  time_total_s: 393.3409516811371
  timers:
    learn_throughput: 8515.515
    learn_time_ms: 18999.673
    sample_throughput: 23451.528
    sample_time_ms: 6898.996
    update_time_ms: 35.102
  timestamp: 1602495463
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     15 |          393.341 | 2426880 |  241.695 |              289.202 |              133.899 |            830.329 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3454.032279757902
    time_step_min: 3147
  date: 2020-10-12_09-38-09
  done: false
  episode_len_mean: 828.5073284477015
  episode_reward_max: 289.20202020202026
  episode_reward_mean: 242.50461645098542
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8471738596757253
        entropy_coeff: 0.0005000000000000001
        kl: 0.009305963292717934
        model: {}
        policy_loss: -0.01094130908313673
        total_loss: 10.646601835886637
        vf_explained_var: 0.9784726500511169
        vf_loss: 10.656105756759644
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.225
    gpu_util_percent0: 0.38656250000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15228918826336724
    mean_env_wait_ms: 1.1914508541726399
    mean_inference_ms: 4.612918529018248
    mean_raw_obs_processing_ms: 0.39737396786903656
  time_since_restore: 419.60946822166443
  time_this_iter_s: 26.268516540527344
  time_total_s: 419.60946822166443
  timers:
    learn_throughput: 8514.727
    learn_time_ms: 19001.431
    sample_throughput: 23437.658
    sample_time_ms: 6903.079
    update_time_ms: 29.57
  timestamp: 1602495489
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     16 |          419.609 | 2588672 |  242.505 |              289.202 |              133.899 |            828.507 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3446.2361408882084
    time_step_min: 3147
  date: 2020-10-12_09-38-36
  done: false
  episode_len_mean: 825.9881566960219
  episode_reward_max: 289.9595959595964
  episode_reward_mean: 243.72948433622582
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 291
  episodes_total: 3293
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8250234176715215
        entropy_coeff: 0.0005000000000000001
        kl: 0.008491925351942578
        model: {}
        policy_loss: -0.014777651784243062
        total_loss: 15.209494908650717
        vf_explained_var: 0.9786728024482727
        vf_loss: 15.222986777623495
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.845161290322586
    gpu_util_percent0: 0.30064516129032254
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15194983700517062
    mean_env_wait_ms: 1.193424276440354
    mean_inference_ms: 4.592054535507143
    mean_raw_obs_processing_ms: 0.3961640095375659
  time_since_restore: 445.8301305770874
  time_this_iter_s: 26.220662355422974
  time_total_s: 445.8301305770874
  timers:
    learn_throughput: 8516.051
    learn_time_ms: 18998.478
    sample_throughput: 23505.365
    sample_time_ms: 6883.194
    update_time_ms: 29.602
  timestamp: 1602495516
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     17 |           445.83 | 2750464 |  243.729 |               289.96 |              133.899 |            825.988 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3440.9040023201856
    time_step_min: 3098
  date: 2020-10-12_09-39-02
  done: false
  episode_len_mean: 824.563003452244
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 244.5732671943833
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 183
  episodes_total: 3476
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8241499215364456
        entropy_coeff: 0.0005000000000000001
        kl: 0.007864817045629025
        model: {}
        policy_loss: -0.01140341673938868
        total_loss: 8.79675587018331
        vf_explained_var: 0.9828992486000061
        vf_loss: 8.806998491287231
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.18387096774193
    gpu_util_percent0: 0.3493548387096774
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.787096774193548
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15175248665701024
    mean_env_wait_ms: 1.1945114475347647
    mean_inference_ms: 4.580413585929778
    mean_raw_obs_processing_ms: 0.3954965651313218
  time_since_restore: 471.92249512672424
  time_this_iter_s: 26.09236454963684
  time_total_s: 471.92249512672424
  timers:
    learn_throughput: 8507.172
    learn_time_ms: 19018.307
    sample_throughput: 23482.92
    sample_time_ms: 6889.773
    update_time_ms: 31.753
  timestamp: 1602495542
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     18 |          471.922 | 2912256 |  244.573 |              296.626 |              133.899 |            824.563 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3436.840266222962
    time_step_min: 3098
  date: 2020-10-12_09-39-28
  done: false
  episode_len_mean: 823.8428728673638
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 245.09397497262097
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8113949745893478
        entropy_coeff: 0.0005000000000000001
        kl: 0.008743428780386845
        model: {}
        policy_loss: -0.012751462903300611
        total_loss: 8.8964794476827
        vf_explained_var: 0.9816879630088806
        vf_loss: 8.907887935638428
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.784375
    gpu_util_percent0: 0.38625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.151597397235719
    mean_env_wait_ms: 1.1953715585590745
    mean_inference_ms: 4.57108739623239
    mean_raw_obs_processing_ms: 0.39495320036159126
  time_since_restore: 498.16626834869385
  time_this_iter_s: 26.243773221969604
  time_total_s: 498.16626834869385
  timers:
    learn_throughput: 8488.395
    learn_time_ms: 19060.376
    sample_throughput: 23518.539
    sample_time_ms: 6879.339
    update_time_ms: 32.878
  timestamp: 1602495568
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     19 |          498.166 | 3074048 |  245.094 |              296.626 |              133.899 |            823.843 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3432.525217850541
    time_step_min: 3098
  date: 2020-10-12_09-39-55
  done: false
  episode_len_mean: 823.0579292267365
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 245.79004990931585
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 181
  episodes_total: 3815
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7609985868136088
        entropy_coeff: 0.0005000000000000001
        kl: 0.00916624628007412
        model: {}
        policy_loss: -0.012107667707217237
        total_loss: 10.657151778539022
        vf_explained_var: 0.9814252257347107
        vf_loss: 10.66780686378479
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.46129032258065
    gpu_util_percent0: 0.29387096774193544
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903227
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15143379689100692
    mean_env_wait_ms: 1.1962897590929857
    mean_inference_ms: 4.561024131285795
    mean_raw_obs_processing_ms: 0.39436647599235486
  time_since_restore: 524.3989090919495
  time_this_iter_s: 26.232640743255615
  time_total_s: 524.3989090919495
  timers:
    learn_throughput: 8479.166
    learn_time_ms: 19081.122
    sample_throughput: 23518.349
    sample_time_ms: 6879.394
    update_time_ms: 33.453
  timestamp: 1602495595
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     20 |          524.399 | 3235840 |   245.79 |              296.626 |              133.899 |            823.058 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3425.473593711619
    time_step_min: 3098
  date: 2020-10-12_09-40-21
  done: false
  episode_len_mean: 821.8972920224445
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 246.80025184758034
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 284
  episodes_total: 4099
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7578712403774261
        entropy_coeff: 0.0005000000000000001
        kl: 0.0086368964985013
        model: {}
        policy_loss: -0.011422600480727851
        total_loss: 10.725571791330973
        vf_explained_var: 0.9839944839477539
        vf_loss: 10.735645691553751
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.603225806451615
    gpu_util_percent0: 0.35129032258064513
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15119852929530592
    mean_env_wait_ms: 1.1975670107903695
    mean_inference_ms: 4.5469503490892755
    mean_raw_obs_processing_ms: 0.3935541127176128
  time_since_restore: 550.3081252574921
  time_this_iter_s: 25.909216165542603
  time_total_s: 550.3081252574921
  timers:
    learn_throughput: 8480.142
    learn_time_ms: 19078.926
    sample_throughput: 23518.656
    sample_time_ms: 6879.305
    update_time_ms: 33.779
  timestamp: 1602495621
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     21 |          550.308 | 3397632 |    246.8 |              296.626 |              133.899 |            821.897 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3421.670599339311
    time_step_min: 3098
  date: 2020-10-12_09-40-47
  done: false
  episode_len_mean: 821.5065635255509
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 247.35105627299706
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 167
  episodes_total: 4266
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7521579414606094
        entropy_coeff: 0.0005000000000000001
        kl: 0.007824398732433716
        model: {}
        policy_loss: -0.01322558480508936
        total_loss: 7.959930698076884
        vf_explained_var: 0.9843184947967529
        vf_loss: 7.971967538197835
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.20322580645162
    gpu_util_percent0: 0.4109677419354838
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.777419354838709
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1510679868990353
    mean_env_wait_ms: 1.1982443737022626
    mean_inference_ms: 4.539386141207358
    mean_raw_obs_processing_ms: 0.3931198875982084
  time_since_restore: 576.5084743499756
  time_this_iter_s: 26.20034909248352
  time_total_s: 576.5084743499756
  timers:
    learn_throughput: 8483.554
    learn_time_ms: 19071.253
    sample_throughput: 23483.086
    sample_time_ms: 6889.725
    update_time_ms: 34.36
  timestamp: 1602495647
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | RUNNING  | 172.17.0.4:69901 |     22 |          576.508 | 3559424 |  247.351 |              296.626 |              133.899 |            821.507 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_a4b10_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3418.63762511374
    time_step_min: 3098
  date: 2020-10-12_09-41-13
  done: true
  episode_len_mean: 821.0913200723327
  episode_reward_max: 296.62626262626276
  episode_reward_mean: 247.84626098233684
  episode_reward_min: 133.89898989898964
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: 3c8f436c080648ceb1e1d86467b9e445
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.739922359585762
        entropy_coeff: 0.0005000000000000001
        kl: 0.008788479414458076
        model: {}
        policy_loss: -0.013709326779159406
        total_loss: 7.252472162246704
        vf_explained_var: 0.9847645163536072
        vf_loss: 7.264793713887532
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.375
    gpu_util_percent0: 0.43624999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 69901
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15095415633269516
    mean_env_wait_ms: 1.1988304948090098
    mean_inference_ms: 4.53258037682116
    mean_raw_obs_processing_ms: 0.3927268538387242
  time_since_restore: 602.7547671794891
  time_this_iter_s: 26.24629282951355
  time_total_s: 602.7547671794891
  timers:
    learn_throughput: 8459.796
    learn_time_ms: 19124.81
    sample_throughput: 23498.028
    sample_time_ms: 6885.344
    update_time_ms: 36.405
  timestamp: 1602495673
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: a4b10_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | TERMINATED |       |     23 |          602.755 | 3721216 |  247.846 |              296.626 |              133.899 |            821.091 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.76 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_a4b10_00000 | TERMINATED |       |     23 |          602.755 | 3721216 |  247.846 |              296.626 |              133.899 |            821.091 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


