2020-10-12 16:29:12,487	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_10a4e_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=47815)[0m 2020-10-12 16:29:15,272	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=47775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47765)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47765)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47782)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47782)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47762)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47762)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47707)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47707)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47693)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47693)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47690)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47690)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47786)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47786)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47687)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47687)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47688)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47688)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47750)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47750)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47692)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47692)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47689)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47689)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47691)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47691)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47763)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47752)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47752)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=47746)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=47746)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 3669
    time_step_mean: 3363.603448275862
    time_step_min: 3125
  date: 2020-10-12_16-29-48
  done: false
  episode_len_mean: 881.5316455696203
  episode_reward_max: 283.8080808080806
  episode_reward_mean: 244.05069684183616
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1690496106942494
        entropy_coeff: 0.009999999999999998
        kl: 0.006537978886626661
        model: {}
        policy_loss: -0.009079588286112994
        total_loss: 516.163818359375
        vf_explained_var: 0.4896630346775055
        vf_loss: 516.1832809448242
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.44117647058824
    gpu_util_percent0: 0.3417647058823529
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5647058823529414
    vram_util_percent0: 0.08636872262844136
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1630507283977757
    mean_env_wait_ms: 1.1254923827267604
    mean_inference_ms: 5.146443363176742
    mean_raw_obs_processing_ms: 0.42512076325753695
  time_since_restore: 27.797527551651
  time_this_iter_s: 27.797527551651
  time_total_s: 27.797527551651
  timers:
    learn_throughput: 8324.728
    learn_time_ms: 19435.109
    sample_throughput: 19499.226
    sample_time_ms: 8297.355
    update_time_ms: 27.463
  timestamp: 1602520188
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |      1 |          27.7975 | 161792 |  244.051 |              283.808 |              164.414 |            881.532 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3394.587591240876
    time_step_min: 3125
  date: 2020-10-12_16-30-15
  done: false
  episode_len_mean: 882.6012658227849
  episode_reward_max: 283.8080808080806
  episode_reward_mean: 240.40857946554164
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.13973867893219
        entropy_coeff: 0.009999999999999998
        kl: 0.0068835660349577665
        model: {}
        policy_loss: -0.010238737158942968
        total_loss: 144.45556640625
        vf_explained_var: 0.783456027507782
        vf_loss: 144.47582499186197
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.62424242424242
    gpu_util_percent0: 0.4090909090909091
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7484848484848485
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16012366894850708
    mean_env_wait_ms: 1.1252142733178416
    mean_inference_ms: 5.045700228270946
    mean_raw_obs_processing_ms: 0.41907214231453915
  time_since_restore: 54.51231288909912
  time_this_iter_s: 26.71478533744812
  time_total_s: 54.51231288909912
  timers:
    learn_throughput: 8389.206
    learn_time_ms: 19285.734
    sample_throughput: 20543.032
    sample_time_ms: 7875.76
    update_time_ms: 23.562
  timestamp: 1602520215
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |      2 |          54.5123 | 323584 |  240.409 |              283.808 |              142.596 |            882.601 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3396.5324074074074
    time_step_min: 3090
  date: 2020-10-12_16-30-41
  done: false
  episode_len_mean: 877.879746835443
  episode_reward_max: 286.98989898989834
  episode_reward_mean: 242.26352128883786
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1335998872915904
        entropy_coeff: 0.009999999999999998
        kl: 0.010012736233572165
        model: {}
        policy_loss: -0.013485087799684456
        total_loss: 55.908753395080566
        vf_explained_var: 0.8782846927642822
        vf_loss: 55.931569735209145
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.953125
    gpu_util_percent0: 0.4046875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7687500000000003
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15809740471507955
    mean_env_wait_ms: 1.1256685861459401
    mean_inference_ms: 4.947955181906817
    mean_raw_obs_processing_ms: 0.4139570461234445
  time_since_restore: 81.02883768081665
  time_this_iter_s: 26.51652479171753
  time_total_s: 81.02883768081665
  timers:
    learn_throughput: 8393.544
    learn_time_ms: 19275.766
    sample_throughput: 21176.182
    sample_time_ms: 7640.282
    update_time_ms: 25.407
  timestamp: 1602520241
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |      3 |          81.0288 | 485376 |  242.264 |               286.99 |              142.596 |             877.88 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3385.8322033898303
    time_step_min: 3090
  date: 2020-10-12_16-31-08
  done: false
  episode_len_mean: 872.8132911392405
  episode_reward_max: 286.98989898989834
  episode_reward_mean: 243.92483378084654
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1175300180912018
        entropy_coeff: 0.009999999999999998
        kl: 0.01007033915569385
        model: {}
        policy_loss: -0.011140253899308542
        total_loss: 41.78742631276449
        vf_explained_var: 0.9090419411659241
        vf_loss: 41.80772686004639
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.7625
    gpu_util_percent0: 0.38875000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1566319275652402
    mean_env_wait_ms: 1.1269462702654205
    mean_inference_ms: 4.870779104581972
    mean_raw_obs_processing_ms: 0.4098453994892821
  time_since_restore: 107.40938258171082
  time_this_iter_s: 26.380544900894165
  time_total_s: 107.40938258171082
  timers:
    learn_throughput: 8391.836
    learn_time_ms: 19279.691
    sample_throughput: 21617.487
    sample_time_ms: 7484.311
    update_time_ms: 25.283
  timestamp: 1602520268
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |      4 |          107.409 | 647168 |  243.925 |               286.99 |              142.596 |            872.813 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3371.477453580902
    time_step_min: 3090
  date: 2020-10-12_16-31-34
  done: false
  episode_len_mean: 866.6394472361809
  episode_reward_max: 290.92929292929307
  episode_reward_mean: 245.98887112329328
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 164
  episodes_total: 796
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0709044933319092
        entropy_coeff: 0.009999999999999998
        kl: 0.009525735086450974
        model: {}
        policy_loss: -0.012302864789186666
        total_loss: 29.769962628682453
        vf_explained_var: 0.9467154145240784
        vf_loss: 29.791069348653156
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.558064516129033
    gpu_util_percent0: 0.3538709677419355
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7548387096774185
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1554973833181102
    mean_env_wait_ms: 1.129735224767452
    mean_inference_ms: 4.807828394663946
    mean_raw_obs_processing_ms: 0.4063126768291828
  time_since_restore: 133.57743787765503
  time_this_iter_s: 26.168055295944214
  time_total_s: 133.57743787765503
  timers:
    learn_throughput: 8399.058
    learn_time_ms: 19263.112
    sample_throughput: 21960.144
    sample_time_ms: 7367.529
    update_time_ms: 24.646
  timestamp: 1602520294
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |      5 |          133.577 | 808960 |  245.989 |              290.929 |              142.596 |            866.639 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3346.6080827067667
    time_step_min: 3062
  date: 2020-10-12_16-32-00
  done: false
  episode_len_mean: 856.125678119349
  episode_reward_max: 295.7777777777781
  episode_reward_mean: 249.31358795915762
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 310
  episodes_total: 1106
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0771660109361012
        entropy_coeff: 0.009999999999999998
        kl: 0.010927017079666257
        model: {}
        policy_loss: -0.012637407460715622
        total_loss: 25.49517822265625
        vf_explained_var: 0.9562179446220398
        vf_loss: 25.516401290893555
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.63125
    gpu_util_percent0: 0.33218749999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15405981981861677
    mean_env_wait_ms: 1.134193486780489
    mean_inference_ms: 4.725522388091436
    mean_raw_obs_processing_ms: 0.40199620336715586
  time_since_restore: 159.55894136428833
  time_this_iter_s: 25.9815034866333
  time_total_s: 159.55894136428833
  timers:
    learn_throughput: 8411.781
    learn_time_ms: 19233.976
    sample_throughput: 22233.599
    sample_time_ms: 7276.915
    update_time_ms: 23.71
  timestamp: 1602520320
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |      6 |          159.559 | 970752 |  249.314 |              295.778 |              142.596 |            856.126 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3336.3199672667756
    time_step_min: 3031
  date: 2020-10-12_16-32-27
  done: false
  episode_len_mean: 851.131329113924
  episode_reward_max: 295.92929292929347
  episode_reward_mean: 250.83831191663478
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0485454301039379
        entropy_coeff: 0.009999999999999998
        kl: 0.0105852244887501
        model: {}
        policy_loss: -0.013379693807413181
        total_loss: 16.539142370224
        vf_explained_var: 0.96026611328125
        vf_loss: 16.560890515645344
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.737499999999997
    gpu_util_percent0: 0.3478125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15353530857178974
    mean_env_wait_ms: 1.1360891644576239
    mean_inference_ms: 4.694652110872158
    mean_raw_obs_processing_ms: 0.40028411394862656
  time_since_restore: 186.04953575134277
  time_this_iter_s: 26.490594387054443
  time_total_s: 186.04953575134277
  timers:
    learn_throughput: 8396.724
    learn_time_ms: 19268.467
    sample_throughput: 22385.342
    sample_time_ms: 7227.587
    update_time_ms: 25.386
  timestamp: 1602520347
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |      7 |           186.05 | 1132544 |  250.838 |              295.929 |              142.596 |            851.131 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3327.0927536231884
    time_step_min: 3031
  date: 2020-10-12_16-32-53
  done: false
  episode_len_mean: 846.570323488045
  episode_reward_max: 295.92929292929347
  episode_reward_mean: 252.02559348761892
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0363778074582417
        entropy_coeff: 0.009999999999999998
        kl: 0.009139514062553644
        model: {}
        policy_loss: -0.01353913598965543
        total_loss: 14.661792198816935
        vf_explained_var: 0.9642079472541809
        vf_loss: 14.68386697769165
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.045161290322582
    gpu_util_percent0: 0.3474193548387097
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7870967741935484
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15308379538769704
    mean_env_wait_ms: 1.1380475158101193
    mean_inference_ms: 4.66769607689209
    mean_raw_obs_processing_ms: 0.3987181564378369
  time_since_restore: 212.13341283798218
  time_this_iter_s: 26.083877086639404
  time_total_s: 212.13341283798218
  timers:
    learn_throughput: 8404.167
    learn_time_ms: 19251.402
    sample_throughput: 22521.867
    sample_time_ms: 7183.774
    update_time_ms: 25.267
  timestamp: 1602520373
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |      8 |          212.133 | 1294336 |  252.026 |              295.929 |              142.596 |             846.57 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3318.3019460138103
    time_step_min: 3031
  date: 2020-10-12_16-33-19
  done: false
  episode_len_mean: 841.3302752293578
  episode_reward_max: 295.92929292929347
  episode_reward_mean: 253.39431007320925
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 213
  episodes_total: 1635
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9824594358603159
        entropy_coeff: 0.009999999999999998
        kl: 0.00922645713823537
        model: {}
        policy_loss: -0.010944843893715491
        total_loss: 18.98201910654704
        vf_explained_var: 0.9674399495124817
        vf_loss: 19.000942707061768
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.371875
    gpu_util_percent0: 0.2621875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7687500000000003
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15256110013746094
    mean_env_wait_ms: 1.140817718437661
    mean_inference_ms: 4.636555649508435
    mean_raw_obs_processing_ms: 0.3968612991354362
  time_since_restore: 238.58922052383423
  time_this_iter_s: 26.45580768585205
  time_total_s: 238.58922052383423
  timers:
    learn_throughput: 8394.656
    learn_time_ms: 19273.214
    sample_throughput: 22617.697
    sample_time_ms: 7153.337
    update_time_ms: 27.413
  timestamp: 1602520399
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |      9 |          238.589 | 1456128 |  253.394 |              295.929 |              142.596 |             841.33 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3308.5399137001077
    time_step_min: 3031
  date: 2020-10-12_16-33-46
  done: false
  episode_len_mean: 835.5606540084389
  episode_reward_max: 295.92929292929347
  episode_reward_mean: 254.990314537783
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 261
  episodes_total: 1896
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9972058087587357
        entropy_coeff: 0.009999999999999998
        kl: 0.008113707144123813
        model: {}
        policy_loss: -0.012943075756387165
        total_loss: 13.375306288401285
        vf_explained_var: 0.9736499190330505
        vf_loss: 13.396598974863688
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.2875
    gpu_util_percent0: 0.35624999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15206380440801137
    mean_env_wait_ms: 1.1438035124414052
    mean_inference_ms: 4.60542360468494
    mean_raw_obs_processing_ms: 0.395142749839035
  time_since_restore: 264.7910785675049
  time_this_iter_s: 26.201858043670654
  time_total_s: 264.7910785675049
  timers:
    learn_throughput: 8394.398
    learn_time_ms: 19273.807
    sample_throughput: 22721.469
    sample_time_ms: 7120.666
    update_time_ms: 28.556
  timestamp: 1602520426
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |     10 |          264.791 | 1617920 |   254.99 |              295.929 |              142.596 |            835.561 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3301.852882703777
    time_step_min: 3031
  date: 2020-10-12_16-34-12
  done: false
  episode_len_mean: 832.4659201557936
  episode_reward_max: 300.777777777778
  episode_reward_mean: 255.89366400125914
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9860943704843521
        entropy_coeff: 0.009999999999999998
        kl: 0.008711384531731406
        model: {}
        policy_loss: -0.013682152261026204
        total_loss: 11.556718111038208
        vf_explained_var: 0.9712724685668945
        vf_loss: 11.578519185384115
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.390625
    gpu_util_percent0: 0.36093749999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1517984541346906
    mean_env_wait_ms: 1.1454414220888514
    mean_inference_ms: 4.589329828083987
    mean_raw_obs_processing_ms: 0.3942286068549999
  time_since_restore: 291.16782808303833
  time_this_iter_s: 26.376749515533447
  time_total_s: 291.16782808303833
  timers:
    learn_throughput: 8395.704
    learn_time_ms: 19270.808
    sample_throughput: 23203.987
    sample_time_ms: 6972.595
    update_time_ms: 34.413
  timestamp: 1602520452
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |     11 |          291.168 | 1779712 |  255.894 |              300.778 |              142.596 |            832.466 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3296.6129774505293
    time_step_min: 3002
  date: 2020-10-12_16-34-38
  done: false
  episode_len_mean: 829.3534988713318
  episode_reward_max: 300.777777777778
  episode_reward_mean: 256.64261121371743
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 161
  episodes_total: 2215
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9568662693103155
        entropy_coeff: 0.009999999999999998
        kl: 0.009676895181958875
        model: {}
        policy_loss: -0.014478526175177345
        total_loss: 13.095171531041464
        vf_explained_var: 0.9692007899284363
        vf_loss: 13.117283741633097
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.180645161290325
    gpu_util_percent0: 0.32290322580645164
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15155594634550987
    mean_env_wait_ms: 1.1471218061684796
    mean_inference_ms: 4.574418416111352
    mean_raw_obs_processing_ms: 0.39335297390272855
  time_since_restore: 317.38680148124695
  time_this_iter_s: 26.218973398208618
  time_total_s: 317.38680148124695
  timers:
    learn_throughput: 8386.696
    learn_time_ms: 19291.507
    sample_throughput: 23424.303
    sample_time_ms: 6907.014
    update_time_ms: 34.507
  timestamp: 1602520478
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |     12 |          317.387 | 1941504 |  256.643 |              300.778 |              142.596 |            829.353 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3286.2321931589536
    time_step_min: 3000
  date: 2020-10-12_16-35-05
  done: false
  episode_len_mean: 824.1547289275821
  episode_reward_max: 300.777777777778
  episode_reward_mean: 257.8743469519094
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 312
  episodes_total: 2527
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9376438011725744
        entropy_coeff: 0.009999999999999998
        kl: 0.006914937325442831
        model: {}
        policy_loss: -0.011854901444166899
        total_loss: 16.590383688608807
        vf_explained_var: 0.9739304184913635
        vf_loss: 16.61023171742757
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.45625
    gpu_util_percent0: 0.2984375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1511392781210421
    mean_env_wait_ms: 1.1502795525991434
    mean_inference_ms: 4.5493286934912645
    mean_raw_obs_processing_ms: 0.39192750587667335
  time_since_restore: 343.7030577659607
  time_this_iter_s: 26.316256284713745
  time_total_s: 343.7030577659607
  timers:
    learn_throughput: 8382.116
    learn_time_ms: 19302.048
    sample_throughput: 23531.553
    sample_time_ms: 6875.534
    update_time_ms: 35.447
  timestamp: 1602520505
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |     13 |          343.703 | 2103296 |  257.874 |              300.778 |              142.596 |            824.155 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3282.018154311649
    time_step_min: 3000
  date: 2020-10-12_16-35-31
  done: false
  episode_len_mean: 821.2725241995532
  episode_reward_max: 300.777777777778
  episode_reward_mean: 258.54916251118794
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 159
  episodes_total: 2686
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9436469227075577
        entropy_coeff: 0.009999999999999998
        kl: 0.008078638037356237
        model: {}
        policy_loss: -0.013201868258571873
        total_loss: 9.603538274765015
        vf_explained_var: 0.9758386015892029
        vf_loss: 9.624560753504435
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.421875
    gpu_util_percent0: 0.3525
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15095802883080287
    mean_env_wait_ms: 1.1517495737395893
    mean_inference_ms: 4.538468909764925
    mean_raw_obs_processing_ms: 0.3913016676679843
  time_since_restore: 370.1500036716461
  time_this_iter_s: 26.446945905685425
  time_total_s: 370.1500036716461
  timers:
    learn_throughput: 8375.181
    learn_time_ms: 19318.03
    sample_throughput: 23568.174
    sample_time_ms: 6864.851
    update_time_ms: 35.963
  timestamp: 1602520531
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |     14 |           370.15 | 2265088 |  258.549 |              300.778 |              142.596 |            821.273 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3276.692115590439
    time_step_min: 3000
  date: 2020-10-12_16-35-58
  done: false
  episode_len_mean: 818.4829525483304
  episode_reward_max: 300.777777777778
  episode_reward_mean: 259.2794553620566
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 159
  episodes_total: 2845
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9246053894360861
        entropy_coeff: 0.009999999999999998
        kl: 0.008220464068775376
        model: {}
        policy_loss: -0.012255150853889063
        total_loss: 10.887465556462606
        vf_explained_var: 0.9728255867958069
        vf_loss: 10.907322963078817
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.440624999999997
    gpu_util_percent0: 0.37875000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7718750000000005
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15078896426576335
    mean_env_wait_ms: 1.1532095323512583
    mean_inference_ms: 4.528301365218143
    mean_raw_obs_processing_ms: 0.3907043930259673
  time_since_restore: 396.44879031181335
  time_this_iter_s: 26.298786640167236
  time_total_s: 396.44879031181335
  timers:
    learn_throughput: 8372.964
    learn_time_ms: 19323.146
    sample_throughput: 23545.377
    sample_time_ms: 6871.498
    update_time_ms: 36.214
  timestamp: 1602520558
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |     15 |          396.449 | 2426880 |  259.279 |              300.778 |              142.596 |            818.483 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3268.717132754741
    time_step_min: 2965
  date: 2020-10-12_16-36-24
  done: false
  episode_len_mean: 813.7456390738979
  episode_reward_max: 305.9292929292928
  episode_reward_mean: 260.53539197877933
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 308
  episodes_total: 3153
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8848728835582733
        entropy_coeff: 0.009999999999999998
        kl: 0.0075942352414131165
        model: {}
        policy_loss: -0.01040121796540916
        total_loss: 14.06405488650004
        vf_explained_var: 0.9769622683525085
        vf_loss: 14.081785917282104
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.496774193548386
    gpu_util_percent0: 0.34161290322580645
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15049421181021175
    mean_env_wait_ms: 1.1559873089584898
    mean_inference_ms: 4.510756889487814
    mean_raw_obs_processing_ms: 0.3897146817756622
  time_since_restore: 422.5060279369354
  time_this_iter_s: 26.05723762512207
  time_total_s: 422.5060279369354
  timers:
    learn_throughput: 8373.291
    learn_time_ms: 19322.39
    sample_throughput: 23520.909
    sample_time_ms: 6878.646
    update_time_ms: 36.3
  timestamp: 1602520584
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |     16 |          422.506 | 2588672 |  260.535 |              305.929 |              142.596 |            813.746 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3264.4813797313795
    time_step_min: 2965
  date: 2020-10-12_16-36-50
  done: false
  episode_len_mean: 811.2802893309222
  episode_reward_max: 305.9292929292928
  episode_reward_mean: 261.12377847187986
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 165
  episodes_total: 3318
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8976395924886068
        entropy_coeff: 0.009999999999999998
        kl: 0.007583257237759729
        model: {}
        policy_loss: -0.011757136050922176
        total_loss: 8.53905431429545
        vf_explained_var: 0.9783466458320618
        vf_loss: 8.558271169662476
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.36875
    gpu_util_percent0: 0.3075
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15035482404189965
    mean_env_wait_ms: 1.15735418004924
    mean_inference_ms: 4.502514510454802
    mean_raw_obs_processing_ms: 0.3892434985346042
  time_since_restore: 448.6567294597626
  time_this_iter_s: 26.15070152282715
  time_total_s: 448.6567294597626
  timers:
    learn_throughput: 8384.247
    learn_time_ms: 19297.14
    sample_throughput: 23551.126
    sample_time_ms: 6869.82
    update_time_ms: 35.095
  timestamp: 1602520610
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |     17 |          448.657 | 2750464 |  261.124 |              305.929 |              142.596 |             811.28 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3261.149344978166
    time_step_min: 2965
  date: 2020-10-12_16-37-17
  done: false
  episode_len_mean: 809.3459879206213
  episode_reward_max: 305.9292929292928
  episode_reward_mean: 261.6435537427773
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 159
  episodes_total: 3477
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8854383230209351
        entropy_coeff: 0.009999999999999998
        kl: 0.007969986802587906
        model: {}
        policy_loss: -0.012435240088962018
        total_loss: 9.791815519332886
        vf_explained_var: 0.9758720993995667
        vf_loss: 9.811510880788168
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.418750000000003
    gpu_util_percent0: 0.385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7718750000000005
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15022791890073986
    mean_env_wait_ms: 1.1586385337732719
    mean_inference_ms: 4.495001851773853
    mean_raw_obs_processing_ms: 0.3888048674567565
  time_since_restore: 475.0851378440857
  time_this_iter_s: 26.42840838432312
  time_total_s: 475.0851378440857
  timers:
    learn_throughput: 8368.634
    learn_time_ms: 19333.144
    sample_throughput: 23559.556
    sample_time_ms: 6867.362
    update_time_ms: 34.717
  timestamp: 1602520637
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |     18 |          475.085 | 2912256 |  261.644 |              305.929 |              142.596 |            809.346 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3255.3602136181576
    time_step_min: 2965
  date: 2020-10-12_16-37-44
  done: false
  episode_len_mean: 805.8407710588857
  episode_reward_max: 305.9292929292928
  episode_reward_mean: 262.39255240549153
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 310
  episodes_total: 3787
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8537611414988836
        entropy_coeff: 0.009999999999999998
        kl: 0.00759998425686111
        model: {}
        policy_loss: -0.011938542632075647
        total_loss: 13.511274973551432
        vf_explained_var: 0.9786655306816101
        vf_loss: 13.530231475830078
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.68125
    gpu_util_percent0: 0.2965625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7718750000000005
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15000275300742102
    mean_env_wait_ms: 1.1610682843535103
    mean_inference_ms: 4.481673742136024
    mean_raw_obs_processing_ms: 0.3880469023557637
  time_since_restore: 501.7275619506836
  time_this_iter_s: 26.6424241065979
  time_total_s: 501.7275619506836
  timers:
    learn_throughput: 8372.676
    learn_time_ms: 19323.811
    sample_throughput: 23466.08
    sample_time_ms: 6894.718
    update_time_ms: 34.389
  timestamp: 1602520664
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |     19 |          501.728 | 3074048 |  262.393 |              305.929 |              142.596 |            805.841 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3252.656090071648
    time_step_min: 2965
  date: 2020-10-12_16-38-10
  done: false
  episode_len_mean: 804.1058227848101
  episode_reward_max: 312.29292929292967
  episode_reward_mean: 262.7498529599797
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 163
  episodes_total: 3950
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.870836133758227
        entropy_coeff: 0.009999999999999998
        kl: 0.007294694699036579
        model: {}
        policy_loss: -0.014577909799603125
        total_loss: 9.375190258026123
        vf_explained_var: 0.9764904379844666
        vf_loss: 9.39701779683431
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.471874999999997
    gpu_util_percent0: 0.3915625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14989394389975852
    mean_env_wait_ms: 1.1622610764169528
    mean_inference_ms: 4.475364412101574
    mean_raw_obs_processing_ms: 0.38768835857399886
  time_since_restore: 527.9036147594452
  time_this_iter_s: 26.176052808761597
  time_total_s: 527.9036147594452
  timers:
    learn_throughput: 8377.775
    learn_time_ms: 19312.048
    sample_throughput: 23452.204
    sample_time_ms: 6898.797
    update_time_ms: 38.619
  timestamp: 1602520690
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |     20 |          527.904 | 3235840 |   262.75 |              312.293 |              142.596 |            804.106 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3250.5444717444716
    time_step_min: 2965
  date: 2020-10-12_16-38-36
  done: false
  episode_len_mean: 802.5437743190662
  episode_reward_max: 312.29292929292967
  episode_reward_mean: 263.12968940376544
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 162
  episodes_total: 4112
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8537296801805496
        entropy_coeff: 0.009999999999999998
        kl: 0.008816904465978345
        model: {}
        policy_loss: -0.013652092044746192
        total_loss: 9.537959814071655
        vf_explained_var: 0.9765708446502686
        vf_loss: 9.558385769526163
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.521875
    gpu_util_percent0: 0.3921875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14979548818890406
    mean_env_wait_ms: 1.1634233875928515
    mean_inference_ms: 4.469447740440828
    mean_raw_obs_processing_ms: 0.3873485970464488
  time_since_restore: 554.3956997394562
  time_this_iter_s: 26.492084980010986
  time_total_s: 554.3956997394562
  timers:
    learn_throughput: 8376.171
    learn_time_ms: 19315.747
    sample_throughput: 23426.107
    sample_time_ms: 6906.483
    update_time_ms: 32.684
  timestamp: 1602520716
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |     21 |          554.396 | 3397632 |   263.13 |              312.293 |              142.596 |            802.544 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3245.4219785241035
    time_step_min: 2965
  date: 2020-10-12_16-39-03
  done: false
  episode_len_mean: 799.8522290110885
  episode_reward_max: 312.29292929292967
  episode_reward_mean: 263.803726333258
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 307
  episodes_total: 4419
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8166241745154063
        entropy_coeff: 0.009999999999999998
        kl: 0.007273945996227364
        model: {}
        policy_loss: -0.011944840254727751
        total_loss: 12.548502286275228
        vf_explained_var: 0.9790549874305725
        vf_loss: 12.567158301671347
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.396774193548385
    gpu_util_percent0: 0.34096774193548396
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1496152407917238
    mean_env_wait_ms: 1.1655387721956085
    mean_inference_ms: 4.459052652357949
    mean_raw_obs_processing_ms: 0.38676181337639165
  time_since_restore: 580.6824307441711
  time_this_iter_s: 26.286731004714966
  time_total_s: 580.6824307441711
  timers:
    learn_throughput: 8377.138
    learn_time_ms: 19313.518
    sample_throughput: 23397.491
    sample_time_ms: 6914.93
    update_time_ms: 32.477
  timestamp: 1602520743
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | RUNNING  | 172.17.0.4:47815 |     22 |          580.682 | 3559424 |  263.804 |              312.293 |              142.596 |            799.852 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_10a4e_00000:
  custom_metrics:
    time_step_max: 4043
    time_step_mean: 3243.001101321586
    time_step_min: 2965
  date: 2020-10-12_16-39-29
  done: true
  episode_len_mean: 798.5934089917067
  episode_reward_max: 312.29292929292967
  episode_reward_mean: 264.1506598062688
  episode_reward_min: 142.59595959595958
  episodes_this_iter: 163
  episodes_total: 4582
  experiment_id: d71d997fbe4a4acb8b57b9204899aac9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8493489970763525
        entropy_coeff: 0.009999999999999998
        kl: 0.0067024485518534975
        model: {}
        policy_loss: -0.013637327191342289
        total_loss: 9.538187503814697
        vf_explained_var: 0.9750792980194092
        vf_loss: 9.558977683385214
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.60625
    gpu_util_percent0: 0.3071875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 47815
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1495308665734383
    mean_env_wait_ms: 1.1665979036365997
    mean_inference_ms: 4.4540914460959815
    mean_raw_obs_processing_ms: 0.38648015829301563
  time_since_restore: 606.832136631012
  time_this_iter_s: 26.14970588684082
  time_total_s: 606.832136631012
  timers:
    learn_throughput: 8383.59
    learn_time_ms: 19298.653
    sample_throughput: 23399.357
    sample_time_ms: 6914.378
    update_time_ms: 30.914
  timestamp: 1602520769
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 10a4e_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | TERMINATED |       |     23 |          606.832 | 3721216 |  264.151 |              312.293 |              142.596 |            798.593 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_10a4e_00000 | TERMINATED |       |     23 |          606.832 | 3721216 |  264.151 |              312.293 |              142.596 |            798.593 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


