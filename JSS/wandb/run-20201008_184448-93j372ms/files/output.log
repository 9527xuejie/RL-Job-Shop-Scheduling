2020-10-08 18:44:50,444	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_59a5f_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=8406)[0m 2020-10-08 18:44:53,509	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=8404)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8404)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8394)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8394)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8412)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8412)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8424)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8424)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8310)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8310)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8363)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8363)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8283)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8283)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8286)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8286)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8282)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8282)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8401)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8401)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8369)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8369)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8409)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8409)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8370)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8370)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8375)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8375)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8276)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8276)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8358)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8358)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8305)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8305)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8383)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8430)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8430)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8290)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8290)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8298)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8298)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8280)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8280)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8393)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8393)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8295)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8295)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8342)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8342)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8353)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8353)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8284)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8284)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8273)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8377)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8377)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8288)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8288)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8281)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8281)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8271)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8274)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8274)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8389)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8389)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8355)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8355)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8349)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8349)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8422)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8422)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8359)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8359)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8435)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8435)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8350)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8350)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8364)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8364)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8348)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8348)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8277)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8277)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8366)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8366)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8365)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8365)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8272)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8272)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8315)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8315)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8373)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8373)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8308)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8308)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8374)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8374)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8344)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8344)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8397)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8397)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8279)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8279)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8362)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8362)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8346)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8346)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8367)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8367)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8343)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8343)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8339)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8339)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8360)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8360)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8352)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8352)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8356)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8356)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8405)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8405)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8301)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8301)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8278)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8278)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8361)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8361)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-08_18-45-25
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.162604773044586
        entropy_coeff: 0.0
        kl: 0.004516670596785843
        model: {}
        policy_loss: -0.0058700776193290945
        total_loss: 9.103691387176514
        vf_explained_var: 0.7204212546348572
        vf_loss: 9.108657932281494
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 37.43
    gpu_util_percent0: 0.21200000000000002
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0003333333333333333
    ram_util_percent: 9.496666666666668
    vram_util_percent0: 0.2735705695856565
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18021369208594684
    mean_env_wait_ms: 1.661212617285865
    mean_inference_ms: 6.167538025453526
    mean_raw_obs_processing_ms: 0.49149459363060555
  time_since_restore: 26.172687768936157
  time_this_iter_s: 26.172687768936157
  time_total_s: 26.172687768936157
  timers:
    learn_throughput: 10205.921
    learn_time_ms: 15852.758
    sample_throughput: 15787.092
    sample_time_ms: 10248.372
    update_time_ms: 43.294
  timestamp: 1602182725
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |      1 |          26.1727 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3259.0
  date: 2020-10-08_18-45-49
  done: false
  episode_len_mean: 870.7151898734177
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 228.08518731619975
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.133619499206543
        entropy_coeff: 0.0
        kl: 0.006721955770626664
        model: {}
        policy_loss: -0.007842451869510113
        total_loss: 9.436727619171142
        vf_explained_var: 0.8514742851257324
        vf_loss: 9.44389762878418
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.13928571428571
    gpu_util_percent0: 0.33107142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.739285714285716
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17494640970241288
    mean_env_wait_ms: 1.6560398732557255
    mean_inference_ms: 5.820230943333687
    mean_raw_obs_processing_ms: 0.47700004041808497
  time_since_restore: 50.003506660461426
  time_this_iter_s: 23.83081889152527
  time_total_s: 50.003506660461426
  timers:
    learn_throughput: 10346.25
    learn_time_ms: 15637.742
    sample_throughput: 17439.333
    sample_time_ms: 9277.419
    update_time_ms: 46.867
  timestamp: 1602182749
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |      2 |          50.0035 | 323584 |  228.085 |              273.131 |              115.788 |            870.715 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-46-13
  done: false
  episode_len_mean: 863.0822784810126
  episode_reward_max: 277.4747474747467
  episode_reward_mean: 228.3773600988789
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1250789165496826
        entropy_coeff: 0.0
        kl: 0.006636957312002778
        model: {}
        policy_loss: -0.008327771187759936
        total_loss: 11.245103454589843
        vf_explained_var: 0.9042207598686218
        vf_loss: 11.252767372131348
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.30714285714286
    gpu_util_percent0: 0.2571428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757142857142858
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1715048250046004
    mean_env_wait_ms: 1.6537253300448513
    mean_inference_ms: 5.6194019509686335
    mean_raw_obs_processing_ms: 0.4661066898859078
  time_since_restore: 74.21808862686157
  time_this_iter_s: 24.214581966400146
  time_total_s: 74.21808862686157
  timers:
    learn_throughput: 10358.706
    learn_time_ms: 15618.939
    sample_throughput: 17908.645
    sample_time_ms: 9034.296
    update_time_ms: 42.975
  timestamp: 1602182773
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |      3 |          74.2181 | 485376 |  228.377 |              277.475 |              115.788 |            863.082 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-46-37
  done: false
  episode_len_mean: 856.873417721519
  episode_reward_max: 277.4747474747467
  episode_reward_mean: 229.05995077355826
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0926247596740724
        entropy_coeff: 0.0
        kl: 0.006028243526816368
        model: {}
        policy_loss: -0.008574559073895215
        total_loss: 11.780026721954346
        vf_explained_var: 0.9307870864868164
        vf_loss: 11.787998867034911
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.99629629629629
    gpu_util_percent0: 0.3740740740740741
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1690594065684926
    mean_env_wait_ms: 1.654961494906529
    mean_inference_ms: 5.474900800115045
    mean_raw_obs_processing_ms: 0.45840715969412654
  time_since_restore: 97.88709950447083
  time_this_iter_s: 23.669010877609253
  time_total_s: 97.88709950447083
  timers:
    learn_throughput: 10398.854
    learn_time_ms: 15558.637
    sample_throughput: 18328.517
    sample_time_ms: 8827.337
    update_time_ms: 40.671
  timestamp: 1602182797
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |      4 |          97.8871 | 647168 |   229.06 |              277.475 |              115.788 |            856.873 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-47-01
  done: false
  episode_len_mean: 844.6585623678646
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 229.39009545774866
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 314
  episodes_total: 946
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0629185914993287
        entropy_coeff: 0.0
        kl: 0.006175320595502853
        model: {}
        policy_loss: -0.007956457312684507
        total_loss: 16.504242610931396
        vf_explained_var: 0.9570220708847046
        vf_loss: 16.511581230163575
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.38571428571428
    gpu_util_percent0: 0.21249999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16601201437009344
    mean_env_wait_ms: 1.6606262154043745
    mean_inference_ms: 5.292839167758187
    mean_raw_obs_processing_ms: 0.44926375151260406
  time_since_restore: 121.74446034431458
  time_this_iter_s: 23.85736083984375
  time_total_s: 121.74446034431458
  timers:
    learn_throughput: 10419.013
    learn_time_ms: 15528.534
    sample_throughput: 18524.475
    sample_time_ms: 8733.959
    update_time_ms: 39.762
  timestamp: 1602182821
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |      5 |          121.744 | 808960 |   229.39 |              282.667 |              115.788 |            844.659 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-47-25
  done: false
  episode_len_mean: 839.1003616636528
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 229.24492666264808
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 160
  episodes_total: 1106
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0421553254127502
        entropy_coeff: 0.0
        kl: 0.006036582356318832
        model: {}
        policy_loss: -0.008919728058390319
        total_loss: 8.211146640777589
        vf_explained_var: 0.9727259874343872
        vf_loss: 8.219462680816651
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.53703703703704
    gpu_util_percent0: 0.2366666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.766666666666667
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1650423417841606
    mean_env_wait_ms: 1.6635207598089863
    mean_inference_ms: 5.229904642916702
    mean_raw_obs_processing_ms: 0.4462203298969397
  time_since_restore: 145.46956825256348
  time_this_iter_s: 23.7251079082489
  time_total_s: 145.46956825256348
  timers:
    learn_throughput: 10433.211
    learn_time_ms: 15507.402
    sample_throughput: 18704.292
    sample_time_ms: 8649.993
    update_time_ms: 38.346
  timestamp: 1602182845
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |      6 |           145.47 | 970752 |  229.245 |              282.667 |              115.788 |              839.1 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-47-49
  done: false
  episode_len_mean: 835.1392405063291
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 229.79947417210064
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0217340111732482
        entropy_coeff: 0.0
        kl: 0.005584974261000753
        model: {}
        policy_loss: -0.008526842575520277
        total_loss: 7.458939266204834
        vf_explained_var: 0.9793227314949036
        vf_loss: 7.466907548904419
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.46785714285714
    gpu_util_percent0: 0.21642857142857141
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757142857142858
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1641939003745201
    mean_env_wait_ms: 1.6660100294405098
    mean_inference_ms: 5.175984586184191
    mean_raw_obs_processing_ms: 0.4435363155738743
  time_since_restore: 169.25247502326965
  time_this_iter_s: 23.782906770706177
  time_total_s: 169.25247502326965
  timers:
    learn_throughput: 10432.93
    learn_time_ms: 15507.82
    sample_throughput: 18851.246
    sample_time_ms: 8582.562
    update_time_ms: 38.895
  timestamp: 1602182869
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |      7 |          169.252 | 1132544 |  229.799 |              282.667 |              115.788 |            835.139 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-48-12
  done: false
  episode_len_mean: 831.6244725738396
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 230.59279148730616
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9723619401454926
        entropy_coeff: 0.0
        kl: 0.0053710225503891705
        model: {}
        policy_loss: -0.008861383493058383
        total_loss: 6.408520889282227
        vf_explained_var: 0.9859654307365417
        vf_loss: 6.416845035552979
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.878571428571426
    gpu_util_percent0: 0.33571428571428574
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75357142857143
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16346682636871185
    mean_env_wait_ms: 1.6685250373483573
    mean_inference_ms: 5.129298132368461
    mean_raw_obs_processing_ms: 0.44112607783898233
  time_since_restore: 192.97706413269043
  time_this_iter_s: 23.724589109420776
  time_total_s: 192.97706413269043
  timers:
    learn_throughput: 10441.332
    learn_time_ms: 15495.34
    sample_throughput: 18948.653
    sample_time_ms: 8538.443
    update_time_ms: 38.343
  timestamp: 1602182892
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |      8 |          192.977 | 1294336 |  230.593 |              282.667 |              115.788 |            831.624 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-48-36
  done: false
  episode_len_mean: 826.0034522439586
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 230.82986365379918
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 1738
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9328798651695251
        entropy_coeff: 0.0
        kl: 0.0052010877523571255
        model: {}
        policy_loss: -0.007984791428316384
        total_loss: 7.61081829071045
        vf_explained_var: 0.9887510538101196
        vf_loss: 7.618283033370972
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.8
    gpu_util_percent0: 0.3222222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1623345125192884
    mean_env_wait_ms: 1.6734334001546654
    mean_inference_ms: 5.055230301831034
    mean_raw_obs_processing_ms: 0.43735093240104206
  time_since_restore: 216.75329446792603
  time_this_iter_s: 23.776230335235596
  time_total_s: 216.75329446792603
  timers:
    learn_throughput: 10448.708
    learn_time_ms: 15484.403
    sample_throughput: 19014.701
    sample_time_ms: 8508.785
    update_time_ms: 39.529
  timestamp: 1602182916
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |      9 |          216.753 | 1456128 |   230.83 |              282.667 |              115.788 |            826.003 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-49-00
  done: false
  episode_len_mean: 823.6181434599156
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 230.96584516046536
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8965197086334229
        entropy_coeff: 0.0
        kl: 0.004859194625169039
        model: {}
        policy_loss: -0.0080272980267182
        total_loss: 4.399553680419922
        vf_explained_var: 0.9910664558410645
        vf_loss: 4.407094955444336
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.76428571428571
    gpu_util_percent0: 0.2775
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.760714285714286
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16186501241660273
    mean_env_wait_ms: 1.6755872477537024
    mean_inference_ms: 5.025282498824276
    mean_raw_obs_processing_ms: 0.43583804835697443
  time_since_restore: 240.48160672187805
  time_this_iter_s: 23.728312253952026
  time_total_s: 240.48160672187805
  timers:
    learn_throughput: 10453.814
    learn_time_ms: 15476.839
    sample_throughput: 19090.285
    sample_time_ms: 8475.096
    update_time_ms: 44.076
  timestamp: 1602182940
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     10 |          240.482 | 1617920 |  230.966 |              282.667 |              115.788 |            823.618 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-49-24
  done: false
  episode_len_mean: 821.1222005842259
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 231.06628111691398
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.8697240889072418
        entropy_coeff: 0.0
        kl: 0.004608499351888895
        model: {}
        policy_loss: -0.00776460135821253
        total_loss: 4.025474977493286
        vf_explained_var: 0.9918241500854492
        vf_loss: 4.033009123802185
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.6037037037037
    gpu_util_percent0: 0.27222222222222225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.774074074074074
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16144539249375348
    mean_env_wait_ms: 1.677802612224073
    mean_inference_ms: 4.998356905951212
    mean_raw_obs_processing_ms: 0.434472713072529
  time_since_restore: 264.4220962524414
  time_this_iter_s: 23.940489530563354
  time_total_s: 264.4220962524414
  timers:
    learn_throughput: 10458.381
    learn_time_ms: 15470.081
    sample_throughput: 19596.22
    sample_time_ms: 8256.286
    update_time_ms: 42.275
  timestamp: 1602182964
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     11 |          264.422 | 1779712 |  231.066 |              282.667 |              115.788 |            821.122 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-49-48
  done: false
  episode_len_mean: 817.6928999144568
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 231.01841338967085
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 284
  episodes_total: 2338
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 5.0e-05
        entropy: 0.8293383002281189
        entropy_coeff: 0.0
        kl: 0.00481296400539577
        model: {}
        policy_loss: -0.006679334840737283
        total_loss: 5.560741901397705
        vf_explained_var: 0.9927679896354675
        vf_loss: 5.567300844192505
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.9
    gpu_util_percent0: 0.2782142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.750000000000002
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16079885747998543
    mean_env_wait_ms: 1.68175431175494
    mean_inference_ms: 4.95669314197755
    mean_raw_obs_processing_ms: 0.4323601365853747
  time_since_restore: 288.53681778907776
  time_this_iter_s: 24.114721536636353
  time_total_s: 288.53681778907776
  timers:
    learn_throughput: 10452.038
    learn_time_ms: 15479.47
    sample_throughput: 19548.766
    sample_time_ms: 8276.328
    update_time_ms: 40.628
  timestamp: 1602182988
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     12 |          288.537 | 1941504 |  231.018 |              282.667 |              115.788 |            817.693 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-50-12
  done: false
  episode_len_mean: 816.3030063291139
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 231.0481036632144
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 190
  episodes_total: 2528
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 5.0e-05
        entropy: 0.7928448736667633
        entropy_coeff: 0.0
        kl: 0.004472650634124875
        model: {}
        policy_loss: -0.007085395837202668
        total_loss: 3.8891869306564333
        vf_explained_var: 0.9931631088256836
        vf_loss: 3.8962164163589477
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.15714285714286
    gpu_util_percent0: 0.3425000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.750000000000002
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1604274687577018
    mean_env_wait_ms: 1.6840836875313414
    mean_inference_ms: 4.932856990233122
    mean_raw_obs_processing_ms: 0.43115150819725534
  time_since_restore: 312.1729428768158
  time_this_iter_s: 23.636125087738037
  time_total_s: 312.1729428768158
  timers:
    learn_throughput: 10462.404
    learn_time_ms: 15464.132
    sample_throughput: 19656.197
    sample_time_ms: 8231.094
    update_time_ms: 41.212
  timestamp: 1602183012
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     13 |          312.173 | 2103296 |  231.048 |              282.667 |              115.788 |            816.303 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-50-36
  done: false
  episode_len_mean: 815.4724497393894
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 231.18262295328563
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00625
        cur_lr: 5.0e-05
        entropy: 0.7857854962348938
        entropy_coeff: 0.0
        kl: 0.004049231857061386
        model: {}
        policy_loss: -0.00699720666743815
        total_loss: 3.257110261917114
        vf_explained_var: 0.9939436912536621
        vf_loss: 3.2640822649002077
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.94814814814814
    gpu_util_percent0: 0.3851851851851852
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.755555555555556
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16014889214692257
    mean_env_wait_ms: 1.6859139955826217
    mean_inference_ms: 4.914784841631009
    mean_raw_obs_processing_ms: 0.43023367393983003
  time_since_restore: 336.07583594322205
  time_this_iter_s: 23.90289306640625
  time_total_s: 336.07583594322205
  timers:
    learn_throughput: 10452.91
    learn_time_ms: 15478.178
    sample_throughput: 19634.778
    sample_time_ms: 8240.073
    update_time_ms: 40.75
  timestamp: 1602183036
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     14 |          336.076 | 2265088 |  231.183 |              282.667 |              115.788 |            815.472 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-51-00
  done: false
  episode_len_mean: 814.732770745429
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 231.29309267072978
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.003125
        cur_lr: 5.0e-05
        entropy: 0.7728670954704284
        entropy_coeff: 0.0
        kl: 0.004302041092887521
        model: {}
        policy_loss: -0.0069694613805040715
        total_loss: 3.1524629831314086
        vf_explained_var: 0.9944815635681152
        vf_loss: 3.1594190120697023
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.135714285714286
    gpu_util_percent0: 0.2925
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757142857142858
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15989219181483574
    mean_env_wait_ms: 1.6876667970564099
    mean_inference_ms: 4.8980241639738376
    mean_raw_obs_processing_ms: 0.42936042529553226
  time_since_restore: 359.80808115005493
  time_this_iter_s: 23.732245206832886
  time_total_s: 359.80808115005493
  timers:
    learn_throughput: 10453.335
    learn_time_ms: 15477.549
    sample_throughput: 19681.128
    sample_time_ms: 8220.667
    update_time_ms: 46.554
  timestamp: 1602183060
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     15 |          359.808 | 2426880 |  231.293 |              282.667 |              115.788 |            814.733 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-51-24
  done: false
  episode_len_mean: 813.6746835443038
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 231.7703107019563
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 3160
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625
        cur_lr: 5.0e-05
        entropy: 0.7282491087913513
        entropy_coeff: 0.0
        kl: 0.004006940103136003
        model: {}
        policy_loss: -0.006194116664119065
        total_loss: 4.220283102989197
        vf_explained_var: 0.9942509531974792
        vf_loss: 4.226470971107483
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.60370370370371
    gpu_util_percent0: 0.31629629629629635
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.744444444444445
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15943912963545015
    mean_env_wait_ms: 1.6908239972825827
    mean_inference_ms: 4.868411406475346
    mean_raw_obs_processing_ms: 0.42784934365249994
  time_since_restore: 383.78414511680603
  time_this_iter_s: 23.9760639667511
  time_total_s: 383.78414511680603
  timers:
    learn_throughput: 10447.397
    learn_time_ms: 15486.346
    sample_throughput: 19642.095
    sample_time_ms: 8237.003
    update_time_ms: 45.973
  timestamp: 1602183084
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     16 |          383.784 | 2588672 |   231.77 |              282.667 |              115.788 |            813.675 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-51-48
  done: false
  episode_len_mean: 813.1286919831224
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 231.98536297270476
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00078125
        cur_lr: 5.0e-05
        entropy: 0.7059951186180115
        entropy_coeff: 0.0
        kl: 0.004128427291288972
        model: {}
        policy_loss: -0.007019754522480071
        total_loss: 2.592034339904785
        vf_explained_var: 0.9950480461120605
        vf_loss: 2.5990509271621702
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.05357142857142
    gpu_util_percent0: 0.2671428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771428571428572
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1592390853047136
    mean_env_wait_ms: 1.6922610916434453
    mean_inference_ms: 4.855254097261909
    mean_raw_obs_processing_ms: 0.42718669248787844
  time_since_restore: 407.35459542274475
  time_this_iter_s: 23.57045030593872
  time_total_s: 407.35459542274475
  timers:
    learn_throughput: 10455.773
    learn_time_ms: 15473.94
    sample_throughput: 19665.002
    sample_time_ms: 8227.408
    update_time_ms: 45.771
  timestamp: 1602183108
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     17 |          407.355 | 2750464 |  231.985 |              282.667 |              115.788 |            813.129 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-52-12
  done: false
  episode_len_mean: 812.4220368239355
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 232.36563273703666
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.000390625
        cur_lr: 5.0e-05
        entropy: 0.7134746849536896
        entropy_coeff: 0.0
        kl: 0.0039050673833116887
        model: {}
        policy_loss: -0.007149371964624151
        total_loss: 2.5212162733078003
        vf_explained_var: 0.9944831132888794
        vf_loss: 2.528364109992981
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.40740740740741
    gpu_util_percent0: 0.21592592592592597
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75925925925926
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1590519166832582
    mean_env_wait_ms: 1.6936630169033324
    mean_inference_ms: 4.842905355214283
    mean_raw_obs_processing_ms: 0.42656575612856706
  time_since_restore: 431.03079557418823
  time_this_iter_s: 23.67620015144348
  time_total_s: 431.03079557418823
  timers:
    learn_throughput: 10456.511
    learn_time_ms: 15472.847
    sample_throughput: 19677.184
    sample_time_ms: 8222.315
    update_time_ms: 46.043
  timestamp: 1602183132
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     18 |          431.031 | 2912256 |  232.366 |              282.667 |              115.788 |            812.422 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-52-36
  done: false
  episode_len_mean: 811.5857956085661
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 232.8110489552615
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 213
  episodes_total: 3689
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0001953125
        cur_lr: 5.0e-05
        entropy: 0.6919934034347535
        entropy_coeff: 0.0
        kl: 0.003743902035057545
        model: {}
        policy_loss: -0.006390705110970884
        total_loss: 3.0629483699798583
        vf_explained_var: 0.9949660301208496
        vf_loss: 3.069338393211365
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.5037037037037
    gpu_util_percent0: 0.412962962962963
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1588299265320732
    mean_env_wait_ms: 1.6955482095298728
    mean_inference_ms: 4.827875250570668
    mean_raw_obs_processing_ms: 0.4258412927032234
  time_since_restore: 454.6350314617157
  time_this_iter_s: 23.604235887527466
  time_total_s: 454.6350314617157
  timers:
    learn_throughput: 10462.027
    learn_time_ms: 15464.689
    sample_throughput: 19692.243
    sample_time_ms: 8216.027
    update_time_ms: 42.888
  timestamp: 1602183156
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     19 |          454.635 | 3074048 |  232.811 |              282.667 |              115.788 |            811.586 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-52-59
  done: false
  episode_len_mean: 810.6050632911392
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 233.40153688786597
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 261
  episodes_total: 3950
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625e-05
        cur_lr: 5.0e-05
        entropy: 0.644848358631134
        entropy_coeff: 0.0
        kl: 0.0032707267440855504
        model: {}
        policy_loss: -0.005984434648416937
        total_loss: 2.995966100692749
        vf_explained_var: 0.9943197965621948
        vf_loss: 3.001950263977051
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.51785714285714
    gpu_util_percent0: 0.32071428571428573
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.750000000000002
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15856079684938035
    mean_env_wait_ms: 1.697572984599497
    mean_inference_ms: 4.810412852034201
    mean_raw_obs_processing_ms: 0.4249825115273482
  time_since_restore: 478.4054114818573
  time_this_iter_s: 23.7703800201416
  time_total_s: 478.4054114818573
  timers:
    learn_throughput: 10453.564
    learn_time_ms: 15477.209
    sample_throughput: 19701.466
    sample_time_ms: 8212.181
    update_time_ms: 38.268
  timestamp: 1602183179
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     20 |          478.405 | 3235840 |  233.402 |              282.667 |              115.788 |            810.605 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-53-23
  done: false
  episode_len_mean: 809.9033592989289
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 233.8510617371377
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4108
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.8828125e-05
        cur_lr: 5.0e-05
        entropy: 0.6544105768203735
        entropy_coeff: 0.0
        kl: 0.003931975481100381
        model: {}
        policy_loss: -0.006711094384081661
        total_loss: 2.2320109605789185
        vf_explained_var: 0.9947303533554077
        vf_loss: 2.2387218713760375
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.129629629629626
    gpu_util_percent0: 0.3014814814814815
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.759259259259261
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15841546676255663
    mean_env_wait_ms: 1.6987539363226858
    mean_inference_ms: 4.8009183804192075
    mean_raw_obs_processing_ms: 0.42452312933140335
  time_since_restore: 502.1364016532898
  time_this_iter_s: 23.730990171432495
  time_total_s: 502.1364016532898
  timers:
    learn_throughput: 10478.015
    learn_time_ms: 15441.092
    sample_throughput: 19663.527
    sample_time_ms: 8228.025
    update_time_ms: 37.801
  timestamp: 1602183203
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     21 |          502.136 | 3397632 |  233.851 |              282.667 |              115.788 |            809.903 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-53-47
  done: false
  episode_len_mean: 809.0105361741981
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 234.26820062010884
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 163
  episodes_total: 4271
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.44140625e-05
        cur_lr: 5.0e-05
        entropy: 0.6465409457683563
        entropy_coeff: 0.0
        kl: 0.003628892661072314
        model: {}
        policy_loss: -0.006876937462948263
        total_loss: 2.291933846473694
        vf_explained_var: 0.9948194622993469
        vf_loss: 2.2988106489181517
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.18928571428571
    gpu_util_percent0: 0.3289285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757142857142858
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15827436062582967
    mean_env_wait_ms: 1.6999772939563607
    mean_inference_ms: 4.791645355308221
    mean_raw_obs_processing_ms: 0.4240693132216104
  time_since_restore: 526.0484850406647
  time_this_iter_s: 23.912083387374878
  time_total_s: 526.0484850406647
  timers:
    learn_throughput: 10473.825
    learn_time_ms: 15447.27
    sample_throughput: 19730.475
    sample_time_ms: 8200.107
    update_time_ms: 38.166
  timestamp: 1602183227
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     22 |          526.048 | 3559424 |  234.268 |              282.667 |              115.788 |            809.011 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-54-11
  done: false
  episode_len_mean: 807.4183762549105
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 235.0165227129435
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 311
  episodes_total: 4582
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.220703125e-05
        cur_lr: 5.0e-05
        entropy: 0.6001478612422944
        entropy_coeff: 0.0
        kl: 0.0032223164103925227
        model: {}
        policy_loss: -0.005369638348929584
        total_loss: 3.248713183403015
        vf_explained_var: 0.994478702545166
        vf_loss: 3.2540828227996825
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.48148148148148
    gpu_util_percent0: 0.22407407407407406
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.74814814814815
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.158025909394538
    mean_env_wait_ms: 1.7021793619112338
    mean_inference_ms: 4.775375058524639
    mean_raw_obs_processing_ms: 0.4232785586119898
  time_since_restore: 549.873411655426
  time_this_iter_s: 23.824926614761353
  time_total_s: 549.873411655426
  timers:
    learn_throughput: 10463.803
    learn_time_ms: 15462.065
    sample_throughput: 19720.226
    sample_time_ms: 8204.368
    update_time_ms: 37.973
  timestamp: 1602183251
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     23 |          549.873 | 3721216 |  235.017 |              282.667 |              115.788 |            807.418 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-54-36
  done: false
  episode_len_mean: 806.5708860759494
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 235.53171589310833
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4740
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 6.103515625e-06
        cur_lr: 5.0e-05
        entropy: 0.5934881210327149
        entropy_coeff: 0.0
        kl: 0.0031419464852660895
        model: {}
        policy_loss: -0.007150630780961365
        total_loss: 1.7831284403800964
        vf_explained_var: 0.9954637289047241
        vf_loss: 1.7902790546417235
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.93928571428571
    gpu_util_percent0: 0.2307142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757142857142858
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15790850288621608
    mean_env_wait_ms: 1.7032341631101033
    mean_inference_ms: 4.767748563445677
    mean_raw_obs_processing_ms: 0.42291100812392474
  time_since_restore: 574.0785098075867
  time_this_iter_s: 24.205098152160645
  time_total_s: 574.0785098075867
  timers:
    learn_throughput: 10459.46
    learn_time_ms: 15468.485
    sample_throughput: 19670.96
    sample_time_ms: 8224.916
    update_time_ms: 38.801
  timestamp: 1602183276
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     24 |          574.079 | 3883008 |  235.532 |              282.667 |              115.788 |            806.571 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-55-00
  done: false
  episode_len_mean: 805.6915067374439
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 235.98718916399602
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4898
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.0517578125e-06
        cur_lr: 5.0e-05
        entropy: 0.6077215075492859
        entropy_coeff: 0.0
        kl: 0.0033059438224881887
        model: {}
        policy_loss: -0.006542587210424245
        total_loss: 1.8678565502166748
        vf_explained_var: 0.9949802160263062
        vf_loss: 1.8743991613388062
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.12222222222223
    gpu_util_percent0: 0.21777777777777782
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.762962962962964
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15779517963189904
    mean_env_wait_ms: 1.7042889680307758
    mean_inference_ms: 4.760458529019579
    mean_raw_obs_processing_ms: 0.42255007616530105
  time_since_restore: 597.930855512619
  time_this_iter_s: 23.85234570503235
  time_total_s: 597.930855512619
  timers:
    learn_throughput: 10452.521
    learn_time_ms: 15478.754
    sample_throughput: 19652.728
    sample_time_ms: 8232.547
    update_time_ms: 32.596
  timestamp: 1602183300
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | RUNNING  | 172.17.0.4:8406 |     25 |          597.931 | 4044800 |  235.987 |              282.667 |              115.788 |            805.692 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_59a5f_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3206.0
  date: 2020-10-08_18-55-24
  done: true
  episode_len_mean: 803.9376199616123
  episode_reward_max: 282.6666666666664
  episode_reward_mean: 236.78976327575177
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 312
  episodes_total: 5210
  experiment_id: 088d18cbd5d54fc0955cf3dd78ce300a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.52587890625e-06
        cur_lr: 5.0e-05
        entropy: 0.5648847818374634
        entropy_coeff: 0.0
        kl: 0.0029501104261726143
        model: {}
        policy_loss: -0.0050168613670393825
        total_loss: 2.9548171520233155
        vf_explained_var: 0.9947786331176758
        vf_loss: 2.959834027290344
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.39259259259259
    gpu_util_percent0: 0.26481481481481484
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.29673663496228275
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8406
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15758722507210374
    mean_env_wait_ms: 1.706332851353458
    mean_inference_ms: 4.74712200941494
    mean_raw_obs_processing_ms: 0.4218893350431027
  time_since_restore: 621.6566300392151
  time_this_iter_s: 23.72577452659607
  time_total_s: 621.6566300392151
  timers:
    learn_throughput: 10453.485
    learn_time_ms: 15477.327
    sample_throughput: 19715.413
    sample_time_ms: 8206.371
    update_time_ms: 34.494
  timestamp: 1602183324
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: 59a5f_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | TERMINATED |       |     26 |          621.657 | 4206592 |   236.79 |              282.667 |              115.788 |            803.938 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_59a5f_00000 | TERMINATED |       |     26 |          621.657 | 4206592 |   236.79 |              282.667 |              115.788 |            803.938 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


