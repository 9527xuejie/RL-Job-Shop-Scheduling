2020-10-12 01:48:55,989	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_1784b_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=17998)[0m 2020-10-12 01:48:58,743	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=18002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17977)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17977)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17973)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17973)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17959)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17959)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17979)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17979)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17972)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17972)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17957)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17957)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17948)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17948)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17943)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17943)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17955)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17955)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17894)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17964)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17964)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17939)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17939)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17886)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17886)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17906)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17906)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17912)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17912)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17901)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17901)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17976)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17976)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17932)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17932)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17956)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17956)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17969)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17969)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17929)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17946)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17946)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17874)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17874)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17935)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17935)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17941)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17941)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17966)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17966)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17908)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17908)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17928)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17928)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17937)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17937)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17997)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17997)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17952)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17952)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17877)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_01-49-35
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.181063751379649
        entropy_coeff: 0.0001
        kl: 0.008582662092521787
        model: {}
        policy_loss: -0.01231548492796719
        total_loss: 502.2360153198242
        vf_explained_var: 0.5664147734642029
        vf_loss: 502.24672444661456
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.10810810810811
    gpu_util_percent0: 0.37189189189189187
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5783783783783787
    vram_util_percent0: 0.08782897361119732
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16705749726067284
    mean_env_wait_ms: 1.1590561891787212
    mean_inference_ms: 5.757315636564456
    mean_raw_obs_processing_ms: 0.44845545133641934
  time_since_restore: 31.772277355194092
  time_this_iter_s: 31.772277355194092
  time_total_s: 31.772277355194092
  timers:
    learn_throughput: 7223.356
    learn_time_ms: 22398.454
    sample_throughput: 17384.648
    sample_time_ms: 9306.602
    update_time_ms: 25.654
  timestamp: 1602467375
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |      1 |          31.7723 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3620.6180555555557
    time_step_min: 3364
  date: 2020-10-12_01-50-05
  done: false
  episode_len_mean: 890.3227848101266
  episode_reward_max: 271.7777777777777
  episode_reward_mean: 215.69655414908556
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1495005985101063
        entropy_coeff: 0.0001
        kl: 0.010878701927140355
        model: {}
        policy_loss: -0.013066152964408198
        total_loss: 124.57837740580241
        vf_explained_var: 0.8186244368553162
        vf_loss: 124.58938217163086
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.594285714285714
    gpu_util_percent0: 0.32685714285714285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.757142857142857
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16325800208982028
    mean_env_wait_ms: 1.157577139480018
    mean_inference_ms: 5.515507766622012
    mean_raw_obs_processing_ms: 0.43787283131748006
  time_since_restore: 61.68302774429321
  time_this_iter_s: 29.91075038909912
  time_total_s: 61.68302774429321
  timers:
    learn_throughput: 7257.536
    learn_time_ms: 22292.965
    sample_throughput: 19074.406
    sample_time_ms: 8482.152
    update_time_ms: 21.94
  timestamp: 1602467405
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |      2 |           61.683 | 323584 |  215.697 |              271.778 |              145.717 |            890.323 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3615.6233183856502
    time_step_min: 3311
  date: 2020-10-12_01-50-35
  done: false
  episode_len_mean: 886.5970464135021
  episode_reward_max: 272.2323232323231
  episode_reward_mean: 217.45544048075675
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1387817859649658
        entropy_coeff: 0.0001
        kl: 0.011558178424214324
        model: {}
        policy_loss: -0.017452113650506362
        total_loss: 53.645773569742836
        vf_explained_var: 0.9055226445198059
        vf_loss: 53.66102854410807
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.934285714285714
    gpu_util_percent0: 0.34714285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7685714285714287
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16063218519469077
    mean_env_wait_ms: 1.158020017036114
    mean_inference_ms: 5.33112621615318
    mean_raw_obs_processing_ms: 0.43016729799301495
  time_since_restore: 91.41437840461731
  time_this_iter_s: 29.731350660324097
  time_total_s: 91.41437840461731
  timers:
    learn_throughput: 7233.636
    learn_time_ms: 22366.623
    sample_throughput: 20135.269
    sample_time_ms: 8035.254
    update_time_ms: 21.423
  timestamp: 1602467435
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |      3 |          91.4144 | 485376 |  217.455 |              272.232 |              129.808 |            886.597 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3609.8311258278145
    time_step_min: 3274
  date: 2020-10-12_01-51-05
  done: false
  episode_len_mean: 884.3259493670886
  episode_reward_max: 272.2323232323231
  episode_reward_mean: 219.2183224651577
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1121165851751964
        entropy_coeff: 0.0001
        kl: 0.013690063419441382
        model: {}
        policy_loss: -0.01847186917439103
        total_loss: 36.848310788472496
        vf_explained_var: 0.9346179366111755
        vf_loss: 36.86415481567383
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.694117647058825
    gpu_util_percent0: 0.4111764705882353
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7676470588235293
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15880041957847973
    mean_env_wait_ms: 1.1584672204751685
    mean_inference_ms: 5.198767786043385
    mean_raw_obs_processing_ms: 0.42427587810068684
  time_since_restore: 120.92481994628906
  time_this_iter_s: 29.510441541671753
  time_total_s: 120.92481994628906
  timers:
    learn_throughput: 7239.787
    learn_time_ms: 22347.618
    sample_throughput: 20707.192
    sample_time_ms: 7813.324
    update_time_ms: 21.634
  timestamp: 1602467465
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |      4 |          120.925 | 647168 |  219.218 |              272.232 |              129.808 |            884.326 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3601.267716535433
    time_step_min: 3274
  date: 2020-10-12_01-51-34
  done: false
  episode_len_mean: 880.9101265822785
  episode_reward_max: 272.2323232323231
  episode_reward_mean: 220.9741721007542
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.080670307079951
        entropy_coeff: 0.0001
        kl: 0.013236191511775056
        model: {}
        policy_loss: -0.015959160402417183
        total_loss: 27.142932573954266
        vf_explained_var: 0.9514850974082947
        vf_loss: 27.156352519989014
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.134285714285713
    gpu_util_percent0: 0.39685714285714296
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15743831889989926
    mean_env_wait_ms: 1.1594320422930795
    mean_inference_ms: 5.098182366805911
    mean_raw_obs_processing_ms: 0.4195055241219639
  time_since_restore: 150.17120051383972
  time_this_iter_s: 29.24638056755066
  time_total_s: 150.17120051383972
  timers:
    learn_throughput: 7254.594
    learn_time_ms: 22302.007
    sample_throughput: 21160.911
    sample_time_ms: 7645.796
    update_time_ms: 23.734
  timestamp: 1602467494
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |      5 |          150.171 | 808960 |  220.974 |              272.232 |              129.808 |             880.91 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3585.995215311005
    time_step_min: 3274
  date: 2020-10-12_01-52-03
  done: false
  episode_len_mean: 873.3867660764213
  episode_reward_max: 272.2323232323231
  episode_reward_mean: 223.0619145791558
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 283
  episodes_total: 1073
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0606468419233959
        entropy_coeff: 0.0001
        kl: 0.01029104832559824
        model: {}
        policy_loss: -0.014472326807056865
        total_loss: 32.89865446090698
        vf_explained_var: 0.9632778763771057
        vf_loss: 32.91117413838705
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.576470588235296
    gpu_util_percent0: 0.3497058823529412
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647054
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1557362693610383
    mean_env_wait_ms: 1.1621454251109906
    mean_inference_ms: 4.972432282498686
    mean_raw_obs_processing_ms: 0.41364164125642655
  time_since_restore: 179.3893871307373
  time_this_iter_s: 29.218186616897583
  time_total_s: 179.3893871307373
  timers:
    learn_throughput: 7263.195
    learn_time_ms: 22275.597
    sample_throughput: 21460.31
    sample_time_ms: 7539.127
    update_time_ms: 23.465
  timestamp: 1602467523
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |      6 |          179.389 | 970752 |  223.062 |              272.232 |              129.808 |            873.387 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3573.5784789644013
    time_step_min: 3268
  date: 2020-10-12_01-52-33
  done: false
  episode_len_mean: 868.2650316455696
  episode_reward_max: 272.2323232323231
  episode_reward_mean: 224.94221487022105
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 191
  episodes_total: 1264
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0628973344961803
        entropy_coeff: 0.0001
        kl: 0.012892291027431687
        model: {}
        policy_loss: -0.016782884097968537
        total_loss: 18.92563517888387
        vf_explained_var: 0.9672024250030518
        vf_loss: 18.939945379892986
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.261764705882356
    gpu_util_percent0: 0.3420588235294118
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7911764705882356
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15488941149377
    mean_env_wait_ms: 1.163762439253942
    mean_inference_ms: 4.9123102784986425
    mean_raw_obs_processing_ms: 0.4108031145585351
  time_since_restore: 208.86158347129822
  time_this_iter_s: 29.472196340560913
  time_total_s: 208.86158347129822
  timers:
    learn_throughput: 7260.347
    learn_time_ms: 22284.336
    sample_throughput: 21655.316
    sample_time_ms: 7471.237
    update_time_ms: 23.147
  timestamp: 1602467553
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |      7 |          208.862 | 1132544 |  224.942 |              272.232 |              129.808 |            868.265 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3561.070301291248
    time_step_min: 3233
  date: 2020-10-12_01-53-02
  done: false
  episode_len_mean: 864.056258790436
  episode_reward_max: 276.17171717171715
  episode_reward_mean: 226.43969228146426
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0395137866338093
        entropy_coeff: 0.0001
        kl: 0.01206846806841592
        model: {}
        policy_loss: -0.02013894442158441
        total_loss: 17.01837929089864
        vf_explained_var: 0.9693992137908936
        vf_loss: 17.036208311716717
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.070588235294117
    gpu_util_percent0: 0.3317647058823529
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7823529411764705
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15430210504050684
    mean_env_wait_ms: 1.1650810795350293
    mean_inference_ms: 4.8699549909587345
    mean_raw_obs_processing_ms: 0.4087762026220438
  time_since_restore: 238.18631839752197
  time_this_iter_s: 29.324734926223755
  time_total_s: 238.18631839752197
  timers:
    learn_throughput: 7259.158
    learn_time_ms: 22287.984
    sample_throughput: 21848.611
    sample_time_ms: 7405.139
    update_time_ms: 22.793
  timestamp: 1602467582
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |      8 |          238.186 | 1294336 |   226.44 |              276.172 |              129.808 |            864.056 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3551.639175257732
    time_step_min: 3233
  date: 2020-10-12_01-53-32
  done: false
  episode_len_mean: 860.0455696202532
  episode_reward_max: 276.17171717171715
  episode_reward_mean: 227.85833013681105
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0099073350429535
        entropy_coeff: 0.0001
        kl: 0.010642366483807564
        model: {}
        policy_loss: -0.016317249076867785
        total_loss: 15.718090295791626
        vf_explained_var: 0.9704262614250183
        vf_loss: 15.732380310694376
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.326470588235296
    gpu_util_percent0: 0.36323529411764705
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15379292185511031
    mean_env_wait_ms: 1.1663451822538713
    mean_inference_ms: 4.832915230431221
    mean_raw_obs_processing_ms: 0.4069394510004978
  time_since_restore: 267.5530321598053
  time_this_iter_s: 29.366713762283325
  time_total_s: 267.5530321598053
  timers:
    learn_throughput: 7254.568
    learn_time_ms: 22302.086
    sample_throughput: 22024.872
    sample_time_ms: 7345.877
    update_time_ms: 23.196
  timestamp: 1602467612
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |      9 |          267.553 | 1456128 |  227.858 |              276.172 |              129.808 |            860.046 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3537.0571587125414
    time_step_min: 3233
  date: 2020-10-12_01-54-01
  done: false
  episode_len_mean: 853.4218579234972
  episode_reward_max: 276.17171717171715
  episode_reward_mean: 230.2154330187116
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 250
  episodes_total: 1830
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9688556840022405
        entropy_coeff: 0.0001
        kl: 0.010992375668138266
        model: {}
        policy_loss: -0.016342121351044625
        total_loss: 21.05446434020996
        vf_explained_var: 0.973168671131134
        vf_loss: 21.068705399831135
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.854285714285716
    gpu_util_percent0: 0.3805714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765714285714286
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1531345225940061
    mean_env_wait_ms: 1.1686109447093054
    mean_inference_ms: 4.783379945906638
    mean_raw_obs_processing_ms: 0.4044755704610716
  time_since_restore: 296.9426794052124
  time_this_iter_s: 29.389647245407104
  time_total_s: 296.9426794052124
  timers:
    learn_throughput: 7250.642
    learn_time_ms: 22314.161
    sample_throughput: 22163.74
    sample_time_ms: 7299.851
    update_time_ms: 23.289
  timestamp: 1602467641
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |     10 |          296.943 | 1617920 |  230.215 |              276.172 |              129.808 |            853.422 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3524.9797630799603
    time_step_min: 3194
  date: 2020-10-12_01-54-31
  done: false
  episode_len_mean: 848.5486854917235
  episode_reward_max: 282.08080808080797
  episode_reward_mean: 232.17958061628937
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 224
  episodes_total: 2054
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.972046027580897
        entropy_coeff: 0.0001
        kl: 0.01127071212977171
        model: {}
        policy_loss: -0.016299222634794813
        total_loss: 13.335344632466635
        vf_explained_var: 0.9777434468269348
        vf_loss: 13.34948698679606
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.002941176470593
    gpu_util_percent0: 0.37058823529411766
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15261273569614606
    mean_env_wait_ms: 1.170340878808492
    mean_inference_ms: 4.7473888800075645
    mean_raw_obs_processing_ms: 0.402648849660472
  time_since_restore: 326.3804178237915
  time_this_iter_s: 29.4377384185791
  time_total_s: 326.3804178237915
  timers:
    learn_throughput: 7247.896
    learn_time_ms: 22322.616
    sample_throughput: 22929.606
    sample_time_ms: 7056.031
    update_time_ms: 23.778
  timestamp: 1602467671
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |     11 |           326.38 | 1779712 |   232.18 |              282.081 |              129.808 |            848.549 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3516.401556776557
    time_step_min: 3194
  date: 2020-10-12_01-55-00
  done: false
  episode_len_mean: 845.2911392405064
  episode_reward_max: 282.08080808080797
  episode_reward_mean: 233.47547354192915
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9463993559281031
        entropy_coeff: 0.0001
        kl: 0.010242945747449994
        model: {}
        policy_loss: -0.01724410749739036
        total_loss: 10.826065381368002
        vf_explained_var: 0.9787660241127014
        vf_loss: 10.841355800628662
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.164705882352944
    gpu_util_percent0: 0.33294117647058824
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7852941176470587
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15230343895095666
    mean_env_wait_ms: 1.1715504957039145
    mean_inference_ms: 4.724912239987923
    mean_raw_obs_processing_ms: 0.40149738920472305
  time_since_restore: 355.81981921195984
  time_this_iter_s: 29.439401388168335
  time_total_s: 355.81981921195984
  timers:
    learn_throughput: 7242.013
    learn_time_ms: 22340.748
    sample_throughput: 23146.75
    sample_time_ms: 6989.837
    update_time_ms: 23.902
  timestamp: 1602467700
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |     12 |           355.82 | 1941504 |  233.475 |              282.081 |              129.808 |            845.291 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3508.5179028132993
    time_step_min: 3192
  date: 2020-10-12_01-55-29
  done: false
  episode_len_mean: 842.1373209772536
  episode_reward_max: 286.7777777777779
  episode_reward_mean: 234.71687813263205
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 162
  episodes_total: 2374
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9109101196130117
        entropy_coeff: 0.0001
        kl: 0.011117507625992099
        model: {}
        policy_loss: -0.016444557656844456
        total_loss: 11.83820629119873
        vf_explained_var: 0.9783290028572083
        vf_loss: 11.85251792271932
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.176470588235293
    gpu_util_percent0: 0.35529411764705876
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7735294117647062
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15201457132489418
    mean_env_wait_ms: 1.1727915051908548
    mean_inference_ms: 4.703741004543446
    mean_raw_obs_processing_ms: 0.40039198133996073
  time_since_restore: 384.7935633659363
  time_this_iter_s: 28.97374415397644
  time_total_s: 384.7935633659363
  timers:
    learn_throughput: 7256.433
    learn_time_ms: 22296.355
    sample_throughput: 23278.171
    sample_time_ms: 6950.374
    update_time_ms: 24.164
  timestamp: 1602467729
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |     13 |          384.794 | 2103296 |  234.717 |              286.778 |              129.808 |            842.137 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3494.433685003768
    time_step_min: 3192
  date: 2020-10-12_01-55-59
  done: false
  episode_len_mean: 836.4082774049217
  episode_reward_max: 286.7777777777779
  episode_reward_mean: 236.68507219849488
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 308
  episodes_total: 2682
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8913575659195582
        entropy_coeff: 0.0001
        kl: 0.010137506372605761
        model: {}
        policy_loss: -0.015370018217557421
        total_loss: 16.413785457611084
        vf_explained_var: 0.9781383872032166
        vf_loss: 16.42721692721049
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.354545454545452
    gpu_util_percent0: 0.36333333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7696969696969695
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15154170667661546
    mean_env_wait_ms: 1.1752428065869198
    mean_inference_ms: 4.669076131677623
    mean_raw_obs_processing_ms: 0.3986280026816754
  time_since_restore: 413.84973430633545
  time_this_iter_s: 29.05617094039917
  time_total_s: 413.84973430633545
  timers:
    learn_throughput: 7257.378
    learn_time_ms: 22293.452
    sample_throughput: 23423.205
    sample_time_ms: 6907.338
    update_time_ms: 23.685
  timestamp: 1602467759
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |     14 |           413.85 | 2265088 |  236.685 |              286.778 |              129.808 |            836.408 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3487.9332386363635
    time_step_min: 3192
  date: 2020-10-12_01-56-28
  done: false
  episode_len_mean: 833.1923347398031
  episode_reward_max: 286.7777777777779
  episode_reward_mean: 237.66358735029613
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 162
  episodes_total: 2844
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8855857849121094
        entropy_coeff: 0.0001
        kl: 0.01048306740509967
        model: {}
        policy_loss: -0.014769956403919574
        total_loss: 9.566025733947754
        vf_explained_var: 0.9811767935752869
        vf_loss: 9.578787962595621
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.63235294117647
    gpu_util_percent0: 0.3255882352941177
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7823529411764705
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15132065457010224
    mean_env_wait_ms: 1.1764299007424723
    mean_inference_ms: 4.653080637105391
    mean_raw_obs_processing_ms: 0.39779691121893357
  time_since_restore: 442.9929447174072
  time_this_iter_s: 29.143210411071777
  time_total_s: 442.9929447174072
  timers:
    learn_throughput: 7253.742
    learn_time_ms: 22304.626
    sample_throughput: 23470.927
    sample_time_ms: 6893.294
    update_time_ms: 22.651
  timestamp: 1602467788
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |     15 |          442.993 | 2426880 |  237.664 |              286.778 |              129.808 |            833.192 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3482.2691532258063
    time_step_min: 3129
  date: 2020-10-12_01-56-57
  done: false
  episode_len_mean: 830.3075898801598
  episode_reward_max: 291.92929292929324
  episode_reward_mean: 238.6527525588776
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 160
  episodes_total: 3004
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8644290914138159
        entropy_coeff: 0.0001
        kl: 0.010357720234120885
        model: {}
        policy_loss: -0.01688353600911796
        total_loss: 9.11955992380778
        vf_explained_var: 0.9811930060386658
        vf_loss: 9.134458223978678
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.73823529411765
    gpu_util_percent0: 0.3855882352941177
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7794117647058822
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15111804947493618
    mean_env_wait_ms: 1.1776250787558569
    mean_inference_ms: 4.638399560156173
    mean_raw_obs_processing_ms: 0.3970181202877681
  time_since_restore: 472.08436584472656
  time_this_iter_s: 29.091421127319336
  time_total_s: 472.08436584472656
  timers:
    learn_throughput: 7250.348
    learn_time_ms: 22315.067
    sample_throughput: 23551.986
    sample_time_ms: 6869.569
    update_time_ms: 22.457
  timestamp: 1602467817
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |     16 |          472.084 | 2588672 |  238.653 |              291.929 |              129.808 |            830.308 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3472.7409785932723
    time_step_min: 3129
  date: 2020-10-12_01-57-26
  done: false
  episode_len_mean: 825.3705275924802
  episode_reward_max: 291.92929292929324
  episode_reward_mean: 240.20804773018233
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 294
  episodes_total: 3298
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8342925310134888
        entropy_coeff: 0.0001
        kl: 0.009202266111969948
        model: {}
        policy_loss: -0.014151455650183683
        total_loss: 12.742331425348917
        vf_explained_var: 0.9821591377258301
        vf_loss: 12.754725774129232
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.823529411764703
    gpu_util_percent0: 0.37
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770588235294117
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1507910302878265
    mean_env_wait_ms: 1.1799039727768812
    mean_inference_ms: 4.614299088018182
    mean_raw_obs_processing_ms: 0.39576801153366503
  time_since_restore: 501.2733244895935
  time_this_iter_s: 29.188958644866943
  time_total_s: 501.2733244895935
  timers:
    learn_throughput: 7250.492
    learn_time_ms: 22314.624
    sample_throughput: 23652.129
    sample_time_ms: 6840.484
    update_time_ms: 23.177
  timestamp: 1602467846
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |     17 |          501.273 | 2750464 |  240.208 |              291.929 |              129.808 |            825.371 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3467.304524361949
    time_step_min: 3129
  date: 2020-10-12_01-57-56
  done: false
  episode_len_mean: 822.9174338319908
  episode_reward_max: 291.92929292929324
  episode_reward_mean: 241.0723779800304
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 178
  episodes_total: 3476
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8305369814236959
        entropy_coeff: 0.0001
        kl: 0.009956153420110544
        model: {}
        policy_loss: -0.017991953315989424
        total_loss: 9.099488496780396
        vf_explained_var: 0.9824022650718689
        vf_loss: 9.115572214126587
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.88181818181818
    gpu_util_percent0: 0.4060606060606061
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.784848484848485
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15060754600126405
    mean_env_wait_ms: 1.1811687772165929
    mean_inference_ms: 4.601266916885908
    mean_raw_obs_processing_ms: 0.3950766683999631
  time_since_restore: 530.5451147556305
  time_this_iter_s: 29.271790266036987
  time_total_s: 530.5451147556305
  timers:
    learn_throughput: 7249.64
    learn_time_ms: 22317.246
    sample_throughput: 23689.919
    sample_time_ms: 6829.572
    update_time_ms: 25.023
  timestamp: 1602467876
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |     18 |          530.545 | 2912256 |  241.072 |              291.929 |              129.808 |            822.917 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3462.718957871397
    time_step_min: 3129
  date: 2020-10-12_01-58-25
  done: false
  episode_len_mean: 821.0467546754676
  episode_reward_max: 291.92929292929324
  episode_reward_mean: 241.80528052805275
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 160
  episodes_total: 3636
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8173427333434423
        entropy_coeff: 0.0001
        kl: 0.009440373784552017
        model: {}
        policy_loss: -0.014355723299862197
        total_loss: 8.806224346160889
        vf_explained_var: 0.9818682074546814
        vf_loss: 8.818773667017618
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.7
    gpu_util_percent0: 0.35911764705882354
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7794117647058822
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15045596871727024
    mean_env_wait_ms: 1.1822726951460594
    mean_inference_ms: 4.590283285444133
    mean_raw_obs_processing_ms: 0.39448959390038396
  time_since_restore: 559.6029958724976
  time_this_iter_s: 29.057881116867065
  time_total_s: 559.6029958724976
  timers:
    learn_throughput: 7257.318
    learn_time_ms: 22293.637
    sample_throughput: 23717.322
    sample_time_ms: 6821.681
    update_time_ms: 24.713
  timestamp: 1602467905
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |     19 |          559.603 | 3074048 |  241.805 |              291.929 |              129.808 |            821.047 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3454.8795366795366
    time_step_min: 3129
  date: 2020-10-12_01-58-54
  done: false
  episode_len_mean: 817.7508305647841
  episode_reward_max: 291.92929292929324
  episode_reward_mean: 242.97348129906263
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 277
  episodes_total: 3913
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7679536491632462
        entropy_coeff: 0.0001
        kl: 0.010047085660820207
        model: {}
        policy_loss: -0.01807921612635255
        total_loss: 11.150868733723959
        vf_explained_var: 0.983900249004364
        vf_loss: 11.167014916737875
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.655882352941177
    gpu_util_percent0: 0.3529411764705883
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.779411764705883
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15021981758282776
    mean_env_wait_ms: 1.1841838112670788
    mean_inference_ms: 4.572856738515567
    mean_raw_obs_processing_ms: 0.39357150267762636
  time_since_restore: 588.9010360240936
  time_this_iter_s: 29.29804015159607
  time_total_s: 588.9010360240936
  timers:
    learn_throughput: 7259.283
    learn_time_ms: 22287.599
    sample_throughput: 23729.116
    sample_time_ms: 6818.29
    update_time_ms: 24.3
  timestamp: 1602467934
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | RUNNING  | 172.17.0.4:17998 |     20 |          588.901 | 3235840 |  242.973 |              291.929 |              129.808 |            817.751 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_1784b_00000:
  custom_metrics:
    time_step_max: 4199
    time_step_mean: 3449.094362745098
    time_step_min: 3129
  date: 2020-10-12_01-59-24
  done: true
  episode_len_mean: 815.8627069133398
  episode_reward_max: 291.92929292929324
  episode_reward_mean: 243.82286349374954
  episode_reward_min: 129.8080808080806
  episodes_this_iter: 195
  episodes_total: 4108
  experiment_id: 04a01aac364d48cdad33bd7cb051e349
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7782599081595739
        entropy_coeff: 0.0001
        kl: 0.008789254274840156
        model: {}
        policy_loss: -0.015413084688285986
        total_loss: 7.130725860595703
        vf_explained_var: 0.9863494038581848
        vf_loss: 7.144459168116252
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.441176470588236
    gpu_util_percent0: 0.2911764705882353
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176474
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 17998
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15006346864645392
    mean_env_wait_ms: 1.1853916030184035
    mean_inference_ms: 4.56185776487621
    mean_raw_obs_processing_ms: 0.39298737857282035
  time_since_restore: 618.1892659664154
  time_this_iter_s: 29.288229942321777
  time_total_s: 618.1892659664154
  timers:
    learn_throughput: 7262.063
    learn_time_ms: 22279.068
    sample_throughput: 23760.234
    sample_time_ms: 6809.36
    update_time_ms: 25.345
  timestamp: 1602467964
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 1784b_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | TERMINATED |       |     21 |          618.189 | 3397632 |  243.823 |              291.929 |              129.808 |            815.863 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.91 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_1784b_00000 | TERMINATED |       |     21 |          618.189 | 3397632 |  243.823 |              291.929 |              129.808 |            815.863 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


