2020-10-12 17:33:12,722	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_018fb_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=34990)[0m 2020-10-12 17:33:15,487	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=34910)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34910)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34971)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34971)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34993)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34993)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34917)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34917)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35011)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35011)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34942)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34942)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34921)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34921)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34947)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34947)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34955)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34955)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34920)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34920)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34979)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34979)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34970)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34970)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34959)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34959)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34901)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34901)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34964)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34964)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34957)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34957)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34912)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34912)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34981)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34981)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34966)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34966)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34903)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34884)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34884)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34939)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34939)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=35005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=35005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34973)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34973)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34886)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34886)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34916)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34916)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 3996
    time_step_mean: 3522.9508196721313
    time_step_min: 3235
  date: 2020-10-12_17-33-48
  done: false
  episode_len_mean: 892.2341772151899
  episode_reward_max: 254.5757575757571
  episode_reward_mean: 208.69735327963153
  episode_reward_min: 139.27272727272737
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1785929004351299
        entropy_coeff: 0.009999999999999998
        kl: 0.006003353434304397
        model: {}
        policy_loss: -0.00872738795199742
        total_loss: 425.67115529378253
        vf_explained_var: 0.5529740452766418
        vf_loss: 425.6904652913411
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.24411764705882
    gpu_util_percent0: 0.34470588235294114
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5588235294117645
    vram_util_percent0: 0.08636872262844136
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16766968315197534
    mean_env_wait_ms: 1.1589801896682084
    mean_inference_ms: 5.532240200719925
    mean_raw_obs_processing_ms: 0.4426023760633948
  time_since_restore: 27.6675546169281
  time_this_iter_s: 27.6675546169281
  time_total_s: 27.6675546169281
  timers:
    learn_throughput: 8602.32
    learn_time_ms: 18807.949
    sample_throughput: 18426.286
    sample_time_ms: 8780.5
    update_time_ms: 45.716
  timestamp: 1602524028
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |      1 |          27.6676 | 161792 |  208.697 |              254.576 |              139.273 |            892.234 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4030
    time_step_mean: 3544.532142857143
    time_step_min: 3235
  date: 2020-10-12_17-34-14
  done: false
  episode_len_mean: 893.1898734177215
  episode_reward_max: 254.5757575757571
  episode_reward_mean: 206.76601457614095
  episode_reward_min: 134.1212121212117
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1485158900419872
        entropy_coeff: 0.009999999999999998
        kl: 0.008262902653465668
        model: {}
        policy_loss: -0.010741421882509409
        total_loss: 119.13157590230306
        vf_explained_var: 0.8070764541625977
        vf_loss: 119.1521504720052
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.493548387096777
    gpu_util_percent0: 0.41
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.751612903225806
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1639484448559951
    mean_env_wait_ms: 1.1560119306493104
    mean_inference_ms: 5.389796570504306
    mean_raw_obs_processing_ms: 0.43374651228669914
  time_since_restore: 53.88422131538391
  time_this_iter_s: 26.21666669845581
  time_total_s: 53.88422131538391
  timers:
    learn_throughput: 8716.303
    learn_time_ms: 18561.998
    sample_throughput: 19482.603
    sample_time_ms: 8304.435
    update_time_ms: 36.159
  timestamp: 1602524054
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |      2 |          53.8842 | 323584 |  206.766 |              254.576 |              134.121 |             893.19 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3556.0890410958905
    time_step_min: 3235
  date: 2020-10-12_17-34-41
  done: false
  episode_len_mean: 889.9852320675105
  episode_reward_max: 264.27272727272714
  episode_reward_mean: 206.3456719089628
  episode_reward_min: 125.78787878787857
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1393644511699677
        entropy_coeff: 0.009999999999999998
        kl: 0.00962495345932742
        model: {}
        policy_loss: -0.012945299502462149
        total_loss: 55.04133447011312
        vf_explained_var: 0.8952179551124573
        vf_loss: 55.06374708811442
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.462500000000002
    gpu_util_percent0: 0.34125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7687500000000003
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16128497356593643
    mean_env_wait_ms: 1.1560022155439398
    mean_inference_ms: 5.242117008589118
    mean_raw_obs_processing_ms: 0.42600662725905336
  time_since_restore: 79.91898679733276
  time_this_iter_s: 26.034765481948853
  time_total_s: 79.91898679733276
  timers:
    learn_throughput: 8676.345
    learn_time_ms: 18647.482
    sample_throughput: 20454.66
    sample_time_ms: 7909.787
    update_time_ms: 38.345
  timestamp: 1602524081
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |      3 |           79.919 | 485376 |  206.346 |              264.273 |              125.788 |            889.985 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3550.4211409395975
    time_step_min: 3235
  date: 2020-10-12_17-35-06
  done: false
  episode_len_mean: 885.4335443037975
  episode_reward_max: 264.27272727272714
  episode_reward_mean: 207.7539796701187
  episode_reward_min: 125.78787878787857
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.131442238887151
        entropy_coeff: 0.009999999999999998
        kl: 0.008981717905650536
        model: {}
        policy_loss: -0.01227370283656152
        total_loss: 42.49345747629801
        vf_explained_var: 0.9157820343971252
        vf_loss: 42.51524957021078
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.246666666666666
    gpu_util_percent0: 0.35300000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1593239420600764
    mean_env_wait_ms: 1.1570642531295547
    mean_inference_ms: 5.125473867935107
    mean_raw_obs_processing_ms: 0.41987367988957813
  time_since_restore: 105.54704070091248
  time_this_iter_s: 25.628053903579712
  time_total_s: 105.54704070091248
  timers:
    learn_throughput: 8659.884
    learn_time_ms: 18682.928
    sample_throughput: 21235.269
    sample_time_ms: 7619.023
    update_time_ms: 39.655
  timestamp: 1602524106
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |      4 |          105.547 | 647168 |  207.754 |              264.273 |              125.788 |            885.434 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3538.261273209549
    time_step_min: 3151
  date: 2020-10-12_17-35-32
  done: false
  episode_len_mean: 880.7303797468354
  episode_reward_max: 267.3030303030303
  episode_reward_mean: 209.50402761795146
  episode_reward_min: 125.78787878787857
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.092871993780136
        entropy_coeff: 0.009999999999999998
        kl: 0.011136533692479134
        model: {}
        policy_loss: -0.014433764178344669
        total_loss: 31.650240580240887
        vf_explained_var: 0.935546875
        vf_loss: 31.673376083374023
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.077419354838714
    gpu_util_percent0: 0.3674193548387096
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15782595215769726
    mean_env_wait_ms: 1.1587904701126348
    mean_inference_ms: 5.03401045631322
    mean_raw_obs_processing_ms: 0.4151125855890459
  time_since_restore: 130.9577488899231
  time_this_iter_s: 25.41070818901062
  time_total_s: 130.9577488899231
  timers:
    learn_throughput: 8671.222
    learn_time_ms: 18658.5
    sample_throughput: 21715.901
    sample_time_ms: 7450.393
    update_time_ms: 37.043
  timestamp: 1602524132
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |      5 |          130.958 | 808960 |  209.504 |              267.303 |              125.788 |             880.73 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3510.7958607714017
    time_step_min: 3151
  date: 2020-10-12_17-35-57
  done: false
  episode_len_mean: 869.0600545950864
  episode_reward_max: 267.3030303030303
  episode_reward_mean: 212.89171974522276
  episode_reward_min: 125.78787878787857
  episodes_this_iter: 309
  episodes_total: 1099
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0781385898590088
        entropy_coeff: 0.009999999999999998
        kl: 0.00861275060257564
        model: {}
        policy_loss: -0.012300338363274932
        total_loss: 35.62503719329834
        vf_explained_var: 0.9525005221366882
        vf_loss: 35.64639631907145
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.741935483870968
    gpu_util_percent0: 0.37548387096774194
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15582444498252243
    mean_env_wait_ms: 1.1637997100447741
    mean_inference_ms: 4.909832290109147
    mean_raw_obs_processing_ms: 0.40903550528496024
  time_since_restore: 156.4623668193817
  time_this_iter_s: 25.504617929458618
  time_total_s: 156.4623668193817
  timers:
    learn_throughput: 8680.566
    learn_time_ms: 18638.415
    sample_throughput: 22020.166
    sample_time_ms: 7347.447
    update_time_ms: 34.455
  timestamp: 1602524157
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |      6 |          156.462 | 970752 |  212.892 |              267.303 |              125.788 |             869.06 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4085
    time_step_mean: 3500.4771986970686
    time_step_min: 3151
  date: 2020-10-12_17-36-23
  done: false
  episode_len_mean: 862.1344936708861
  episode_reward_max: 267.3030303030303
  episode_reward_mean: 214.29562236286907
  episode_reward_min: 125.78787878787857
  episodes_this_iter: 165
  episodes_total: 1264
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.073935975631078
        entropy_coeff: 0.009999999999999998
        kl: 0.009326611645519733
        model: {}
        policy_loss: -0.013501299933219949
        total_loss: 19.68155558904012
        vf_explained_var: 0.9590120911598206
        vf_loss: 19.703930536905926
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.76333333333334
    gpu_util_percent0: 0.33433333333333337
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7866666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15505142197073596
    mean_env_wait_ms: 1.1663249410913412
    mean_inference_ms: 4.861891005929708
    mean_raw_obs_processing_ms: 0.40664223858725135
  time_since_restore: 181.90738582611084
  time_this_iter_s: 25.445019006729126
  time_total_s: 181.90738582611084
  timers:
    learn_throughput: 8679.397
    learn_time_ms: 18640.927
    sample_throughput: 22293.866
    sample_time_ms: 7257.243
    update_time_ms: 32.946
  timestamp: 1602524183
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |      7 |          181.907 | 1132544 |  214.296 |              267.303 |              125.788 |            862.134 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3491.839105339105
    time_step_min: 3151
  date: 2020-10-12_17-36-48
  done: false
  episode_len_mean: 856.9353023909986
  episode_reward_max: 267.3030303030303
  episode_reward_mean: 215.65905894386896
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0581396222114563
        entropy_coeff: 0.009999999999999998
        kl: 0.008448764138544599
        model: {}
        policy_loss: -0.012718810874503106
        total_loss: 18.828676064809162
        vf_explained_var: 0.9593338966369629
        vf_loss: 18.85028648376465
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.677419354838708
    gpu_util_percent0: 0.34129032258064523
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.767741935483871
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1544091240115801
    mean_env_wait_ms: 1.1685984011753072
    mean_inference_ms: 4.821723604736413
    mean_raw_obs_processing_ms: 0.40462295619840405
  time_since_restore: 207.30775785446167
  time_this_iter_s: 25.40037202835083
  time_total_s: 207.30775785446167
  timers:
    learn_throughput: 8688.683
    learn_time_ms: 18621.004
    sample_throughput: 22476.795
    sample_time_ms: 7198.179
    update_time_ms: 31.607
  timestamp: 1602524208
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |      8 |          207.308 | 1294336 |  215.659 |              267.303 |              112.606 |            856.935 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3480.853074433657
    time_step_min: 3116
  date: 2020-10-12_17-37-14
  done: false
  episode_len_mean: 852.5192915876028
  episode_reward_max: 272.6060606060606
  episode_reward_mean: 217.29938857263323
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 159
  episodes_total: 1581
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0106363743543625
        entropy_coeff: 0.009999999999999998
        kl: 0.010456287690127889
        model: {}
        policy_loss: -0.014151785304420628
        total_loss: 16.45870002110799
        vf_explained_var: 0.9646652340888977
        vf_loss: 16.4808673063914
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.49666666666667
    gpu_util_percent0: 0.361
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15384398321364642
    mean_env_wait_ms: 1.1708461890051
    mean_inference_ms: 4.786174740659295
    mean_raw_obs_processing_ms: 0.4027575164814692
  time_since_restore: 232.80377554893494
  time_this_iter_s: 25.496017694473267
  time_total_s: 232.80377554893494
  timers:
    learn_throughput: 8685.875
    learn_time_ms: 18627.023
    sample_throughput: 22637.006
    sample_time_ms: 7147.235
    update_time_ms: 30.936
  timestamp: 1602524234
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |      9 |          232.804 | 1456128 |  217.299 |              272.606 |              112.606 |            852.519 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3460.4085037674918
    time_step_min: 3116
  date: 2020-10-12_17-37-39
  done: false
  episode_len_mean: 843.9915522703274
  episode_reward_max: 279.2727272727273
  episode_reward_mean: 220.3342933026142
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 313
  episodes_total: 1894
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9937391330798467
        entropy_coeff: 0.009999999999999998
        kl: 0.008761537571748098
        model: {}
        policy_loss: -0.014342184682997564
        total_loss: 20.109087308247883
        vf_explained_var: 0.97035813331604
        vf_loss: 20.131614844004314
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.73870967741936
    gpu_util_percent0: 0.35677419354838713
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.152943776641429
    mean_env_wait_ms: 1.175145377511525
    mean_inference_ms: 4.729140609921587
    mean_raw_obs_processing_ms: 0.39989322033799607
  time_since_restore: 258.0785405635834
  time_this_iter_s: 25.274765014648438
  time_total_s: 258.0785405635834
  timers:
    learn_throughput: 8697.019
    learn_time_ms: 18603.156
    sample_throughput: 22742.006
    sample_time_ms: 7114.236
    update_time_ms: 29.571
  timestamp: 1602524259
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |     10 |          258.079 | 1617920 |  220.334 |              279.273 |              112.606 |            843.992 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3452.0564915758177
    time_step_min: 3116
  date: 2020-10-12_17-38-05
  done: false
  episode_len_mean: 840.0053554040895
  episode_reward_max: 279.2727272727273
  episode_reward_mean: 221.47441798707612
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 160
  episodes_total: 2054
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9863049139579138
        entropy_coeff: 0.009999999999999998
        kl: 0.008405384530002872
        model: {}
        policy_loss: -0.012832364627684001
        total_loss: 14.188737074534098
        vf_explained_var: 0.9707646369934082
        vf_loss: 14.20975104967753
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.53000000000001
    gpu_util_percent0: 0.3053333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15255992852179243
    mean_env_wait_ms: 1.1771415240341907
    mean_inference_ms: 4.705221915247456
    mean_raw_obs_processing_ms: 0.39866448492566103
  time_since_restore: 283.67282605171204
  time_this_iter_s: 25.594285488128662
  time_total_s: 283.67282605171204
  timers:
    learn_throughput: 8699.572
    learn_time_ms: 18597.696
    sample_throughput: 23409.098
    sample_time_ms: 6911.501
    update_time_ms: 28.42
  timestamp: 1602524285
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |     11 |          283.673 | 1779712 |  221.474 |              279.273 |              112.606 |            840.005 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3443.744025735294
    time_step_min: 3116
  date: 2020-10-12_17-38-31
  done: false
  episode_len_mean: 836.2726039783001
  episode_reward_max: 279.2727272727273
  episode_reward_mean: 222.68538002082298
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9818761001030604
        entropy_coeff: 0.009999999999999998
        kl: 0.007776216759035985
        model: {}
        policy_loss: -0.013005162404927736
        total_loss: 14.346432050069174
        vf_explained_var: 0.9673736691474915
        vf_loss: 14.367700974146524
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.996774193548386
    gpu_util_percent0: 0.3629032258064517
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1522204693779118
    mean_env_wait_ms: 1.1789622832707494
    mean_inference_ms: 4.68377776562609
    mean_raw_obs_processing_ms: 0.3975528863548381
  time_since_restore: 309.212482213974
  time_this_iter_s: 25.539656162261963
  time_total_s: 309.212482213974
  timers:
    learn_throughput: 8682.214
    learn_time_ms: 18634.877
    sample_throughput: 23773.318
    sample_time_ms: 6805.613
    update_time_ms: 28.442
  timestamp: 1602524311
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |     12 |          309.212 | 1941504 |  222.685 |              279.273 |              112.606 |            836.273 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3428.730753564155
    time_step_min: 3103
  date: 2020-10-12_17-38-56
  done: false
  episode_len_mean: 830.2533119229225
  episode_reward_max: 279.2727272727273
  episode_reward_mean: 224.90330036616663
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 279
  episodes_total: 2491
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9307829837004343
        entropy_coeff: 0.009999999999999998
        kl: 0.008615611121058464
        model: {}
        policy_loss: -0.013792748524186512
        total_loss: 18.303478558858234
        vf_explained_var: 0.9723107814788818
        vf_loss: 18.32485580444336
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.39333333333333
    gpu_util_percent0: 0.3153333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15169499613111392
    mean_env_wait_ms: 1.1821009135222922
    mean_inference_ms: 4.650913506278572
    mean_raw_obs_processing_ms: 0.39587774082846156
  time_since_restore: 334.68457436561584
  time_this_iter_s: 25.472092151641846
  time_total_s: 334.68457436561584
  timers:
    learn_throughput: 8693.743
    learn_time_ms: 18610.166
    sample_throughput: 23877.853
    sample_time_ms: 6775.819
    update_time_ms: 26.495
  timestamp: 1602524336
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |     13 |          334.685 | 2103296 |  224.903 |              279.273 |              112.606 |            830.253 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3419.3116981132075
    time_step_min: 3103
  date: 2020-10-12_17-39-22
  done: false
  episode_len_mean: 826.8801191362621
  episode_reward_max: 279.2727272727273
  episode_reward_mean: 226.24524470317462
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 195
  episodes_total: 2686
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9342880547046661
        entropy_coeff: 0.009999999999999998
        kl: 0.0076674557058140635
        model: {}
        policy_loss: -0.014156218016675362
        total_loss: 11.458270708719889
        vf_explained_var: 0.9761472344398499
        vf_loss: 11.480236371358236
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.758064516129036
    gpu_util_percent0: 0.3970967741935484
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15138663153413626
    mean_env_wait_ms: 1.1840804079869562
    mean_inference_ms: 4.630970190378165
    mean_raw_obs_processing_ms: 0.39487408835432536
  time_since_restore: 360.1877589225769
  time_this_iter_s: 25.50318455696106
  time_total_s: 360.1877589225769
  timers:
    learn_throughput: 8699.743
    learn_time_ms: 18597.331
    sample_throughput: 23877.582
    sample_time_ms: 6775.896
    update_time_ms: 25.97
  timestamp: 1602524362
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |     14 |          360.188 | 2265088 |  226.245 |              279.273 |              112.606 |             826.88 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3413.3668091168092
    time_step_min: 3103
  date: 2020-10-12_17-39-47
  done: false
  episode_len_mean: 824.454641350211
  episode_reward_max: 279.2727272727273
  episode_reward_mean: 227.22141243660224
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.929691289861997
        entropy_coeff: 0.009999999999999998
        kl: 0.007844772539101541
        model: {}
        policy_loss: -0.01405186164204982
        total_loss: 10.37425963083903
        vf_explained_var: 0.9759666323661804
        vf_loss: 10.396039803822836
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.926666666666662
    gpu_util_percent0: 0.3143333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15115467971046784
    mean_env_wait_ms: 1.185548328889103
    mean_inference_ms: 4.616264200316562
    mean_raw_obs_processing_ms: 0.39412234560889053
  time_since_restore: 385.6678612232208
  time_this_iter_s: 25.48010230064392
  time_total_s: 385.6678612232208
  timers:
    learn_throughput: 8698.023
    learn_time_ms: 18601.009
    sample_throughput: 23869.858
    sample_time_ms: 6778.088
    update_time_ms: 25.828
  timestamp: 1602524387
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |     15 |          385.668 | 2426880 |  227.221 |              279.273 |              112.606 |            824.455 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3404.4651086240947
    time_step_min: 3103
  date: 2020-10-12_17-40-13
  done: false
  episode_len_mean: 820.850357839948
  episode_reward_max: 279.2727272727273
  episode_reward_mean: 228.62960115139683
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 230
  episodes_total: 3074
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8882327526807785
        entropy_coeff: 0.009999999999999998
        kl: 0.008508770105739435
        model: {}
        policy_loss: -0.0125256748093913
        total_loss: 13.108482281366983
        vf_explained_var: 0.9782342910766602
        vf_loss: 13.128188371658325
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.838709677419363
    gpu_util_percent0: 0.3567741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15084415712139526
    mean_env_wait_ms: 1.187586407357516
    mean_inference_ms: 4.596735499650143
    mean_raw_obs_processing_ms: 0.39313060325085747
  time_since_restore: 411.41037106513977
  time_this_iter_s: 25.742509841918945
  time_total_s: 411.41037106513977
  timers:
    learn_throughput: 8684.079
    learn_time_ms: 18630.875
    sample_throughput: 23876.572
    sample_time_ms: 6776.182
    update_time_ms: 27.153
  timestamp: 1602524413
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |     16 |           411.41 | 2588672 |   228.63 |              279.273 |              112.606 |             820.85 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3396.1950030469225
    time_step_min: 3096
  date: 2020-10-12_17-40-39
  done: false
  episode_len_mean: 817.5774562989753
  episode_reward_max: 279.2727272727273
  episode_reward_mean: 229.94728478272776
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 244
  episodes_total: 3318
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.884555995464325
        entropy_coeff: 0.009999999999999998
        kl: 0.008091287726225952
        model: {}
        policy_loss: -0.014456669770879671
        total_loss: 11.980777184168497
        vf_explained_var: 0.9779896140098572
        vf_loss: 12.002461671829224
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.616129032258065
    gpu_util_percent0: 0.3616129032258064
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.150560665506234
    mean_env_wait_ms: 1.1896486877203054
    mean_inference_ms: 4.578512715461155
    mean_raw_obs_processing_ms: 0.39220016091078913
  time_since_restore: 437.1312427520752
  time_this_iter_s: 25.720871686935425
  time_total_s: 437.1312427520752
  timers:
    learn_throughput: 8677.272
    learn_time_ms: 18645.491
    sample_throughput: 23838.922
    sample_time_ms: 6786.884
    update_time_ms: 28.42
  timestamp: 1602524439
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |     17 |          437.131 | 2750464 |  229.947 |              279.273 |              112.606 |            817.577 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3390.8642441860466
    time_step_min: 3090
  date: 2020-10-12_17-41-05
  done: false
  episode_len_mean: 815.9401611047181
  episode_reward_max: 279.2727272727273
  episode_reward_mean: 230.82741395543462
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8847105503082275
        entropy_coeff: 0.009999999999999998
        kl: 0.009156484001626572
        model: {}
        policy_loss: -0.013465729823413616
        total_loss: 9.131061633427938
        vf_explained_var: 0.9790604114532471
        vf_loss: 9.151543219884237
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.835483870967742
    gpu_util_percent0: 0.3680645161290323
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15039162290374414
    mean_env_wait_ms: 1.1908280117180243
    mean_inference_ms: 4.567706832590241
    mean_raw_obs_processing_ms: 0.3916538254177532
  time_since_restore: 462.5014691352844
  time_this_iter_s: 25.37022638320923
  time_total_s: 462.5014691352844
  timers:
    learn_throughput: 8678.332
    learn_time_ms: 18643.213
    sample_throughput: 23855.272
    sample_time_ms: 6782.232
    update_time_ms: 34.927
  timestamp: 1602524465
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |     18 |          462.501 | 2912256 |  230.827 |              279.273 |              112.606 |             815.94 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3384.7108599779494
    time_step_min: 3008
  date: 2020-10-12_17-41-31
  done: false
  episode_len_mean: 814.4044759825327
  episode_reward_max: 288.969696969697
  episode_reward_mean: 231.7107400423448
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 188
  episodes_total: 3664
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8468334426482519
        entropy_coeff: 0.009999999999999998
        kl: 0.008183772171226641
        model: {}
        policy_loss: -0.01301492563895105
        total_loss: 12.189703305562338
        vf_explained_var: 0.9780506491661072
        vf_loss: 12.209549903869629
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.583333333333336
    gpu_util_percent0: 0.401
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15020233198716276
    mean_env_wait_ms: 1.1921469044650697
    mean_inference_ms: 4.555702910394152
    mean_raw_obs_processing_ms: 0.39104411847545273
  time_since_restore: 488.2027757167816
  time_this_iter_s: 25.701306581497192
  time_total_s: 488.2027757167816
  timers:
    learn_throughput: 8673.385
    learn_time_ms: 18653.847
    sample_throughput: 23827.466
    sample_time_ms: 6790.147
    update_time_ms: 36.212
  timestamp: 1602524491
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |     19 |          488.203 | 3074048 |  231.711 |               288.97 |              112.606 |            814.404 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3376.4398159979555
    time_step_min: 3008
  date: 2020-10-12_17-41-56
  done: false
  episode_len_mean: 812.0645733096986
  episode_reward_max: 288.969696969697
  episode_reward_mean: 232.99100654557728
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 285
  episodes_total: 3949
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.844902753829956
        entropy_coeff: 0.009999999999999998
        kl: 0.00681539853879561
        model: {}
        policy_loss: -0.010327448408740262
        total_loss: 13.47906748453776
        vf_explained_var: 0.9781637787818909
        vf_loss: 13.496480703353882
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.870967741935488
    gpu_util_percent0: 0.3545161290322581
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14994780631066423
    mean_env_wait_ms: 1.1940280402245056
    mean_inference_ms: 4.539306550558999
    mean_raw_obs_processing_ms: 0.3902226136223614
  time_since_restore: 513.9388725757599
  time_this_iter_s: 25.73609685897827
  time_total_s: 513.9388725757599
  timers:
    learn_throughput: 8654.728
    learn_time_ms: 18694.059
    sample_throughput: 23818.503
    sample_time_ms: 6792.702
    update_time_ms: 38.6
  timestamp: 1602524516
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |     20 |          513.939 | 3235840 |  232.991 |               288.97 |              112.606 |            812.065 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3372.0832514734775
    time_step_min: 3008
  date: 2020-10-12_17-42-22
  done: false
  episode_len_mean: 810.8843719571568
  episode_reward_max: 288.969696969697
  episode_reward_mean: 233.6287141128913
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 159
  episodes_total: 4108
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8471351613601049
        entropy_coeff: 0.009999999999999998
        kl: 0.006919933211368819
        model: {}
        policy_loss: -0.013059665022107462
        total_loss: 8.156870126724243
        vf_explained_var: 0.9820349216461182
        vf_loss: 8.177016894022623
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.654838709677417
    gpu_util_percent0: 0.2767741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14981590462948322
    mean_env_wait_ms: 1.1949598869212676
    mean_inference_ms: 4.530957217765023
    mean_raw_obs_processing_ms: 0.38979417144377093
  time_since_restore: 539.5573906898499
  time_this_iter_s: 25.618518114089966
  time_total_s: 539.5573906898499
  timers:
    learn_throughput: 8660.462
    learn_time_ms: 18681.683
    sample_throughput: 23768.91
    sample_time_ms: 6806.875
    update_time_ms: 37.997
  timestamp: 1602524542
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |     21 |          539.557 | 3397632 |  233.629 |               288.97 |              112.606 |            810.884 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3368.8189106342843
    time_step_min: 3008
  date: 2020-10-12_17-42-48
  done: false
  episode_len_mean: 809.6656534954408
  episode_reward_max: 288.969696969697
  episode_reward_mean: 234.1700994041419
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 169
  episodes_total: 4277
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8184048781792322
        entropy_coeff: 0.009999999999999998
        kl: 0.007598333293572068
        model: {}
        policy_loss: -0.0130914378532907
        total_loss: 10.225142478942871
        vf_explained_var: 0.9800808429718018
        vf_loss: 10.244898080825806
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.583870967741937
    gpu_util_percent0: 0.3396774193548388
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14968350570104377
    mean_env_wait_ms: 1.1958980443809937
    mean_inference_ms: 4.522507575366134
    mean_raw_obs_processing_ms: 0.3893517138185869
  time_since_restore: 565.3559064865112
  time_this_iter_s: 25.798515796661377
  time_total_s: 565.3559064865112
  timers:
    learn_throughput: 8653.4
    learn_time_ms: 18696.929
    sample_throughput: 23739.834
    sample_time_ms: 6815.212
    update_time_ms: 39.399
  timestamp: 1602524568
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |     22 |          565.356 | 3559424 |   234.17 |               288.97 |              112.606 |            809.666 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3361.433575677462
    time_step_min: 3008
  date: 2020-10-12_17-43-14
  done: false
  episode_len_mean: 807.5101639344263
  episode_reward_max: 288.969696969697
  episode_reward_mean: 235.2869680410664
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 298
  episodes_total: 4575
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8023013919591904
        entropy_coeff: 0.009999999999999998
        kl: 0.007954640702034036
        model: {}
        policy_loss: -0.015180180998868309
        total_loss: 11.328969399134317
        vf_explained_var: 0.9823959469795227
        vf_loss: 11.350581487019857
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.222580645161294
    gpu_util_percent0: 0.3564516129032259
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1494706003613123
    mean_env_wait_ms: 1.1974844825401687
    mean_inference_ms: 4.508993212367624
    mean_raw_obs_processing_ms: 0.38867749636792687
  time_since_restore: 590.8195765018463
  time_this_iter_s: 25.463670015335083
  time_total_s: 590.8195765018463
  timers:
    learn_throughput: 8661.37
    learn_time_ms: 18679.723
    sample_throughput: 23714.77
    sample_time_ms: 6822.415
    update_time_ms: 41.04
  timestamp: 1602524594
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | RUNNING  | 172.17.0.4:34990 |     23 |           590.82 | 3721216 |  235.287 |               288.97 |              112.606 |             807.51 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_018fb_00000:
  custom_metrics:
    time_step_max: 4172
    time_step_mean: 3357.250425170068
    time_step_min: 3008
  date: 2020-10-12_17-43-39
  done: true
  episode_len_mean: 806.5417721518987
  episode_reward_max: 288.969696969697
  episode_reward_mean: 235.86191024165703
  episode_reward_min: 112.60606060606048
  episodes_this_iter: 165
  episodes_total: 4740
  experiment_id: 575a8bdc93f04dbebdb6db9e8ca47096
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8087094575166702
        entropy_coeff: 0.009999999999999998
        kl: 0.007366352753403286
        model: {}
        policy_loss: -0.01227302038266013
        total_loss: 8.883998155593872
        vf_explained_var: 0.9802711606025696
        vf_loss: 8.90288503964742
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.58666666666667
    gpu_util_percent0: 0.31666666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.79
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34990
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14936125008621381
    mean_env_wait_ms: 1.1983038847073455
    mean_inference_ms: 4.502095832399694
    mean_raw_obs_processing_ms: 0.38833117586554516
  time_since_restore: 616.1198632717133
  time_this_iter_s: 25.300286769866943
  time_total_s: 616.1198632717133
  timers:
    learn_throughput: 8672.0
    learn_time_ms: 18656.826
    sample_throughput: 23707.185
    sample_time_ms: 6824.598
    update_time_ms: 40.6
  timestamp: 1602524619
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 018fb_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | TERMINATED |       |     24 |           616.12 | 3883008 |  235.862 |               288.97 |              112.606 |            806.542 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.37 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_018fb_00000 | TERMINATED |       |     24 |           616.12 | 3883008 |  235.862 |               288.97 |              112.606 |            806.542 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


