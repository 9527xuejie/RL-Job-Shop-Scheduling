2020-10-11 19:03:09,848	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_68137_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=34989)[0m 2020-10-11 19:03:12,591	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=34965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34969)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34969)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34946)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34946)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34959)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34959)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34952)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34952)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34972)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34972)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34976)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34976)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34956)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34956)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34977)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34977)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34942)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34942)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34928)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34928)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34863)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34863)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34966)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34966)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34949)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34949)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34941)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34941)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34947)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34947)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34939)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34939)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34923)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34923)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34934)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34934)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34857)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34857)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34917)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34917)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34874)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34874)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34937)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34937)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34861)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34861)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34980)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34980)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34868)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34868)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34871)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34871)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34935)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34935)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34870)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34870)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34922)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34922)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34864)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34864)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34970)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34970)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34927)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34927)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34943)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34943)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34921)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34921)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=34894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=34894)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_19-03-49
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1843508349524603
        entropy_coeff: 0.0001
        kl: 0.004721578572773271
        model: {}
        policy_loss: -0.00988805560498602
        total_loss: 509.25912136501734
        vf_explained_var: 0.5215201377868652
        vf_loss: 509.2681816948785
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.84594594594595
    gpu_util_percent0: 0.2797297297297297
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5783783783783787
    vram_util_percent0: 0.09648932303901146
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16912770955862177
    mean_env_wait_ms: 1.1683856855759323
    mean_inference_ms: 5.754670398991283
    mean_raw_obs_processing_ms: 0.44948987145231023
  time_since_restore: 31.20080828666687
  time_this_iter_s: 31.20080828666687
  time_total_s: 31.20080828666687
  timers:
    learn_throughput: 7336.324
    learn_time_ms: 22053.551
    sample_throughput: 17828.962
    sample_time_ms: 9074.673
    update_time_ms: 24.16
  timestamp: 1602443029
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |      1 |          31.2008 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4187
    time_step_mean: 3618.434027777778
    time_step_min: 3345
  date: 2020-10-11_19-04-18
  done: false
  episode_len_mean: 889.7056962025316
  episode_reward_max: 259.20202020201975
  episode_reward_mean: 217.59145249968014
  episode_reward_min: 131.62626262626236
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1520691580242581
        entropy_coeff: 0.0001
        kl: 0.008920241250760026
        model: {}
        policy_loss: -0.011849463710354434
        total_loss: 136.11983066134982
        vf_explained_var: 0.7991345524787903
        vf_loss: 136.13090345594617
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.667647058823526
    gpu_util_percent0: 0.43823529411764706
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7588235294117647
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16421513331074938
    mean_env_wait_ms: 1.1651073749649579
    mean_inference_ms: 5.478277618353002
    mean_raw_obs_processing_ms: 0.4366864445877905
  time_since_restore: 60.46730899810791
  time_this_iter_s: 29.26650071144104
  time_total_s: 60.46730899810791
  timers:
    learn_throughput: 7376.734
    learn_time_ms: 21932.742
    sample_throughput: 19662.735
    sample_time_ms: 8228.357
    update_time_ms: 25.311
  timestamp: 1602443058
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |      2 |          60.4673 | 323584 |  217.591 |              259.202 |              131.626 |            889.706 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3615.634529147982
    time_step_min: 3345
  date: 2020-10-11_19-04-47
  done: false
  episode_len_mean: 887.3122362869199
  episode_reward_max: 266.929292929293
  episode_reward_mean: 217.47238204833118
  episode_reward_min: 126.77777777777789
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1390231847763062
        entropy_coeff: 0.0001
        kl: 0.009641255355543561
        model: {}
        policy_loss: -0.013636472686711285
        total_loss: 66.86244625515408
        vf_explained_var: 0.8877179026603699
        vf_loss: 66.87523227267795
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.66470588235294
    gpu_util_percent0: 0.31823529411764706
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16115141251807502
    mean_env_wait_ms: 1.1639139184844556
    mean_inference_ms: 5.2888166120498745
    mean_raw_obs_processing_ms: 0.4278098716395371
  time_since_restore: 89.85774087905884
  time_this_iter_s: 29.390431880950928
  time_total_s: 89.85774087905884
  timers:
    learn_throughput: 7353.455
    learn_time_ms: 22002.173
    sample_throughput: 20547.321
    sample_time_ms: 7874.116
    update_time_ms: 24.888
  timestamp: 1602443087
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |      3 |          89.8577 | 485376 |  217.472 |              266.929 |              126.778 |            887.312 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3610.9387417218545
    time_step_min: 3280
  date: 2020-10-11_19-05-17
  done: false
  episode_len_mean: 882.4398734177215
  episode_reward_max: 269.050505050505
  episode_reward_mean: 218.5214007160208
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1255579259660509
        entropy_coeff: 0.0001
        kl: 0.00822751068820556
        model: {}
        policy_loss: -0.014474232939796315
        total_loss: 55.75923114352756
        vf_explained_var: 0.9051828384399414
        vf_loss: 55.77299499511719
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.11714285714286
    gpu_util_percent0: 0.3194285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.11634962282715645
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15904656797259006
    mean_env_wait_ms: 1.1641475228601192
    mean_inference_ms: 5.154463731320554
    mean_raw_obs_processing_ms: 0.4213398386522793
  time_since_restore: 118.95987915992737
  time_this_iter_s: 29.10213828086853
  time_total_s: 118.95987915992737
  timers:
    learn_throughput: 7347.28
    learn_time_ms: 22020.665
    sample_throughput: 21181.909
    sample_time_ms: 7638.216
    update_time_ms: 25.303
  timestamp: 1602443117
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |      4 |           118.96 | 647168 |  218.521 |              269.051 |              119.202 |             882.44 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4219
    time_step_mean: 3602.5643044619424
    time_step_min: 3235
  date: 2020-10-11_19-05-46
  done: false
  episode_len_mean: 876.9202531645569
  episode_reward_max: 275.8686868686872
  episode_reward_mean: 219.68801943485468
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0947299003601074
        entropy_coeff: 0.0001
        kl: 0.008854356697864003
        model: {}
        policy_loss: -0.01442181184473965
        total_loss: 41.541700998942055
        vf_explained_var: 0.932768702507019
        vf_loss: 41.5553470187717
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.54117647058823
    gpu_util_percent0: 0.4111764705882353
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15752222506706975
    mean_env_wait_ms: 1.165356679443121
    mean_inference_ms: 5.054958737901049
    mean_raw_obs_processing_ms: 0.41642468265789084
  time_since_restore: 147.9515721797943
  time_this_iter_s: 28.991693019866943
  time_total_s: 147.9515721797943
  timers:
    learn_throughput: 7355.288
    learn_time_ms: 21996.692
    sample_throughput: 21534.138
    sample_time_ms: 7513.28
    update_time_ms: 25.876
  timestamp: 1602443146
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |      5 |          147.952 | 808960 |  219.688 |              275.869 |              119.202 |             876.92 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3587.8841121495325
    time_step_min: 3235
  date: 2020-10-11_19-06-15
  done: false
  episode_len_mean: 867.9408014571949
  episode_reward_max: 275.8686868686872
  episode_reward_mean: 221.79695865761423
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 308
  episodes_total: 1098
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0886027548048232
        entropy_coeff: 0.0001
        kl: 0.007741722743958235
        model: {}
        policy_loss: -0.012663001556777291
        total_loss: 46.83814027574327
        vf_explained_var: 0.9481419324874878
        vf_loss: 46.85013749864366
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.620588235294115
    gpu_util_percent0: 0.2979411764705882
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770588235294118
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15552242378336747
    mean_env_wait_ms: 1.1687653968489085
    mean_inference_ms: 4.92440089048827
    mean_raw_obs_processing_ms: 0.4102719813954278
  time_since_restore: 177.00740003585815
  time_this_iter_s: 29.055827856063843
  time_total_s: 177.00740003585815
  timers:
    learn_throughput: 7355.309
    learn_time_ms: 21996.63
    sample_throughput: 21796.857
    sample_time_ms: 7422.721
    update_time_ms: 28.386
  timestamp: 1602443175
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |      6 |          177.007 | 970752 |  221.797 |              275.869 |              119.202 |            867.941 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3581.128640776699
    time_step_min: 3233
  date: 2020-10-11_19-06-44
  done: false
  episode_len_mean: 863.0419303797469
  episode_reward_max: 278.44444444444446
  episode_reward_mean: 223.4365330520392
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 166
  episodes_total: 1264
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0738010009129841
        entropy_coeff: 0.0001
        kl: 0.00765216676518321
        model: {}
        policy_loss: -0.013023157115336895
        total_loss: 22.13796827528212
        vf_explained_var: 0.9615828394889832
        vf_loss: 22.150333616468643
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.55
    gpu_util_percent0: 0.36823529411764705
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785294117647059
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15475981852492898
    mean_env_wait_ms: 1.1704312695695176
    mean_inference_ms: 4.874181575401931
    mean_raw_obs_processing_ms: 0.40785561784743807
  time_since_restore: 205.9240894317627
  time_this_iter_s: 28.91668939590454
  time_total_s: 205.9240894317627
  timers:
    learn_throughput: 7365.147
    learn_time_ms: 21967.248
    sample_throughput: 21952.28
    sample_time_ms: 7370.168
    update_time_ms: 27.24
  timestamp: 1602443204
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |      7 |          205.924 | 1132544 |  223.437 |              278.444 |              119.202 |            863.042 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3572.0466284074605
    time_step_min: 3233
  date: 2020-10-11_19-07-12
  done: false
  episode_len_mean: 859.0126582278481
  episode_reward_max: 278.44444444444446
  episode_reward_mean: 224.67052380343503
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0556381013658311
        entropy_coeff: 0.0001
        kl: 0.00822339134497775
        model: {}
        policy_loss: -0.014104325013856093
        total_loss: 21.331751505533855
        vf_explained_var: 0.9627946019172668
        vf_loss: 21.34513897365994
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.03030303030303
    gpu_util_percent0: 0.30787878787878786
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778787878787879
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15414084305342393
    mean_env_wait_ms: 1.1718793910414262
    mean_inference_ms: 4.832905952086587
    mean_raw_obs_processing_ms: 0.4058470505341066
  time_since_restore: 234.6480495929718
  time_this_iter_s: 28.723960161209106
  time_total_s: 234.6480495929718
  timers:
    learn_throughput: 7367.114
    learn_time_ms: 21961.382
    sample_throughput: 22201.419
    sample_time_ms: 7287.462
    update_time_ms: 27.231
  timestamp: 1602443232
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |      8 |          234.648 | 1294336 |  224.671 |              278.444 |              119.202 |            859.013 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3562.9194587628867
    time_step_min: 3217
  date: 2020-10-11_19-07-42
  done: false
  episode_len_mean: 855.1715189873418
  episode_reward_max: 278.59595959595987
  episode_reward_mean: 225.94051272215813
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0263097021314833
        entropy_coeff: 0.0001
        kl: 0.008362756990310218
        model: {}
        policy_loss: -0.014461110244155861
        total_loss: 18.91820780436198
        vf_explained_var: 0.9667680263519287
        vf_loss: 18.931934992472332
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.138235294117653
    gpu_util_percent0: 0.3647058823529412
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776470588235295
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15360329718731425
    mean_env_wait_ms: 1.1733223037387466
    mean_inference_ms: 4.796832377246881
    mean_raw_obs_processing_ms: 0.4040339770210954
  time_since_restore: 263.58513927459717
  time_this_iter_s: 28.937089681625366
  time_total_s: 263.58513927459717
  timers:
    learn_throughput: 7364.704
    learn_time_ms: 21968.568
    sample_throughput: 22361.93
    sample_time_ms: 7235.154
    update_time_ms: 28.041
  timestamp: 1602443262
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |      9 |          263.585 | 1456128 |  225.941 |              278.596 |              119.202 |            855.172 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3549.151024811219
    time_step_min: 3217
  date: 2020-10-11_19-08-11
  done: false
  episode_len_mean: 848.3198724760892
  episode_reward_max: 278.59595959595987
  episode_reward_mean: 228.1208847239664
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 302
  episodes_total: 1882
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9993236263593038
        entropy_coeff: 0.0001
        kl: 0.007044322685235077
        model: {}
        policy_loss: -0.012485993327572942
        total_loss: 29.24024200439453
        vf_explained_var: 0.9663772583007812
        vf_loss: 29.252121183607315
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.429411764705883
    gpu_util_percent0: 0.3258823529411764
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7676470588235293
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15277088140337935
    mean_env_wait_ms: 1.1763172138012616
    mean_inference_ms: 4.740379871611037
    mean_raw_obs_processing_ms: 0.40129395737556733
  time_since_restore: 292.45828580856323
  time_this_iter_s: 28.873146533966064
  time_total_s: 292.45828580856323
  timers:
    learn_throughput: 7365.584
    learn_time_ms: 21965.944
    sample_throughput: 22507.672
    sample_time_ms: 7188.305
    update_time_ms: 35.688
  timestamp: 1602443291
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |     10 |          292.458 | 1617920 |  228.121 |              278.596 |              119.202 |             848.32 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3540.383514313919
    time_step_min: 3194
  date: 2020-10-11_19-08-39
  done: false
  episode_len_mean: 845.0628042843233
  episode_reward_max: 282.0808080808081
  episode_reward_mean: 229.41741661994814
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 172
  episodes_total: 2054
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9859415888786316
        entropy_coeff: 0.0001
        kl: 0.006805953466229969
        model: {}
        policy_loss: -0.013446049040390385
        total_loss: 17.021724277072483
        vf_explained_var: 0.9711102247238159
        vf_loss: 17.0345884958903
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.869696969696967
    gpu_util_percent0: 0.34393939393939393
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.787878787878788
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15237843330291714
    mean_env_wait_ms: 1.1777261652308781
    mean_inference_ms: 4.7140248527445685
    mean_raw_obs_processing_ms: 0.3999725885348071
  time_since_restore: 321.2885081768036
  time_this_iter_s: 28.830222368240356
  time_total_s: 321.2885081768036
  timers:
    learn_throughput: 7368.499
    learn_time_ms: 21957.253
    sample_throughput: 23251.951
    sample_time_ms: 6958.212
    update_time_ms: 36.063
  timestamp: 1602443319
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |     11 |          321.289 | 1779712 |  229.417 |              282.081 |              119.202 |            845.063 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3534.3695054945056
    time_step_min: 3194
  date: 2020-10-11_19-09-08
  done: false
  episode_len_mean: 842.0660036166365
  episode_reward_max: 282.0808080808081
  episode_reward_mean: 230.48243282736942
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9706595540046692
        entropy_coeff: 0.0001
        kl: 0.006862661490837733
        model: {}
        policy_loss: -0.01380531924466292
        total_loss: 14.500430425008139
        vf_explained_var: 0.9731002449989319
        vf_loss: 14.513646549648708
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.644117647058827
    gpu_util_percent0: 0.4635294117647059
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1520569584826106
    mean_env_wait_ms: 1.1789787559790301
    mean_inference_ms: 4.692178776331337
    mean_raw_obs_processing_ms: 0.3988552107885348
  time_since_restore: 350.2643461227417
  time_this_iter_s: 28.97583794593811
  time_total_s: 350.2643461227417
  timers:
    learn_throughput: 7362.155
    learn_time_ms: 21976.173
    sample_throughput: 23445.4
    sample_time_ms: 6900.799
    update_time_ms: 36.846
  timestamp: 1602443348
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |     12 |          350.264 | 1941504 |  230.482 |              282.081 |              119.202 |            842.066 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3527.7171331636982
    time_step_min: 3194
  date: 2020-10-11_19-09-37
  done: false
  episode_len_mean: 839.0037720033529
  episode_reward_max: 282.0808080808081
  episode_reward_mean: 231.58327194831799
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 174
  episodes_total: 2386
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9348431163363986
        entropy_coeff: 0.0001
        kl: 0.0074637361491719885
        model: {}
        policy_loss: -0.0140232573935969
        total_loss: 14.015959527757433
        vf_explained_var: 0.9776356816291809
        vf_loss: 14.029329829745823
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.663636363636364
    gpu_util_percent0: 0.3618181818181818
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7818181818181817
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15174326153556397
    mean_env_wait_ms: 1.1804613184066395
    mean_inference_ms: 4.670654433056212
    mean_raw_obs_processing_ms: 0.39772163772133984
  time_since_restore: 378.96267890930176
  time_this_iter_s: 28.69833278656006
  time_total_s: 378.96267890930176
  timers:
    learn_throughput: 7372.593
    learn_time_ms: 21945.06
    sample_throughput: 23573.089
    sample_time_ms: 6863.419
    update_time_ms: 36.294
  timestamp: 1602443377
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |     13 |          378.963 | 2103296 |  231.583 |              282.081 |              119.202 |            839.004 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3516.135867519759
    time_step_min: 3193
  date: 2020-10-11_19-10-06
  done: false
  episode_len_mean: 834.3154562383613
  episode_reward_max: 286.17171717171715
  episode_reward_mean: 233.5126685852942
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 299
  episodes_total: 2685
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9252206219567193
        entropy_coeff: 0.0001
        kl: 0.006078497661898534
        model: {}
        policy_loss: -0.01180143483603994
        total_loss: 17.539153416951496
        vf_explained_var: 0.9762699604034424
        vf_loss: 17.5504396226671
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.891176470588235
    gpu_util_percent0: 0.32499999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770588235294117
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1512706171499517
    mean_env_wait_ms: 1.182708688991563
    mean_inference_ms: 4.638351770777441
    mean_raw_obs_processing_ms: 0.39607009268171867
  time_since_restore: 407.7465856075287
  time_this_iter_s: 28.78390669822693
  time_total_s: 407.7465856075287
  timers:
    learn_throughput: 7380.476
    learn_time_ms: 21921.62
    sample_throughput: 23620.095
    sample_time_ms: 6849.761
    update_time_ms: 35.742
  timestamp: 1602443406
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |     14 |          407.747 | 2265088 |  233.513 |              286.172 |              119.202 |            834.315 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3509.3366477272725
    time_step_min: 3183
  date: 2020-10-11_19-10-35
  done: false
  episode_len_mean: 831.9680028129395
  episode_reward_max: 286.17171717171715
  episode_reward_mean: 234.53616332097343
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 159
  episodes_total: 2844
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9084723525577121
        entropy_coeff: 0.0001
        kl: 0.0066332718253963524
        model: {}
        policy_loss: -0.013506995410554938
        total_loss: 11.586083518134224
        vf_explained_var: 0.9771859645843506
        vf_loss: 11.599017884996202
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.387878787878787
    gpu_util_percent0: 0.33272727272727276
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.790909090909091
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15105306419424241
    mean_env_wait_ms: 1.183814694085487
    mean_inference_ms: 4.623427096098771
    mean_raw_obs_processing_ms: 0.39529322561975677
  time_since_restore: 436.24228739738464
  time_this_iter_s: 28.495701789855957
  time_total_s: 436.24228739738464
  timers:
    learn_throughput: 7389.232
    learn_time_ms: 21895.644
    sample_throughput: 23701.875
    sample_time_ms: 6826.127
    update_time_ms: 34.913
  timestamp: 1602443435
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |     15 |          436.242 | 2426880 |  234.536 |              286.172 |              119.202 |            831.968 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3502.817417619368
    time_step_min: 3183
  date: 2020-10-11_19-11-04
  done: false
  episode_len_mean: 829.9267155229846
  episode_reward_max: 287.0808080808082
  episode_reward_mean: 235.3969306657514
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8938175174925063
        entropy_coeff: 0.0001
        kl: 0.006722591403457854
        model: {}
        policy_loss: -0.014099026991364857
        total_loss: 11.053231239318848
        vf_explained_var: 0.9781302213668823
        vf_loss: 11.06674755944146
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.075757575757574
    gpu_util_percent0: 0.32181818181818184
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.790909090909091
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15085442570581237
    mean_env_wait_ms: 1.1848797540221532
    mean_inference_ms: 4.609734779754749
    mean_raw_obs_processing_ms: 0.3945641638510214
  time_since_restore: 464.8976318836212
  time_this_iter_s: 28.655344486236572
  time_total_s: 464.8976318836212
  timers:
    learn_throughput: 7397.551
    learn_time_ms: 21871.022
    sample_throughput: 23760.74
    sample_time_ms: 6809.216
    update_time_ms: 34.175
  timestamp: 1602443464
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |     16 |          464.898 | 2588672 |  235.397 |              287.081 |              119.202 |            829.927 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3492.750997850783
    time_step_min: 3183
  date: 2020-10-11_19-11-32
  done: false
  episode_len_mean: 826.7564687975647
  episode_reward_max: 287.0808080808082
  episode_reward_mean: 236.85245145519113
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 283
  episodes_total: 3285
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8706453177664015
        entropy_coeff: 0.0001
        kl: 0.006674821436819103
        model: {}
        policy_loss: -0.0120168204108874
        total_loss: 15.801198323567709
        vf_explained_var: 0.9784578680992126
        vf_loss: 15.812634997897678
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.854545454545455
    gpu_util_percent0: 0.336969696969697
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7757575757575754
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15053721943301615
    mean_env_wait_ms: 1.186779016734399
    mean_inference_ms: 4.587761004289641
    mean_raw_obs_processing_ms: 0.39340898458694856
  time_since_restore: 493.5617845058441
  time_this_iter_s: 28.6641526222229
  time_total_s: 493.5617845058441
  timers:
    learn_throughput: 7397.3
    learn_time_ms: 21871.765
    sample_throughput: 23860.58
    sample_time_ms: 6780.724
    update_time_ms: 35.677
  timestamp: 1602443492
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |     17 |          493.562 | 2750464 |  236.852 |              287.081 |              119.202 |            826.756 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3486.8764501160094
    time_step_min: 3183
  date: 2020-10-11_19-12-01
  done: false
  episode_len_mean: 824.9016110471807
  episode_reward_max: 287.0808080808082
  episode_reward_mean: 237.82521997884479
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 191
  episodes_total: 3476
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8568403522173563
        entropy_coeff: 0.0001
        kl: 0.006638096076332861
        model: {}
        policy_loss: -0.012599811336258426
        total_loss: 11.889694531758627
        vf_explained_var: 0.9782626032829285
        vf_loss: 11.901715914408365
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.194117647058825
    gpu_util_percent0: 0.4147058823529412
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7852941176470587
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15034662991395234
    mean_env_wait_ms: 1.1879150818137951
    mean_inference_ms: 4.574650197749895
    mean_raw_obs_processing_ms: 0.392736130534304
  time_since_restore: 522.1141166687012
  time_this_iter_s: 28.552332162857056
  time_total_s: 522.1141166687012
  timers:
    learn_throughput: 7407.018
    learn_time_ms: 21843.068
    sample_throughput: 23824.076
    sample_time_ms: 6791.113
    update_time_ms: 37.232
  timestamp: 1602443521
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |     18 |          522.114 | 2912256 |  237.825 |              287.081 |              119.202 |            824.902 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3481.9750415973376
    time_step_min: 3183
  date: 2020-10-11_19-12-30
  done: false
  episode_len_mean: 823.6560264171711
  episode_reward_max: 287.0808080808082
  episode_reward_mean: 238.62281038230398
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8560408817397224
        entropy_coeff: 0.0001
        kl: 0.00649417657405138
        model: {}
        policy_loss: -0.014412520097620372
        total_loss: 9.365952597724068
        vf_explained_var: 0.9802858829498291
        vf_loss: 9.379801114400228
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.539393939393943
    gpu_util_percent0: 0.2972727272727273
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7939393939393944
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15020009937634554
    mean_env_wait_ms: 1.1887982131747603
    mean_inference_ms: 4.564529301125016
    mean_raw_obs_processing_ms: 0.39220301039414135
  time_since_restore: 550.6970415115356
  time_this_iter_s: 28.582924842834473
  time_total_s: 550.6970415115356
  timers:
    learn_throughput: 7417.051
    learn_time_ms: 21813.522
    sample_throughput: 23844.686
    sample_time_ms: 6785.244
    update_time_ms: 37.23
  timestamp: 1602443550
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |     19 |          550.697 | 3074048 |  238.623 |              287.081 |              119.202 |            823.656 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3475.8040451799316
    time_step_min: 3157
  date: 2020-10-11_19-12-59
  done: false
  episode_len_mean: 821.9382007822686
  episode_reward_max: 287.6868686868686
  episode_reward_mean: 239.55439663914234
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 201
  episodes_total: 3835
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8144117461310493
        entropy_coeff: 0.0001
        kl: 0.006672416244530016
        model: {}
        policy_loss: -0.013254672651075654
        total_loss: 11.530830277336968
        vf_explained_var: 0.9809316992759705
        vf_loss: 11.543498675028482
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.879411764705882
    gpu_util_percent0: 0.28352941176470586
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7764705882352945
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15002360401022194
    mean_env_wait_ms: 1.1899033349338448
    mean_inference_ms: 4.552402965682505
    mean_raw_obs_processing_ms: 0.39156476050049965
  time_since_restore: 579.5107696056366
  time_this_iter_s: 28.813728094100952
  time_total_s: 579.5107696056366
  timers:
    learn_throughput: 7418.809
    learn_time_ms: 21808.353
    sample_throughput: 23828.065
    sample_time_ms: 6789.976
    update_time_ms: 31.565
  timestamp: 1602443579
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | RUNNING  | 172.17.0.4:34989 |     20 |          579.511 | 3235840 |  239.554 |              287.687 |              119.202 |            821.938 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_68137_00000:
  custom_metrics:
    time_step_max: 4229
    time_step_mean: 3467.278009316009
    time_step_min: 3157
  date: 2020-10-11_19-13-28
  done: true
  episode_len_mean: 819.8220112003896
  episode_reward_max: 287.6868686868686
  episode_reward_mean: 240.7451357991898
  episode_reward_min: 119.20202020201985
  episodes_this_iter: 272
  episodes_total: 4107
  experiment_id: e5ce4b3634444ca680de62ad641cc969
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8046955797407362
        entropy_coeff: 0.0001
        kl: 0.006084833345893357
        model: {}
        policy_loss: -0.01188867363250918
        total_loss: 10.848699569702148
        vf_explained_var: 0.9828770160675049
        vf_loss: 10.860060373942057
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.375757575757575
    gpu_util_percent0: 0.4403030303030303
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775757575757576
    vram_util_percent0: 0.11634962282715644
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 34989
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14981704883843427
    mean_env_wait_ms: 1.1913199789620945
    mean_inference_ms: 4.537842317787346
    mean_raw_obs_processing_ms: 0.3908060432000154
  time_since_restore: 608.1585955619812
  time_this_iter_s: 28.647825956344604
  time_total_s: 608.1585955619812
  timers:
    learn_throughput: 7427.293
    learn_time_ms: 21783.441
    sample_throughput: 23807.72
    sample_time_ms: 6795.779
    update_time_ms: 32.581
  timestamp: 1602443608
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: '68137_00000'
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | TERMINATED |       |     21 |          608.159 | 3397632 |  240.745 |              287.687 |              119.202 |            819.822 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_68137_00000 | TERMINATED |       |     21 |          608.159 | 3397632 |  240.745 |              287.687 |              119.202 |            819.822 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


