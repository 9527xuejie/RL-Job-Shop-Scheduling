2020-10-11 22:47:34,163	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_c17e7_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=42427)[0m 2020-10-11 22:47:36,925	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=42387)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42387)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42383)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42346)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42346)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42389)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42389)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42413)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42413)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42406)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42406)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42380)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42380)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42407)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42407)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42372)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42372)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42373)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42373)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42424)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42424)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42370)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42370)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42402)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42402)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42294)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42294)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42319)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42319)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42362)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42362)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42416)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42416)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42371)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42371)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42307)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42307)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42412)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42412)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42393)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42393)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42419)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42419)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42378)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42378)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42292)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42292)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42349)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42349)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42361)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42361)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42299)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42299)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42404)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42404)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42315)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42315)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42297)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42297)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42365)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42365)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42382)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42382)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42305)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42305)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42414)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42414)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42364)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42364)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42291)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42291)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42367)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42367)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42375)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42375)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42308)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42308)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42302)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42302)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42317)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42317)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42376)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42376)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42296)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42296)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42374)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42374)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42345)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42345)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42422)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42422)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42401)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42401)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42295)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42295)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42418)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42418)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42369)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42369)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42377)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42377)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42304)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42304)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42368)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42368)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42288)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42288)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42316)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42316)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42320)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42320)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42363)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42363)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42399)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42399)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42287)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42314)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42314)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42290)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42290)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=42293)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=42293)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_22-48-17
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1834738949934642
        entropy_coeff: 0.0001
        kl: 0.005454853371096154
        model: {}
        policy_loss: -0.012349865341093391
        total_loss: 500.4129358927409
        vf_explained_var: 0.5819632411003113
        vf_loss: 500.42430623372394
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.565116279069766
    gpu_util_percent0: 0.3416279069767442
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5837209302325572
    vram_util_percent0: 0.08906656395158155
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1696691221571072
    mean_env_wait_ms: 1.1749438526969735
    mean_inference_ms: 5.6507638281751245
    mean_raw_obs_processing_ms: 0.45560722256855085
  time_since_restore: 35.24601197242737
  time_this_iter_s: 35.24601197242737
  time_total_s: 35.24601197242737
  timers:
    learn_throughput: 6179.73
    learn_time_ms: 26181.08
    sample_throughput: 18004.091
    sample_time_ms: 8986.402
    update_time_ms: 46.025
  timestamp: 1602456497
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |      1 |           35.246 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3626.0416666666665
    time_step_min: 3322
  date: 2020-10-11_22-48-51
  done: false
  episode_len_mean: 889.5569620253165
  episode_reward_max: 262.68686868686837
  episode_reward_mean: 216.59221966500425
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.153631995121638
        entropy_coeff: 0.0001
        kl: 0.006733731327888866
        model: {}
        policy_loss: -0.015433513093739748
        total_loss: 123.00872484842937
        vf_explained_var: 0.8223300576210022
        vf_loss: 123.02292696634929
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.068292682926828
    gpu_util_percent0: 0.3475609756097561
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7634146341463417
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16532973114873817
    mean_env_wait_ms: 1.1708135555660915
    mean_inference_ms: 5.488722361028039
    mean_raw_obs_processing_ms: 0.44419180096298017
  time_since_restore: 69.00362491607666
  time_this_iter_s: 33.75761294364929
  time_total_s: 69.00362491607666
  timers:
    learn_throughput: 6211.981
    learn_time_ms: 26045.152
    sample_throughput: 19300.877
    sample_time_ms: 8382.624
    update_time_ms: 34.359
  timestamp: 1602456531
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |      2 |          69.0036 | 323584 |  216.592 |              262.687 |              120.566 |            889.557 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3631.4887892376682
    time_step_min: 3322
  date: 2020-10-11_22-49-24
  done: false
  episode_len_mean: 889.3354430379746
  episode_reward_max: 262.8383838383837
  episode_reward_mean: 216.54666922388424
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.148065874973933
        entropy_coeff: 0.0001
        kl: 0.007898864258701602
        model: {}
        policy_loss: -0.01633385052749266
        total_loss: 50.64865493774414
        vf_explained_var: 0.9149531722068787
        vf_loss: 50.66352367401123
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.492682926829268
    gpu_util_percent0: 0.36804878048780487
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773170731707317
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16247180641058523
    mean_env_wait_ms: 1.168376317145219
    mean_inference_ms: 5.329788578869985
    mean_raw_obs_processing_ms: 0.43520111476006185
  time_since_restore: 102.35661029815674
  time_this_iter_s: 33.35298538208008
  time_total_s: 102.35661029815674
  timers:
    learn_throughput: 6212.824
    learn_time_ms: 26041.621
    sample_throughput: 20297.769
    sample_time_ms: 7970.925
    update_time_ms: 37.215
  timestamp: 1602456564
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |      3 |          102.357 | 485376 |  216.547 |              262.838 |              120.566 |            889.335 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3619.432119205298
    time_step_min: 3259
  date: 2020-10-11_22-49-57
  done: false
  episode_len_mean: 888.0443037974684
  episode_reward_max: 272.232323232323
  episode_reward_mean: 218.3509461705662
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1337408522764842
        entropy_coeff: 0.0001
        kl: 0.00856308825314045
        model: {}
        policy_loss: -0.01822439635482927
        total_loss: 30.27436621983846
        vf_explained_var: 0.945147693157196
        vf_loss: 30.29099130630493
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.51
    gpu_util_percent0: 0.38475000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16039955685342944
    mean_env_wait_ms: 1.166864314371423
    mean_inference_ms: 5.206117031317599
    mean_raw_obs_processing_ms: 0.42826035277405816
  time_since_restore: 135.3511233329773
  time_this_iter_s: 32.99451303482056
  time_total_s: 135.3511233329773
  timers:
    learn_throughput: 6225.924
    learn_time_ms: 25986.824
    sample_throughput: 20911.825
    sample_time_ms: 7736.867
    update_time_ms: 49.526
  timestamp: 1602456597
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |      4 |          135.351 | 647168 |  218.351 |              272.232 |              120.566 |            888.044 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3604.251968503937
    time_step_min: 3259
  date: 2020-10-11_22-50-31
  done: false
  episode_len_mean: 885.7405063291139
  episode_reward_max: 272.232323232323
  episode_reward_mean: 220.2714486638535
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1095956365267436
        entropy_coeff: 0.0001
        kl: 0.008476723683997989
        model: {}
        policy_loss: -0.018784551260372002
        total_loss: 21.67502562204997
        vf_explained_var: 0.9593363404273987
        vf_loss: 21.692224979400635
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.03
    gpu_util_percent0: 0.37275
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1588376804560216
    mean_env_wait_ms: 1.1661102542523518
    mean_inference_ms: 5.108991880231475
    mean_raw_obs_processing_ms: 0.4227688338883001
  time_since_restore: 168.69302034378052
  time_this_iter_s: 33.34189701080322
  time_total_s: 168.69302034378052
  timers:
    learn_throughput: 6211.095
    learn_time_ms: 26048.868
    sample_throughput: 21340.008
    sample_time_ms: 7581.628
    update_time_ms: 46.742
  timestamp: 1602456631
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |      5 |          168.693 | 808960 |  220.271 |              272.232 |              120.566 |            885.741 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3595.3253638253636
    time_step_min: 3259
  date: 2020-10-11_22-51-04
  done: false
  episode_len_mean: 882.2626262626262
  episode_reward_max: 272.232323232323
  episode_reward_mean: 221.76553412917028
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 200
  episodes_total: 990
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0751022398471832
        entropy_coeff: 0.0001
        kl: 0.008189312415197492
        model: {}
        policy_loss: -0.017144305321077507
        total_loss: 27.28472836812337
        vf_explained_var: 0.9654313921928406
        vf_loss: 27.300341924031574
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.294999999999998
    gpu_util_percent0: 0.39775
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7650000000000006
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15733171057314776
    mean_env_wait_ms: 1.1665160866093556
    mean_inference_ms: 5.015526282450932
    mean_raw_obs_processing_ms: 0.4174510396389767
  time_since_restore: 201.92006540298462
  time_this_iter_s: 33.2270450592041
  time_total_s: 201.92006540298462
  timers:
    learn_throughput: 6205.84
    learn_time_ms: 26070.928
    sample_throughput: 21638.338
    sample_time_ms: 7477.099
    update_time_ms: 45.624
  timestamp: 1602456664
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |      6 |           201.92 | 970752 |  221.766 |              272.232 |              120.566 |            882.263 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3579.279935275081
    time_step_min: 3249
  date: 2020-10-11_22-51-37
  done: false
  episode_len_mean: 877.0537974683544
  episode_reward_max: 276.4747474747467
  episode_reward_mean: 223.8852048970718
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 274
  episodes_total: 1264
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0967270930608113
        entropy_coeff: 0.0001
        kl: 0.007618502209273477
        model: {}
        policy_loss: -0.01663926666757713
        total_loss: 20.69811248779297
        vf_explained_var: 0.9685643315315247
        vf_loss: 20.713337580362957
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.1625
    gpu_util_percent0: 0.41025
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7725
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15585735867234476
    mean_env_wait_ms: 1.1671277981437962
    mean_inference_ms: 4.92209788050393
    mean_raw_obs_processing_ms: 0.4124142138615991
  time_since_restore: 234.90016222000122
  time_this_iter_s: 32.9800968170166
  time_total_s: 234.90016222000122
  timers:
    learn_throughput: 6208.809
    learn_time_ms: 26058.46
    sample_throughput: 21880.371
    sample_time_ms: 7394.39
    update_time_ms: 45.455
  timestamp: 1602456697
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |      7 |            234.9 | 1132544 |  223.885 |              276.475 |              120.566 |            877.054 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3572.093256814921
    time_step_min: 3249
  date: 2020-10-11_22-52-10
  done: false
  episode_len_mean: 873.9669479606189
  episode_reward_max: 276.4747474747467
  episode_reward_mean: 224.73264288454146
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0730946858723958
        entropy_coeff: 0.0001
        kl: 0.007681428687646985
        model: {}
        policy_loss: -0.019395024864934385
        total_loss: 18.505067825317383
        vf_explained_var: 0.969425618648529
        vf_loss: 18.523033618927002
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.279999999999998
    gpu_util_percent0: 0.40549999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7875000000000005
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15519586831397225
    mean_env_wait_ms: 1.1677025067848434
    mean_inference_ms: 4.880321107959008
    mean_raw_obs_processing_ms: 0.410133873662762
  time_since_restore: 267.900945186615
  time_this_iter_s: 33.00078296661377
  time_total_s: 267.900945186615
  timers:
    learn_throughput: 6211.598
    learn_time_ms: 26046.758
    sample_throughput: 22049.928
    sample_time_ms: 7337.53
    update_time_ms: 44.582
  timestamp: 1602456730
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |      8 |          267.901 | 1294336 |  224.733 |              276.475 |              120.566 |            873.967 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3565.2873711340208
    time_step_min: 3225
  date: 2020-10-11_22-52-43
  done: false
  episode_len_mean: 870.6284810126582
  episode_reward_max: 277.38383838383817
  episode_reward_mean: 225.68658099987195
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.056985209385554
        entropy_coeff: 0.0001
        kl: 0.007343478578453262
        model: {}
        policy_loss: -0.018959627525570493
        total_loss: 18.582411924997967
        vf_explained_var: 0.9673232436180115
        vf_loss: 18.600008646647137
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.26
    gpu_util_percent0: 0.404
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7825
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1546175836288185
    mean_env_wait_ms: 1.1683302930942498
    mean_inference_ms: 4.843563018410747
    mean_raw_obs_processing_ms: 0.40810881462599735
  time_since_restore: 301.00118255615234
  time_this_iter_s: 33.10023736953735
  time_total_s: 301.00118255615234
  timers:
    learn_throughput: 6207.76
    learn_time_ms: 26062.865
    sample_throughput: 22225.25
    sample_time_ms: 7279.648
    update_time_ms: 43.226
  timestamp: 1602456763
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |      9 |          301.001 | 1456128 |  225.687 |              277.384 |              120.566 |            870.628 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3557.6816588785045
    time_step_min: 3225
  date: 2020-10-11_22-53-16
  done: false
  episode_len_mean: 867.835632183908
  episode_reward_max: 277.38383838383817
  episode_reward_mean: 226.59535005224646
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 160
  episodes_total: 1740
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0210702617963154
        entropy_coeff: 0.0001
        kl: 0.007802742416970432
        model: {}
        policy_loss: -0.01712881602967779
        total_loss: 16.34047261873881
        vf_explained_var: 0.973002016544342
        vf_loss: 16.35614315668742
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.475
    gpu_util_percent0: 0.39875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.154106317175076
    mean_env_wait_ms: 1.1689713518564762
    mean_inference_ms: 4.810498412261051
    mean_raw_obs_processing_ms: 0.40624511642659916
  time_since_restore: 333.7547996044159
  time_this_iter_s: 32.75361704826355
  time_total_s: 333.7547996044159
  timers:
    learn_throughput: 6212.356
    learn_time_ms: 26043.582
    sample_throughput: 22373.059
    sample_time_ms: 7231.555
    update_time_ms: 41.913
  timestamp: 1602456796
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |     10 |          333.755 | 1617920 |  226.595 |              277.384 |              120.566 |            867.836 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3544.7104208416836
    time_step_min: 3192
  date: 2020-10-11_22-53-49
  done: false
  episode_len_mean: 862.5410079051384
  episode_reward_max: 282.383838383838
  episode_reward_mean: 228.73100570926644
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 284
  episodes_total: 2024
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0004554241895676
        entropy_coeff: 0.0001
        kl: 0.007008174356694023
        model: {}
        policy_loss: -0.014261304051615298
        total_loss: 21.756542205810547
        vf_explained_var: 0.9730474352836609
        vf_loss: 21.769501368204754
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.607692307692304
    gpu_util_percent0: 0.3869230769230769
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7743589743589756
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15335028657233715
    mean_env_wait_ms: 1.170418601958122
    mean_inference_ms: 4.761464506023064
    mean_raw_obs_processing_ms: 0.40350988536540505
  time_since_restore: 366.5784296989441
  time_this_iter_s: 32.8236300945282
  time_total_s: 366.5784296989441
  timers:
    learn_throughput: 6218.721
    learn_time_ms: 26016.926
    sample_throughput: 23063.601
    sample_time_ms: 7015.036
    update_time_ms: 40.827
  timestamp: 1602456829
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |     11 |          366.578 | 1779712 |  228.731 |              282.384 |              120.566 |            862.541 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3536.3365384615386
    time_step_min: 3180
  date: 2020-10-11_22-54-22
  done: false
  episode_len_mean: 859.5981012658228
  episode_reward_max: 284.2020202020195
  episode_reward_mean: 229.9621303450416
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 188
  episodes_total: 2212
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9927633504072825
        entropy_coeff: 0.0001
        kl: 0.0071070904765898986
        model: {}
        policy_loss: -0.015478810217852393
        total_loss: 14.608761866887411
        vf_explained_var: 0.9756807684898376
        vf_loss: 14.622918526331583
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.09
    gpu_util_percent0: 0.34325
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7900000000000005
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15292615683957814
    mean_env_wait_ms: 1.1712580487774007
    mean_inference_ms: 4.734126389070937
    mean_raw_obs_processing_ms: 0.40206489253921024
  time_since_restore: 399.3442587852478
  time_this_iter_s: 32.76582908630371
  time_total_s: 399.3442587852478
  timers:
    learn_throughput: 6221.36
    learn_time_ms: 26005.89
    sample_throughput: 23359.139
    sample_time_ms: 6926.283
    update_time_ms: 40.696
  timestamp: 1602456862
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |     12 |          399.344 | 1941504 |  229.962 |              284.202 |              120.566 |            859.598 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3529.1161400512383
    time_step_min: 3180
  date: 2020-10-11_22-54-55
  done: false
  episode_len_mean: 856.9987341772152
  episode_reward_max: 284.2020202020195
  episode_reward_mean: 231.04871499808192
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9785503546396891
        entropy_coeff: 0.0001
        kl: 0.0066998258310680585
        model: {}
        policy_loss: -0.01659416116308421
        total_loss: 12.112172524134317
        vf_explained_var: 0.9769558906555176
        vf_loss: 12.127524693806967
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.5475
    gpu_util_percent0: 0.43375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1526068937276864
    mean_env_wait_ms: 1.1719773957779012
    mean_inference_ms: 4.713496002356736
    mean_raw_obs_processing_ms: 0.40093940532202693
  time_since_restore: 432.0939476490021
  time_this_iter_s: 32.74968886375427
  time_total_s: 432.0939476490021
  timers:
    learn_throughput: 6223.264
    learn_time_ms: 25997.934
    sample_throughput: 23508.475
    sample_time_ms: 6882.284
    update_time_ms: 40.03
  timestamp: 1602456895
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |     13 |          432.094 | 2103296 |  231.049 |              284.202 |              120.566 |            856.999 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3522.2450039968026
    time_step_min: 3180
  date: 2020-10-11_22-55-28
  done: false
  episode_len_mean: 854.7565217391304
  episode_reward_max: 284.2020202020195
  episode_reward_mean: 232.16081766279382
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 160
  episodes_total: 2530
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9523601333300272
        entropy_coeff: 0.0001
        kl: 0.007005700026638806
        model: {}
        policy_loss: -0.016709179772684973
        total_loss: 14.093456188837687
        vf_explained_var: 0.9736056327819824
        vf_loss: 14.108859856923422
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.4375
    gpu_util_percent0: 0.37975000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1523155112099015
    mean_env_wait_ms: 1.1727005389378
    mean_inference_ms: 4.694411938697692
    mean_raw_obs_processing_ms: 0.39988018789527896
  time_since_restore: 465.2259941101074
  time_this_iter_s: 33.13204646110535
  time_total_s: 465.2259941101074
  timers:
    learn_throughput: 6213.413
    learn_time_ms: 26039.149
    sample_throughput: 23584.329
    sample_time_ms: 6860.149
    update_time_ms: 33.992
  timestamp: 1602456928
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |     14 |          465.226 | 2265088 |  232.161 |              284.202 |              120.566 |            854.757 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3512.859712230216
    time_step_min: 3180
  date: 2020-10-11_22-56-01
  done: false
  episode_len_mean: 851.0089031339031
  episode_reward_max: 284.2020202020195
  episode_reward_mean: 233.64214797548118
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 278
  episodes_total: 2808
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9255728522936503
        entropy_coeff: 0.0001
        kl: 0.00734855638196071
        model: {}
        policy_loss: -0.01726455270545557
        total_loss: 16.12038493156433
        vf_explained_var: 0.9789693355560303
        vf_loss: 16.136271476745605
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.3425
    gpu_util_percent0: 0.38199999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7725
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1518727934908542
    mean_env_wait_ms: 1.1740061991898996
    mean_inference_ms: 4.665210238764482
    mean_raw_obs_processing_ms: 0.3982600605928617
  time_since_restore: 498.27474761009216
  time_this_iter_s: 33.04875349998474
  time_total_s: 498.27474761009216
  timers:
    learn_throughput: 6218.521
    learn_time_ms: 26017.761
    sample_throughput: 23610.158
    sample_time_ms: 6852.644
    update_time_ms: 32.598
  timestamp: 1602456961
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |     15 |          498.275 | 2426880 |  233.642 |              284.202 |              120.566 |            851.009 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3506.206119704102
    time_step_min: 3157
  date: 2020-10-11_22-56-34
  done: false
  episode_len_mean: 848.6092604930046
  episode_reward_max: 287.68686868686865
  episode_reward_mean: 234.71147854292414
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 194
  episodes_total: 3002
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9191652685403824
        entropy_coeff: 0.0001
        kl: 0.006143487524241209
        model: {}
        policy_loss: -0.0171775213869599
        total_loss: 12.585402409235636
        vf_explained_var: 0.978458821773529
        vf_loss: 12.60144313176473
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.095
    gpu_util_percent0: 0.35324999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785000000000001
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15159422522258834
    mean_env_wait_ms: 1.1747915642070197
    mean_inference_ms: 4.647300767362802
    mean_raw_obs_processing_ms: 0.39728651203985665
  time_since_restore: 531.4953570365906
  time_this_iter_s: 33.22060942649841
  time_total_s: 531.4953570365906
  timers:
    learn_throughput: 6217.061
    learn_time_ms: 26023.872
    sample_throughput: 23633.603
    sample_time_ms: 6845.846
    update_time_ms: 31.923
  timestamp: 1602456994
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |     16 |          531.495 | 2588672 |  234.711 |              287.687 |              120.566 |            848.609 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3500.676883780332
    time_step_min: 3157
  date: 2020-10-11_22-57-08
  done: false
  episode_len_mean: 846.661075949367
  episode_reward_max: 287.68686868686865
  episode_reward_mean: 235.54791586753603
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9140579352776209
        entropy_coeff: 0.0001
        kl: 0.006779154452184836
        model: {}
        policy_loss: -0.017671994011228282
        total_loss: 10.448014736175537
        vf_explained_var: 0.9795067310333252
        vf_loss: 10.464422225952148
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.235
    gpu_util_percent0: 0.389
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7925000000000004
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15139032758925142
    mean_env_wait_ms: 1.175433947095243
    mean_inference_ms: 4.633968277975556
    mean_raw_obs_processing_ms: 0.3965415827193224
  time_since_restore: 564.4989569187164
  time_this_iter_s: 33.003599882125854
  time_total_s: 564.4989569187164
  timers:
    learn_throughput: 6216.921
    learn_time_ms: 26024.457
    sample_throughput: 23630.368
    sample_time_ms: 6846.783
    update_time_ms: 31.397
  timestamp: 1602457028
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |     17 |          564.499 | 2750464 |  235.548 |              287.687 |              120.566 |            846.661 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3495.7973341411694
    time_step_min: 3157
  date: 2020-10-11_22-57-41
  done: false
  episode_len_mean: 844.6701712225894
  episode_reward_max: 287.68686868686865
  episode_reward_mean: 236.41758225086542
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 169
  episodes_total: 3329
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8826338549455007
        entropy_coeff: 0.0001
        kl: 0.007100394073252876
        model: {}
        policy_loss: -0.016915303965409596
        total_loss: 11.768179734547934
        vf_explained_var: 0.9790385365486145
        vf_loss: 11.783763488133749
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.322499999999998
    gpu_util_percent0: 0.39349999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7825
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15118770253518926
    mean_env_wait_ms: 1.1761323044618492
    mean_inference_ms: 4.62072847489667
    mean_raw_obs_processing_ms: 0.39579523513236287
  time_since_restore: 597.4037351608276
  time_this_iter_s: 32.904778242111206
  time_total_s: 597.4037351608276
  timers:
    learn_throughput: 6216.164
    learn_time_ms: 26027.626
    sample_throughput: 23675.795
    sample_time_ms: 6833.646
    update_time_ms: 31.403
  timestamp: 1602457061
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | RUNNING  | 172.17.0.4:42427 |     18 |          597.404 | 2912256 |  236.418 |              287.687 |              120.566 |             844.67 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c17e7_00000:
  custom_metrics:
    time_step_max: 4260
    time_step_mean: 3487.352728285078
    time_step_min: 3149
  date: 2020-10-11_22-58-14
  done: true
  episode_len_mean: 841.6825966850829
  episode_reward_max: 288.89898989899
  episode_reward_mean: 237.6950722696578
  episode_reward_min: 120.56565656565611
  episodes_this_iter: 291
  episodes_total: 3620
  experiment_id: e25a02c8ad6445cd870e071e6e7d8a12
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.867693359653155
        entropy_coeff: 0.0001
        kl: 0.006560247663098077
        model: {}
        policy_loss: -0.016814545126787078
        total_loss: 13.963152964909872
        vf_explained_var: 0.980877697467804
        vf_loss: 13.978742440541586
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.365
    gpu_util_percent0: 0.3835
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7700000000000005
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 42427
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1508738052795856
    mean_env_wait_ms: 1.1773074184848813
    mean_inference_ms: 4.6002367546819105
    mean_raw_obs_processing_ms: 0.3946540568738682
  time_since_restore: 630.654304265976
  time_this_iter_s: 33.250569105148315
  time_total_s: 630.654304265976
  timers:
    learn_throughput: 6211.569
    learn_time_ms: 26046.88
    sample_throughput: 23693.203
    sample_time_ms: 6828.625
    update_time_ms: 32.178
  timestamp: 1602457094
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: c17e7_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | TERMINATED |       |     19 |          630.654 | 3074048 |  237.695 |              288.899 |              120.566 |            841.683 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c17e7_00000 | TERMINATED |       |     19 |          630.654 | 3074048 |  237.695 |              288.899 |              120.566 |            841.683 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


[2m[33m(pid=raylet)[0m E1011 22:58:14.769701 42246 42246 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1011 22:58:14.770013 42246 42246 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
