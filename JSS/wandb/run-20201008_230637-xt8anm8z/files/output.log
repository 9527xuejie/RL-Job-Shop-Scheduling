2020-10-08 23:06:39,429	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_ececf_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=2744)[0m 2020-10-08 23:06:42,418	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=2741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2707)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2707)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2746)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2746)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2644)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2644)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2651)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2651)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2622)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2622)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2625)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2625)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2690)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2690)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2648)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2648)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2763)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2692)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2692)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2619)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2619)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2652)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2652)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2616)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2616)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2641)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2641)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2615)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2615)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2750)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2750)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2686)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2686)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2626)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2626)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2655)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2655)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2620)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2620)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2621)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2621)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2688)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2688)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2618)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2618)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2693)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2693)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2661)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2661)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2637)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2637)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2658)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2658)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2638)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2638)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2645)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2645)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2623)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2623)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2691)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2691)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2635)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2635)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2756)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2756)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2689)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2689)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2617)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2617)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2628)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2628)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2697)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2697)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=2614)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=2614)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-08_23-07-13
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 1.0e-05
        entropy: 1.1652722597122191
        entropy_coeff: 0.0
        kl: 0.0018208788009360433
        model: {}
        policy_loss: -0.0018318576272577046
        total_loss: 41.143595123291014
        vf_explained_var: -0.09858112037181854
        vf_loss: 41.14506301879883
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 39.12413793103448
    gpu_util_percent0: 0.23758620689655174
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0003448275862068966
    ram_util_percent: 9.489655172413793
    vram_util_percent0: 0.3069321767453434
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18300872925219253
    mean_env_wait_ms: 1.655376737005146
    mean_inference_ms: 5.9318178058517095
    mean_raw_obs_processing_ms: 0.49441138547524577
  time_since_restore: 25.06350564956665
  time_this_iter_s: 25.06350564956665
  time_total_s: 25.06350564956665
  timers:
    learn_throughput: 10674.59
    learn_time_ms: 15156.741
    sample_throughput: 16443.297
    sample_time_ms: 9839.389
    update_time_ms: 27.012
  timestamp: 1602198433
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |      1 |          25.0635 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-07-36
  done: false
  episode_len_mean: 871.5253164556962
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 228.69907940161085
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 1.0e-05
        entropy: 1.1422624588012695
        entropy_coeff: 0.0
        kl: 0.00270484066568315
        model: {}
        policy_loss: -0.0030830021481961013
        total_loss: 37.135110473632814
        vf_explained_var: -0.19128592312335968
        vf_loss: 37.13792114257812
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.18518518518518
    gpu_util_percent0: 0.3422222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.73703703703704
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17669679871146823
    mean_env_wait_ms: 1.64998700813424
    mean_inference_ms: 5.645655831480442
    mean_raw_obs_processing_ms: 0.4781097805963125
  time_since_restore: 48.31134271621704
  time_this_iter_s: 23.24783706665039
  time_total_s: 48.31134271621704
  timers:
    learn_throughput: 10861.392
    learn_time_ms: 14896.065
    sample_throughput: 17616.051
    sample_time_ms: 9184.351
    update_time_ms: 25.468
  timestamp: 1602198456
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |      2 |          48.3113 | 323584 |  228.699 |              285.879 |              115.788 |            871.525 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-08-00
  done: false
  episode_len_mean: 865.6793248945148
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 229.89724246686254
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 1.0e-05
        entropy: 1.1373253107070922
        entropy_coeff: 0.0
        kl: 0.003590932209044695
        model: {}
        policy_loss: -0.0021974042057991026
        total_loss: 36.37514953613281
        vf_explained_var: -0.17007236182689667
        vf_loss: 36.377167510986325
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.800000000000004
    gpu_util_percent0: 0.3211538461538461
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17275326923246453
    mean_env_wait_ms: 1.6464178368820674
    mean_inference_ms: 5.474784463133249
    mean_raw_obs_processing_ms: 0.46684245410033126
  time_since_restore: 71.40456318855286
  time_this_iter_s: 23.093220472335815
  time_total_s: 71.40456318855286
  timers:
    learn_throughput: 10900.407
    learn_time_ms: 14842.749
    sample_throughput: 18223.996
    sample_time_ms: 8877.965
    update_time_ms: 31.557
  timestamp: 1602198480
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |      3 |          71.4046 | 485376 |  229.897 |              285.879 |              115.788 |            865.679 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-08-22
  done: false
  episode_len_mean: 860.618670886076
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 230.91925584963545
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 1.0e-05
        entropy: 1.1174269437789917
        entropy_coeff: 0.0
        kl: 0.005197844095528125
        model: {}
        policy_loss: -0.003057718090713024
        total_loss: 33.15993728637695
        vf_explained_var: -0.03412260860204697
        vf_loss: 33.162865447998044
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.23846153846154
    gpu_util_percent0: 0.28038461538461534
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.750000000000002
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1700191552381755
    mean_env_wait_ms: 1.6461669506679122
    mean_inference_ms: 5.348189839446925
    mean_raw_obs_processing_ms: 0.45862599144266164
  time_since_restore: 94.10924863815308
  time_this_iter_s: 22.70468544960022
  time_total_s: 94.10924863815308
  timers:
    learn_throughput: 10959.333
    learn_time_ms: 14762.942
    sample_throughput: 18639.654
    sample_time_ms: 8679.99
    update_time_ms: 34.396
  timestamp: 1602198502
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |      4 |          94.1092 | 647168 |  230.919 |              285.879 |              115.788 |            860.619 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-08-45
  done: false
  episode_len_mean: 851.3164835164836
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 233.0595515595514
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 278
  episodes_total: 910
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 1.0e-05
        entropy: 1.0863438367843627
        entropy_coeff: 0.0
        kl: 0.00440745959058404
        model: {}
        policy_loss: -0.0022132677608169616
        total_loss: 39.472592163085935
        vf_explained_var: 0.291675865650177
        vf_loss: 39.474694061279294
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.87692307692308
    gpu_util_percent0: 0.37269230769230766
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.750000000000002
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16687947036873801
    mean_env_wait_ms: 1.6511541646033803
    mean_inference_ms: 5.201407466438364
    mean_raw_obs_processing_ms: 0.44970665083691
  time_since_restore: 116.80484771728516
  time_this_iter_s: 22.69559907913208
  time_total_s: 116.80484771728516
  timers:
    learn_throughput: 10995.81
    learn_time_ms: 14713.969
    sample_throughput: 18895.831
    sample_time_ms: 8562.312
    update_time_ms: 34.332
  timestamp: 1602198525
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |      5 |          116.805 | 808960 |   233.06 |              285.879 |              115.788 |            851.316 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-09-08
  done: false
  episode_len_mean: 845.4819168173599
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 234.1874075291795
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 196
  episodes_total: 1106
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 1.0e-05
        entropy: 1.1013004064559937
        entropy_coeff: 0.0
        kl: 0.007676664646714926
        model: {}
        policy_loss: -0.0036800186266191305
        total_loss: 24.566482925415038
        vf_explained_var: 0.4189487099647522
        vf_loss: 24.570066452026367
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.41538461538462
    gpu_util_percent0: 0.24000000000000002
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.750000000000002
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1654426980396639
    mean_env_wait_ms: 1.6542208673675725
    mean_inference_ms: 5.129280915675828
    mean_raw_obs_processing_ms: 0.4455399183196251
  time_since_restore: 139.62431502342224
  time_this_iter_s: 22.819467306137085
  time_total_s: 139.62431502342224
  timers:
    learn_throughput: 10985.277
    learn_time_ms: 14728.077
    sample_throughput: 19132.717
    sample_time_ms: 8456.3
    update_time_ms: 36.155
  timestamp: 1602198548
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |      6 |          139.624 | 970752 |  234.187 |              285.879 |              115.788 |            845.482 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-09-31
  done: false
  episode_len_mean: 840.6107594936709
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 234.54061181434585
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 1.0e-05
        entropy: 1.0674725294113159
        entropy_coeff: 0.0
        kl: 0.006006504222750664
        model: {}
        policy_loss: -0.0033113975659944117
        total_loss: 24.367380905151368
        vf_explained_var: 0.57246994972229
        vf_loss: 24.370616912841797
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.2
    gpu_util_percent0: 0.3396153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16451466199125178
    mean_env_wait_ms: 1.6569275965531143
    mean_inference_ms: 5.08142554528983
    mean_raw_obs_processing_ms: 0.4427667473769145
  time_since_restore: 162.58744406700134
  time_this_iter_s: 22.9631290435791
  time_total_s: 162.58744406700134
  timers:
    learn_throughput: 10985.715
    learn_time_ms: 14727.49
    sample_throughput: 19227.794
    sample_time_ms: 8414.486
    update_time_ms: 34.355
  timestamp: 1602198571
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |      7 |          162.587 | 1132544 |  234.541 |              285.879 |              115.788 |            840.611 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-09-54
  done: false
  episode_len_mean: 835.6863572433193
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 235.38319197601885
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 1.0e-05
        entropy: 1.0178650617599487
        entropy_coeff: 0.0
        kl: 0.005809717439115047
        model: {}
        policy_loss: -0.0031855221604928374
        total_loss: 20.166453552246093
        vf_explained_var: 0.7124794721603394
        vf_loss: 20.16956672668457
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.15384615384615
    gpu_util_percent0: 0.295
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1637285830246511
    mean_env_wait_ms: 1.6600807728192168
    mean_inference_ms: 5.0400358397403835
    mean_raw_obs_processing_ms: 0.44034952802225547
  time_since_restore: 185.23956990242004
  time_this_iter_s: 22.6521258354187
  time_total_s: 185.23956990242004
  timers:
    learn_throughput: 11001.14
    learn_time_ms: 14706.839
    sample_throughput: 19347.656
    sample_time_ms: 8362.357
    update_time_ms: 35.129
  timestamp: 1602198594
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |      8 |           185.24 | 1294336 |  235.383 |              285.879 |              115.788 |            835.686 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-10-17
  done: false
  episode_len_mean: 826.3941311852705
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 236.76252164917287
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 1738
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 1.0e-05
        entropy: 1.0121636867523194
        entropy_coeff: 0.0
        kl: 0.0045164206996560095
        model: {}
        policy_loss: -0.002461699163541198
        total_loss: 20.257687759399413
        vf_explained_var: 0.8613412976264954
        vf_loss: 20.26009330749512
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.176923076923075
    gpu_util_percent0: 0.30961538461538457
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16250260480822878
    mean_env_wait_ms: 1.6667084962926506
    mean_inference_ms: 4.974199492050972
    mean_raw_obs_processing_ms: 0.4365626580976265
  time_since_restore: 208.0713083744049
  time_this_iter_s: 22.831738471984863
  time_total_s: 208.0713083744049
  timers:
    learn_throughput: 11014.136
    learn_time_ms: 14689.487
    sample_throughput: 19390.228
    sample_time_ms: 8343.997
    update_time_ms: 34.101
  timestamp: 1602198617
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |      9 |          208.071 | 1456128 |  236.763 |              285.879 |              115.788 |            826.394 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-10-40
  done: false
  episode_len_mean: 822.3723628691984
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 236.96278715424276
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00625
        cur_lr: 1.0e-05
        entropy: 0.9995546460151672
        entropy_coeff: 0.0
        kl: 0.004150549694895744
        model: {}
        policy_loss: -0.0025695788208395243
        total_loss: 16.3574275970459
        vf_explained_var: 0.8746175765991211
        vf_loss: 16.359971237182616
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.43846153846153
    gpu_util_percent0: 0.20346153846153847
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.76923076923077
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16201140342559806
    mean_env_wait_ms: 1.669773358678498
    mean_inference_ms: 4.947580594867321
    mean_raw_obs_processing_ms: 0.43504528218591426
  time_since_restore: 230.92161989212036
  time_this_iter_s: 22.850311517715454
  time_total_s: 230.92161989212036
  timers:
    learn_throughput: 11006.691
    learn_time_ms: 14699.423
    sample_throughput: 19476.368
    sample_time_ms: 8307.093
    update_time_ms: 33.974
  timestamp: 1602198640
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     10 |          230.922 | 1617920 |  236.963 |              285.879 |              115.788 |            822.372 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-11-03
  done: false
  episode_len_mean: 818.5881207400195
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.2846134175247
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.003125
        cur_lr: 1.0e-05
        entropy: 0.9633565902709961
        entropy_coeff: 0.0
        kl: 0.0039147865027189255
        model: {}
        policy_loss: -0.0025393093936145307
        total_loss: 16.481643676757812
        vf_explained_var: 0.8988913297653198
        vf_loss: 16.484170532226564
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.81923076923077
    gpu_util_percent0: 0.2469230769230769
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16157049577324287
    mean_env_wait_ms: 1.672907997028146
    mean_inference_ms: 4.923514821099307
    mean_raw_obs_processing_ms: 0.4336211941694385
  time_since_restore: 253.7618052959442
  time_this_iter_s: 22.840185403823853
  time_total_s: 253.7618052959442
  timers:
    learn_throughput: 11042.694
    learn_time_ms: 14651.498
    sample_throughput: 19896.679
    sample_time_ms: 8131.608
    update_time_ms: 33.071
  timestamp: 1602198663
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     11 |          253.762 | 1779712 |  237.285 |              285.879 |              115.788 |            818.588 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-11-26
  done: false
  episode_len_mean: 812.3253164556962
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.6968162639048
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 2370
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625
        cur_lr: 1.0e-05
        entropy: 0.9323606252670288
        entropy_coeff: 0.0
        kl: 0.003979995660483837
        model: {}
        policy_loss: -0.002804832113906741
        total_loss: 18.016672897338868
        vf_explained_var: 0.9442146420478821
        vf_loss: 18.019471740722658
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.37692307692308
    gpu_util_percent0: 0.24769230769230768
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746153846153847
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16080541000016563
    mean_env_wait_ms: 1.6790714029728122
    mean_inference_ms: 4.882460692708905
    mean_raw_obs_processing_ms: 0.4312476063822916
  time_since_restore: 276.81990480422974
  time_this_iter_s: 23.058099508285522
  time_total_s: 276.81990480422974
  timers:
    learn_throughput: 11046.835
    learn_time_ms: 14646.004
    sample_throughput: 19933.573
    sample_time_ms: 8116.558
    update_time_ms: 34.819
  timestamp: 1602198686
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     12 |           276.82 | 1941504 |  237.697 |              285.879 |              115.788 |            812.325 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-11-49
  done: false
  episode_len_mean: 809.5747626582279
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.9070051783659
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00078125
        cur_lr: 1.0e-05
        entropy: 0.9178185343742371
        entropy_coeff: 0.0
        kl: 0.003604936087504029
        model: {}
        policy_loss: -0.002743382565677166
        total_loss: 15.9567081451416
        vf_explained_var: 0.9375184178352356
        vf_loss: 15.959449005126952
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.54615384615385
    gpu_util_percent0: 0.26653846153846156
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16048126617711148
    mean_env_wait_ms: 1.681914640618352
    mean_inference_ms: 4.864913090537836
    mean_raw_obs_processing_ms: 0.4302271106430311
  time_since_restore: 299.80875730514526
  time_this_iter_s: 22.988852500915527
  time_total_s: 299.80875730514526
  timers:
    learn_throughput: 11052.801
    learn_time_ms: 14638.099
    sample_throughput: 19942.136
    sample_time_ms: 8113.073
    update_time_ms: 34.717
  timestamp: 1602198709
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     13 |          299.809 | 2103296 |  237.907 |              285.879 |              115.788 |            809.575 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-12-12
  done: false
  episode_len_mean: 807.0882352941177
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.9746045714027
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.000390625
        cur_lr: 1.0e-05
        entropy: 0.8832141399383545
        entropy_coeff: 0.0
        kl: 0.0033940990921109914
        model: {}
        policy_loss: -0.002475153189152479
        total_loss: 15.834994888305664
        vf_explained_var: 0.9461385607719421
        vf_loss: 15.837468910217286
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.26296296296296
    gpu_util_percent0: 0.3896296296296296
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.762962962962964
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16018343381231182
    mean_env_wait_ms: 1.684761152211468
    mean_inference_ms: 4.8486992269580105
    mean_raw_obs_processing_ms: 0.429259963823755
  time_since_restore: 322.7731602191925
  time_this_iter_s: 22.96440291404724
  time_total_s: 322.7731602191925
  timers:
    learn_throughput: 11045.478
    learn_time_ms: 14647.804
    sample_throughput: 19904.106
    sample_time_ms: 8128.574
    update_time_ms: 34.717
  timestamp: 1602198732
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     14 |          322.773 | 2265088 |  237.975 |              285.879 |              115.788 |            807.088 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-12-35
  done: false
  episode_len_mean: 802.7671552298468
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.86192033593758
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 3002
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0001953125
        cur_lr: 1.0e-05
        entropy: 0.8587614893913269
        entropy_coeff: 0.0
        kl: 0.0035093153361231088
        model: {}
        policy_loss: -0.002451853733509779
        total_loss: 18.763727569580077
        vf_explained_var: 0.9632667303085327
        vf_loss: 18.76617851257324
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.312000000000005
    gpu_util_percent0: 0.37200000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.748000000000001
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1596617842146857
    mean_env_wait_ms: 1.6902655959597221
    mean_inference_ms: 4.820133440541919
    mean_raw_obs_processing_ms: 0.42755052206519956
  time_since_restore: 345.72896242141724
  time_this_iter_s: 22.95580220222473
  time_total_s: 345.72896242141724
  timers:
    learn_throughput: 11037.911
    learn_time_ms: 14657.846
    sample_throughput: 19866.873
    sample_time_ms: 8143.808
    update_time_ms: 34.138
  timestamp: 1602198755
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     15 |          345.729 | 2426880 |  237.862 |              285.879 |              115.788 |            802.767 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-12-58
  done: false
  episode_len_mean: 800.8018987341773
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.77705856028632
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625e-05
        cur_lr: 1.0e-05
        entropy: 0.8390299201011657
        entropy_coeff: 0.0
        kl: 0.002947103837504983
        model: {}
        policy_loss: -0.002457785792648792
        total_loss: 16.04230327606201
        vf_explained_var: 0.9570821523666382
        vf_loss: 16.044761085510252
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.955555555555556
    gpu_util_percent0: 0.3237037037037037
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.762962962962964
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15943048867696924
    mean_env_wait_ms: 1.6928222053420767
    mean_inference_ms: 4.807521600795396
    mean_raw_obs_processing_ms: 0.42679898283455325
  time_since_restore: 368.61216497421265
  time_this_iter_s: 22.88320255279541
  time_total_s: 368.61216497421265
  timers:
    learn_throughput: 11048.282
    learn_time_ms: 14644.086
    sample_throughput: 19821.546
    sample_time_ms: 8162.431
    update_time_ms: 34.269
  timestamp: 1602198778
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     16 |          368.612 | 2588672 |  237.777 |              285.879 |              115.788 |            800.802 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-13-21
  done: false
  episode_len_mean: 798.9975889089814
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.71792974957526
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.8828125e-05
        cur_lr: 1.0e-05
        entropy: 0.8090176701545715
        entropy_coeff: 0.0
        kl: 0.002774837240576744
        model: {}
        policy_loss: -0.0021960040321573615
        total_loss: 15.002488327026366
        vf_explained_var: 0.9621447324752808
        vf_loss: 15.004683685302734
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.21153846153846
    gpu_util_percent0: 0.31307692307692303
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15921204547616077
    mean_env_wait_ms: 1.6953438700985541
    mean_inference_ms: 4.7957260115032145
    mean_raw_obs_processing_ms: 0.42608956908283346
  time_since_restore: 391.62461495399475
  time_this_iter_s: 23.012449979782104
  time_total_s: 391.62461495399475
  timers:
    learn_throughput: 11051.884
    learn_time_ms: 14639.315
    sample_throughput: 19803.461
    sample_time_ms: 8169.885
    update_time_ms: 35.526
  timestamp: 1602198801
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     17 |          391.625 | 2750464 |  237.718 |              285.879 |              115.788 |            798.998 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-13-44
  done: false
  episode_len_mean: 795.7369290038525
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.65547883902315
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 3634
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.44140625e-05
        cur_lr: 1.0e-05
        entropy: 0.7903251409530639
        entropy_coeff: 0.0
        kl: 0.003325528558343649
        model: {}
        policy_loss: -0.0026587538421154024
        total_loss: 17.81261787414551
        vf_explained_var: 0.971113383769989
        vf_loss: 17.81527633666992
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.403703703703705
    gpu_util_percent0: 0.40481481481481474
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.755555555555556
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.158816015283353
    mean_env_wait_ms: 1.7001702252779363
    mean_inference_ms: 4.77441690890747
    mean_raw_obs_processing_ms: 0.42483994093483546
  time_since_restore: 414.5519919395447
  time_this_iter_s: 22.927376985549927
  time_total_s: 414.5519919395447
  timers:
    learn_throughput: 11042.939
    learn_time_ms: 14651.172
    sample_throughput: 19777.747
    sample_time_ms: 8180.507
    update_time_ms: 36.471
  timestamp: 1602198824
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     18 |          414.552 | 2912256 |  237.655 |              285.879 |              115.788 |            795.737 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-14-07
  done: false
  episode_len_mean: 794.3338607594936
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.5698679836338
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.220703125e-05
        cur_lr: 1.0e-05
        entropy: 0.7638633251190186
        entropy_coeff: 0.0
        kl: 0.0024296802468597887
        model: {}
        policy_loss: -0.0019365656655281783
        total_loss: 14.48437786102295
        vf_explained_var: 0.9672373533248901
        vf_loss: 14.486314392089843
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.75384615384615
    gpu_util_percent0: 0.25846153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765384615384617
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15863780250085338
    mean_env_wait_ms: 1.702397503580973
    mean_inference_ms: 4.764797078937041
    mean_raw_obs_processing_ms: 0.4242760258435369
  time_since_restore: 437.4178955554962
  time_this_iter_s: 22.865903615951538
  time_total_s: 437.4178955554962
  timers:
    learn_throughput: 11035.257
    learn_time_ms: 14661.371
    sample_throughput: 19795.895
    sample_time_ms: 8173.008
    update_time_ms: 36.08
  timestamp: 1602198847
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     19 |          437.418 | 3074048 |   237.57 |              285.879 |              115.788 |            794.334 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-14-30
  done: false
  episode_len_mean: 793.006835443038
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.52229382431912
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3950
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 6.103515625e-06
        cur_lr: 1.0e-05
        entropy: 0.7309654235839844
        entropy_coeff: 0.0
        kl: 0.002661111392080784
        model: {}
        policy_loss: -0.0020635456312447786
        total_loss: 12.704303359985351
        vf_explained_var: 0.9723785519599915
        vf_loss: 12.706367301940919
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.40769230769231
    gpu_util_percent0: 0.2984615384615385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15847003642021582
    mean_env_wait_ms: 1.7046176843620493
    mean_inference_ms: 4.7556996634598825
    mean_raw_obs_processing_ms: 0.4237317026379155
  time_since_restore: 460.3518662452698
  time_this_iter_s: 22.93397068977356
  time_total_s: 460.3518662452698
  timers:
    learn_throughput: 11044.465
    learn_time_ms: 14649.148
    sample_throughput: 19750.58
    sample_time_ms: 8191.759
    update_time_ms: 36.55
  timestamp: 1602198870
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     20 |          460.352 | 3235840 |  237.522 |              285.879 |              115.788 |            793.007 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-14-54
  done: false
  episode_len_mean: 790.6029067041725
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.31879507688228
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 4266
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.0517578125e-06
        cur_lr: 1.0e-05
        entropy: 0.7231234550476074
        entropy_coeff: 0.0
        kl: 0.0025939150713384152
        model: {}
        policy_loss: -0.0019222962204366923
        total_loss: 16.38651351928711
        vf_explained_var: 0.9748998880386353
        vf_loss: 16.388436317443848
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.900000000000006
    gpu_util_percent0: 0.28192307692307694
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746153846153847
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1581681420883827
    mean_env_wait_ms: 1.7088537951044787
    mean_inference_ms: 4.739060951527613
    mean_raw_obs_processing_ms: 0.4227381845966048
  time_since_restore: 483.51784086227417
  time_this_iter_s: 23.165974617004395
  time_total_s: 483.51784086227417
  timers:
    learn_throughput: 11051.492
    learn_time_ms: 14639.834
    sample_throughput: 19655.975
    sample_time_ms: 8231.187
    update_time_ms: 38.36
  timestamp: 1602198894
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     21 |          483.518 | 3397632 |  237.319 |              285.879 |              115.788 |            790.603 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-15-17
  done: false
  episode_len_mean: 789.498643761302
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.2675968546222
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.52587890625e-06
        cur_lr: 1.0e-05
        entropy: 0.6957624435424805
        entropy_coeff: 0.0
        kl: 0.002647694246843457
        model: {}
        policy_loss: -0.0022573374910280107
        total_loss: 13.187001800537109
        vf_explained_var: 0.970838725566864
        vf_loss: 13.18925895690918
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.888888888888886
    gpu_util_percent0: 0.2911111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.766666666666667
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15803019121493084
    mean_env_wait_ms: 1.7108169993928382
    mean_inference_ms: 4.731451215953534
    mean_raw_obs_processing_ms: 0.4222845259335569
  time_since_restore: 506.67281460762024
  time_this_iter_s: 23.15497374534607
  time_total_s: 506.67281460762024
  timers:
    learn_throughput: 11050.05
    learn_time_ms: 14641.743
    sample_throughput: 19635.174
    sample_time_ms: 8239.907
    update_time_ms: 36.168
  timestamp: 1602198917
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     22 |          506.673 | 3559424 |  237.268 |              285.879 |              115.788 |            789.499 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-15-40
  done: false
  episode_len_mean: 788.4299738219895
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.39052391277525
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 160
  episodes_total: 4584
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 7.62939453125e-07
        cur_lr: 1.0e-05
        entropy: 0.6730040669441223
        entropy_coeff: 0.0
        kl: 0.0023754809983074663
        model: {}
        policy_loss: -0.002006137417629361
        total_loss: 10.785014343261718
        vf_explained_var: 0.9781079292297363
        vf_loss: 10.787020492553712
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.08888888888889
    gpu_util_percent0: 0.3711111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75925925925926
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15789647855267835
    mean_env_wait_ms: 1.7127624883034973
    mean_inference_ms: 4.724050245770916
    mean_raw_obs_processing_ms: 0.42183215219659276
  time_since_restore: 529.7152490615845
  time_this_iter_s: 23.042434453964233
  time_total_s: 529.7152490615845
  timers:
    learn_throughput: 11052.869
    learn_time_ms: 14638.009
    sample_throughput: 19612.899
    sample_time_ms: 8249.265
    update_time_ms: 34.903
  timestamp: 1602198940
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     23 |          529.715 | 3721216 |  237.391 |              285.879 |              115.788 |             788.43 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-16-03
  done: false
  episode_len_mean: 786.4465087790935
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.40519733884375
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 314
  episodes_total: 4898
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.814697265625e-07
        cur_lr: 1.0e-05
        entropy: 0.6581726312637329
        entropy_coeff: 0.0
        kl: 0.002339748525992036
        model: {}
        policy_loss: -0.0018961639842018485
        total_loss: 14.96220874786377
        vf_explained_var: 0.9753497838973999
        vf_loss: 14.964105033874512
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.86923076923077
    gpu_util_percent0: 0.23846153846153845
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1576559984398443
    mean_env_wait_ms: 1.7164801950936686
    mean_inference_ms: 4.710766971640682
    mean_raw_obs_processing_ms: 0.42104928302403155
  time_since_restore: 552.8046824932098
  time_this_iter_s: 23.089433431625366
  time_total_s: 552.8046824932098
  timers:
    learn_throughput: 11049.449
    learn_time_ms: 14642.54
    sample_throughput: 19600.357
    sample_time_ms: 8254.544
    update_time_ms: 34.347
  timestamp: 1602198963
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     24 |          552.805 | 3883008 |  237.405 |              285.879 |              115.788 |            786.447 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-16-27
  done: false
  episode_len_mean: 785.5081091772151
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.45478719153562
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 5056
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.9073486328125e-07
        cur_lr: 1.0e-05
        entropy: 0.6403773903846741
        entropy_coeff: 0.0
        kl: 0.002284112526103854
        model: {}
        policy_loss: -0.001956451334990561
        total_loss: 10.764216041564941
        vf_explained_var: 0.9747551679611206
        vf_loss: 10.766172218322755
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.37692307692308
    gpu_util_percent0: 0.3096153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15754431297750984
    mean_env_wait_ms: 1.7182243778150237
    mean_inference_ms: 4.704558013591782
    mean_raw_obs_processing_ms: 0.42068502752396614
  time_since_restore: 575.8271081447601
  time_this_iter_s: 23.022425651550293
  time_total_s: 575.8271081447601
  timers:
    learn_throughput: 11050.358
    learn_time_ms: 14641.336
    sample_throughput: 19584.777
    sample_time_ms: 8261.11
    update_time_ms: 34.917
  timestamp: 1602198987
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     25 |          575.827 | 4044800 |  237.455 |              285.879 |              115.788 |            785.508 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-16-50
  done: false
  episode_len_mean: 784.399542508578
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.5190775463365
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 190
  episodes_total: 5246
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.5367431640625e-08
        cur_lr: 1.0e-05
        entropy: 0.6121410012245179
        entropy_coeff: 0.0
        kl: 0.0021173045970499516
        model: {}
        policy_loss: -0.0016448890324681996
        total_loss: 9.955957984924316
        vf_explained_var: 0.9813610315322876
        vf_loss: 9.95760269165039
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.74444444444445
    gpu_util_percent0: 0.3066666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.766666666666666
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15740839938909992
    mean_env_wait_ms: 1.7203000649484128
    mean_inference_ms: 4.697342193798375
    mean_raw_obs_processing_ms: 0.42025438995562164
  time_since_restore: 599.0565950870514
  time_this_iter_s: 23.22948694229126
  time_total_s: 599.0565950870514
  timers:
    learn_throughput: 11048.238
    learn_time_ms: 14644.145
    sample_throughput: 19507.89
    sample_time_ms: 8293.67
    update_time_ms: 33.263
  timestamp: 1602199010
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | RUNNING  | 172.17.0.4:2744 |     26 |          599.057 | 4206592 |  237.519 |              285.879 |              115.788 |              784.4 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ececf_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3168.0
  date: 2020-10-08_23-17-13
  done: true
  episode_len_mean: 782.9003616636528
  episode_reward_max: 285.8787878787876
  episode_reward_mean: 237.4819515224579
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 284
  episodes_total: 5530
  experiment_id: ec799f28033f427f9b29657ff1f76e01
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.76837158203125e-08
        cur_lr: 1.0e-05
        entropy: 0.6140739798545838
        entropy_coeff: 0.0
        kl: 0.0023297975771129132
        model: {}
        policy_loss: -0.001847643149085343
        total_loss: 13.083107185363769
        vf_explained_var: 0.9742870330810547
        vf_loss: 13.084954833984375
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.669230769230765
    gpu_util_percent0: 0.391923076923077
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746153846153847
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 2744
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15723775582820948
    mean_env_wait_ms: 1.7232974670627128
    mean_inference_ms: 4.6876031856125
    mean_raw_obs_processing_ms: 0.41968818166668187
  time_since_restore: 622.2138888835907
  time_this_iter_s: 23.157293796539307
  time_total_s: 622.2138888835907
  timers:
    learn_throughput: 11055.556
    learn_time_ms: 14634.451
    sample_throughput: 19450.655
    sample_time_ms: 8318.075
    update_time_ms: 31.673
  timestamp: 1602199033
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: ececf_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | TERMINATED |       |     27 |          622.214 | 4368384 |  237.482 |              285.879 |              115.788 |              782.9 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ececf_00000 | TERMINATED |       |     27 |          622.214 | 4368384 |  237.482 |              285.879 |              115.788 |              782.9 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


