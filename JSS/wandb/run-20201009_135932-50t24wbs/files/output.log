2020-10-09 13:59:36,003	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_aaf69_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=80831)[0m 2020-10-09 13:59:39,021	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=80726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80757)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80757)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80813)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80813)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80797)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80745)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80745)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80715)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80715)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80845)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80845)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80822)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80723)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80723)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80752)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80752)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80820)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80820)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80749)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80749)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=80816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=80816)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3797
    time_step_mean: 3497.6666666666665
    time_step_min: 3221
  date: 2020-10-09_14-00-16
  done: false
  episode_len_mean: 531.1111111111111
  episode_reward_max: 277.9898989898986
  episode_reward_mean: 237.80377852600074
  episode_reward_min: 166.17171717171732
  episodes_this_iter: 162
  episodes_total: 162
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.4082539406689731
        entropy_coeff: 0.0
        kl: 0.004426429175179113
        model: {}
        policy_loss: -0.006858204449103637
        total_loss: 1506.230546431108
        vf_explained_var: 0.1678946167230606
        vf_loss: 1506.2365056818182
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.02368421052632
    gpu_util_percent0: 0.3560526315789474
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5999999999999996
    vram_util_percent0: 0.0931323471025876
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15796325106966821
    mean_env_wait_ms: 1.6725595512148919
    mean_inference_ms: 4.903671120491706
    mean_raw_obs_processing_ms: 0.41337825490278995
  time_since_restore: 31.94119429588318
  time_this_iter_s: 31.94119429588318
  time_total_s: 31.94119429588318
  timers:
    learn_throughput: 6880.356
    learn_time_ms: 23515.063
    sample_throughput: 19384.953
    sample_time_ms: 8346.268
    update_time_ms: 45.096
  timestamp: 1602252016
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 27.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |      1 |          31.9412 | 161792 |  237.804 |               277.99 |              166.172 |            531.111 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3831
    time_step_mean: 3486.4050925925926
    time_step_min: 3221
  date: 2020-10-09_14-00-47
  done: false
  episode_len_mean: 533.9071729957806
  episode_reward_max: 279.5050505050504
  episode_reward_mean: 239.06808592251633
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 312
  episodes_total: 474
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.4057313312183728
        entropy_coeff: 0.0
        kl: 0.006900185211138291
        model: {}
        policy_loss: -0.011274658651514486
        total_loss: 748.3431507457386
        vf_explained_var: 0.638849675655365
        vf_loss: 748.3537542169744
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.119444444444447
    gpu_util_percent0: 0.36111111111111116
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.755555555555556
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15469881596745194
    mean_env_wait_ms: 1.6778308283734265
    mean_inference_ms: 4.771366374067994
    mean_raw_obs_processing_ms: 0.40706119979284483
  time_since_restore: 62.906075954437256
  time_this_iter_s: 30.964881658554077
  time_total_s: 62.906075954437256
  timers:
    learn_throughput: 6974.46
    learn_time_ms: 23197.78
    sample_throughput: 19875.269
    sample_time_ms: 8140.368
    update_time_ms: 71.262
  timestamp: 1602252047
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |      2 |          62.9061 | 323584 |  239.068 |              279.505 |              155.414 |            533.907 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3831
    time_step_mean: 3476.724598930481
    time_step_min: 3162
  date: 2020-10-09_14-01-17
  done: false
  episode_len_mean: 533.4367088607595
  episode_reward_max: 286.929292929293
  episode_reward_mean: 240.05875207773946
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 316
  episodes_total: 790
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.397063287821683
        entropy_coeff: 0.0
        kl: 0.005955585786564784
        model: {}
        policy_loss: -0.01380472019875676
        total_loss: 176.46752652254972
        vf_explained_var: 0.8390511870384216
        vf_loss: 176.480732310902
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.565714285714282
    gpu_util_percent0: 0.3297142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15275084751773957
    mean_env_wait_ms: 1.6844497975187425
    mean_inference_ms: 4.672836107761753
    mean_raw_obs_processing_ms: 0.4020425199419138
  time_since_restore: 93.38371586799622
  time_this_iter_s: 30.47763991355896
  time_total_s: 93.38371586799622
  timers:
    learn_throughput: 6982.561
    learn_time_ms: 23170.867
    sample_throughput: 20595.406
    sample_time_ms: 7855.732
    update_time_ms: 55.815
  timestamp: 1602252077
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |      3 |          93.3837 | 485376 |  240.059 |              286.929 |              155.414 |            533.437 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3831
    time_step_mean: 3475.7377819548874
    time_step_min: 3162
  date: 2020-10-09_14-01-48
  done: false
  episode_len_mean: 533.5506329113924
  episode_reward_max: 287.0808080808076
  episode_reward_mean: 239.88548230953296
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 316
  episodes_total: 1106
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.3838633082129739
        entropy_coeff: 0.0
        kl: 0.006310357204215093
        model: {}
        policy_loss: -0.0029946926938877864
        total_loss: 87.36324587735263
        vf_explained_var: 0.9065824747085571
        vf_loss: 87.365610296076
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.01666666666667
    gpu_util_percent0: 0.3622222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775000000000001
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1514360059677624
    mean_env_wait_ms: 1.689408926658459
    mean_inference_ms: 4.603672731065159
    mean_raw_obs_processing_ms: 0.3982316937896282
  time_since_restore: 124.10386228561401
  time_this_iter_s: 30.720146417617798
  time_total_s: 124.10386228561401
  timers:
    learn_throughput: 6970.872
    learn_time_ms: 23209.723
    sample_throughput: 21002.337
    sample_time_ms: 7703.524
    update_time_ms: 64.345
  timestamp: 1602252108
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |      4 |          124.104 | 647168 |  239.885 |              287.081 |              155.414 |            533.551 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3831
    time_step_mean: 3474.1340579710145
    time_step_min: 3162
  date: 2020-10-09_14-02-19
  done: false
  episode_len_mean: 533.4542897327707
  episode_reward_max: 287.0808080808076
  episode_reward_mean: 240.4233047777352
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 316
  episodes_total: 1422
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.368765809319236
        entropy_coeff: 0.0
        kl: 0.006381339943883094
        model: {}
        policy_loss: -0.01008255783976479
        total_loss: 59.26996994018555
        vf_explained_var: 0.9346147775650024
        vf_loss: 59.2794154774059
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.86
    gpu_util_percent0: 0.3048571428571429
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142856
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15046687090651448
    mean_env_wait_ms: 1.6932497978763614
    mean_inference_ms: 4.552577282219411
    mean_raw_obs_processing_ms: 0.3953956116610121
  time_since_restore: 154.57825303077698
  time_this_iter_s: 30.474390745162964
  time_total_s: 154.57825303077698
  timers:
    learn_throughput: 6968.637
    learn_time_ms: 23217.167
    sample_throughput: 21320.634
    sample_time_ms: 7588.517
    update_time_ms: 59.595
  timestamp: 1602252139
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |      5 |          154.578 | 808960 |  240.423 |              287.081 |              155.414 |            533.454 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3869
    time_step_mean: 3462.807783018868
    time_step_min: 3162
  date: 2020-10-09_14-02-49
  done: false
  episode_len_mean: 533.3584579976985
  episode_reward_max: 287.0808080808076
  episode_reward_mean: 241.81910009182738
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 316
  episodes_total: 1738
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.3548793901096692
        entropy_coeff: 0.0
        kl: 0.007498216222633015
        model: {}
        policy_loss: -0.015204489315775309
        total_loss: 37.10323645851829
        vf_explained_var: 0.9551796317100525
        vf_loss: 37.11769173362038
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.299999999999997
    gpu_util_percent0: 0.3565714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857143
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1497109868949295
    mean_env_wait_ms: 1.6961531571289057
    mean_inference_ms: 4.513287755908082
    mean_raw_obs_processing_ms: 0.39321517648892074
  time_since_restore: 185.22691106796265
  time_this_iter_s: 30.64865803718567
  time_total_s: 185.22691106796265
  timers:
    learn_throughput: 6967.052
    learn_time_ms: 23222.448
    sample_throughput: 21459.087
    sample_time_ms: 7539.556
    update_time_ms: 57.924
  timestamp: 1602252169
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |      6 |          185.227 | 970752 |  241.819 |              287.081 |              155.414 |            533.358 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3869
    time_step_mean: 3453.4169980119286
    time_step_min: 3162
  date: 2020-10-09_14-03-20
  done: false
  episode_len_mean: 533.319376825706
  episode_reward_max: 287.0808080808076
  episode_reward_mean: 243.14502867034514
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 316
  episodes_total: 2054
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.3395666534250432
        entropy_coeff: 0.0
        kl: 0.006248738108710809
        model: {}
        policy_loss: -0.012656875378028913
        total_loss: 29.2696309523149
        vf_explained_var: 0.963606059551239
        vf_loss: 29.281663027676668
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.03611111111111
    gpu_util_percent0: 0.3252777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333337
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14910401662869924
    mean_env_wait_ms: 1.6982870030103812
    mean_inference_ms: 4.482105728366936
    mean_raw_obs_processing_ms: 0.3915040055887088
  time_since_restore: 215.68649411201477
  time_this_iter_s: 30.459583044052124
  time_total_s: 215.68649411201477
  timers:
    learn_throughput: 6975.557
    learn_time_ms: 23194.133
    sample_throughput: 21564.925
    sample_time_ms: 7502.553
    update_time_ms: 63.175
  timestamp: 1602252200
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |      7 |          215.686 | 1132544 |  243.145 |              287.081 |              155.414 |            533.319 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3869
    time_step_mean: 3445.716065292096
    time_step_min: 3137
  date: 2020-10-09_14-03-51
  done: false
  episode_len_mean: 533.3666666666667
  episode_reward_max: 290.717171717172
  episode_reward_mean: 244.3447768827516
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 316
  episodes_total: 2370
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.3237226551229304
        entropy_coeff: 0.0
        kl: 0.006206684195521203
        model: {}
        policy_loss: -0.012298170725857331
        total_loss: 23.847660411487926
        vf_explained_var: 0.9700092077255249
        vf_loss: 23.859338586980645
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.854285714285716
    gpu_util_percent0: 0.34685714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7942857142857145
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1486231816229204
    mean_env_wait_ms: 1.6999286719919944
    mean_inference_ms: 4.456678736813022
    mean_raw_obs_processing_ms: 0.39015867414881145
  time_since_restore: 246.24187588691711
  time_this_iter_s: 30.555381774902344
  time_total_s: 246.24187588691711
  timers:
    learn_throughput: 6976.565
    learn_time_ms: 23190.784
    sample_throughput: 21633.735
    sample_time_ms: 7478.69
    update_time_ms: 57.79
  timestamp: 1602252231
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |      8 |          246.242 | 1294336 |  244.345 |              290.717 |              155.414 |            533.367 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3869
    time_step_mean: 3436.2126371547483
    time_step_min: 3137
  date: 2020-10-09_14-04-21
  done: false
  episode_len_mean: 533.4446927374302
  episode_reward_max: 291.1717171717172
  episode_reward_mean: 245.7155352406749
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 315
  episodes_total: 2685
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.3094925988804211
        entropy_coeff: 0.0
        kl: 0.008637016300450672
        model: {}
        policy_loss: -0.017939656978176736
        total_loss: 23.353191895918414
        vf_explained_var: 0.9695344567298889
        vf_loss: 23.370267868041992
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.491666666666667
    gpu_util_percent0: 0.32861111111111113
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7861111111111114
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14821968210965727
    mean_env_wait_ms: 1.7011852509454328
    mean_inference_ms: 4.435485333505504
    mean_raw_obs_processing_ms: 0.3890569525070243
  time_since_restore: 276.8136646747589
  time_this_iter_s: 30.571788787841797
  time_total_s: 276.8136646747589
  timers:
    learn_throughput: 6980.129
    learn_time_ms: 23178.942
    sample_throughput: 21662.299
    sample_time_ms: 7468.829
    update_time_ms: 56.087
  timestamp: 1602252261
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |      9 |          276.814 | 1456128 |  245.716 |              291.172 |              155.414 |            533.445 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3869
    time_step_mean: 3428.6195468380115
    time_step_min: 3115
  date: 2020-10-09_14-04-52
  done: false
  episode_len_mean: 533.4484828276092
  episode_reward_max: 294.05050505050497
  episode_reward_mean: 246.92317978046557
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 314
  episodes_total: 2999
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.2910438559272073
        entropy_coeff: 0.0
        kl: 0.007647149984470822
        model: {}
        policy_loss: -0.006416853305629708
        total_loss: 21.108406587080523
        vf_explained_var: 0.9721044898033142
        vf_loss: 21.11405962163752
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.67777777777778
    gpu_util_percent0: 0.3419444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8000000000000003
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1478801425104045
    mean_env_wait_ms: 1.702164839121596
    mean_inference_ms: 4.417647283310146
    mean_raw_obs_processing_ms: 0.38814448604757723
  time_since_restore: 307.7144351005554
  time_this_iter_s: 30.90077042579651
  time_total_s: 307.7144351005554
  timers:
    learn_throughput: 6971.317
    learn_time_ms: 23208.239
    sample_throughput: 21703.049
    sample_time_ms: 7454.805
    update_time_ms: 54.569
  timestamp: 1602252292
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |     10 |          307.714 | 1617920 |  246.923 |              294.051 |              155.414 |            533.448 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3869
    time_step_mean: 3421.5446153846156
    time_step_min: 3115
  date: 2020-10-09_14-05-23
  done: false
  episode_len_mean: 533.3587484811665
  episode_reward_max: 294.05050505050497
  episode_reward_mean: 247.96458509763494
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 293
  episodes_total: 3292
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.2838217995383523
        entropy_coeff: 0.0
        kl: 0.007724557579918342
        model: {}
        policy_loss: -0.013594060501253063
        total_loss: 16.81612422249534
        vf_explained_var: 0.9771291613578796
        vf_loss: 16.82894620028409
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.834285714285713
    gpu_util_percent0: 0.37228571428571433
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.797142857142857
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1476122006553313
    mean_env_wait_ms: 1.702901418321913
    mean_inference_ms: 4.403467303246584
    mean_raw_obs_processing_ms: 0.38743606196543484
  time_since_restore: 338.37576723098755
  time_this_iter_s: 30.66133213043213
  time_total_s: 338.37576723098755
  timers:
    learn_throughput: 6984.676
    learn_time_ms: 23163.852
    sample_throughput: 21950.779
    sample_time_ms: 7370.672
    update_time_ms: 52.047
  timestamp: 1602252323
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |     11 |          338.376 | 1779712 |  247.965 |              294.051 |              155.414 |            533.359 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3869
    time_step_mean: 3415.7526152106307
    time_step_min: 3115
  date: 2020-10-09_14-05-54
  done: false
  episode_len_mean: 533.2084381112043
  episode_reward_max: 294.05050505050497
  episode_reward_mean: 248.83807056313344
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 287
  episodes_total: 3579
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.2656284137205644
        entropy_coeff: 0.0
        kl: 0.00639463152567094
        model: {}
        policy_loss: -0.012070076397239145
        total_loss: 18.601294604214754
        vf_explained_var: 0.973305881023407
        vf_loss: 18.61272517117587
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.180555555555554
    gpu_util_percent0: 0.2986111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8055555555555562
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14737489446738625
    mean_env_wait_ms: 1.7034544433402912
    mean_inference_ms: 4.391196765005525
    mean_raw_obs_processing_ms: 0.38680230019336637
  time_since_restore: 369.11932373046875
  time_this_iter_s: 30.7435564994812
  time_total_s: 369.11932373046875
  timers:
    learn_throughput: 6973.175
    learn_time_ms: 23202.058
    sample_throughput: 22119.074
    sample_time_ms: 7314.592
    update_time_ms: 46.865
  timestamp: 1602252354
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |     12 |          369.119 | 1941504 |  248.838 |              294.051 |              155.414 |            533.208 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3869
    time_step_mean: 3411.586414896407
    time_step_min: 3115
  date: 2020-10-09_14-06-25
  done: false
  episode_len_mean: 533.0565499351492
  episode_reward_max: 294.05050505050497
  episode_reward_mean: 249.50670125378295
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 276
  episodes_total: 3855
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.2511377876455134
        entropy_coeff: 0.0
        kl: 0.007038203787735917
        model: {}
        policy_loss: -0.009672184257810428
        total_loss: 16.58900581706654
        vf_explained_var: 0.9759765863418579
        vf_loss: 16.597974517128684
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.016666666666666
    gpu_util_percent0: 0.2894444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7972222222222234
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14716511971447685
    mean_env_wait_ms: 1.7037207680908488
    mean_inference_ms: 4.380591501408815
    mean_raw_obs_processing_ms: 0.3862487398605462
  time_since_restore: 400.068243265152
  time_this_iter_s: 30.948919534683228
  time_total_s: 400.068243265152
  timers:
    learn_throughput: 6964.32
    learn_time_ms: 23231.557
    sample_throughput: 22074.979
    sample_time_ms: 7329.203
    update_time_ms: 48.349
  timestamp: 1602252385
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |     13 |          400.068 | 2103296 |  249.507 |              294.051 |              155.414 |            533.057 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3869
    time_step_mean: 3406.569163210539
    time_step_min: 3115
  date: 2020-10-09_14-06-56
  done: false
  episode_len_mean: 533.0137647911132
  episode_reward_max: 294.05050505050497
  episode_reward_mean: 250.3002397800756
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 286
  episodes_total: 4141
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.2354369271885266
        entropy_coeff: 0.0
        kl: 0.007028599185022441
        model: {}
        policy_loss: -0.006014510819857771
        total_loss: 17.08614141290838
        vf_explained_var: 0.9748998880386353
        vf_loss: 17.091453292153098
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.897142857142857
    gpu_util_percent0: 0.38628571428571434
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14697641846517812
    mean_env_wait_ms: 1.7038830728300087
    mean_inference_ms: 4.370742446950562
    mean_raw_obs_processing_ms: 0.38571541433611933
  time_since_restore: 430.4829089641571
  time_this_iter_s: 30.414665699005127
  time_total_s: 430.4829089641571
  timers:
    learn_throughput: 6974.23
    learn_time_ms: 23198.546
    sample_throughput: 22053.565
    sample_time_ms: 7336.32
    update_time_ms: 43.666
  timestamp: 1602252416
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |     14 |          430.483 | 2265088 |    250.3 |              294.051 |              155.414 |            533.014 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3869
    time_step_mean: 3402.1277853569804
    time_step_min: 3115
  date: 2020-10-09_14-07-26
  done: false
  episode_len_mean: 532.8662162162162
  episode_reward_max: 294.05050505050497
  episode_reward_mean: 251.01965601965603
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 299
  episodes_total: 4440
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.2277861833572388
        entropy_coeff: 0.0
        kl: 0.006500624162568288
        model: {}
        policy_loss: -0.005067531389861621
        total_loss: 15.261276245117188
        vf_explained_var: 0.9786954522132874
        vf_loss: 15.265694011341441
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.605555555555558
    gpu_util_percent0: 0.4394444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7861111111111123
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14679792684511558
    mean_env_wait_ms: 1.7040216781615347
    mean_inference_ms: 4.361440568159238
    mean_raw_obs_processing_ms: 0.3852156078894924
  time_since_restore: 461.01817870140076
  time_this_iter_s: 30.535269737243652
  time_total_s: 461.01817870140076
  timers:
    learn_throughput: 6974.692
    learn_time_ms: 23197.009
    sample_throughput: 22036.734
    sample_time_ms: 7341.923
    update_time_ms: 43.859
  timestamp: 1602252446
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |     15 |          461.018 | 2426880 |   251.02 |              294.051 |              155.414 |            532.866 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3869
    time_step_mean: 3397.7765731292516
    time_step_min: 3115
  date: 2020-10-09_14-07-57
  done: false
  episode_len_mean: 532.7197640117994
  episode_reward_max: 294.05050505050497
  episode_reward_mean: 251.77282943212148
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 306
  episodes_total: 4746
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.2151403752240268
        entropy_coeff: 0.0
        kl: 0.007618674500422044
        model: {}
        policy_loss: -0.00804092265157537
        total_loss: 15.841158606789328
        vf_explained_var: 0.9775257706642151
        vf_loss: 15.848437482660467
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.385714285714286
    gpu_util_percent0: 0.2822857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.791428571428572
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1466239797747957
    mean_env_wait_ms: 1.7041312997712612
    mean_inference_ms: 4.352595886118709
    mean_raw_obs_processing_ms: 0.38472547011104913
  time_since_restore: 491.5100169181824
  time_this_iter_s: 30.491838216781616
  time_total_s: 491.5100169181824
  timers:
    learn_throughput: 6975.777
    learn_time_ms: 23193.403
    sample_throughput: 22075.224
    sample_time_ms: 7329.122
    update_time_ms: 43.222
  timestamp: 1602252477
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |     16 |           491.51 | 2588672 |  251.773 |              294.051 |              155.414 |             532.72 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3972
    time_step_mean: 3392.583250249252
    time_step_min: 3115
  date: 2020-10-09_14-08-27
  done: false
  episode_len_mean: 532.6343682024916
  episode_reward_max: 294.05050505050497
  episode_reward_mean: 252.47701855413942
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 311
  episodes_total: 5057
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.2003130262548274
        entropy_coeff: 0.0
        kl: 0.0070174436762251635
        model: {}
        policy_loss: -0.014499883315610614
        total_loss: 17.864229895851828
        vf_explained_var: 0.975391149520874
        vf_loss: 17.878027655861594
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.651428571428575
    gpu_util_percent0: 0.3411428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7885714285714283
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1464689357547198
    mean_env_wait_ms: 1.7042261262185285
    mean_inference_ms: 4.344487379470365
    mean_raw_obs_processing_ms: 0.38427866141717926
  time_since_restore: 521.9545061588287
  time_this_iter_s: 30.444489240646362
  time_total_s: 521.9545061588287
  timers:
    learn_throughput: 6973.444
    learn_time_ms: 23201.16
    sample_throughput: 22088.945
    sample_time_ms: 7324.569
    update_time_ms: 37.87
  timestamp: 1602252507
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |     17 |          521.955 | 2750464 |  252.477 |              294.051 |              155.414 |            532.634 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3972
    time_step_mean: 3388.5014068655037
    time_step_min: 3115
  date: 2020-10-09_14-08-58
  done: false
  episode_len_mean: 532.5274520751908
  episode_reward_max: 295.5656565656567
  episode_reward_mean: 253.10830809490778
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 316
  episodes_total: 5373
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1784665801308372
        entropy_coeff: 0.0
        kl: 0.007377536882731048
        model: {}
        policy_loss: -0.011685685868459668
        total_loss: 16.378832296891645
        vf_explained_var: 0.9778797626495361
        vf_loss: 16.38978030464866
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.933333333333337
    gpu_util_percent0: 0.36361111111111105
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7805555555555563
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14632459699932765
    mean_env_wait_ms: 1.704333856748477
    mean_inference_ms: 4.336969722857954
    mean_raw_obs_processing_ms: 0.3838656298159948
  time_since_restore: 552.3888156414032
  time_this_iter_s: 30.434309482574463
  time_total_s: 552.3888156414032
  timers:
    learn_throughput: 6976.847
    learn_time_ms: 23189.844
    sample_throughput: 22124.598
    sample_time_ms: 7312.766
    update_time_ms: 46.971
  timestamp: 1602252538
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |     18 |          552.389 | 2912256 |  253.108 |              295.566 |              155.414 |            532.527 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3972
    time_step_mean: 3384.15302869288
    time_step_min: 3115
  date: 2020-10-09_14-09-29
  done: false
  episode_len_mean: 532.3762306610408
  episode_reward_max: 295.5656565656567
  episode_reward_mean: 253.75986127093725
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 315
  episodes_total: 5688
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1598864685405383
        entropy_coeff: 0.0
        kl: 0.007244374730031599
        model: {}
        policy_loss: -0.0132050701120699
        total_loss: 16.083130402998492
        vf_explained_var: 0.9781112670898438
        vf_loss: 16.09561096538197
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.48857142857143
    gpu_util_percent0: 0.2654285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.791428571428572
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14619280651609548
    mean_env_wait_ms: 1.7044530450912685
    mean_inference_ms: 4.3300713254906915
    mean_raw_obs_processing_ms: 0.38349213558823353
  time_since_restore: 583.047269821167
  time_this_iter_s: 30.658454179763794
  time_total_s: 583.047269821167
  timers:
    learn_throughput: 6969.778
    learn_time_ms: 23213.366
    sample_throughput: 22175.271
    sample_time_ms: 7296.055
    update_time_ms: 47.072
  timestamp: 1602252569
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | RUNNING  | 172.17.0.4:80831 |     19 |          583.047 | 3074048 |   253.76 |              295.566 |              155.414 |            532.376 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aaf69_00000:
  custom_metrics:
    time_step_max: 3972
    time_step_mean: 3379.254444817175
    time_step_min: 3115
  date: 2020-10-09_14-10-00
  done: true
  episode_len_mean: 532.2260159893405
  episode_reward_max: 295.5656565656567
  episode_reward_mean: 254.4404471093345
  episode_reward_min: 155.41414141414134
  episodes_this_iter: 316
  episodes_total: 6004
  experiment_id: c1d413a21af8445293390651c5f2495a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1448364908044988
        entropy_coeff: 0.0
        kl: 0.008506301197816025
        model: {}
        policy_loss: -0.010588546785584185
        total_loss: 16.21653513474898
        vf_explained_var: 0.9770536422729492
        vf_loss: 16.22627318989147
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.352777777777778
    gpu_util_percent0: 0.29750000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.794444444444446
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 80831
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14607213940975733
    mean_env_wait_ms: 1.7045792549408296
    mean_inference_ms: 4.3236820016622755
    mean_raw_obs_processing_ms: 0.3831491626071145
  time_since_restore: 614.0868623256683
  time_this_iter_s: 31.039592504501343
  time_total_s: 614.0868623256683
  timers:
    learn_throughput: 6963.918
    learn_time_ms: 23232.899
    sample_throughput: 22191.69
    sample_time_ms: 7290.657
    update_time_ms: 45.572
  timestamp: 1602252600
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: aaf69_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | TERMINATED |       |     20 |          614.087 | 3235840 |   254.44 |              295.566 |              155.414 |            532.226 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aaf69_00000 | TERMINATED |       |     20 |          614.087 | 3235840 |   254.44 |              295.566 |              155.414 |            532.226 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


2020-10-09 14:10:00,785	WARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffffefbd9801000000.
[2m[36m(pid=80823)[0m 2020-10-09 14:10:00,766	ERROR worker.py:372 -- SystemExit was raised from the worker
[2m[36m(pid=80823)[0m Traceback (most recent call last):
[2m[36m(pid=80823)[0m   File "python/ray/_raylet.pyx", line 553, in ray._raylet.task_execution_handler
[2m[36m(pid=80823)[0m   File "python/ray/_raylet.pyx", line 440, in ray._raylet.execute_task
[2m[36m(pid=80823)[0m   File "python/ray/_raylet.pyx", line 479, in ray._raylet.execute_task
[2m[36m(pid=80823)[0m   File "python/ray/_raylet.pyx", line 483, in ray._raylet.execute_task
[2m[36m(pid=80823)[0m   File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
[2m[36m(pid=80823)[0m   File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
[2m[36m(pid=80823)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/function_manager.py", line 553, in actor_method_executor
[2m[36m(pid=80823)[0m     return method(actor, *args, **kwargs)
[2m[36m(pid=80823)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/actor.py", line 929, in __ray_terminate__
[2m[36m(pid=80823)[0m     ray.actor.exit_actor()
[2m[36m(pid=80823)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/actor.py", line 991, in exit_actor
[2m[36m(pid=80823)[0m     ray.state.state.disconnect()
[2m[36m(pid=80823)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/state.py", line 60, in disconnect
[2m[36m(pid=80823)[0m     self.global_state_accessor.disconnect()
[2m[36m(pid=80823)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/worker.py", line 369, in sigterm_handler
[2m[36m(pid=80823)[0m     sys.exit(1)
[2m[36m(pid=80823)[0m SystemExit: 1
