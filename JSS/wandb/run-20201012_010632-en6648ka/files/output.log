2020-10-12 01:06:35,990	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_2d923_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=8465)[0m 2020-10-12 01:06:38,689	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=8429)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8429)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8468)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8468)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8462)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8462)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8466)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8466)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8363)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8363)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8361)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8361)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8346)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8346)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8474)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8474)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8369)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8369)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8350)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8350)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8464)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8464)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8443)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8443)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8455)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8455)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8409)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8409)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8364)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8364)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8368)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8368)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8412)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8412)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8441)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8441)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8345)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8345)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8447)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8447)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8421)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8421)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8348)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8348)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8454)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8454)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8459)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8459)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8417)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8417)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8478)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8478)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8430)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8430)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8445)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8445)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8360)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8360)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8433)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8433)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8349)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8349)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8427)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8427)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8439)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8439)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8470)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8470)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8419)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8419)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8365)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8365)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8353)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8353)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8418)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8418)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8463)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8463)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8425)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8425)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8358)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8358)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8415)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8415)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8438)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8438)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8457)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8457)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8472)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8472)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8414)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8414)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8420)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8420)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8431)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8431)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8423)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8423)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8362)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8362)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8356)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8356)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8424)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8424)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8357)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8357)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8366)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8366)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8347)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8347)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8422)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8422)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8410)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8410)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8372)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8372)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8426)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8426)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8370)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8370)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8416)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8416)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8378)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8378)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8413)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8413)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8377)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8377)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8371)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8371)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8355)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8355)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8352)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8352)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8367)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8367)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8374)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8374)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=8432)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=8432)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_01-07-12
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1767964959144592
        entropy_coeff: 0.0001
        kl: 0.01263958215713501
        model: {}
        policy_loss: -0.009614835051858487
        total_loss: 507.07483164469403
        vf_explained_var: 0.540532648563385
        vf_loss: 507.0832926432292
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.811428571428568
    gpu_util_percent0: 0.262
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5571428571428574
    vram_util_percent0: 0.08551047181745773
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16776733834201002
    mean_env_wait_ms: 1.168843469858243
    mean_inference_ms: 5.7580520857186475
    mean_raw_obs_processing_ms: 0.44959608291762587
  time_since_restore: 28.33779239654541
  time_this_iter_s: 28.33779239654541
  time_total_s: 28.33779239654541
  timers:
    learn_throughput: 8401.403
    learn_time_ms: 19257.736
    sample_throughput: 17944.038
    sample_time_ms: 9016.477
    update_time_ms: 32.864
  timestamp: 1602464832
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |      1 |          28.3378 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3625.0520833333335
    time_step_min: 3330
  date: 2020-10-12_01-07-39
  done: false
  episode_len_mean: 891.1740506329114
  episode_reward_max: 261.4747474747477
  episode_reward_mean: 214.95576013297512
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1391337017218273
        entropy_coeff: 0.0001
        kl: 0.016295223341633875
        model: {}
        policy_loss: -0.012537292988175372
        total_loss: 141.4903678894043
        vf_explained_var: 0.7995468974113464
        vf_loss: 141.5013885498047
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.653125000000003
    gpu_util_percent0: 0.3225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.75625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1633261232155548
    mean_env_wait_ms: 1.1655079614464003
    mean_inference_ms: 5.498364281996561
    mean_raw_obs_processing_ms: 0.43729047470698823
  time_since_restore: 54.94073295593262
  time_this_iter_s: 26.602940559387207
  time_total_s: 54.94073295593262
  timers:
    learn_throughput: 8451.73
    learn_time_ms: 19143.064
    sample_throughput: 19588.438
    sample_time_ms: 8259.566
    update_time_ms: 26.806
  timestamp: 1602464859
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |      2 |          54.9407 | 323584 |  214.956 |              261.475 |              128.596 |            891.174 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3626.4887892376682
    time_step_min: 3290
  date: 2020-10-12_01-08-05
  done: false
  episode_len_mean: 886.0253164556962
  episode_reward_max: 267.5353535353534
  episode_reward_mean: 215.7529727656308
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1252431273460388
        entropy_coeff: 0.0001
        kl: 0.018957633680353563
        model: {}
        policy_loss: -0.015984986093826592
        total_loss: 61.0221160252889
        vf_explained_var: 0.9007654190063477
        vf_loss: 61.03631718953451
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.143749999999997
    gpu_util_percent0: 0.3103125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1604980968185966
    mean_env_wait_ms: 1.1652348957873904
    mean_inference_ms: 5.31252901880141
    mean_raw_obs_processing_ms: 0.42872421711388087
  time_since_restore: 81.68346810340881
  time_this_iter_s: 26.742735147476196
  time_total_s: 81.68346810340881
  timers:
    learn_throughput: 8395.599
    learn_time_ms: 19271.049
    sample_throughput: 20549.269
    sample_time_ms: 7873.37
    update_time_ms: 32.187
  timestamp: 1602464885
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |      3 |          81.6835 | 485376 |  215.753 |              267.535 |              128.596 |            886.025 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3616.7367549668875
    time_step_min: 3290
  date: 2020-10-12_01-08-32
  done: false
  episode_len_mean: 881.3386075949367
  episode_reward_max: 267.5353535353534
  episode_reward_mean: 216.93408771256858
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0986024836699169
        entropy_coeff: 0.0001
        kl: 0.01563542227571209
        model: {}
        policy_loss: -0.014506756172825893
        total_loss: 43.91647815704346
        vf_explained_var: 0.9264408946037292
        vf_loss: 43.92953109741211
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.940624999999997
    gpu_util_percent0: 0.27468750000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1585219754295648
    mean_env_wait_ms: 1.1657956972993282
    mean_inference_ms: 5.178449731694735
    mean_raw_obs_processing_ms: 0.4223232281761027
  time_since_restore: 107.97444653511047
  time_this_iter_s: 26.29097843170166
  time_total_s: 107.97444653511047
  timers:
    learn_throughput: 8400.039
    learn_time_ms: 19260.864
    sample_throughput: 21152.887
    sample_time_ms: 7648.696
    update_time_ms: 33.169
  timestamp: 1602464912
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |      4 |          107.974 | 647168 |  216.934 |              267.535 |              128.596 |            881.339 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4145
    time_step_mean: 3608.2332896461335
    time_step_min: 3290
  date: 2020-10-12_01-08-58
  done: false
  episode_len_mean: 874.417193426043
  episode_reward_max: 267.5353535353534
  episode_reward_mean: 218.94706866388267
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 159
  episodes_total: 791
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0436101357142131
        entropy_coeff: 0.0001
        kl: 0.016446901485323906
        model: {}
        policy_loss: -0.014361151998552183
        total_loss: 32.676722049713135
        vf_explained_var: 0.9506146907806396
        vf_loss: 32.6895432472229
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.990625
    gpu_util_percent0: 0.3246875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15707544597799833
    mean_env_wait_ms: 1.1678228410955813
    mean_inference_ms: 5.07708676818911
    mean_raw_obs_processing_ms: 0.4173292337607439
  time_since_restore: 133.9839973449707
  time_this_iter_s: 26.00955080986023
  time_total_s: 133.9839973449707
  timers:
    learn_throughput: 8420.539
    learn_time_ms: 19213.971
    sample_throughput: 21573.187
    sample_time_ms: 7499.68
    update_time_ms: 32.063
  timestamp: 1602464938
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |      5 |          133.984 | 808960 |  218.947 |              267.535 |              128.596 |            874.417 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3596.1706864564007
    time_step_min: 3290
  date: 2020-10-12_01-09-24
  done: false
  episode_len_mean: 860.8354430379746
  episode_reward_max: 267.9898989898982
  episode_reward_mean: 220.97937786545367
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 315
  episodes_total: 1106
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0351270337899525
        entropy_coeff: 0.0001
        kl: 0.015771994677682716
        model: {}
        policy_loss: -0.010413421783596277
        total_loss: 32.19759098688761
        vf_explained_var: 0.9626547694206238
        vf_loss: 32.20653041203817
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.59032258064516
    gpu_util_percent0: 0.334516129032258
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15515538935286008
    mean_env_wait_ms: 1.1731318638438044
    mean_inference_ms: 4.942227537276689
    mean_raw_obs_processing_ms: 0.41090589776265074
  time_since_restore: 160.09370708465576
  time_this_iter_s: 26.10970973968506
  time_total_s: 160.09370708465576
  timers:
    learn_throughput: 8426.213
    learn_time_ms: 19201.034
    sample_throughput: 21863.915
    sample_time_ms: 7399.955
    update_time_ms: 30.201
  timestamp: 1602464964
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |      6 |          160.094 | 970752 |  220.979 |               267.99 |              128.596 |            860.835 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3585.8381877022653
    time_step_min: 3290
  date: 2020-10-12_01-09-50
  done: false
  episode_len_mean: 854.3473101265823
  episode_reward_max: 275.56565656565664
  episode_reward_mean: 222.60967267612827
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0033620248238246
        entropy_coeff: 0.0001
        kl: 0.015898818848654628
        model: {}
        policy_loss: -0.01447581589066734
        total_loss: 20.10945479075114
        vf_explained_var: 0.9643989205360413
        vf_loss: 20.122440973917644
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.999999999999996
    gpu_util_percent0: 0.38483870967741945
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1544556884482299
    mean_env_wait_ms: 1.1755923520629141
    mean_inference_ms: 4.893408955486199
    mean_raw_obs_processing_ms: 0.408538909420635
  time_since_restore: 185.96739053726196
  time_this_iter_s: 25.8736834526062
  time_total_s: 185.96739053726196
  timers:
    learn_throughput: 8441.48
    learn_time_ms: 19166.306
    sample_throughput: 22100.271
    sample_time_ms: 7320.815
    update_time_ms: 29.053
  timestamp: 1602464990
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |      7 |          185.967 | 1132544 |   222.61 |              275.566 |              128.596 |            854.347 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3574.5659971305595
    time_step_min: 3257
  date: 2020-10-12_01-10-16
  done: false
  episode_len_mean: 848.6132208157525
  episode_reward_max: 277.9898989898989
  episode_reward_mean: 224.1129437838298
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9827794680992762
        entropy_coeff: 0.0001
        kl: 0.013033068428436915
        model: {}
        policy_loss: -0.014622460507477323
        total_loss: 19.91641330718994
        vf_explained_var: 0.9618073105812073
        vf_loss: 19.929830233256023
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.85
    gpu_util_percent0: 0.2940625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15384664461651076
    mean_env_wait_ms: 1.1779735086236518
    mean_inference_ms: 4.851037960284149
    mean_raw_obs_processing_ms: 0.4064181771411752
  time_since_restore: 211.92199206352234
  time_this_iter_s: 25.954601526260376
  time_total_s: 211.92199206352234
  timers:
    learn_throughput: 8449.193
    learn_time_ms: 19148.81
    sample_throughput: 22281.937
    sample_time_ms: 7261.128
    update_time_ms: 29.615
  timestamp: 1602465016
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |      8 |          211.922 | 1294336 |  224.113 |               277.99 |              128.596 |            848.613 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3560.472955974843
    time_step_min: 3183
  date: 2020-10-12_01-10-42
  done: false
  episode_len_mean: 843.5908529048207
  episode_reward_max: 283.74747474747454
  episode_reward_mean: 226.21282665967453
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 196
  episodes_total: 1618
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9249962766965231
        entropy_coeff: 0.0001
        kl: 0.013993104143689076
        model: {}
        policy_loss: -0.013552097215627631
        total_loss: 17.59092919031779
        vf_explained_var: 0.9732310771942139
        vf_loss: 17.603174209594727
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.329032258064515
    gpu_util_percent0: 0.34483870967741936
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1531814496663626
    mean_env_wait_ms: 1.1809005572732676
    mean_inference_ms: 4.8061904293948094
    mean_raw_obs_processing_ms: 0.40412383142319347
  time_since_restore: 237.9688069820404
  time_this_iter_s: 26.046814918518066
  time_total_s: 237.9688069820404
  timers:
    learn_throughput: 8448.538
    learn_time_ms: 19150.295
    sample_throughput: 22439.918
    sample_time_ms: 7210.009
    update_time_ms: 28.941
  timestamp: 1602465042
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |      9 |          237.969 | 1456128 |  226.213 |              283.747 |              128.596 |            843.591 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3543.2928265524624
    time_step_min: 3183
  date: 2020-10-12_01-11-08
  done: false
  episode_len_mean: 838.6028481012659
  episode_reward_max: 287.2323232323231
  episode_reward_mean: 228.72853535353528
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 278
  episodes_total: 1896
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9178415189186732
        entropy_coeff: 0.0001
        kl: 0.014521399280056357
        model: {}
        policy_loss: -0.011789818954033157
        total_loss: 13.876439015070597
        vf_explained_var: 0.9792876839637756
        vf_loss: 13.886868635813395
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.65
    gpu_util_percent0: 0.315
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15245166759418688
    mean_env_wait_ms: 1.1843893740515044
    mean_inference_ms: 4.754762108220247
    mean_raw_obs_processing_ms: 0.40156280717779835
  time_since_restore: 264.2311809062958
  time_this_iter_s: 26.26237392425537
  time_total_s: 264.2311809062958
  timers:
    learn_throughput: 8441.477
    learn_time_ms: 19166.314
    sample_throughput: 22550.668
    sample_time_ms: 7174.599
    update_time_ms: 30.081
  timestamp: 1602465068
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |     10 |          264.231 | 1617920 |  228.729 |              287.232 |              128.596 |            838.603 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3535.993089832182
    time_step_min: 3183
  date: 2020-10-12_01-11-35
  done: false
  episode_len_mean: 836.0842259006816
  episode_reward_max: 287.2323232323231
  episode_reward_mean: 229.99847058707815
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8869168112675349
        entropy_coeff: 0.0001
        kl: 0.014199987441922227
        model: {}
        policy_loss: -0.01139706582762301
        total_loss: 10.883146603902182
        vf_explained_var: 0.9792971014976501
        vf_loss: 10.893212080001831
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.662499999999998
    gpu_util_percent0: 0.3921875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1520945769067054
    mean_env_wait_ms: 1.1860850636603661
    mean_inference_ms: 4.73017548706449
    mean_raw_obs_processing_ms: 0.40031238746583925
  time_since_restore: 290.4084322452545
  time_this_iter_s: 26.17725133895874
  time_total_s: 290.4084322452545
  timers:
    learn_throughput: 8439.327
    learn_time_ms: 19171.196
    sample_throughput: 23274.016
    sample_time_ms: 6951.615
    update_time_ms: 29.794
  timestamp: 1602465095
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |     11 |          290.408 | 1779712 |  229.998 |              287.232 |              128.596 |            836.084 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3528.6675824175823
    time_step_min: 3183
  date: 2020-10-12_01-12-01
  done: false
  episode_len_mean: 833.9796564195299
  episode_reward_max: 287.2323232323231
  episode_reward_mean: 231.18103275065295
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8576548546552658
        entropy_coeff: 0.0001
        kl: 0.01188174239359796
        model: {}
        policy_loss: -0.013003805147794386
        total_loss: 11.322892824808756
        vf_explained_var: 0.9773592948913574
        vf_loss: 11.334794521331787
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.13225806451613
    gpu_util_percent0: 0.33709677419354833
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15177253295002424
    mean_env_wait_ms: 1.1876340583799172
    mean_inference_ms: 4.7080481074712095
    mean_raw_obs_processing_ms: 0.3991508637526763
  time_since_restore: 316.67616868019104
  time_this_iter_s: 26.267736434936523
  time_total_s: 316.67616868019104
  timers:
    learn_throughput: 8429.965
    learn_time_ms: 19192.488
    sample_throughput: 23462.208
    sample_time_ms: 6895.856
    update_time_ms: 30.024
  timestamp: 1602465121
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |     12 |          316.676 | 1941504 |  231.181 |              287.232 |              128.596 |             833.98 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3516.861955628595
    time_step_min: 3183
  date: 2020-10-12_01-12-28
  done: false
  episode_len_mean: 831.1035743298131
  episode_reward_max: 287.2323232323231
  episode_reward_mean: 233.146583626681
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 250
  episodes_total: 2462
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8087696780761083
        entropy_coeff: 0.0001
        kl: 0.013298001838847995
        model: {}
        policy_loss: -0.011577495587213585
        total_loss: 16.399420181910198
        vf_explained_var: 0.9766891598701477
        vf_loss: 16.409748315811157
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.446875
    gpu_util_percent0: 0.26468749999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7687500000000003
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15131609167641555
    mean_env_wait_ms: 1.1899119560861549
    mean_inference_ms: 4.677606861550691
    mean_raw_obs_processing_ms: 0.397562269567555
  time_since_restore: 343.1395585536957
  time_this_iter_s: 26.46338987350464
  time_total_s: 343.1395585536957
  timers:
    learn_throughput: 8432.706
    learn_time_ms: 19186.25
    sample_throughput: 23526.577
    sample_time_ms: 6876.989
    update_time_ms: 28.233
  timestamp: 1602465148
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |     13 |           343.14 | 2103296 |  233.147 |              287.232 |              128.596 |            831.104 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3506.9292701279155
    time_step_min: 3183
  date: 2020-10-12_01-12-54
  done: false
  episode_len_mean: 829.9322412509307
  episode_reward_max: 287.2323232323231
  episode_reward_mean: 234.6693141391577
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 224
  episodes_total: 2686
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7972748031218847
        entropy_coeff: 0.0001
        kl: 0.012066885518531004
        model: {}
        policy_loss: -0.01203015421439583
        total_loss: 11.252704779307047
        vf_explained_var: 0.9807917475700378
        vf_loss: 11.263607819875082
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.290625
    gpu_util_percent0: 0.3390625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15098308110222985
    mean_env_wait_ms: 1.1915353585857706
    mean_inference_ms: 4.653963176251371
    mean_raw_obs_processing_ms: 0.3963566210730421
  time_since_restore: 369.34619760513306
  time_this_iter_s: 26.206639051437378
  time_total_s: 369.34619760513306
  timers:
    learn_throughput: 8436.117
    learn_time_ms: 19178.492
    sample_throughput: 23527.315
    sample_time_ms: 6876.773
    update_time_ms: 27.078
  timestamp: 1602465174
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |     14 |          369.346 | 2265088 |  234.669 |              287.232 |              128.596 |            829.932 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3500.012784090909
    time_step_min: 3183
  date: 2020-10-12_01-13-20
  done: false
  episode_len_mean: 828.4989451476794
  episode_reward_max: 287.2323232323231
  episode_reward_mean: 235.78381920470522
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7762151261170706
        entropy_coeff: 0.0001
        kl: 0.01208118605427444
        model: {}
        policy_loss: -0.011558594085120907
        total_loss: 9.857942899068197
        vf_explained_var: 0.9792948365211487
        vf_loss: 9.868370850880941
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.438709677419357
    gpu_util_percent0: 0.3583870967741935
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783870967741935
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1507662095362239
    mean_env_wait_ms: 1.1925844445317904
    mean_inference_ms: 4.639063427397945
    mean_raw_obs_processing_ms: 0.3955841423020196
  time_since_restore: 395.1558327674866
  time_this_iter_s: 25.809635162353516
  time_total_s: 395.1558327674866
  timers:
    learn_throughput: 8440.795
    learn_time_ms: 19167.862
    sample_throughput: 23564.192
    sample_time_ms: 6866.011
    update_time_ms: 27.683
  timestamp: 1602465200
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |     15 |          395.156 | 2426880 |  235.784 |              287.232 |              128.596 |            828.499 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3492.782797858099
    time_step_min: 3183
  date: 2020-10-12_01-13-46
  done: false
  episode_len_mean: 826.8173076923077
  episode_reward_max: 287.2323232323231
  episode_reward_mean: 236.88282359403047
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 172
  episodes_total: 3016
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7374959240357081
        entropy_coeff: 0.0001
        kl: 0.010634501619885365
        model: {}
        policy_loss: -0.013188904073710242
        total_loss: 11.342817147572836
        vf_explained_var: 0.9777500033378601
        vf_loss: 11.355016469955444
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.612903225806456
    gpu_util_percent0: 0.33645161290322584
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15054341347363656
    mean_env_wait_ms: 1.1937055508099634
    mean_inference_ms: 4.624052698808522
    mean_raw_obs_processing_ms: 0.3947856771345266
  time_since_restore: 420.92763233184814
  time_this_iter_s: 25.771799564361572
  time_total_s: 420.92763233184814
  timers:
    learn_throughput: 8456.133
    learn_time_ms: 19133.096
    sample_throughput: 23584.925
    sample_time_ms: 6859.975
    update_time_ms: 27.61
  timestamp: 1602465226
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |     16 |          420.928 | 2588672 |  236.883 |              287.232 |              128.596 |            826.817 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3482.887086903305
    time_step_min: 3183
  date: 2020-10-12_01-14-12
  done: false
  episode_len_mean: 824.2945995145631
  episode_reward_max: 287.2323232323231
  episode_reward_mean: 238.4553851623026
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 280
  episodes_total: 3296
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7092584123214086
        entropy_coeff: 0.0001
        kl: 0.01076288684271276
        model: {}
        policy_loss: -0.010383333147425825
        total_loss: 12.785799344380697
        vf_explained_var: 0.9805514216423035
        vf_loss: 12.795177459716797
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.351612903225806
    gpu_util_percent0: 0.3045161290322581
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15022970045728007
    mean_env_wait_ms: 1.1953918313454988
    mean_inference_ms: 4.602413006780591
    mean_raw_obs_processing_ms: 0.39367264869165036
  time_since_restore: 446.9989790916443
  time_this_iter_s: 26.071346759796143
  time_total_s: 446.9989790916443
  timers:
    learn_throughput: 8452.592
    learn_time_ms: 19141.11
    sample_throughput: 23557.777
    sample_time_ms: 6867.88
    update_time_ms: 29.054
  timestamp: 1602465252
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |     17 |          446.999 | 2750464 |  238.455 |              287.232 |              128.596 |            824.295 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3476.575116009281
    time_step_min: 3183
  date: 2020-10-12_01-14-38
  done: false
  episode_len_mean: 822.8144418872267
  episode_reward_max: 288.44444444444434
  episode_reward_mean: 239.42371354511744
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 180
  episodes_total: 3476
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.6950379560391108
        entropy_coeff: 0.0001
        kl: 0.010578197194263339
        model: {}
        policy_loss: -0.01011715704225935
        total_loss: 8.300967375437418
        vf_explained_var: 0.9830548763275146
        vf_loss: 8.310096502304077
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.009677419354844
    gpu_util_percent0: 0.36258064516129035
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15004489327959136
    mean_env_wait_ms: 1.196328421325281
    mean_inference_ms: 4.5896652098849495
    mean_raw_obs_processing_ms: 0.3930072610424162
  time_since_restore: 472.54093766212463
  time_this_iter_s: 25.541958570480347
  time_total_s: 472.54093766212463
  timers:
    learn_throughput: 8466.375
    learn_time_ms: 19109.95
    sample_throughput: 23592.864
    sample_time_ms: 6857.667
    update_time_ms: 28.071
  timestamp: 1602465278
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |     18 |          472.541 | 2912256 |  239.424 |              288.444 |              128.596 |            822.814 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3470.959523149432
    time_step_min: 3183
  date: 2020-10-12_01-15-04
  done: false
  episode_len_mean: 821.5279229711142
  episode_reward_max: 288.44444444444434
  episode_reward_mean: 240.2092729217901
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 159
  episodes_total: 3635
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.6826299875974655
        entropy_coeff: 0.0001
        kl: 0.010139216979344686
        model: {}
        policy_loss: -0.011945712817578169
        total_loss: 10.196185032526651
        vf_explained_var: 0.9778048992156982
        vf_loss: 10.20718510945638
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.338709677419356
    gpu_util_percent0: 0.38258064516129037
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14989323573296232
    mean_env_wait_ms: 1.197155497307612
    mean_inference_ms: 4.579258122298553
    mean_raw_obs_processing_ms: 0.3924623139857683
  time_since_restore: 498.3192002773285
  time_this_iter_s: 25.778262615203857
  time_total_s: 498.3192002773285
  timers:
    learn_throughput: 8477.28
    learn_time_ms: 19085.368
    sample_throughput: 23606.829
    sample_time_ms: 6853.61
    update_time_ms: 29.274
  timestamp: 1602465304
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |     19 |          498.319 | 3074048 |  240.209 |              288.444 |              128.596 |            821.528 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3463.93623112962
    time_step_min: 3183
  date: 2020-10-12_01-15-30
  done: false
  episode_len_mean: 819.7330749354005
  episode_reward_max: 288.44444444444434
  episode_reward_mean: 241.24391198809798
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 235
  episodes_total: 3870
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.6425882081190745
        entropy_coeff: 0.0001
        kl: 0.009800318395718932
        model: {}
        policy_loss: -0.012736022346264994
        total_loss: 10.096623023351034
        vf_explained_var: 0.9834440350532532
        vf_loss: 10.108443339665731
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.73225806451613
    gpu_util_percent0: 0.37806451612903236
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1496822466990633
    mean_env_wait_ms: 1.198386430940289
    mean_inference_ms: 4.565150853027251
    mean_raw_obs_processing_ms: 0.39173285283652104
  time_since_restore: 524.1882493495941
  time_this_iter_s: 25.869049072265625
  time_total_s: 524.1882493495941
  timers:
    learn_throughput: 8488.876
    learn_time_ms: 19059.296
    sample_throughput: 23649.716
    sample_time_ms: 6841.181
    update_time_ms: 28.398
  timestamp: 1602465330
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |     20 |          524.188 | 3235840 |  241.244 |              288.444 |              128.596 |            819.733 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3456.848247119392
    time_step_min: 3156
  date: 2020-10-12_01-15-55
  done: false
  episode_len_mean: 817.9240321402483
  episode_reward_max: 288.44444444444434
  episode_reward_mean: 242.27257232662637
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 237
  episodes_total: 4107
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.6394364535808563
        entropy_coeff: 0.0001
        kl: 0.0093312735358874
        model: {}
        policy_loss: -0.009989628699258901
        total_loss: 9.597819089889526
        vf_explained_var: 0.9830818176269531
        vf_loss: 9.606939713160196
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.553125
    gpu_util_percent0: 0.35750000000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7593750000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14949773382285736
    mean_env_wait_ms: 1.1994558067494865
    mean_inference_ms: 4.552039530821604
    mean_raw_obs_processing_ms: 0.3910574890854858
  time_since_restore: 549.9038982391357
  time_this_iter_s: 25.715648889541626
  time_total_s: 549.9038982391357
  timers:
    learn_throughput: 8506.966
    learn_time_ms: 19018.767
    sample_throughput: 23668.886
    sample_time_ms: 6835.641
    update_time_ms: 27.419
  timestamp: 1602465355
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |     21 |          549.904 | 3397632 |  242.273 |              288.444 |              128.596 |            817.924 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3452.612317130722
    time_step_min: 3156
  date: 2020-10-12_01-16-22
  done: false
  episode_len_mean: 816.8117674636662
  episode_reward_max: 288.44444444444434
  episode_reward_mean: 242.9289164500135
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 159
  episodes_total: 4266
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.6394699116547903
        entropy_coeff: 0.0001
        kl: 0.009713159874081612
        model: {}
        policy_loss: -0.010728772190001715
        total_loss: 8.435858885447184
        vf_explained_var: 0.981187105178833
        vf_loss: 8.445680220921835
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.741935483870968
    gpu_util_percent0: 0.2667741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.787096774193548
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14937860637709172
    mean_env_wait_ms: 1.2001505173800098
    mean_inference_ms: 4.543877503310556
    mean_raw_obs_processing_ms: 0.3906341189667434
  time_since_restore: 575.9693341255188
  time_this_iter_s: 26.065435886383057
  time_total_s: 575.9693341255188
  timers:
    learn_throughput: 8507.963
    learn_time_ms: 19016.539
    sample_throughput: 23734.557
    sample_time_ms: 6816.727
    update_time_ms: 27.383
  timestamp: 1602465382
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | RUNNING  | 172.17.0.4:8465 |     22 |          575.969 | 3559424 |  242.929 |              288.444 |              128.596 |            816.812 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2d923_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3447.9898557258794
    time_step_min: 3156
  date: 2020-10-12_01-16-48
  done: true
  episode_len_mean: 815.4625896057348
  episode_reward_max: 288.44444444444434
  episode_reward_mean: 243.66503068317581
  episode_reward_min: 128.59595959595976
  episodes_this_iter: 198
  episodes_total: 4464
  experiment_id: ecc00052a0fa440c828f2a6d87a6f2d9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.6084126532077789
        entropy_coeff: 0.0001
        kl: 0.010839478500808278
        model: {}
        policy_loss: -0.010573671092667306
        total_loss: 7.917505621910095
        vf_explained_var: 0.9849058985710144
        vf_loss: 7.9270561536153155
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.254838709677422
    gpu_util_percent0: 0.3648387096774194
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 8465
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1492356903865046
    mean_env_wait_ms: 1.2010432153666812
    mean_inference_ms: 4.534370091315779
    mean_raw_obs_processing_ms: 0.3901345791323901
  time_since_restore: 601.9076294898987
  time_this_iter_s: 25.938295364379883
  time_total_s: 601.9076294898987
  timers:
    learn_throughput: 8524.875
    learn_time_ms: 18978.812
    sample_throughput: 23786.448
    sample_time_ms: 6801.856
    update_time_ms: 27.115
  timestamp: 1602465408
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 2d923_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | TERMINATED |       |     23 |          601.908 | 3721216 |  243.665 |              288.444 |              128.596 |            815.463 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.96 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2d923_00000 | TERMINATED |       |     23 |          601.908 | 3721216 |  243.665 |              288.444 |              128.596 |            815.463 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


[2m[33m(pid=raylet)[0m E1012 01:16:48.493824  8304  8304 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1012 01:16:48.493903  8304  8304 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1012 01:16:48.494048  8304  8304 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1012 01:16:48.494349  8304  8304 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1012 01:16:48.545274  8304  8304 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
