diff --git a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
index 71f6e33..6d794ec 100644
--- a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
@@ -79,8 +79,8 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: mq1j5yvs\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\n"
+      "Create sweep with ID: rfs7la4y\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\n"
      ]
     }
    ],
@@ -90,2468 +90,19 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-08 11:45:48,119 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-08 11:45:48,430 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 11:45:48,431 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 4096\n",
-      "2020-10-08 11:45:48,434 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.4\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33musual-sweep-1\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/82d8n3my\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_114550-82d8n3my\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 11:45:52,454\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268\u001b[39m\u001b[22m\n",
-      "2020-10-08 11:45:53,470 - wandb.wandb_agent - INFO - Running runs: ['82d8n3my']\n",
-      "== Status ==\n",
-      "Memory usage on this node: 17.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=80010)\u001b[0m 2020-10-08 11:45:55,254\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=79990)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79990)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80020)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80020)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79986)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79986)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79996)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79996)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79992)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79992)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79974)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79974)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80017)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80017)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79966)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79966)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79993)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79993)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79977)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79977)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80000)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80000)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79965)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79965)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79975)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79975)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79970)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79970)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80002)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80002)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80012)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80012)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79960)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79960)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79941)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79941)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80004)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80004)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79976)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79976)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79957)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79957)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80006)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80006)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79888)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79888)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79902)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79902)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79901)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79901)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79891)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79891)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79962)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79962)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79972)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79972)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79898)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79898)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79985)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79985)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79978)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79978)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79895)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79895)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79908)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79908)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79967)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79967)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79875)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79875)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79953)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79953)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79907)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79907)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79968)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79968)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79910)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79910)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79887)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79887)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79959)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79959)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79886)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79886)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79958)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79958)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79981)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79981)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79955)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79955)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79948)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79948)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79973)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79973)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79917)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79917)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79890)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79890)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79997)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79997)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79964)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79964)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79956)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79956)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79914)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79914)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79942)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79942)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79989)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79989)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79900)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79900)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79916)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79916)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79984)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79984)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79885)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79885)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79896)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79896)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79893)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79893)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79944)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79944)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79943)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79943)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79971)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79971)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79969)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79969)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79987)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79987)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79961)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79961)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79952)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79952)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79913)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79913)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79892)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79892)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79963)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79963)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-46-31\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1603952676057816\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006529558636248112\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01697929573711008\n",
-      "        total_loss: 6.624263763427734\n",
-      "        vf_explained_var: 0.8197423815727234\n",
-      "        vf_loss: 6.639937055110932\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 29.499999999999993\n",
-      "    gpu_util_percent0: 0.2733333333333334\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0002777777777777778\n",
-      "    ram_util_percent: 4.261111111111112\n",
-      "    vram_util_percent0: 0.06302157355781494\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16875616228481102\n",
-      "    mean_env_wait_ms: 1.5739218855242776\n",
-      "    mean_inference_ms: 5.591068856691865\n",
-      "    mean_raw_obs_processing_ms: 0.4506270552020118\n",
-      "  time_since_restore: 30.11682629585266\n",
-      "  time_this_iter_s: 30.11682629585266\n",
-      "  time_total_s: 30.11682629585266\n",
-      "  timers:\n",
-      "    learn_throughput: 7796.6\n",
-      "    learn_time_ms: 20751.61\n",
-      "    sample_throughput: 17419.067\n",
-      "    sample_time_ms: 9288.213\n",
-      "    update_time_ms: 44.874\n",
-      "  timestamp: 1602157591\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 32.9/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      1 |          30.1168 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-46-59\n",
-      "  done: false\n",
-      "  episode_len_mean: 869.3417721518987\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.90004475131036\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1352683365345002\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007792104431428015\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020531148964073508\n",
-      "        total_loss: 5.638339829444885\n",
-      "        vf_explained_var: 0.9249752759933472\n",
-      "        vf_loss: 5.657312452793121\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 26.066666666666663\n",
-      "    gpu_util_percent0: 0.29\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.451515151515152\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1640005638893568\n",
-      "    mean_env_wait_ms: 1.5775274092583902\n",
-      "    mean_inference_ms: 5.302413775269009\n",
-      "    mean_raw_obs_processing_ms: 0.43677931133826275\n",
-      "  time_since_restore: 58.54918050765991\n",
-      "  time_this_iter_s: 28.43235421180725\n",
-      "  time_total_s: 58.54918050765991\n",
-      "  timers:\n",
-      "    learn_throughput: 7837.771\n",
-      "    learn_time_ms: 20642.602\n",
-      "    sample_throughput: 18926.883\n",
-      "    sample_time_ms: 8548.264\n",
-      "    update_time_ms: 42.329\n",
-      "  timestamp: 1602157619\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      2 |          58.5492 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_11-47-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 864.6983122362869\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.52218386395583\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1208289206027984\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008471710339654237\n",
-      "        model: {}\n",
-      "        policy_loss: -0.024524397612549365\n",
-      "        total_loss: 4.379646378755569\n",
-      "        vf_explained_var: 0.9663649797439575\n",
-      "        vf_loss: 4.4024763882160185\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.75151515151515\n",
-      "    gpu_util_percent0: 0.2918181818181818\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.466666666666667\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1610433593452084\n",
-      "    mean_env_wait_ms: 1.5791339042559354\n",
-      "    mean_inference_ms: 5.141168556600388\n",
-      "    mean_raw_obs_processing_ms: 0.4272760547189869\n",
-      "  time_since_restore: 86.52022004127502\n",
-      "  time_this_iter_s: 27.971039533615112\n",
-      "  time_total_s: 86.52022004127502\n",
-      "  timers:\n",
-      "    learn_throughput: 7892.613\n",
-      "    learn_time_ms: 20499.168\n",
-      "    sample_throughput: 19596.92\n",
-      "    sample_time_ms: 8255.991\n",
-      "    update_time_ms: 42.426\n",
-      "  timestamp: 1602157647\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      3 |          86.5202 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_11-47-55\n",
-      "  done: false\n",
-      "  episode_len_mean: 860.242088607595\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.50586561820717\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0932798445224763\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.009407231188379227\n",
-      "        model: {}\n",
-      "        policy_loss: -0.026628604688448833\n",
-      "        total_loss: 4.111228054761886\n",
-      "        vf_explained_var: 0.9783345460891724\n",
-      "        vf_loss: 4.135975193977356\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.815625\n",
-      "    gpu_util_percent0: 0.26625\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.46875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1590423832293999\n",
-      "    mean_env_wait_ms: 1.5820174193292231\n",
-      "    mean_inference_ms: 5.0251596991819705\n",
-      "    mean_raw_obs_processing_ms: 0.42029578233494164\n",
-      "  time_since_restore: 114.42771482467651\n",
-      "  time_this_iter_s: 27.90749478340149\n",
-      "  time_total_s: 114.42771482467651\n",
-      "  timers:\n",
-      "    learn_throughput: 7915.515\n",
-      "    learn_time_ms: 20439.858\n",
-      "    sample_throughput: 20021.505\n",
-      "    sample_time_ms: 8080.911\n",
-      "    update_time_ms: 41.717\n",
-      "  timestamp: 1602157675\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      4 |          114.428 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_11-48-23\n",
-      "  done: false\n",
-      "  episode_len_mean: 853.6054421768707\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 226.6438076914266\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 250\n",
-      "  episodes_total: 882\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0601136475801467\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008663335489109159\n",
-      "        model: {}\n",
-      "        policy_loss: -0.029689956549555065\n",
-      "        total_loss: 5.979247343540192\n",
-      "        vf_explained_var: 0.9847942590713501\n",
-      "        vf_loss: 6.007204520702362\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.309374999999996\n",
-      "    gpu_util_percent0: 0.2690625\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4593750000000005\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1569472608169185\n",
-      "    mean_env_wait_ms: 1.5876407685008682\n",
-      "    mean_inference_ms: 4.901463646021808\n",
-      "    mean_raw_obs_processing_ms: 0.4132403078994484\n",
-      "  time_since_restore: 142.0127465724945\n",
-      "  time_this_iter_s: 27.585031747817993\n",
-      "  time_total_s: 142.0127465724945\n",
-      "  timers:\n",
-      "    learn_throughput: 7949.618\n",
-      "    learn_time_ms: 20352.173\n",
-      "    sample_throughput: 20316.996\n",
-      "    sample_time_ms: 7963.382\n",
-      "    update_time_ms: 40.79\n",
-      "  timestamp: 1602157703\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      5 |          142.013 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_11-48-50\n",
-      "  done: false\n",
-      "  episode_len_mean: 847.8264014466546\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 227.10596927685518\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 224\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0766338467597962\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008614842919632793\n",
-      "        model: {}\n",
-      "        policy_loss: -0.030333096848335118\n",
-      "        total_loss: 4.108908116817474\n",
-      "        vf_explained_var: 0.987047553062439\n",
-      "        vf_loss: 4.137518179416657\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.978125\n",
-      "    gpu_util_percent0: 0.294375\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1557195397072005\n",
-      "    mean_env_wait_ms: 1.5919018099970674\n",
-      "    mean_inference_ms: 4.826965344047954\n",
-      "    mean_raw_obs_processing_ms: 0.4091659356791254\n",
-      "  time_since_restore: 168.97307991981506\n",
-      "  time_this_iter_s: 26.960333347320557\n",
-      "  time_total_s: 168.97307991981506\n",
-      "  timers:\n",
-      "    learn_throughput: 8004.051\n",
-      "    learn_time_ms: 20213.764\n",
-      "    sample_throughput: 20586.195\n",
-      "    sample_time_ms: 7859.248\n",
-      "    update_time_ms: 40.239\n",
-      "  timestamp: 1602157730\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      6 |          168.973 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-49-17\n",
-      "  done: false\n",
-      "  episode_len_mean: 844.1083860759494\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.6303302007414\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0495809823274613\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008355090976692736\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03242016874719411\n",
-      "        total_loss: 3.189230865240097\n",
-      "        vf_explained_var: 0.9909769296646118\n",
-      "        vf_loss: 3.2199800491333006\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.95\n",
-      "    gpu_util_percent0: 0.28812499999999996\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.475\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15503429170730368\n",
-      "    mean_env_wait_ms: 1.594563087955357\n",
-      "    mean_inference_ms: 4.785002724236677\n",
-      "    mean_raw_obs_processing_ms: 0.4068913211080966\n",
-      "  time_since_restore: 195.9782907962799\n",
-      "  time_this_iter_s: 27.005210876464844\n",
-      "  time_total_s: 195.9782907962799\n",
-      "  timers:\n",
-      "    learn_throughput: 8045.813\n",
-      "    learn_time_ms: 20108.844\n",
-      "    sample_throughput: 20766.024\n",
-      "    sample_time_ms: 7791.188\n",
-      "    update_time_ms: 38.206\n",
-      "  timestamp: 1602157757\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      7 |          195.978 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-49-44\n",
-      "  done: false\n",
-      "  episode_len_mean: 840.8741209563995\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.87909332424087\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0188148379325868\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008204545732587576\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03408731806557626\n",
-      "        total_loss: 3.0473277091979982\n",
-      "        vf_explained_var: 0.9921058416366577\n",
-      "        vf_loss: 3.079774135351181\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.5625\n",
-      "    gpu_util_percent0: 0.2934375\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15445205035357232\n",
-      "    mean_env_wait_ms: 1.5970754276033823\n",
-      "    mean_inference_ms: 4.748860951121171\n",
-      "    mean_raw_obs_processing_ms: 0.40491847437517203\n",
-      "  time_since_restore: 223.42373943328857\n",
-      "  time_this_iter_s: 27.445448637008667\n",
-      "  time_total_s: 223.42373943328857\n",
-      "  timers:\n",
-      "    learn_throughput: 8055.885\n",
-      "    learn_time_ms: 20083.703\n",
-      "    sample_throughput: 20900.724\n",
-      "    sample_time_ms: 7740.976\n",
-      "    update_time_ms: 44.602\n",
-      "  timestamp: 1602157784\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      8 |          223.424 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-50-12\n",
-      "  done: false\n",
-      "  episode_len_mean: 835.0944055944055\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.1691507146051\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 1716\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9918270707130432\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007521937682759017\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03050975254736841\n",
-      "        total_loss: 5.504689037799835\n",
-      "        vf_explained_var: 0.9918516874313354\n",
-      "        vf_loss: 5.53369448184967\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 26.15625\n",
-      "    gpu_util_percent0: 0.2734375\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.465625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15359854017386879\n",
-      "    mean_env_wait_ms: 1.601715352177999\n",
-      "    mean_inference_ms: 4.694742071474369\n",
-      "    mean_raw_obs_processing_ms: 0.4019907511305347\n",
-      "  time_since_restore: 250.65174460411072\n",
-      "  time_this_iter_s: 27.228005170822144\n",
-      "  time_total_s: 250.65174460411072\n",
-      "  timers:\n",
-      "    learn_throughput: 8078.417\n",
-      "    learn_time_ms: 20027.685\n",
-      "    sample_throughput: 20977.883\n",
-      "    sample_time_ms: 7712.504\n",
-      "    update_time_ms: 43.814\n",
-      "  timestamp: 1602157812\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      9 |          250.652 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-50-39\n",
-      "  done: false\n",
-      "  episode_len_mean: 832.079641350211\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.59731279035063\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9763310596346855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007896899722982197\n",
-      "        model: {}\n",
-      "        policy_loss: -0.033220290520694105\n",
-      "        total_loss: 2.953149896860123\n",
-      "        vf_explained_var: 0.993627667427063\n",
-      "        vf_loss: 2.98479083776474\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.484375\n",
-      "    gpu_util_percent0: 0.288125\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15317220656345867\n",
-      "    mean_env_wait_ms: 1.604245414768565\n",
-      "    mean_inference_ms: 4.668108436640403\n",
-      "    mean_raw_obs_processing_ms: 0.40059241178385674\n",
-      "  time_since_restore: 278.01485896110535\n",
-      "  time_this_iter_s: 27.36311435699463\n",
-      "  time_total_s: 278.01485896110535\n",
-      "  timers:\n",
-      "    learn_throughput: 8090.085\n",
-      "    learn_time_ms: 19998.802\n",
-      "    sample_throughput: 21045.891\n",
-      "    sample_time_ms: 7687.581\n",
-      "    update_time_ms: 43.4\n",
-      "  timestamp: 1602157839\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     10 |          278.015 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-51-07\n",
-      "  done: false\n",
-      "  episode_len_mean: 830.1703992210321\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 229.0675253017024\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9670185938477516\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007682974718045443\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03496774770319462\n",
-      "        total_loss: 2.589013671875\n",
-      "        vf_explained_var: 0.9946534037590027\n",
-      "        vf_loss: 2.622444784641266\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 26.23548387096774\n",
-      "    gpu_util_percent0: 0.26903225806451614\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.47741935483871\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15283766436808183\n",
-      "    mean_env_wait_ms: 1.6062695046004585\n",
-      "    mean_inference_ms: 4.647350806058767\n",
-      "    mean_raw_obs_processing_ms: 0.39949114295740445\n",
-      "  time_since_restore: 305.27174377441406\n",
-      "  time_this_iter_s: 27.256884813308716\n",
-      "  time_total_s: 305.27174377441406\n",
-      "  timers:\n",
-      "    learn_throughput: 8137.51\n",
-      "    learn_time_ms: 19882.248\n",
-      "    sample_throughput: 21520.396\n",
-      "    sample_time_ms: 7518.077\n",
-      "    update_time_ms: 41.114\n",
-      "  timestamp: 1602157867\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     11 |          305.272 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-51-34\n",
-      "  done: false\n",
-      "  episode_len_mean: 828.50904159132\n",
-      "  episode_reward_max: 287.9191919191919\n",
-      "  episode_reward_mean: 229.5476966774434\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.940390695631504\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007805287896189839\n",
-      "        model: {}\n",
-      "        policy_loss: -0.035866627853829415\n",
-      "        total_loss: 2.6927455008029937\n",
-      "        vf_explained_var: 0.9949959516525269\n",
-      "        vf_loss: 2.7270510613918306\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.678787878787883\n",
-      "    gpu_util_percent0: 0.2809090909090909\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.466666666666667\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15253638840628728\n",
-      "    mean_env_wait_ms: 1.6081161690939731\n",
-      "    mean_inference_ms: 4.628595571108588\n",
-      "    mean_raw_obs_processing_ms: 0.39846808184493565\n",
-      "  time_since_restore: 332.607017993927\n",
-      "  time_this_iter_s: 27.33527421951294\n",
-      "  time_total_s: 332.607017993927\n",
-      "  timers:\n",
-      "    learn_throughput: 8176.778\n",
-      "    learn_time_ms: 19786.766\n",
-      "    sample_throughput: 21563.454\n",
-      "    sample_time_ms: 7503.065\n",
-      "    update_time_ms: 41.647\n",
-      "  timestamp: 1602157894\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     12 |          332.607 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-01\n",
-      "  done: false\n",
-      "  episode_len_mean: 825.9173259493671\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 230.737545550441\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9119029730558396\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007374470541253686\n",
-      "        model: {}\n",
-      "        policy_loss: -0.031025875953491776\n",
-      "        total_loss: 3.626113736629486\n",
-      "        vf_explained_var: 0.9953392744064331\n",
-      "        vf_loss: 3.655664700269699\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.699999999999996\n",
-      "    gpu_util_percent0: 0.2815625\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.465625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15202521348457168\n",
-      "    mean_env_wait_ms: 1.6115012963552209\n",
-      "    mean_inference_ms: 4.596639178335069\n",
-      "    mean_raw_obs_processing_ms: 0.3967428044141634\n",
-      "  time_since_restore: 359.82592964172363\n",
-      "  time_this_iter_s: 27.21891164779663\n",
-      "  time_total_s: 359.82592964172363\n",
-      "  timers:\n",
-      "    learn_throughput: 8195.68\n",
-      "    learn_time_ms: 19741.132\n",
-      "    sample_throughput: 21654.113\n",
-      "    sample_time_ms: 7471.652\n",
-      "    update_time_ms: 42.032\n",
-      "  timestamp: 1602157921\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     13 |          359.826 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-29\n",
-      "  done: false\n",
-      "  episode_len_mean: 824.9274013402829\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.18682355949656\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8989204004406929\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0074366391287185255\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03388760575326159\n",
-      "        total_loss: 2.3619153201580048\n",
-      "        vf_explained_var: 0.9957093000411987\n",
-      "        vf_loss: 2.394315606355667\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.40625\n",
-      "    gpu_util_percent0: 0.2846875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4781249999999995\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15180800096963903\n",
-      "    mean_env_wait_ms: 1.613010827888792\n",
-      "    mean_inference_ms: 4.582932598838708\n",
-      "    mean_raw_obs_processing_ms: 0.39601789200760174\n",
-      "  time_since_restore: 387.4496352672577\n",
-      "  time_this_iter_s: 27.623705625534058\n",
-      "  time_total_s: 387.4496352672577\n",
-      "  timers:\n",
-      "    learn_throughput: 8204.033\n",
-      "    learn_time_ms: 19721.031\n",
-      "    sample_throughput: 21680.325\n",
-      "    sample_time_ms: 7462.619\n",
-      "    update_time_ms: 41.93\n",
-      "  timestamp: 1602157949\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     14 |           387.45 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-57\n",
-      "  done: false\n",
-      "  episode_len_mean: 824.0777074542897\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.63322749293204\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.895898899435997\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007697970513254404\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03602396983187646\n",
-      "        total_loss: 1.9372931450605393\n",
-      "        vf_explained_var: 0.9962417483329773\n",
-      "        vf_loss: 1.9717775255441665\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.83125\n",
-      "    gpu_util_percent0: 0.285625\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.475\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15161473875055903\n",
-      "    mean_env_wait_ms: 1.6144244916591914\n",
-      "    mean_inference_ms: 4.570359858195114\n",
-      "    mean_raw_obs_processing_ms: 0.3953474948059144\n",
-      "  time_since_restore: 414.69566917419434\n",
-      "  time_this_iter_s: 27.246033906936646\n",
-      "  time_total_s: 414.69566917419434\n",
-      "  timers:\n",
-      "    learn_throughput: 8216.436\n",
-      "    learn_time_ms: 19691.264\n",
-      "    sample_throughput: 21698.645\n",
-      "    sample_time_ms: 7456.318\n",
-      "    update_time_ms: 43.356\n",
-      "  timestamp: 1602157977\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     15 |          414.696 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-53-24\n",
-      "  done: false\n",
-      "  episode_len_mean: 822.9910447761195\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 232.33685444829712\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 171\n",
-      "  episodes_total: 3015\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8683042243123055\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007607861259020865\n",
-      "        model: {}\n",
-      "        policy_loss: -0.036039730068296194\n",
-      "        total_loss: 2.116857588291168\n",
-      "        vf_explained_var: 0.9965157508850098\n",
-      "        vf_loss: 2.1513757526874544\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.764516129032256\n",
-      "    gpu_util_percent0: 0.297741935483871\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.470967741935484\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15141989112198903\n",
-      "    mean_env_wait_ms: 1.6159236661106888\n",
-      "    mean_inference_ms: 4.557815570915645\n",
-      "    mean_raw_obs_processing_ms: 0.39467050753293315\n",
-      "  time_since_restore: 441.87632274627686\n",
-      "  time_this_iter_s: 27.18065357208252\n",
-      "  time_total_s: 441.87632274627686\n",
-      "  timers:\n",
-      "    learn_throughput: 8211.786\n",
-      "    learn_time_ms: 19702.413\n",
-      "    sample_throughput: 21667.308\n",
-      "    sample_time_ms: 7467.102\n",
-      "    update_time_ms: 43.552\n",
-      "  timestamp: 1602158004\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     16 |          441.876 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-53-51\n",
-      "  done: false\n",
-      "  episode_len_mean: 821.0216998191681\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.1551683197252\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 303\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8348902150988579\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00740289380773902\n",
-      "        model: {}\n",
-      "        policy_loss: -0.029998348827939482\n",
-      "        total_loss: 2.5100847482681274\n",
-      "        vf_explained_var: 0.9960853457450867\n",
-      "        vf_loss: 2.538602519035339\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.715625000000003\n",
-      "    gpu_util_percent0: 0.301875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4593750000000005\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15111617742851072\n",
-      "    mean_env_wait_ms: 1.6183026472863848\n",
-      "    mean_inference_ms: 4.5380869771344665\n",
-      "    mean_raw_obs_processing_ms: 0.3936242667088673\n",
-      "  time_since_restore: 469.05478024482727\n",
-      "  time_this_iter_s: 27.178457498550415\n",
-      "  time_total_s: 469.05478024482727\n",
-      "  timers:\n",
-      "    learn_throughput: 8204.084\n",
-      "    learn_time_ms: 19720.91\n",
-      "    sample_throughput: 21655.953\n",
-      "    sample_time_ms: 7471.017\n",
-      "    update_time_ms: 43.943\n",
-      "  timestamp: 1602158031\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     17 |          469.055 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-54-19\n",
-      "  done: false\n",
-      "  episode_len_mean: 820.0376869965478\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.58232206995146\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8338133722543717\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007797137019224465\n",
-      "        model: {}\n",
-      "        policy_loss: -0.0366627115290612\n",
-      "        total_loss: 1.7475906014442444\n",
-      "        vf_explained_var: 0.9965535998344421\n",
-      "        vf_loss: 1.7826938778162003\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.784375\n",
-      "    gpu_util_percent0: 0.2903125\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.481249999999999\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15097538572791852\n",
-      "    mean_env_wait_ms: 1.6194704277376637\n",
-      "    mean_inference_ms: 4.52891423862918\n",
-      "    mean_raw_obs_processing_ms: 0.3931393304580003\n",
-      "  time_since_restore: 496.22354912757874\n",
-      "  time_this_iter_s: 27.168768882751465\n",
-      "  time_total_s: 496.22354912757874\n",
-      "  timers:\n",
-      "    learn_throughput: 8215.377\n",
-      "    learn_time_ms: 19693.8\n",
-      "    sample_throughput: 21639.305\n",
-      "    sample_time_ms: 7476.765\n",
-      "    update_time_ms: 37.093\n",
-      "  timestamp: 1602158059\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     18 |          496.224 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-54-45\n",
-      "  done: false\n",
-      "  episode_len_mean: 819.1164006604292\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.0312925623877\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8341425269842148\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007575143571011722\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03457739797886461\n",
-      "        total_loss: 1.834545186161995\n",
-      "        vf_explained_var: 0.9961616396903992\n",
-      "        vf_loss: 1.8676075398921967\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 26.36774193548387\n",
-      "    gpu_util_percent0: 0.30548387096774193\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.480645161290322\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15084453438607362\n",
-      "    mean_env_wait_ms: 1.6205942190593885\n",
-      "    mean_inference_ms: 4.520349568470547\n",
-      "    mean_raw_obs_processing_ms: 0.3926786361932948\n",
-      "  time_since_restore: 522.9063003063202\n",
-      "  time_this_iter_s: 26.682751178741455\n",
-      "  time_total_s: 522.9063003063202\n",
-      "  timers:\n",
-      "    learn_throughput: 8235.447\n",
-      "    learn_time_ms: 19645.806\n",
-      "    sample_throughput: 21635.851\n",
-      "    sample_time_ms: 7477.959\n",
-      "    update_time_ms: 35.387\n",
-      "  timestamp: 1602158085\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     19 |          522.906 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-55-13\n",
-      "  done: false\n",
-      "  episode_len_mean: 817.554763117677\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.8146184205786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 292\n",
-      "  episodes_total: 3926\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7916461393237114\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007353159273043275\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03166137257358059\n",
-      "        total_loss: 2.4200849175453185\n",
-      "        vf_explained_var: 0.9965318441390991\n",
-      "        vf_loss: 2.450275695323944\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.421875\n",
-      "    gpu_util_percent0: 0.2903125\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875000000001\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15062615343426108\n",
-      "    mean_env_wait_ms: 1.6226010223295135\n",
-      "    mean_inference_ms: 4.5059904498713115\n",
-      "    mean_raw_obs_processing_ms: 0.3919086060605794\n",
-      "  time_since_restore: 550.2158420085907\n",
-      "  time_this_iter_s: 27.309541702270508\n",
-      "  time_total_s: 550.2158420085907\n",
-      "  timers:\n",
-      "    learn_throughput: 8238.594\n",
-      "    learn_time_ms: 19638.301\n",
-      "    sample_throughput: 21617.958\n",
-      "    sample_time_ms: 7484.148\n",
-      "    update_time_ms: 35.351\n",
-      "  timestamp: 1602158113\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     20 |          550.216 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-55-40\n",
-      "  done: false\n",
-      "  episode_len_mean: 816.6701557935735\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.22827594346575\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 182\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7638061985373497\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007330618624109775\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03147139406064525\n",
-      "        total_loss: 1.8828283458948136\n",
-      "        vf_explained_var: 0.9963488578796387\n",
-      "        vf_loss: 1.912833634018898\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.924999999999997\n",
-      "    gpu_util_percent0: 0.301875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.481249999999999\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15050530919609634\n",
-      "    mean_env_wait_ms: 1.623724292281501\n",
-      "    mean_inference_ms: 4.497921157414929\n",
-      "    mean_raw_obs_processing_ms: 0.3914896591205486\n",
-      "  time_since_restore: 577.2629189491272\n",
-      "  time_this_iter_s: 27.0470769405365\n",
-      "  time_total_s: 577.2629189491272\n",
-      "  timers:\n",
-      "    learn_throughput: 8242.44\n",
-      "    learn_time_ms: 19629.139\n",
-      "    sample_throughput: 21663.425\n",
-      "    sample_time_ms: 7468.441\n",
-      "    update_time_ms: 36.165\n",
-      "  timestamp: 1602158140\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     21 |          577.263 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-56-08\n",
-      "  done: true\n",
-      "  episode_len_mean: 815.9498359118612\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.53961319713775\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4266\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7843831703066826\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007404250220861286\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03531548953615129\n",
-      "        total_loss: 1.534095871448517\n",
-      "        vf_explained_var: 0.996734619140625\n",
-      "        vf_loss: 1.5679305166006088\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.875\n",
-      "    gpu_util_percent0: 0.2996875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15040791303314213\n",
-      "    mean_env_wait_ms: 1.6246785514214\n",
-      "    mean_inference_ms: 4.4913398893005585\n",
-      "    mean_raw_obs_processing_ms: 0.39114072918445014\n",
-      "  time_since_restore: 604.5293033123016\n",
-      "  time_this_iter_s: 27.26638436317444\n",
-      "  time_total_s: 604.5293033123016\n",
-      "  timers:\n",
-      "    learn_throughput: 8243.137\n",
-      "    learn_time_ms: 19627.479\n",
-      "    sample_throughput: 21703.935\n",
-      "    sample_time_ms: 7454.501\n",
-      "    update_time_ms: 41.057\n",
-      "  timestamp: 1602158168\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | TERMINATED |       |     22 |          604.529 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | TERMINATED |       |     22 |          604.529 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2895, in get_loc\n",
-      "    return self._engine.get_loc(casted_key)\n",
-      "  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n",
-      "  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n",
-      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1675, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
-      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1683, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
-      "KeyError: 'custom_metrics'\n",
-      "\n",
-      "The above exception was the direct cause of the following exception:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"train.py\", line 66, in <module>\n",
-      "    train_func()\n",
-      "  File \"train.py\", line 55, in train_func\n",
-      "    my_custom_metric = result['custom_metrics']\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 2902, in __getitem__\n",
-      "    indexer = self.columns.get_loc(key)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2897, in get_loc\n",
-      "    raise KeyError(key) from err\n",
-      "KeyError: 'custom_metrics'\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 79778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_114550-82d8n3my/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_114550-82d8n3my/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33musual-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/82d8n3my\u001b[0m\n",
-      "2020-10-08 11:56:16,232 - wandb.wandb_agent - INFO - Cleaning up finished run: 82d8n3my\n",
-      "2020-10-08 11:56:16,524 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 11:56:16,524 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 8192\n",
-      "2020-10-08 11:56:16,529 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=8192\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.4\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msandy-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/uaw0r211\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_115618-uaw0r211\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 11:56:20,530\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268\u001b[39m\u001b[22m\n",
-      "2020-10-08 11:56:21,566 - wandb.wandb_agent - INFO - Running runs: ['uaw0r211']\n",
-      "== Status ==\n",
-      "Memory usage on this node: 17.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=22161)\u001b[0m 2020-10-08 11:56:23,493\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=22120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22156)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22156)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22038)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22038)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22035)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22035)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22151)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22151)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22051)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22051)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22136)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22136)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22129)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22129)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22039)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22039)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22091)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22091)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22036)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22036)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22060)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22060)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22062)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22062)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22029)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22029)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22027)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22027)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22024)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22024)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22040)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22040)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22084)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22084)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22139)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22139)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22081)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22081)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22037)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22037)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22048)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22048)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22065)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22065)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22042)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22042)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22025)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22025)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22033)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22033)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22083)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22083)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22058)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22058)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22092)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22092)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22053)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22053)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22034)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22034)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22028)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22028)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22041)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22041)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22026)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22026)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22112)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22112)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22054)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22054)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22030)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22030)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22032)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22032)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22131)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22131)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22031)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22031)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22109)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22109)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22050)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22050)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22110)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22110)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22133)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22133)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_4898a_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-56-55\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 8196fe3f2c5c4e22af63c11ec84b6459\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1611746549606323\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005718740075826645\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013096390827558934\n",
-      "        total_loss: 7.403090405464172\n",
-      "        vf_explained_var: 0.7892305254936218\n",
-      "        vf_loss: 7.415043115615845\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 32.55\n",
-      "    gpu_util_percent0: 0.22966666666666669\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.250000000000002\n",
-      "    vram_util_percent0: 0.06902809664370832\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 22161\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17109087125207587\n",
-      "    mean_env_wait_ms: 1.5727916416028063\n",
-      "    mean_inference_ms: 5.579640846923753\n",
-      "    mean_raw_obs_processing_ms: 0.4581124033961777\n",
-      "  time_since_restore: 25.996026754379272\n",
-      "  time_this_iter_s: 25.996026754379272\n",
-      "  time_total_s: 25.996026754379272\n",
-      "  timers:\n",
-      "    learn_throughput: 9708.757\n",
-      "    learn_time_ms: 16664.542\n",
-      "    sample_throughput: 17496.047\n",
-      "    sample_time_ms: 9247.346\n",
-      "    update_time_ms: 51.617\n",
-      "  timestamp: 1602158215\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 4898a_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 32.9/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  | 172.17.0.4:22161 |      1 |           25.996 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_4898a_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_11-57-19\n",
-      "  done: false\n",
-      "  episode_len_mean: 873.4715189873418\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 227.3690384861269\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 8196fe3f2c5c4e22af63c11ec84b6459\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.132627922296524\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006706285546533764\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016248987091239543\n",
-      "        total_loss: 5.631959009170532\n",
-      "        vf_explained_var: 0.9176143407821655\n",
-      "        vf_loss: 5.646866726875305\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 30.485714285714288\n",
-      "    gpu_util_percent0: 0.1157142857142857\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.446428571428571\n",
-      "    vram_util_percent0: 0.08043620859298131\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 22161\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1665971035079177\n",
-      "    mean_env_wait_ms: 1.5718622755619396\n",
-      "    mean_inference_ms: 5.344314668249787\n",
-      "    mean_raw_obs_processing_ms: 0.44582337103132463\n",
-      "  time_since_restore: 50.581798791885376\n",
-      "  time_this_iter_s: 24.585772037506104\n",
-      "  time_total_s: 50.581798791885376\n",
-      "  timers:\n",
-      "    learn_throughput: 9785.94\n",
-      "    learn_time_ms: 16533.108\n",
-      "    sample_throughput: 18656.081\n",
-      "    sample_time_ms: 8672.347\n",
-      "    update_time_ms: 45.172\n",
-      "  timestamp: 1602158239\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 4898a_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  | 172.17.0.4:22161 |      2 |          50.5818 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n"
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent mq1j5yvs"
+    "!wandb agent rfs7la4y"
    ]
   },
   {
diff --git a/JSS/.ipynb_checkpoints/train-checkpoint.py b/JSS/.ipynb_checkpoints/train-checkpoint.py
index 7209fb9..863e891 100644
--- a/JSS/.ipynb_checkpoints/train-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/train-checkpoint.py
@@ -45,20 +45,24 @@ def train_func():
     config.pop('layer_size', None)
     config.pop('layer_nb', None)
 
-    
     ray.init()
+    
     stop = {
         "time_total_s": 600,
     }
-    analysis = tune.run(PPOTrainer, config=config, stop=stop)
-    result = analysis.results_df
-    my_custom_metric = result['custom_metrics']
-    wandb.log(my_custom_metric)
+    
+    analysis = tune.run(PPOTrainer, config=config, stop=stop, name="ppo-jss")
+    result = analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').to_dict('index')[0]
+    wandb.log({'time_step_min': result['custom_metrics/time_step_min']})
+    if result['custom_metrics/time_step_max'] != float('inf'):
+        wandb.log({'time_step_max': result['custom_metrics/time_step_max']})
+        wandb.log({'time_step_mean': result['custom_metrics/time_step_mean']})
     wandb.log({'episode_reward_max': result['episode_reward_max']})
     wandb.log({'episode_reward_min': result['episode_reward_min']})
     wandb.log({'episode_reward_mean': result['episode_reward_mean']})
     wandb.log({'episodes_total': result['episodes_total']})
     wandb.log({'training_iteration': result['training_iteration']})
+
     ray.shutdown()
 
 
diff --git a/JSS/Untitled.ipynb b/JSS/Untitled.ipynb
index 71f6e33..8122189 100644
--- a/JSS/Untitled.ipynb
+++ b/JSS/Untitled.ipynb
@@ -79,8 +79,8 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: mq1j5yvs\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\n"
+      "Create sweep with ID: rfs7la4y\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\n"
      ]
     }
    ],
@@ -90,7 +90,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "metadata": {},
    "outputs": [
     {
@@ -98,207 +98,205 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-08 11:45:48,119 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-08 11:45:48,430 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 11:45:48,431 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "2020-10-08 14:03:50,854 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.2\n",
       "\tlambda: 0.95\n",
       "\tlr: 0.0001\n",
       "\tnum_envs_per_worker: 2\n",
       "\tnum_sgd_iter: 20\n",
       "\tsgd_minibatch_size: 4096\n",
-      "2020-10-08 11:45:48,434 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
+      "2020-10-08 14:03:51,192 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.4\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33musual-sweep-1\u001b[0m\n",
+      "2020-10-08 14:03:56,246 - wandb.wandb_agent - INFO - Running runs: ['5nvugt1y']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-1\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/82d8n3my\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_114550-82d8n3my\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_140356-5nvugt1y\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 11:45:52,454\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268\u001b[39m\u001b[22m\n",
-      "2020-10-08 11:45:53,470 - wandb.wandb_agent - INFO - Running runs: ['82d8n3my']\n",
+      "2020-10-08 14:03:58,257\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8271\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 17.1/754.6 GiB\n",
+      "Memory usage on this node: 77.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=80010)\u001b[0m 2020-10-08 11:45:55,254\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=79990)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79990)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80020)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80020)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79986)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79986)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79996)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79996)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79992)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79992)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79974)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79974)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80017)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80017)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79966)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79966)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79993)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79993)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79977)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79977)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80000)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80000)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79965)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79965)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79975)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79975)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79970)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79970)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80002)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80002)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80012)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80012)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79960)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79960)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79941)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79941)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80004)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80004)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79976)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79976)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79957)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79957)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=80006)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=80006)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79888)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79888)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79902)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79902)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79901)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79901)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79891)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79891)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79962)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79962)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79972)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79972)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79898)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79898)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79985)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79985)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79978)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79978)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79895)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79895)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79908)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79908)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79967)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79967)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79875)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79875)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79953)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79953)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79907)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79907)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79968)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79968)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79910)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79910)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79887)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79887)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79959)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79959)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79886)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79886)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79958)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79958)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79981)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79981)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79955)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79955)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79948)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79948)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79973)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79973)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79917)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79917)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79890)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79890)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79997)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79997)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79964)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79964)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79956)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79956)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79914)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79914)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79942)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79942)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79989)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79989)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79900)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79900)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79916)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79916)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79984)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79984)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79885)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79885)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79896)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79896)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79893)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79893)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79944)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79944)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79943)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79943)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79971)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79971)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79969)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79969)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79987)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79987)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79961)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79961)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79952)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79952)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79913)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79913)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79892)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79892)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=79963)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=79963)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "\u001b[2m\u001b[36m(pid=57899)\u001b[0m 2020-10-08 14:04:01,486\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-46-31\n",
+      "  date: 2020-10-08_14-04-38\n",
       "  done: false\n",
       "  episode_len_mean: 877.1708860759494\n",
       "  episode_reward_max: 273.13131313131294\n",
@@ -306,7 +304,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -330,59 +328,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.499999999999993\n",
-      "    gpu_util_percent0: 0.2733333333333334\n",
+      "    cpu_util_percent: 36.00833333333333\n",
+      "    gpu_util_percent0: 0.3225\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0002777777777777778\n",
-      "    ram_util_percent: 4.261111111111112\n",
-      "    vram_util_percent0: 0.06302157355781494\n",
+      "    ram_util_percent: 10.413888888888891\n",
+      "    vram_util_percent0: 0.27462328267920266\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16875616228481102\n",
-      "    mean_env_wait_ms: 1.5739218855242776\n",
-      "    mean_inference_ms: 5.591068856691865\n",
-      "    mean_raw_obs_processing_ms: 0.4506270552020118\n",
-      "  time_since_restore: 30.11682629585266\n",
-      "  time_this_iter_s: 30.11682629585266\n",
-      "  time_total_s: 30.11682629585266\n",
+      "    mean_action_processing_ms: 0.18350994266746734\n",
+      "    mean_env_wait_ms: 1.6865222444501913\n",
+      "    mean_inference_ms: 5.985971555624452\n",
+      "    mean_raw_obs_processing_ms: 0.49480385234157925\n",
+      "  time_since_restore: 30.92910385131836\n",
+      "  time_this_iter_s: 30.92910385131836\n",
+      "  time_total_s: 30.92910385131836\n",
       "  timers:\n",
-      "    learn_throughput: 7796.6\n",
-      "    learn_time_ms: 20751.61\n",
-      "    sample_throughput: 17419.067\n",
-      "    sample_time_ms: 9288.213\n",
-      "    update_time_ms: 44.874\n",
-      "  timestamp: 1602157591\n",
+      "    learn_throughput: 7789.468\n",
+      "    learn_time_ms: 20770.611\n",
+      "    sample_throughput: 16046.653\n",
+      "    sample_time_ms: 10082.601\n",
+      "    update_time_ms: 36.409\n",
+      "  timestamp: 1602165878\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 32.9/754.6 GiB\n",
+      "Memory usage on this node: 72.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      1 |          30.1168 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      1 |          30.9291 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-46-59\n",
+      "  date: 2020-10-08_14-05-08\n",
       "  done: false\n",
       "  episode_len_mean: 869.3417721518987\n",
       "  episode_reward_max: 273.13131313131294\n",
@@ -390,7 +388,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -414,59 +412,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.066666666666663\n",
-      "    gpu_util_percent0: 0.29\n",
+      "    cpu_util_percent: 30.90294117647059\n",
+      "    gpu_util_percent0: 0.26941176470588235\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.451515151515152\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.747058823529413\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1640005638893568\n",
-      "    mean_env_wait_ms: 1.5775274092583902\n",
-      "    mean_inference_ms: 5.302413775269009\n",
-      "    mean_raw_obs_processing_ms: 0.43677931133826275\n",
-      "  time_since_restore: 58.54918050765991\n",
-      "  time_this_iter_s: 28.43235421180725\n",
-      "  time_total_s: 58.54918050765991\n",
+      "    mean_action_processing_ms: 0.17676173480204843\n",
+      "    mean_env_wait_ms: 1.6752662514608032\n",
+      "    mean_inference_ms: 5.6785297305935405\n",
+      "    mean_raw_obs_processing_ms: 0.4787812236414886\n",
+      "  time_since_restore: 59.91080617904663\n",
+      "  time_this_iter_s: 28.98170232772827\n",
+      "  time_total_s: 59.91080617904663\n",
       "  timers:\n",
-      "    learn_throughput: 7837.771\n",
-      "    learn_time_ms: 20642.602\n",
-      "    sample_throughput: 18926.883\n",
-      "    sample_time_ms: 8548.264\n",
-      "    update_time_ms: 42.329\n",
-      "  timestamp: 1602157619\n",
+      "    learn_throughput: 7835.536\n",
+      "    learn_time_ms: 20648.493\n",
+      "    sample_throughput: 17536.73\n",
+      "    sample_time_ms: 9225.893\n",
+      "    update_time_ms: 38.294\n",
+      "  timestamp: 1602165908\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      2 |          58.5492 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      2 |          59.9108 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_11-47-27\n",
+      "  date: 2020-10-08_14-05-37\n",
       "  done: false\n",
       "  episode_len_mean: 864.6983122362869\n",
       "  episode_reward_max: 278.99999999999983\n",
@@ -474,7 +472,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -498,59 +496,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.75151515151515\n",
-      "    gpu_util_percent0: 0.2918181818181818\n",
+      "    cpu_util_percent: 31.057142857142864\n",
+      "    gpu_util_percent0: 0.2717142857142857\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.466666666666667\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.762857142857143\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1610433593452084\n",
-      "    mean_env_wait_ms: 1.5791339042559354\n",
-      "    mean_inference_ms: 5.141168556600388\n",
-      "    mean_raw_obs_processing_ms: 0.4272760547189869\n",
-      "  time_since_restore: 86.52022004127502\n",
-      "  time_this_iter_s: 27.971039533615112\n",
-      "  time_total_s: 86.52022004127502\n",
+      "    mean_action_processing_ms: 0.17253118731808845\n",
+      "    mean_env_wait_ms: 1.669123154241675\n",
+      "    mean_inference_ms: 5.508714332828136\n",
+      "    mean_raw_obs_processing_ms: 0.46803146600593976\n",
+      "  time_since_restore: 89.00577521324158\n",
+      "  time_this_iter_s: 29.094969034194946\n",
+      "  time_total_s: 89.00577521324158\n",
       "  timers:\n",
-      "    learn_throughput: 7892.613\n",
-      "    learn_time_ms: 20499.168\n",
-      "    sample_throughput: 19596.92\n",
-      "    sample_time_ms: 8255.991\n",
-      "    update_time_ms: 42.426\n",
-      "  timestamp: 1602157647\n",
+      "    learn_throughput: 7852.583\n",
+      "    learn_time_ms: 20603.665\n",
+      "    sample_throughput: 18018.223\n",
+      "    sample_time_ms: 8979.354\n",
+      "    update_time_ms: 41.291\n",
+      "  timestamp: 1602165937\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      3 |          86.5202 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      3 |          89.0058 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_11-47-55\n",
+      "  date: 2020-10-08_14-06-05\n",
       "  done: false\n",
       "  episode_len_mean: 860.242088607595\n",
       "  episode_reward_max: 278.99999999999983\n",
@@ -558,7 +556,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -582,59 +580,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.815625\n",
-      "    gpu_util_percent0: 0.26625\n",
+      "    cpu_util_percent: 29.938235294117646\n",
+      "    gpu_util_percent0: 0.24941176470588236\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.46875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.761764705882353\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1590423832293999\n",
-      "    mean_env_wait_ms: 1.5820174193292231\n",
-      "    mean_inference_ms: 5.0251596991819705\n",
-      "    mean_raw_obs_processing_ms: 0.42029578233494164\n",
-      "  time_since_restore: 114.42771482467651\n",
-      "  time_this_iter_s: 27.90749478340149\n",
-      "  time_total_s: 114.42771482467651\n",
+      "    mean_action_processing_ms: 0.16972262222291365\n",
+      "    mean_env_wait_ms: 1.6663911084469907\n",
+      "    mean_inference_ms: 5.381286213374226\n",
+      "    mean_raw_obs_processing_ms: 0.46035908038467466\n",
+      "  time_since_restore: 117.6076283454895\n",
+      "  time_this_iter_s: 28.601853132247925\n",
+      "  time_total_s: 117.6076283454895\n",
       "  timers:\n",
-      "    learn_throughput: 7915.515\n",
-      "    learn_time_ms: 20439.858\n",
-      "    sample_throughput: 20021.505\n",
-      "    sample_time_ms: 8080.911\n",
-      "    update_time_ms: 41.717\n",
-      "  timestamp: 1602157675\n",
+      "    learn_throughput: 7898.804\n",
+      "    learn_time_ms: 20483.102\n",
+      "    sample_throughput: 18320.006\n",
+      "    sample_time_ms: 8831.438\n",
+      "    update_time_ms: 41.53\n",
+      "  timestamp: 1602165965\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      4 |          114.428 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      4 |          117.608 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_11-48-23\n",
+      "  date: 2020-10-08_14-06-34\n",
       "  done: false\n",
       "  episode_len_mean: 853.6054421768707\n",
       "  episode_reward_max: 278.99999999999983\n",
@@ -642,7 +640,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 250\n",
       "  episodes_total: 882\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -666,59 +664,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.309374999999996\n",
-      "    gpu_util_percent0: 0.2690625\n",
+      "    cpu_util_percent: 30.05\n",
+      "    gpu_util_percent0: 0.27676470588235297\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4593750000000005\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.755882352941178\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1569472608169185\n",
-      "    mean_env_wait_ms: 1.5876407685008682\n",
-      "    mean_inference_ms: 4.901463646021808\n",
-      "    mean_raw_obs_processing_ms: 0.4132403078994484\n",
-      "  time_since_restore: 142.0127465724945\n",
-      "  time_this_iter_s: 27.585031747817993\n",
-      "  time_total_s: 142.0127465724945\n",
+      "    mean_action_processing_ms: 0.1668569945682094\n",
+      "    mean_env_wait_ms: 1.6661518036410352\n",
+      "    mean_inference_ms: 5.245339771382172\n",
+      "    mean_raw_obs_processing_ms: 0.45204585691645865\n",
+      "  time_since_restore: 146.34429287910461\n",
+      "  time_this_iter_s: 28.736664533615112\n",
+      "  time_total_s: 146.34429287910461\n",
       "  timers:\n",
-      "    learn_throughput: 7949.618\n",
-      "    learn_time_ms: 20352.173\n",
-      "    sample_throughput: 20316.996\n",
-      "    sample_time_ms: 7963.382\n",
-      "    update_time_ms: 40.79\n",
-      "  timestamp: 1602157703\n",
+      "    learn_throughput: 7912.652\n",
+      "    learn_time_ms: 20447.253\n",
+      "    sample_throughput: 18556.235\n",
+      "    sample_time_ms: 8719.01\n",
+      "    update_time_ms: 53.489\n",
+      "  timestamp: 1602165994\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      5 |          142.013 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      5 |          146.344 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_11-48-50\n",
+      "  date: 2020-10-08_14-07-03\n",
       "  done: false\n",
       "  episode_len_mean: 847.8264014466546\n",
       "  episode_reward_max: 278.99999999999983\n",
@@ -726,7 +724,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 224\n",
       "  episodes_total: 1106\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -750,59 +748,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.978125\n",
-      "    gpu_util_percent0: 0.294375\n",
+      "    cpu_util_percent: 31.087878787878783\n",
+      "    gpu_util_percent0: 0.2751515151515152\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.751515151515152\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1557195397072005\n",
-      "    mean_env_wait_ms: 1.5919018099970674\n",
-      "    mean_inference_ms: 4.826965344047954\n",
-      "    mean_raw_obs_processing_ms: 0.4091659356791254\n",
-      "  time_since_restore: 168.97307991981506\n",
-      "  time_this_iter_s: 26.960333347320557\n",
-      "  time_total_s: 168.97307991981506\n",
+      "    mean_action_processing_ms: 0.16521363319543925\n",
+      "    mean_env_wait_ms: 1.6677695579501226\n",
+      "    mean_inference_ms: 5.160918708210536\n",
+      "    mean_raw_obs_processing_ms: 0.4472775860567577\n",
+      "  time_since_restore: 174.83844447135925\n",
+      "  time_this_iter_s: 28.49415159225464\n",
+      "  time_total_s: 174.83844447135925\n",
       "  timers:\n",
-      "    learn_throughput: 8004.051\n",
-      "    learn_time_ms: 20213.764\n",
-      "    sample_throughput: 20586.195\n",
-      "    sample_time_ms: 7859.248\n",
-      "    update_time_ms: 40.239\n",
-      "  timestamp: 1602157730\n",
+      "    learn_throughput: 7937.482\n",
+      "    learn_time_ms: 20383.289\n",
+      "    sample_throughput: 18693.433\n",
+      "    sample_time_ms: 8655.018\n",
+      "    update_time_ms: 51.581\n",
+      "  timestamp: 1602166023\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      6 |          168.973 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      6 |          174.838 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-49-17\n",
+      "  date: 2020-10-08_14-07-31\n",
       "  done: false\n",
       "  episode_len_mean: 844.1083860759494\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -810,7 +808,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1264\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -834,59 +832,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.95\n",
-      "    gpu_util_percent0: 0.28812499999999996\n",
+      "    cpu_util_percent: 30.423529411764708\n",
+      "    gpu_util_percent0: 0.25617647058823534\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.475\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.76764705882353\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15503429170730368\n",
-      "    mean_env_wait_ms: 1.594563087955357\n",
-      "    mean_inference_ms: 4.785002724236677\n",
-      "    mean_raw_obs_processing_ms: 0.4068913211080966\n",
-      "  time_since_restore: 195.9782907962799\n",
-      "  time_this_iter_s: 27.005210876464844\n",
-      "  time_total_s: 195.9782907962799\n",
+      "    mean_action_processing_ms: 0.16428938352115002\n",
+      "    mean_env_wait_ms: 1.6688146539398103\n",
+      "    mean_inference_ms: 5.1135213379920055\n",
+      "    mean_raw_obs_processing_ms: 0.4445629925416077\n",
+      "  time_since_restore: 203.33799719810486\n",
+      "  time_this_iter_s: 28.499552726745605\n",
+      "  time_total_s: 203.33799719810486\n",
       "  timers:\n",
-      "    learn_throughput: 8045.813\n",
-      "    learn_time_ms: 20108.844\n",
-      "    sample_throughput: 20766.024\n",
-      "    sample_time_ms: 7791.188\n",
-      "    update_time_ms: 38.206\n",
-      "  timestamp: 1602157757\n",
+      "    learn_throughput: 7953.152\n",
+      "    learn_time_ms: 20343.13\n",
+      "    sample_throughput: 18800.381\n",
+      "    sample_time_ms: 8605.783\n",
+      "    update_time_ms: 48.851\n",
+      "  timestamp: 1602166051\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      7 |          195.978 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      7 |          203.338 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-49-44\n",
+      "  date: 2020-10-08_14-08-00\n",
       "  done: false\n",
       "  episode_len_mean: 840.8741209563995\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -894,7 +892,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1422\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -918,59 +916,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.5625\n",
-      "    gpu_util_percent0: 0.2934375\n",
+      "    cpu_util_percent: 30.724242424242426\n",
+      "    gpu_util_percent0: 0.2678787878787879\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.763636363636364\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15445205035357232\n",
-      "    mean_env_wait_ms: 1.5970754276033823\n",
-      "    mean_inference_ms: 4.748860951121171\n",
-      "    mean_raw_obs_processing_ms: 0.40491847437517203\n",
-      "  time_since_restore: 223.42373943328857\n",
-      "  time_this_iter_s: 27.445448637008667\n",
-      "  time_total_s: 223.42373943328857\n",
+      "    mean_action_processing_ms: 0.16348854866217513\n",
+      "    mean_env_wait_ms: 1.6700574598453726\n",
+      "    mean_inference_ms: 5.072164794599845\n",
+      "    mean_raw_obs_processing_ms: 0.44213624402114293\n",
+      "  time_since_restore: 231.6390438079834\n",
+      "  time_this_iter_s: 28.30104660987854\n",
+      "  time_total_s: 231.6390438079834\n",
       "  timers:\n",
-      "    learn_throughput: 8055.885\n",
-      "    learn_time_ms: 20083.703\n",
-      "    sample_throughput: 20900.724\n",
-      "    sample_time_ms: 7740.976\n",
-      "    update_time_ms: 44.602\n",
-      "  timestamp: 1602157784\n",
+      "    learn_throughput: 7959.464\n",
+      "    learn_time_ms: 20326.997\n",
+      "    sample_throughput: 18968.066\n",
+      "    sample_time_ms: 8529.705\n",
+      "    update_time_ms: 47.225\n",
+      "  timestamp: 1602166080\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1294336\n",
       "  training_iteration: 8\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      8 |          223.424 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      8 |          231.639 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-50-12\n",
+      "  date: 2020-10-08_14-08-28\n",
       "  done: false\n",
       "  episode_len_mean: 835.0944055944055\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -978,7 +976,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 294\n",
       "  episodes_total: 1716\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1002,59 +1000,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.15625\n",
-      "    gpu_util_percent0: 0.2734375\n",
+      "    cpu_util_percent: 30.59705882352941\n",
+      "    gpu_util_percent0: 0.25941176470588234\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.465625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.755882352941178\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15359854017386879\n",
-      "    mean_env_wait_ms: 1.601715352177999\n",
-      "    mean_inference_ms: 4.694742071474369\n",
-      "    mean_raw_obs_processing_ms: 0.4019907511305347\n",
-      "  time_since_restore: 250.65174460411072\n",
-      "  time_this_iter_s: 27.228005170822144\n",
-      "  time_total_s: 250.65174460411072\n",
+      "    mean_action_processing_ms: 0.162284443845516\n",
+      "    mean_env_wait_ms: 1.6727489665801578\n",
+      "    mean_inference_ms: 5.009821132584934\n",
+      "    mean_raw_obs_processing_ms: 0.4384857629606629\n",
+      "  time_since_restore: 259.97689414024353\n",
+      "  time_this_iter_s: 28.337850332260132\n",
+      "  time_total_s: 259.97689414024353\n",
       "  timers:\n",
-      "    learn_throughput: 8078.417\n",
-      "    learn_time_ms: 20027.685\n",
-      "    sample_throughput: 20977.883\n",
-      "    sample_time_ms: 7712.504\n",
-      "    update_time_ms: 43.814\n",
-      "  timestamp: 1602157812\n",
+      "    learn_throughput: 7968.61\n",
+      "    learn_time_ms: 20303.667\n",
+      "    sample_throughput: 19067.411\n",
+      "    sample_time_ms: 8485.263\n",
+      "    update_time_ms: 45.663\n",
+      "  timestamp: 1602166108\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1456128\n",
       "  training_iteration: 9\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |      9 |          250.652 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      9 |          259.977 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-50-39\n",
+      "  date: 2020-10-08_14-08-57\n",
       "  done: false\n",
       "  episode_len_mean: 832.079641350211\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -1062,7 +1060,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 180\n",
       "  episodes_total: 1896\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1086,59 +1084,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.484375\n",
-      "    gpu_util_percent0: 0.288125\n",
+      "    cpu_util_percent: 29.339393939393936\n",
+      "    gpu_util_percent0: 0.29575757575757583\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.769696969696971\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15317220656345867\n",
-      "    mean_env_wait_ms: 1.604245414768565\n",
-      "    mean_inference_ms: 4.668108436640403\n",
-      "    mean_raw_obs_processing_ms: 0.40059241178385674\n",
-      "  time_since_restore: 278.01485896110535\n",
-      "  time_this_iter_s: 27.36311435699463\n",
-      "  time_total_s: 278.01485896110535\n",
+      "    mean_action_processing_ms: 0.16170883141459513\n",
+      "    mean_env_wait_ms: 1.6746347609608598\n",
+      "    mean_inference_ms: 4.978956771385591\n",
+      "    mean_raw_obs_processing_ms: 0.43667186446988804\n",
+      "  time_since_restore: 288.5126984119415\n",
+      "  time_this_iter_s: 28.535804271697998\n",
+      "  time_total_s: 288.5126984119415\n",
       "  timers:\n",
-      "    learn_throughput: 8090.085\n",
-      "    learn_time_ms: 19998.802\n",
-      "    sample_throughput: 21045.891\n",
-      "    sample_time_ms: 7687.581\n",
-      "    update_time_ms: 43.4\n",
-      "  timestamp: 1602157839\n",
+      "    learn_throughput: 7972.454\n",
+      "    learn_time_ms: 20293.877\n",
+      "    sample_throughput: 19124.35\n",
+      "    sample_time_ms: 8460.0\n",
+      "    update_time_ms: 44.735\n",
+      "  timestamp: 1602166137\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1617920\n",
       "  training_iteration: 10\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     10 |          278.015 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     10 |          288.513 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-51-07\n",
+      "  date: 2020-10-08_14-09-25\n",
       "  done: false\n",
       "  episode_len_mean: 830.1703992210321\n",
       "  episode_reward_max: 282.4848484848477\n",
@@ -1146,7 +1144,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1170,59 +1168,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.23548387096774\n",
-      "    gpu_util_percent0: 0.26903225806451614\n",
+      "    cpu_util_percent: 29.45151515151515\n",
+      "    gpu_util_percent0: 0.2739393939393939\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.47741935483871\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
+      "    ram_util_percent: 9.763636363636364\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15283766436808183\n",
-      "    mean_env_wait_ms: 1.6062695046004585\n",
-      "    mean_inference_ms: 4.647350806058767\n",
-      "    mean_raw_obs_processing_ms: 0.39949114295740445\n",
-      "  time_since_restore: 305.27174377441406\n",
-      "  time_this_iter_s: 27.256884813308716\n",
-      "  time_total_s: 305.27174377441406\n",
+      "    mean_action_processing_ms: 0.16125382205207386\n",
+      "    mean_env_wait_ms: 1.6761243985903949\n",
+      "    mean_inference_ms: 4.954596343237678\n",
+      "    mean_raw_obs_processing_ms: 0.4352361222242559\n",
+      "  time_since_restore: 316.5878527164459\n",
+      "  time_this_iter_s: 28.075154304504395\n",
+      "  time_total_s: 316.5878527164459\n",
       "  timers:\n",
-      "    learn_throughput: 8137.51\n",
-      "    learn_time_ms: 19882.248\n",
-      "    sample_throughput: 21520.396\n",
-      "    sample_time_ms: 7518.077\n",
-      "    update_time_ms: 41.114\n",
-      "  timestamp: 1602157867\n",
+      "    learn_throughput: 8000.406\n",
+      "    learn_time_ms: 20222.974\n",
+      "    sample_throughput: 19629.04\n",
+      "    sample_time_ms: 8242.482\n",
+      "    update_time_ms: 45.435\n",
+      "  timestamp: 1602166165\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
       "  training_iteration: 11\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     11 |          305.272 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     11 |          316.588 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-51-34\n",
+      "  date: 2020-10-08_14-09-54\n",
       "  done: false\n",
       "  episode_len_mean: 828.50904159132\n",
       "  episode_reward_max: 287.9191919191919\n",
@@ -1230,7 +1228,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2212\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1254,59 +1252,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.678787878787883\n",
-      "    gpu_util_percent0: 0.2809090909090909\n",
+      "    cpu_util_percent: 29.993939393939392\n",
+      "    gpu_util_percent0: 0.26969696969696966\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.466666666666667\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.757575757575758\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15253638840628728\n",
-      "    mean_env_wait_ms: 1.6081161690939731\n",
-      "    mean_inference_ms: 4.628595571108588\n",
-      "    mean_raw_obs_processing_ms: 0.39846808184493565\n",
-      "  time_since_restore: 332.607017993927\n",
-      "  time_this_iter_s: 27.33527421951294\n",
-      "  time_total_s: 332.607017993927\n",
+      "    mean_action_processing_ms: 0.16085250209822033\n",
+      "    mean_env_wait_ms: 1.6775510346401423\n",
+      "    mean_inference_ms: 4.932401985457557\n",
+      "    mean_raw_obs_processing_ms: 0.4338907507677086\n",
+      "  time_since_restore: 345.2145109176636\n",
+      "  time_this_iter_s: 28.62665820121765\n",
+      "  time_total_s: 345.2145109176636\n",
       "  timers:\n",
-      "    learn_throughput: 8176.778\n",
-      "    learn_time_ms: 19786.766\n",
-      "    sample_throughput: 21563.454\n",
-      "    sample_time_ms: 7503.065\n",
-      "    update_time_ms: 41.647\n",
-      "  timestamp: 1602157894\n",
+      "    learn_throughput: 8013.686\n",
+      "    learn_time_ms: 20189.46\n",
+      "    sample_throughput: 19635.364\n",
+      "    sample_time_ms: 8239.827\n",
+      "    update_time_ms: 45.402\n",
+      "  timestamp: 1602166194\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1941504\n",
       "  training_iteration: 12\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.6/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     12 |          332.607 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     12 |          345.215 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-01\n",
+      "  date: 2020-10-08_14-10-22\n",
       "  done: false\n",
       "  episode_len_mean: 825.9173259493671\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1314,7 +1312,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 316\n",
       "  episodes_total: 2528\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1338,59 +1336,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.699999999999996\n",
-      "    gpu_util_percent0: 0.2815625\n",
+      "    cpu_util_percent: 30.370588235294115\n",
+      "    gpu_util_percent0: 0.2747058823529412\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.465625\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.75294117647059\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15202521348457168\n",
-      "    mean_env_wait_ms: 1.6115012963552209\n",
-      "    mean_inference_ms: 4.596639178335069\n",
-      "    mean_raw_obs_processing_ms: 0.3967428044141634\n",
-      "  time_since_restore: 359.82592964172363\n",
-      "  time_this_iter_s: 27.21891164779663\n",
-      "  time_total_s: 359.82592964172363\n",
+      "    mean_action_processing_ms: 0.16017287678084888\n",
+      "    mean_env_wait_ms: 1.6802277086992836\n",
+      "    mean_inference_ms: 4.89439148640374\n",
+      "    mean_raw_obs_processing_ms: 0.4316389620412026\n",
+      "  time_since_restore: 373.45997977256775\n",
+      "  time_this_iter_s: 28.245468854904175\n",
+      "  time_total_s: 373.45997977256775\n",
       "  timers:\n",
-      "    learn_throughput: 8195.68\n",
-      "    learn_time_ms: 19741.132\n",
-      "    sample_throughput: 21654.113\n",
-      "    sample_time_ms: 7471.652\n",
-      "    update_time_ms: 42.032\n",
-      "  timestamp: 1602157921\n",
+      "    learn_throughput: 8026.419\n",
+      "    learn_time_ms: 20157.433\n",
+      "    sample_throughput: 19763.446\n",
+      "    sample_time_ms: 8186.427\n",
+      "    update_time_ms: 44.475\n",
+      "  timestamp: 1602166222\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2103296\n",
       "  training_iteration: 13\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     13 |          359.826 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     13 |           373.46 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-29\n",
+      "  date: 2020-10-08_14-10-50\n",
       "  done: false\n",
       "  episode_len_mean: 824.9274013402829\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1398,7 +1396,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2686\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1422,59 +1420,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.40625\n",
-      "    gpu_util_percent0: 0.2846875\n",
+      "    cpu_util_percent: 30.312121212121212\n",
+      "    gpu_util_percent0: 0.26151515151515153\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4781249999999995\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.772727272727275\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15180800096963903\n",
-      "    mean_env_wait_ms: 1.613010827888792\n",
-      "    mean_inference_ms: 4.582932598838708\n",
-      "    mean_raw_obs_processing_ms: 0.39601789200760174\n",
-      "  time_since_restore: 387.4496352672577\n",
-      "  time_this_iter_s: 27.623705625534058\n",
-      "  time_total_s: 387.4496352672577\n",
+      "    mean_action_processing_ms: 0.15988462752258317\n",
+      "    mean_env_wait_ms: 1.6814425515145586\n",
+      "    mean_inference_ms: 4.878041025826835\n",
+      "    mean_raw_obs_processing_ms: 0.430664812314108\n",
+      "  time_since_restore: 401.80727195739746\n",
+      "  time_this_iter_s: 28.347292184829712\n",
+      "  time_total_s: 401.80727195739746\n",
       "  timers:\n",
-      "    learn_throughput: 8204.033\n",
-      "    learn_time_ms: 19721.031\n",
-      "    sample_throughput: 21680.325\n",
-      "    sample_time_ms: 7462.619\n",
-      "    update_time_ms: 41.93\n",
-      "  timestamp: 1602157949\n",
+      "    learn_throughput: 8023.866\n",
+      "    learn_time_ms: 20163.846\n",
+      "    sample_throughput: 19841.783\n",
+      "    sample_time_ms: 8154.106\n",
+      "    update_time_ms: 44.12\n",
+      "  timestamp: 1602166250\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2265088\n",
       "  training_iteration: 14\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     14 |           387.45 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     14 |          401.807 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-52-57\n",
+      "  date: 2020-10-08_14-11-19\n",
       "  done: false\n",
       "  episode_len_mean: 824.0777074542897\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1482,7 +1480,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2844\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1506,59 +1504,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.83125\n",
-      "    gpu_util_percent0: 0.285625\n",
+      "    cpu_util_percent: 29.59705882352941\n",
+      "    gpu_util_percent0: 0.27\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.475\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.761764705882353\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15161473875055903\n",
-      "    mean_env_wait_ms: 1.6144244916591914\n",
-      "    mean_inference_ms: 4.570359858195114\n",
-      "    mean_raw_obs_processing_ms: 0.3953474948059144\n",
-      "  time_since_restore: 414.69566917419434\n",
-      "  time_this_iter_s: 27.246033906936646\n",
-      "  time_total_s: 414.69566917419434\n",
+      "    mean_action_processing_ms: 0.15962256586295442\n",
+      "    mean_env_wait_ms: 1.6825632050368664\n",
+      "    mean_inference_ms: 4.862887505621167\n",
+      "    mean_raw_obs_processing_ms: 0.42975456496408376\n",
+      "  time_since_restore: 430.180118560791\n",
+      "  time_this_iter_s: 28.372846603393555\n",
+      "  time_total_s: 430.180118560791\n",
       "  timers:\n",
-      "    learn_throughput: 8216.436\n",
-      "    learn_time_ms: 19691.264\n",
-      "    sample_throughput: 21698.645\n",
-      "    sample_time_ms: 7456.318\n",
-      "    update_time_ms: 43.356\n",
-      "  timestamp: 1602157977\n",
+      "    learn_throughput: 8029.244\n",
+      "    learn_time_ms: 20150.342\n",
+      "    sample_throughput: 19898.49\n",
+      "    sample_time_ms: 8130.868\n",
+      "    update_time_ms: 37.742\n",
+      "  timestamp: 1602166279\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2426880\n",
       "  training_iteration: 15\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     15 |          414.696 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     15 |           430.18 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-53-24\n",
+      "  date: 2020-10-08_14-11-48\n",
       "  done: false\n",
       "  episode_len_mean: 822.9910447761195\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1566,7 +1564,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 171\n",
       "  episodes_total: 3015\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1590,59 +1588,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.764516129032256\n",
-      "    gpu_util_percent0: 0.297741935483871\n",
+      "    cpu_util_percent: 31.03030303030303\n",
+      "    gpu_util_percent0: 0.28878787878787876\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.470967741935484\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
+      "    ram_util_percent: 9.76060606060606\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15141989112198903\n",
-      "    mean_env_wait_ms: 1.6159236661106888\n",
-      "    mean_inference_ms: 4.557815570915645\n",
-      "    mean_raw_obs_processing_ms: 0.39467050753293315\n",
-      "  time_since_restore: 441.87632274627686\n",
-      "  time_this_iter_s: 27.18065357208252\n",
-      "  time_total_s: 441.87632274627686\n",
+      "    mean_action_processing_ms: 0.15936424957771478\n",
+      "    mean_env_wait_ms: 1.6837075606485503\n",
+      "    mean_inference_ms: 4.8476482100837615\n",
+      "    mean_raw_obs_processing_ms: 0.4288385279340961\n",
+      "  time_since_restore: 458.61421608924866\n",
+      "  time_this_iter_s: 28.43409752845764\n",
+      "  time_total_s: 458.61421608924866\n",
       "  timers:\n",
-      "    learn_throughput: 8211.786\n",
-      "    learn_time_ms: 19702.413\n",
-      "    sample_throughput: 21667.308\n",
-      "    sample_time_ms: 7467.102\n",
-      "    update_time_ms: 43.552\n",
-      "  timestamp: 1602158004\n",
+      "    learn_throughput: 8025.775\n",
+      "    learn_time_ms: 20159.051\n",
+      "    sample_throughput: 19933.741\n",
+      "    sample_time_ms: 8116.489\n",
+      "    update_time_ms: 36.891\n",
+      "  timestamp: 1602166308\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2588672\n",
       "  training_iteration: 16\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     16 |          441.876 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     16 |          458.614 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-53-51\n",
+      "  date: 2020-10-08_14-12-16\n",
       "  done: false\n",
       "  episode_len_mean: 821.0216998191681\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1650,7 +1648,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 303\n",
       "  episodes_total: 3318\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1674,59 +1672,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.715625000000003\n",
-      "    gpu_util_percent0: 0.301875\n",
+      "    cpu_util_percent: 30.170588235294122\n",
+      "    gpu_util_percent0: 0.22911764705882354\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4593750000000005\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.75294117647059\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15111617742851072\n",
-      "    mean_env_wait_ms: 1.6183026472863848\n",
-      "    mean_inference_ms: 4.5380869771344665\n",
-      "    mean_raw_obs_processing_ms: 0.3936242667088673\n",
-      "  time_since_restore: 469.05478024482727\n",
-      "  time_this_iter_s: 27.178457498550415\n",
-      "  time_total_s: 469.05478024482727\n",
+      "    mean_action_processing_ms: 0.1589481712029165\n",
+      "    mean_env_wait_ms: 1.6856610626461734\n",
+      "    mean_inference_ms: 4.823647348850542\n",
+      "    mean_raw_obs_processing_ms: 0.4273782452417025\n",
+      "  time_since_restore: 486.7920489311218\n",
+      "  time_this_iter_s: 28.17783284187317\n",
+      "  time_total_s: 486.7920489311218\n",
       "  timers:\n",
-      "    learn_throughput: 8204.084\n",
-      "    learn_time_ms: 19720.91\n",
-      "    sample_throughput: 21655.953\n",
-      "    sample_time_ms: 7471.017\n",
-      "    update_time_ms: 43.943\n",
-      "  timestamp: 1602158031\n",
+      "    learn_throughput: 8025.414\n",
+      "    learn_time_ms: 20159.958\n",
+      "    sample_throughput: 20020.205\n",
+      "    sample_time_ms: 8081.436\n",
+      "    update_time_ms: 37.784\n",
+      "  timestamp: 1602166336\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2750464\n",
       "  training_iteration: 17\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     17 |          469.055 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     17 |          486.792 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-54-19\n",
+      "  date: 2020-10-08_14-12-44\n",
       "  done: false\n",
       "  episode_len_mean: 820.0376869965478\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1734,7 +1732,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 3476\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1758,59 +1756,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.784375\n",
-      "    gpu_util_percent0: 0.2903125\n",
+      "    cpu_util_percent: 30.263636363636362\n",
+      "    gpu_util_percent0: 0.2739393939393939\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.481249999999999\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.769696969696971\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15097538572791852\n",
-      "    mean_env_wait_ms: 1.6194704277376637\n",
-      "    mean_inference_ms: 4.52891423862918\n",
-      "    mean_raw_obs_processing_ms: 0.3931393304580003\n",
-      "  time_since_restore: 496.22354912757874\n",
-      "  time_this_iter_s: 27.168768882751465\n",
-      "  time_total_s: 496.22354912757874\n",
+      "    mean_action_processing_ms: 0.15875079551526766\n",
+      "    mean_env_wait_ms: 1.6865974079727117\n",
+      "    mean_inference_ms: 4.812393081904589\n",
+      "    mean_raw_obs_processing_ms: 0.42669712128025067\n",
+      "  time_since_restore: 515.002126455307\n",
+      "  time_this_iter_s: 28.21007752418518\n",
+      "  time_total_s: 515.002126455307\n",
       "  timers:\n",
-      "    learn_throughput: 8215.377\n",
-      "    learn_time_ms: 19693.8\n",
-      "    sample_throughput: 21639.305\n",
-      "    sample_time_ms: 7476.765\n",
-      "    update_time_ms: 37.093\n",
-      "  timestamp: 1602158059\n",
+      "    learn_throughput: 8034.771\n",
+      "    learn_time_ms: 20136.48\n",
+      "    sample_throughput: 19987.012\n",
+      "    sample_time_ms: 8094.857\n",
+      "    update_time_ms: 37.274\n",
+      "  timestamp: 1602166364\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2912256\n",
       "  training_iteration: 18\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     18 |          496.224 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     18 |          515.002 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-54-45\n",
+      "  date: 2020-10-08_14-13-13\n",
       "  done: false\n",
       "  episode_len_mean: 819.1164006604292\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1818,7 +1816,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 3634\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1842,59 +1840,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.36774193548387\n",
-      "    gpu_util_percent0: 0.30548387096774193\n",
+      "    cpu_util_percent: 30.017647058823528\n",
+      "    gpu_util_percent0: 0.2832352941176471\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.480645161290322\n",
-      "    vram_util_percent0: 0.06928501147917349\n",
+      "    ram_util_percent: 9.76764705882353\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15084453438607362\n",
-      "    mean_env_wait_ms: 1.6205942190593885\n",
-      "    mean_inference_ms: 4.520349568470547\n",
-      "    mean_raw_obs_processing_ms: 0.3926786361932948\n",
-      "  time_since_restore: 522.9063003063202\n",
-      "  time_this_iter_s: 26.682751178741455\n",
-      "  time_total_s: 522.9063003063202\n",
+      "    mean_action_processing_ms: 0.15856558726293105\n",
+      "    mean_env_wait_ms: 1.6874969155605837\n",
+      "    mean_inference_ms: 4.801814859500953\n",
+      "    mean_raw_obs_processing_ms: 0.42604884838564067\n",
+      "  time_since_restore: 543.3891928195953\n",
+      "  time_this_iter_s: 28.38706636428833\n",
+      "  time_total_s: 543.3891928195953\n",
       "  timers:\n",
-      "    learn_throughput: 8235.447\n",
-      "    learn_time_ms: 19645.806\n",
-      "    sample_throughput: 21635.851\n",
-      "    sample_time_ms: 7477.959\n",
-      "    update_time_ms: 35.387\n",
-      "  timestamp: 1602158085\n",
+      "    learn_throughput: 8037.512\n",
+      "    learn_time_ms: 20129.612\n",
+      "    sample_throughput: 19971.836\n",
+      "    sample_time_ms: 8101.008\n",
+      "    update_time_ms: 41.201\n",
+      "  timestamp: 1602166393\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3074048\n",
       "  training_iteration: 19\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.6/754.6 GiB\n",
+      "Memory usage on this node: 73.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     19 |          522.906 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     19 |          543.389 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-55-13\n",
+      "  date: 2020-10-08_14-13-42\n",
       "  done: false\n",
       "  episode_len_mean: 817.554763117677\n",
       "  episode_reward_max: 289.9797979797982\n",
@@ -1902,7 +1900,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 292\n",
       "  episodes_total: 3926\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1926,67 +1924,67 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.421875\n",
-      "    gpu_util_percent0: 0.2903125\n",
+      "    cpu_util_percent: 30.500000000000007\n",
+      "    gpu_util_percent0: 0.2582352941176471\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.471875000000001\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.755882352941178\n",
+      "    vram_util_percent0: 0.257051492292555\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15062615343426108\n",
-      "    mean_env_wait_ms: 1.6226010223295135\n",
-      "    mean_inference_ms: 4.5059904498713115\n",
-      "    mean_raw_obs_processing_ms: 0.3919086060605794\n",
-      "  time_since_restore: 550.2158420085907\n",
-      "  time_this_iter_s: 27.309541702270508\n",
-      "  time_total_s: 550.2158420085907\n",
+      "    mean_action_processing_ms: 0.15824728170515573\n",
+      "    mean_env_wait_ms: 1.689080359464987\n",
+      "    mean_inference_ms: 4.783977737237845\n",
+      "    mean_raw_obs_processing_ms: 0.4249789923662631\n",
+      "  time_since_restore: 572.0331726074219\n",
+      "  time_this_iter_s: 28.643979787826538\n",
+      "  time_total_s: 572.0331726074219\n",
       "  timers:\n",
-      "    learn_throughput: 8238.594\n",
-      "    learn_time_ms: 19638.301\n",
-      "    sample_throughput: 21617.958\n",
-      "    sample_time_ms: 7484.148\n",
-      "    update_time_ms: 35.351\n",
-      "  timestamp: 1602158113\n",
+      "    learn_throughput: 8035.517\n",
+      "    learn_time_ms: 20134.61\n",
+      "    sample_throughput: 19976.949\n",
+      "    sample_time_ms: 8098.935\n",
+      "    update_time_ms: 46.558\n",
+      "  timestamp: 1602166422\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3235840\n",
       "  training_iteration: 20\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     20 |          550.216 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
+      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     20 |          572.033 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
+      "Result for PPO_jss_env_1cfe6_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-55-40\n",
-      "  done: false\n",
+      "  date: 2020-10-08_14-14-10\n",
+      "  done: true\n",
       "  episode_len_mean: 816.6701557935735\n",
       "  episode_reward_max: 289.9797979797982\n",
       "  episode_reward_mean: 235.22827594346575\n",
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 182\n",
       "  episodes_total: 4108\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
+      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2010,381 +2008,295 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.924999999999997\n",
-      "    gpu_util_percent0: 0.301875\n",
+      "    cpu_util_percent: 30.76060606060606\n",
+      "    gpu_util_percent0: 0.25030303030303036\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.481249999999999\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
+      "    ram_util_percent: 9.769696969696971\n",
+      "    vram_util_percent0: 0.2570514922925549\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
+      "  pid: 57899\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15050530919609634\n",
-      "    mean_env_wait_ms: 1.623724292281501\n",
-      "    mean_inference_ms: 4.497921157414929\n",
-      "    mean_raw_obs_processing_ms: 0.3914896591205486\n",
-      "  time_since_restore: 577.2629189491272\n",
-      "  time_this_iter_s: 27.0470769405365\n",
-      "  time_total_s: 577.2629189491272\n",
+      "    mean_action_processing_ms: 0.15806698356889384\n",
+      "    mean_env_wait_ms: 1.6900183481280247\n",
+      "    mean_inference_ms: 4.773945395364269\n",
+      "    mean_raw_obs_processing_ms: 0.42436064467246504\n",
+      "  time_since_restore: 600.5207903385162\n",
+      "  time_this_iter_s: 28.48761773109436\n",
+      "  time_total_s: 600.5207903385162\n",
       "  timers:\n",
-      "    learn_throughput: 8242.44\n",
-      "    learn_time_ms: 19629.139\n",
-      "    sample_throughput: 21663.425\n",
-      "    sample_time_ms: 7468.441\n",
-      "    update_time_ms: 36.165\n",
-      "  timestamp: 1602158140\n",
+      "    learn_throughput: 8034.641\n",
+      "    learn_time_ms: 20136.804\n",
+      "    sample_throughput: 19881.19\n",
+      "    sample_time_ms: 8137.943\n",
+      "    update_time_ms: 46.415\n",
+      "  timestamp: 1602166450\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3397632\n",
       "  training_iteration: 21\n",
-      "  trial_id: d22af_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | RUNNING  | 172.17.0.4:80010 |     21 |          577.263 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_d22af_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_11-56-08\n",
-      "  done: true\n",
-      "  episode_len_mean: 815.9498359118612\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.53961319713775\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4266\n",
-      "  experiment_id: c7f2f8355ee643febdfbacca57dd7b7b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7843831703066826\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007404250220861286\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03531548953615129\n",
-      "        total_loss: 1.534095871448517\n",
-      "        vf_explained_var: 0.996734619140625\n",
-      "        vf_loss: 1.5679305166006088\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.875\n",
-      "    gpu_util_percent0: 0.2996875\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.4875\n",
-      "    vram_util_percent0: 0.0692850114791735\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 80010\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15040791303314213\n",
-      "    mean_env_wait_ms: 1.6246785514214\n",
-      "    mean_inference_ms: 4.4913398893005585\n",
-      "    mean_raw_obs_processing_ms: 0.39114072918445014\n",
-      "  time_since_restore: 604.5293033123016\n",
-      "  time_this_iter_s: 27.26638436317444\n",
-      "  time_total_s: 604.5293033123016\n",
-      "  timers:\n",
-      "    learn_throughput: 8243.137\n",
-      "    learn_time_ms: 19627.479\n",
-      "    sample_throughput: 21703.935\n",
-      "    sample_time_ms: 7454.501\n",
-      "    update_time_ms: 41.057\n",
-      "  timestamp: 1602158168\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: d22af_00000\n",
+      "  trial_id: 1cfe6_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.5/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | TERMINATED |       |     22 |          604.529 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |\n",
+      "| PPO_jss_env_1cfe6_00000 | TERMINATED |       |     21 |          600.521 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_d22af_00000 | TERMINATED |       |     22 |          604.529 | 3559424 |   235.54 |               289.98 |              115.788 |             815.95 |\n",
+      "| PPO_jss_env_1cfe6_00000 | TERMINATED |       |     21 |          600.521 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2895, in get_loc\n",
-      "    return self._engine.get_loc(casted_key)\n",
-      "  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n",
-      "  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n",
-      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1675, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
-      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1683, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
-      "KeyError: 'custom_metrics'\n",
-      "\n",
-      "The above exception was the direct cause of the following exception:\n",
-      "\n",
-      "Traceback (most recent call last):\n",
-      "  File \"train.py\", line 66, in <module>\n",
-      "    train_func()\n",
-      "  File \"train.py\", line 55, in train_func\n",
-      "    my_custom_metric = result['custom_metrics']\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 2902, in __getitem__\n",
-      "    indexer = self.columns.get_loc(key)\n",
-      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2897, in get_loc\n",
-      "    raise KeyError(key) from err\n",
-      "KeyError: 'custom_metrics'\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 79778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 57594\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_114550-82d8n3my/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_114550-82d8n3my/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_140356-5nvugt1y/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_140356-5nvugt1y/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3176.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 614\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602166450\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 282.48485\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 227.63033\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1264\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33musual-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/82d8n3my\u001b[0m\n",
-      "2020-10-08 11:56:16,232 - wandb.wandb_agent - INFO - Cleaning up finished run: 82d8n3my\n",
-      "2020-10-08 11:56:16,524 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 11:56:16,524 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
+      "2020-10-08 14:14:19,138 - wandb.wandb_agent - INFO - Cleaning up finished run: 5nvugt1y\n",
+      "2020-10-08 14:14:19,448 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-08 14:14:19,448 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.2\n",
       "\tlambda: 0.95\n",
       "\tlr: 0.0001\n",
       "\tnum_envs_per_worker: 2\n",
       "\tnum_sgd_iter: 20\n",
       "\tsgd_minibatch_size: 8192\n",
-      "2020-10-08 11:56:16,529 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=8192\n",
+      "2020-10-08 14:14:19,452 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=8192\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.5 is available!  To upgrade, please run:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.4\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msandy-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-2\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/mq1j5yvs\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/uaw0r211\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_115618-uaw0r211\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/fpfrymi0\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_141421-fpfrymi0\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 11:56:20,530\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8268\u001b[39m\u001b[22m\n",
-      "2020-10-08 11:56:21,566 - wandb.wandb_agent - INFO - Running runs: ['uaw0r211']\n",
+      "2020-10-08 14:14:23,731\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
+      "2020-10-08 14:14:24,486 - wandb.wandb_agent - INFO - Running runs: ['fpfrymi0']\n",
       "== Status ==\n",
-      "Memory usage on this node: 17.1/754.6 GiB\n",
+      "Memory usage on this node: 57.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=22161)\u001b[0m 2020-10-08 11:56:23,493\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=22120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22156)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22156)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22038)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22038)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22035)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22035)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22151)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22151)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22051)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22051)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22136)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22136)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22129)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22129)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22039)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22039)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22091)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22091)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22036)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22036)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22060)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22060)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22062)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22062)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22029)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22029)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22027)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22027)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22024)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22024)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22040)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22040)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22084)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22084)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22139)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22139)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22081)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22081)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22037)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22037)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22048)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22048)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22065)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22065)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22042)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22042)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22025)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22025)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22033)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22033)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22083)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22083)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22058)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22058)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22092)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22092)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22053)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22053)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22034)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22034)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22028)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22028)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22041)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22041)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22026)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22026)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22112)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22112)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22054)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22054)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22030)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22030)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22032)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22032)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22131)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22131)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22031)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22031)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22109)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22109)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22050)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22050)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22110)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22110)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22133)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22133)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=22125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=22125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_4898a_00000:\n",
+      "\u001b[2m\u001b[36m(pid=756)\u001b[0m 2020-10-08 14:14:26,675\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=710)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=734)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=734)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=742)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=742)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=711)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=696)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=696)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=731)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=731)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=679)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=679)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=725)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=725)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=718)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=718)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=697)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=697)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=723)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=723)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=687)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=687)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=707)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=707)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=703)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=703)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=699)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=699)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=730)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=730)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=684)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=684)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=700)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=700)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=612)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=612)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=650)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=650)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=689)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=689)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=733)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=733)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=691)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=691)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=615)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=615)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=649)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=649)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=686)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=686)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=712)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=712)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=646)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=646)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=629)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=629)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=702)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=702)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=638)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=638)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=688)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=688)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=608)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=608)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=606)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=606)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=620)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=620)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=690)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=690)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=698)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=698)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=678)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=678)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=692)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=692)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=683)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=683)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=727)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=727)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=626)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=626)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=609)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=609)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=695)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=695)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=720)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=720)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=680)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=680)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=641)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=641)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=682)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=682)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=607)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=607)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=715)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=715)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=623)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=623)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=622)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=622)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=705)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=705)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=624)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=624)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=611)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=611)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=685)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=685)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=621)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=621)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_11-56-55\n",
+      "  date: 2020-10-08_14-14-58\n",
       "  done: false\n",
       "  episode_len_mean: 877.1708860759494\n",
       "  episode_reward_max: 273.13131313131294\n",
@@ -2392,7 +2304,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 8196fe3f2c5c4e22af63c11ec84b6459\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2416,59 +2328,59 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.55\n",
-      "    gpu_util_percent0: 0.22966666666666669\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.250000000000002\n",
-      "    vram_util_percent0: 0.06902809664370832\n",
+      "    cpu_util_percent: 37.735483870967734\n",
+      "    gpu_util_percent0: 0.051935483870967754\n",
+      "    gpu_util_percent1: 0.0003225806451612903\n",
+      "    gpu_util_percent2: 0.0003225806451612903\n",
+      "    ram_util_percent: 9.529032258064516\n",
+      "    vram_util_percent0: 0.25613104243591234\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 22161\n",
+      "  pid: 756\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17109087125207587\n",
-      "    mean_env_wait_ms: 1.5727916416028063\n",
-      "    mean_inference_ms: 5.579640846923753\n",
-      "    mean_raw_obs_processing_ms: 0.4581124033961777\n",
-      "  time_since_restore: 25.996026754379272\n",
-      "  time_this_iter_s: 25.996026754379272\n",
-      "  time_total_s: 25.996026754379272\n",
+      "    mean_action_processing_ms: 0.17423707785964127\n",
+      "    mean_env_wait_ms: 1.645963223637825\n",
+      "    mean_inference_ms: 5.692081848902995\n",
+      "    mean_raw_obs_processing_ms: 0.4677243687628816\n",
+      "  time_since_restore: 26.03303360939026\n",
+      "  time_this_iter_s: 26.03303360939026\n",
+      "  time_total_s: 26.03303360939026\n",
       "  timers:\n",
-      "    learn_throughput: 9708.757\n",
-      "    learn_time_ms: 16664.542\n",
-      "    sample_throughput: 17496.047\n",
-      "    sample_time_ms: 9247.346\n",
-      "    update_time_ms: 51.617\n",
-      "  timestamp: 1602158215\n",
+      "    learn_throughput: 9842.911\n",
+      "    learn_time_ms: 16437.413\n",
+      "    sample_throughput: 17001.439\n",
+      "    sample_time_ms: 9516.371\n",
+      "    update_time_ms: 39.605\n",
+      "  timestamp: 1602166498\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: 4898a_00000\n",
+      "  trial_id: 91b37_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 32.9/754.6 GiB\n",
+      "Memory usage on this node: 72.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  | 172.17.0.4:22161 |      1 |           25.996 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      1 |           26.033 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_4898a_00000:\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: .inf\n",
       "    time_step_mean: .inf\n",
       "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_11-57-19\n",
+      "  date: 2020-10-08_14-15-23\n",
       "  done: false\n",
       "  episode_len_mean: 873.4715189873418\n",
       "  episode_reward_max: 274.85858585858557\n",
@@ -2476,7 +2388,7 @@
       "  episode_reward_min: 115.78787878787875\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 8196fe3f2c5c4e22af63c11ec84b6459\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2500,50 +2412,5058 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.485714285714288\n",
-      "    gpu_util_percent0: 0.1157142857142857\n",
+      "    cpu_util_percent: 33.220689655172414\n",
+      "    gpu_util_percent0: 0.019655172413793106\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 4.446428571428571\n",
-      "    vram_util_percent0: 0.08043620859298131\n",
+      "    ram_util_percent: 9.74137931034483\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 22161\n",
+      "  pid: 756\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1665971035079177\n",
-      "    mean_env_wait_ms: 1.5718622755619396\n",
-      "    mean_inference_ms: 5.344314668249787\n",
-      "    mean_raw_obs_processing_ms: 0.44582337103132463\n",
-      "  time_since_restore: 50.581798791885376\n",
-      "  time_this_iter_s: 24.585772037506104\n",
-      "  time_total_s: 50.581798791885376\n",
+      "    mean_action_processing_ms: 0.17038163777984144\n",
+      "    mean_env_wait_ms: 1.6424572254451888\n",
+      "    mean_inference_ms: 5.447572680731352\n",
+      "    mean_raw_obs_processing_ms: 0.4584056950467155\n",
+      "  time_since_restore: 50.949177742004395\n",
+      "  time_this_iter_s: 24.916144132614136\n",
+      "  time_total_s: 50.949177742004395\n",
       "  timers:\n",
-      "    learn_throughput: 9785.94\n",
-      "    learn_time_ms: 16533.108\n",
-      "    sample_throughput: 18656.081\n",
-      "    sample_time_ms: 8672.347\n",
-      "    update_time_ms: 45.172\n",
-      "  timestamp: 1602158239\n",
+      "    learn_throughput: 9861.266\n",
+      "    learn_time_ms: 16406.818\n",
+      "    sample_throughput: 18024.658\n",
+      "    sample_time_ms: 8976.148\n",
+      "    update_time_ms: 38.131\n",
+      "  timestamp: 1602166523\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: 4898a_00000\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      2 |          50.9492 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3265.0\n",
+      "  date: 2020-10-08_14-15-48\n",
+      "  done: false\n",
+      "  episode_len_mean: 867.8713080168776\n",
+      "  episode_reward_max: 274.85858585858557\n",
+      "  episode_reward_mean: 228.246196138601\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.1271256804466248\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.007389193354174495\n",
+      "        model: {}\n",
+      "        policy_loss: -0.018508310522884132\n",
+      "        total_loss: 6.457739639282226\n",
+      "        vf_explained_var: 0.9464155435562134\n",
+      "        vf_loss: 6.4747700691223145\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.61379310344827\n",
+      "    gpu_util_percent0: 0.21344827586206902\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.755172413793105\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16769761323536675\n",
+      "    mean_env_wait_ms: 1.6416986329657957\n",
+      "    mean_inference_ms: 5.306852272749373\n",
+      "    mean_raw_obs_processing_ms: 0.4500760030355006\n",
+      "  time_since_restore: 75.78218650817871\n",
+      "  time_this_iter_s: 24.833008766174316\n",
+      "  time_total_s: 75.78218650817871\n",
+      "  timers:\n",
+      "    learn_throughput: 9901.992\n",
+      "    learn_time_ms: 16339.339\n",
+      "    sample_throughput: 18316.884\n",
+      "    sample_time_ms: 8832.943\n",
+      "    update_time_ms: 36.895\n",
+      "  timestamp: 1602166548\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      3 |          75.7822 | 485376 |  228.246 |              274.859 |              115.788 |            867.871 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3230.0\n",
+      "  date: 2020-10-08_14-16-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 862.3544303797469\n",
+      "  episode_reward_max: 278.70707070707056\n",
+      "  episode_reward_mean: 230.3964326812426\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.0996861219406129\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.008276985818520188\n",
+      "        model: {}\n",
+      "        policy_loss: -0.020328705292195083\n",
+      "        total_loss: 5.005046558380127\n",
+      "        vf_explained_var: 0.9697187542915344\n",
+      "        vf_loss: 5.023719763755798\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.723333333333336\n",
+      "    gpu_util_percent0: 0.4343333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.750000000000002\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1657578301907817\n",
+      "    mean_env_wait_ms: 1.6430517247856948\n",
+      "    mean_inference_ms: 5.2018997182402025\n",
+      "    mean_raw_obs_processing_ms: 0.44406851617825566\n",
+      "  time_since_restore: 100.74394655227661\n",
+      "  time_this_iter_s: 24.9617600440979\n",
+      "  time_total_s: 100.74394655227661\n",
+      "  timers:\n",
+      "    learn_throughput: 9911.992\n",
+      "    learn_time_ms: 16322.854\n",
+      "    sample_throughput: 18445.327\n",
+      "    sample_time_ms: 8771.436\n",
+      "    update_time_ms: 36.541\n",
+      "  timestamp: 1602166573\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      4 |          100.744 | 647168 |  230.396 |              278.707 |              115.788 |            862.354 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3223.0\n",
+      "  date: 2020-10-08_14-16-38\n",
+      "  done: false\n",
+      "  episode_len_mean: 852.6247216035634\n",
+      "  episode_reward_max: 278.70707070707056\n",
+      "  episode_reward_mean: 231.18069334773102\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 266\n",
+      "  episodes_total: 898\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.0624429881572723\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.0077964670956134794\n",
+      "        model: {}\n",
+      "        policy_loss: -0.02084309732308611\n",
+      "        total_loss: 7.683893799781799\n",
+      "        vf_explained_var: 0.9791978597640991\n",
+      "        vf_loss: 7.703177666664123\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.225\n",
+      "    gpu_util_percent0: 0.25178571428571433\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.750000000000002\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16364555568838862\n",
+      "    mean_env_wait_ms: 1.649353801806338\n",
+      "    mean_inference_ms: 5.083644859595276\n",
+      "    mean_raw_obs_processing_ms: 0.4376329609722663\n",
+      "  time_since_restore: 125.15412139892578\n",
+      "  time_this_iter_s: 24.41017484664917\n",
+      "  time_total_s: 125.15412139892578\n",
+      "  timers:\n",
+      "    learn_throughput: 9921.993\n",
+      "    learn_time_ms: 16306.401\n",
+      "    sample_throughput: 18736.645\n",
+      "    sample_time_ms: 8635.057\n",
+      "    update_time_ms: 35.191\n",
+      "  timestamp: 1602166598\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      5 |          125.154 | 808960 |  231.181 |              278.707 |              115.788 |            852.625 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3223.0\n",
+      "  date: 2020-10-08_14-17-02\n",
+      "  done: false\n",
+      "  episode_len_mean: 846.0479204339964\n",
+      "  episode_reward_max: 278.70707070707056\n",
+      "  episode_reward_mean: 231.96029919447625\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 208\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.0738083600997925\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.007217544643208384\n",
+      "        model: {}\n",
+      "        policy_loss: -0.02225890466943383\n",
+      "        total_loss: 4.545075726509094\n",
+      "        vf_explained_var: 0.9842392206192017\n",
+      "        vf_loss: 4.565891194343567\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.55517241379311\n",
+      "    gpu_util_percent0: 0.4293103448275861\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.748275862068967\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16251990142651115\n",
+      "    mean_env_wait_ms: 1.6530343779974206\n",
+      "    mean_inference_ms: 5.018380813854082\n",
+      "    mean_raw_obs_processing_ms: 0.43409996967266995\n",
+      "  time_since_restore: 149.7096438407898\n",
+      "  time_this_iter_s: 24.555522441864014\n",
+      "  time_total_s: 149.7096438407898\n",
+      "  timers:\n",
+      "    learn_throughput: 9912.286\n",
+      "    learn_time_ms: 16322.371\n",
+      "    sample_throughput: 18942.241\n",
+      "    sample_time_ms: 8541.334\n",
+      "    update_time_ms: 33.368\n",
+      "  timestamp: 1602166622\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      6 |           149.71 | 970752 |   231.96 |              278.707 |              115.788 |            846.048 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3170.0\n",
+      "  date: 2020-10-08_14-17-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 841.3995253164557\n",
+      "  episode_reward_max: 284.4040404040406\n",
+      "  episode_reward_mean: 232.7926815624599\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.0473353922367097\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006994991353712976\n",
+      "        model: {}\n",
+      "        policy_loss: -0.022564191045239566\n",
+      "        total_loss: 4.000831997394561\n",
+      "        vf_explained_var: 0.9874190092086792\n",
+      "        vf_loss: 4.021997082233429\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.59655172413793\n",
+      "    gpu_util_percent0: 0.4562068965517241\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.758620689655174\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16183355318977655\n",
+      "    mean_env_wait_ms: 1.656038102133309\n",
+      "    mean_inference_ms: 4.9782716342931606\n",
+      "    mean_raw_obs_processing_ms: 0.4319914234530791\n",
+      "  time_since_restore: 174.1368727684021\n",
+      "  time_this_iter_s: 24.427228927612305\n",
+      "  time_total_s: 174.1368727684021\n",
+      "  timers:\n",
+      "    learn_throughput: 9918.301\n",
+      "    learn_time_ms: 16312.471\n",
+      "    sample_throughput: 19088.76\n",
+      "    sample_time_ms: 8475.773\n",
+      "    update_time_ms: 33.238\n",
+      "  timestamp: 1602166647\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      7 |          174.137 | 1132544 |  232.793 |              284.404 |              115.788 |              841.4 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3170.0\n",
+      "  date: 2020-10-08_14-17-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 837.3713080168776\n",
+      "  episode_reward_max: 284.4040404040406\n",
+      "  episode_reward_mean: 233.61432184006011\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.01868434548378\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.007189809367991984\n",
+      "        model: {}\n",
+      "        policy_loss: -0.023347471375018358\n",
+      "        total_loss: 3.781139385700226\n",
+      "        vf_explained_var: 0.9891014099121094\n",
+      "        vf_loss: 3.803048861026764\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.625\n",
+      "    gpu_util_percent0: 0.04107142857142857\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.771428571428572\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16125876245924115\n",
+      "    mean_env_wait_ms: 1.6590341255429097\n",
+      "    mean_inference_ms: 4.943515953135972\n",
+      "    mean_raw_obs_processing_ms: 0.430128591449942\n",
+      "  time_since_restore: 198.50214219093323\n",
+      "  time_this_iter_s: 24.365269422531128\n",
+      "  time_total_s: 198.50214219093323\n",
+      "  timers:\n",
+      "    learn_throughput: 9923.421\n",
+      "    learn_time_ms: 16304.054\n",
+      "    sample_throughput: 19218.701\n",
+      "    sample_time_ms: 8418.467\n",
+      "    update_time_ms: 34.044\n",
+      "  timestamp: 1602166671\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      8 |          198.502 | 1294336 |  233.614 |              284.404 |              115.788 |            837.371 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-18-15\n",
+      "  done: false\n",
+      "  episode_len_mean: 829.8141542002302\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 235.34277179156337\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 1738\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9904811769723892\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006311689200811088\n",
+      "        model: {}\n",
+      "        policy_loss: -0.020997717510908842\n",
+      "        total_loss: 5.1504497051239015\n",
+      "        vf_explained_var: 0.9909344911575317\n",
+      "        vf_loss: 5.170185089111328\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.78928571428572\n",
+      "    gpu_util_percent0: 0.30821428571428566\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.750000000000002\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.160369309924211\n",
+      "    mean_env_wait_ms: 1.6650071130850876\n",
+      "    mean_inference_ms: 4.888377085687167\n",
+      "    mean_raw_obs_processing_ms: 0.42729617584826485\n",
+      "  time_since_restore: 222.59675359725952\n",
+      "  time_this_iter_s: 24.094611406326294\n",
+      "  time_total_s: 222.59675359725952\n",
+      "  timers:\n",
+      "    learn_throughput: 9938.553\n",
+      "    learn_time_ms: 16279.231\n",
+      "    sample_throughput: 19342.706\n",
+      "    sample_time_ms: 8364.497\n",
+      "    update_time_ms: 33.218\n",
+      "  timestamp: 1602166695\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      9 |          222.597 | 1456128 |  235.343 |              290.242 |              115.788 |            829.814 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-18-40\n",
+      "  done: false\n",
+      "  episode_len_mean: 826.4541139240506\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 235.7108905510803\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9730047971010208\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006372990598902106\n",
+      "        model: {}\n",
+      "        policy_loss: -0.022790615819394587\n",
+      "        total_loss: 3.343014180660248\n",
+      "        vf_explained_var: 0.9915106892585754\n",
+      "        vf_loss: 3.3645302057266235\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.324137931034485\n",
+      "    gpu_util_percent0: 0.2775862068965517\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.762068965517242\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16000657164975352\n",
+      "    mean_env_wait_ms: 1.6678046661692965\n",
+      "    mean_inference_ms: 4.86599024622493\n",
+      "    mean_raw_obs_processing_ms: 0.42614775920547227\n",
+      "  time_since_restore: 246.9238064289093\n",
+      "  time_this_iter_s: 24.32705283164978\n",
+      "  time_total_s: 246.9238064289093\n",
+      "  timers:\n",
+      "    learn_throughput: 9939.106\n",
+      "    learn_time_ms: 16278.326\n",
+      "    sample_throughput: 19435.411\n",
+      "    sample_time_ms: 8324.599\n",
+      "    update_time_ms: 33.566\n",
+      "  timestamp: 1602166720\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     10 |          246.924 | 1617920 |  235.711 |              290.242 |              115.788 |            826.454 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-19-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 823.6002921129503\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 236.65748035368276\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2054\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9577732890844345\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006211055861786008\n",
+      "        model: {}\n",
+      "        policy_loss: -0.022765795403392984\n",
+      "        total_loss: 3.0192813992500307\n",
+      "        vf_explained_var: 0.9923363924026489\n",
+      "        vf_loss: 3.0408049702644346\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.706896551724135\n",
+      "    gpu_util_percent0: 0.43068965517241387\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.755172413793105\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1596848966715417\n",
+      "    mean_env_wait_ms: 1.6704675074629387\n",
+      "    mean_inference_ms: 4.845793508809106\n",
+      "    mean_raw_obs_processing_ms: 0.42510446710641553\n",
+      "  time_since_restore: 271.42553091049194\n",
+      "  time_this_iter_s: 24.50172448158264\n",
+      "  time_total_s: 271.42553091049194\n",
+      "  timers:\n",
+      "    learn_throughput: 9946.653\n",
+      "    learn_time_ms: 16265.974\n",
+      "    sample_throughput: 19772.529\n",
+      "    sample_time_ms: 8182.666\n",
+      "    update_time_ms: 32.542\n",
+      "  timestamp: 1602166744\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     11 |          271.426 | 1779712 |  236.657 |              290.242 |              115.788 |              823.6 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-19-29\n",
+      "  done: false\n",
+      "  episode_len_mean: 820.2957437472576\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 237.36838769440774\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 225\n",
+      "  episodes_total: 2279\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9244333893060684\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006004941323772073\n",
+      "        model: {}\n",
+      "        policy_loss: -0.021168453525751828\n",
+      "        total_loss: 4.074023377895355\n",
+      "        vf_explained_var: 0.9932994842529297\n",
+      "        vf_loss: 4.093990921974182\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.251724137931035\n",
+      "    gpu_util_percent0: 0.39206896551724135\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.744827586206897\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1592619934185692\n",
+      "    mean_env_wait_ms: 1.6739541868498113\n",
+      "    mean_inference_ms: 4.819806265535011\n",
+      "    mean_raw_obs_processing_ms: 0.42372078258183\n",
+      "  time_since_restore: 296.40609192848206\n",
+      "  time_this_iter_s: 24.980561017990112\n",
+      "  time_total_s: 296.40609192848206\n",
+      "  timers:\n",
+      "    learn_throughput: 9957.289\n",
+      "    learn_time_ms: 16248.6\n",
+      "    sample_throughput: 19727.515\n",
+      "    sample_time_ms: 8201.337\n",
+      "    update_time_ms: 32.973\n",
+      "  timestamp: 1602166769\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     12 |          296.406 | 1941504 |  237.368 |              290.242 |              115.788 |            820.296 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-19-54\n",
+      "  done: false\n",
+      "  episode_len_mean: 817.5490506329114\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 238.05452068149842\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 249\n",
+      "  episodes_total: 2528\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9116032361984253\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.0059999656863510605\n",
+      "        model: {}\n",
+      "        policy_loss: -0.020421561488183214\n",
+      "        total_loss: 3.2677656054496764\n",
+      "        vf_explained_var: 0.9931272268295288\n",
+      "        vf_loss: 3.2869871616363526\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.02857142857143\n",
+      "    gpu_util_percent0: 0.06035714285714285\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.764285714285716\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15888263499780286\n",
+      "    mean_env_wait_ms: 1.677646536061787\n",
+      "    mean_inference_ms: 4.796171409815506\n",
+      "    mean_raw_obs_processing_ms: 0.42253131691795703\n",
+      "  time_since_restore: 320.67564845085144\n",
+      "  time_this_iter_s: 24.269556522369385\n",
+      "  time_total_s: 320.67564845085144\n",
+      "  timers:\n",
+      "    learn_throughput: 9954.003\n",
+      "    learn_time_ms: 16253.963\n",
+      "    sample_throughput: 19876.989\n",
+      "    sample_time_ms: 8139.664\n",
+      "    update_time_ms: 31.685\n",
+      "  timestamp: 1602166794\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     13 |          320.676 | 2103296 |  238.055 |              290.242 |              115.788 |            817.549 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-20-18\n",
+      "  done: false\n",
+      "  episode_len_mean: 816.2442293373045\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 238.46138225140444\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9013321816921234\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006421135948039591\n",
+      "        model: {}\n",
+      "        policy_loss: -0.021805241936817765\n",
+      "        total_loss: 2.9366058349609374\n",
+      "        vf_explained_var: 0.9931826591491699\n",
+      "        vf_loss: 2.9571268558502197\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.642857142857146\n",
+      "    gpu_util_percent0: 0.30678571428571433\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.757142857142858\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15866013164662812\n",
+      "    mean_env_wait_ms: 1.6796736234314602\n",
+      "    mean_inference_ms: 4.782626736230756\n",
+      "    mean_raw_obs_processing_ms: 0.42183995211689523\n",
+      "  time_since_restore: 344.8741044998169\n",
+      "  time_this_iter_s: 24.198456048965454\n",
+      "  time_total_s: 344.8741044998169\n",
+      "  timers:\n",
+      "    learn_throughput: 9964.721\n",
+      "    learn_time_ms: 16236.481\n",
+      "    sample_throughput: 20015.961\n",
+      "    sample_time_ms: 8083.149\n",
+      "    update_time_ms: 29.819\n",
+      "  timestamp: 1602166818\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     14 |          344.874 | 2265088 |  238.461 |              290.242 |              115.788 |            816.244 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-20-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 814.502106741573\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 238.95662736919752\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 162\n",
+      "  episodes_total: 2848\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.8737345904111862\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005880716699175536\n",
+      "        model: {}\n",
+      "        policy_loss: -0.023541058914270253\n",
+      "        total_loss: 2.77874299287796\n",
+      "        vf_explained_var: 0.9943079948425293\n",
+      "        vf_loss: 2.801107919216156\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.53793103448275\n",
+      "    gpu_util_percent0: 0.09275862068965515\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.77241379310345\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15844943627409838\n",
+      "    mean_env_wait_ms: 1.6816497328437465\n",
+      "    mean_inference_ms: 4.769681731783559\n",
+      "    mean_raw_obs_processing_ms: 0.42115262835775236\n",
+      "  time_since_restore: 369.2295935153961\n",
+      "  time_this_iter_s: 24.355489015579224\n",
+      "  time_total_s: 369.2295935153961\n",
+      "  timers:\n",
+      "    learn_throughput: 9970.424\n",
+      "    learn_time_ms: 16227.193\n",
+      "    sample_throughput: 20006.648\n",
+      "    sample_time_ms: 8086.912\n",
+      "    update_time_ms: 28.747\n",
+      "  timestamp: 1602166843\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     15 |           369.23 | 2426880 |  238.957 |              290.242 |              115.788 |            814.502 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-21-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 811.5661392405063\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 239.56847270170044\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 312\n",
+      "  episodes_total: 3160\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.836417630314827\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005600748467259109\n",
+      "        model: {}\n",
+      "        policy_loss: -0.019153478858061134\n",
+      "        total_loss: 3.4916038155555724\n",
+      "        vf_explained_var: 0.9944165349006653\n",
+      "        vf_loss: 3.5096370816230773\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.9551724137931\n",
+      "    gpu_util_percent0: 0.43275862068965526\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.748275862068967\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15809978406417496\n",
+      "    mean_env_wait_ms: 1.6853761096348427\n",
+      "    mean_inference_ms: 4.748027409045223\n",
+      "    mean_raw_obs_processing_ms: 0.42003623239671906\n",
+      "  time_since_restore: 393.7941789627075\n",
+      "  time_this_iter_s: 24.5645854473114\n",
+      "  time_total_s: 393.7941789627075\n",
+      "  timers:\n",
+      "    learn_throughput: 9977.021\n",
+      "    learn_time_ms: 16216.464\n",
+      "    sample_throughput: 19987.267\n",
+      "    sample_time_ms: 8094.753\n",
+      "    update_time_ms: 30.454\n",
+      "  timestamp: 1602166867\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     16 |          393.794 | 2588672 |  239.568 |              290.242 |              115.788 |            811.566 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-21-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 810.3282097649186\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 239.7355501975754\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3318\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.8335719257593155\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006123062083497643\n",
+      "        model: {}\n",
+      "        policy_loss: -0.020987965818494558\n",
+      "        total_loss: 2.507720983028412\n",
+      "        vf_explained_var: 0.9944343566894531\n",
+      "        vf_loss: 2.5274842858314512\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.18275862068966\n",
+      "    gpu_util_percent0: 0.27655172413793105\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.758620689655173\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15794348066077543\n",
+      "    mean_env_wait_ms: 1.687080352601384\n",
+      "    mean_inference_ms: 4.7382363513709365\n",
+      "    mean_raw_obs_processing_ms: 0.41954097731825146\n",
+      "  time_since_restore: 418.4777216911316\n",
+      "  time_this_iter_s: 24.683542728424072\n",
+      "  time_total_s: 418.4777216911316\n",
+      "  timers:\n",
+      "    learn_throughput: 9984.096\n",
+      "    learn_time_ms: 16204.972\n",
+      "    sample_throughput: 19915.659\n",
+      "    sample_time_ms: 8123.859\n",
+      "    update_time_ms: 31.876\n",
+      "  timestamp: 1602166892\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     17 |          418.478 | 2750464 |  239.736 |              290.242 |              115.788 |            810.328 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-21-57\n",
+      "  done: false\n",
+      "  episode_len_mean: 809.0097813578826\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 239.89810649649536\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.830751609802246\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005981297581456602\n",
+      "        model: {}\n",
+      "        policy_loss: -0.023448871518485247\n",
+      "        total_loss: 2.440117084980011\n",
+      "        vf_explained_var: 0.994672954082489\n",
+      "        vf_loss: 2.462369680404663\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.78928571428572\n",
+      "    gpu_util_percent0: 0.04142857142857143\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.792857142857144\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15779369461228313\n",
+      "    mean_env_wait_ms: 1.6887300269221321\n",
+      "    mean_inference_ms: 4.729069241301459\n",
+      "    mean_raw_obs_processing_ms: 0.419066132995007\n",
+      "  time_since_restore: 442.8714327812195\n",
+      "  time_this_iter_s: 24.39371109008789\n",
+      "  time_total_s: 442.8714327812195\n",
+      "  timers:\n",
+      "    learn_throughput: 9977.82\n",
+      "    learn_time_ms: 16215.165\n",
+      "    sample_throughput: 19931.133\n",
+      "    sample_time_ms: 8117.551\n",
+      "    update_time_ms: 31.094\n",
+      "  timestamp: 1602166917\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     18 |          442.871 | 2912256 |  239.898 |              290.242 |              115.788 |             809.01 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-22-21\n",
+      "  done: false\n",
+      "  episode_len_mean: 806.8230485232068\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 240.2267639474917\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 3792\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7929262965917587\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005467748525552452\n",
+      "        model: {}\n",
+      "        policy_loss: -0.018968340079300105\n",
+      "        total_loss: 3.431827688217163\n",
+      "        vf_explained_var: 0.9950782060623169\n",
+      "        vf_loss: 3.4497024059295653\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.99655172413794\n",
+      "    gpu_util_percent0: 0.27379310344827584\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.755172413793105\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15751807790452294\n",
+      "    mean_env_wait_ms: 1.6918670821992567\n",
+      "    mean_inference_ms: 4.71261405039136\n",
+      "    mean_raw_obs_processing_ms: 0.41822277427376653\n",
+      "  time_since_restore: 467.25490164756775\n",
+      "  time_this_iter_s: 24.383468866348267\n",
+      "  time_total_s: 467.25490164756775\n",
+      "  timers:\n",
+      "    learn_throughput: 9975.719\n",
+      "    learn_time_ms: 16218.58\n",
+      "    sample_throughput: 19874.518\n",
+      "    sample_time_ms: 8140.676\n",
+      "    update_time_ms: 32.327\n",
+      "  timestamp: 1602166941\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     19 |          467.255 | 3074048 |  240.227 |              290.242 |              115.788 |            806.823 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-22-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 805.7225316455696\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 240.49984400971735\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3950\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7794228792190552\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005526655982248485\n",
+      "        model: {}\n",
+      "        policy_loss: -0.023039081250317395\n",
+      "        total_loss: 2.078591358661652\n",
+      "        vf_explained_var: 0.9953739047050476\n",
+      "        vf_loss: 2.1005250751972198\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.92068965517242\n",
+      "    gpu_util_percent0: 0.4165517241379311\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.762068965517242\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1573904574836841\n",
+      "    mean_env_wait_ms: 1.6933221569620878\n",
+      "    mean_inference_ms: 4.705165325354333\n",
+      "    mean_raw_obs_processing_ms: 0.4178457110788417\n",
+      "  time_since_restore: 491.8251175880432\n",
+      "  time_this_iter_s: 24.570215940475464\n",
+      "  time_total_s: 491.8251175880432\n",
+      "  timers:\n",
+      "    learn_throughput: 9972.19\n",
+      "    learn_time_ms: 16224.319\n",
+      "    sample_throughput: 19829.965\n",
+      "    sample_time_ms: 8158.965\n",
+      "    update_time_ms: 31.231\n",
+      "  timestamp: 1602166966\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     20 |          491.825 | 3235840 |    240.5 |              290.242 |              115.788 |            805.723 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-23-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 804.7280915287245\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 240.70876486382807\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4108\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7865538984537125\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005757506913505494\n",
+      "        model: {}\n",
+      "        policy_loss: -0.02310952057596296\n",
+      "        total_loss: 1.973700213432312\n",
+      "        vf_explained_var: 0.9953605532646179\n",
+      "        vf_loss: 1.9956582367420197\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.99655172413794\n",
+      "    gpu_util_percent0: 0.4148275862068965\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.755172413793105\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15726970308067142\n",
+      "    mean_env_wait_ms: 1.6947178273814376\n",
+      "    mean_inference_ms: 4.698130026253491\n",
+      "    mean_raw_obs_processing_ms: 0.4174790686263623\n",
+      "  time_since_restore: 516.4608044624329\n",
+      "  time_this_iter_s: 24.63568687438965\n",
+      "  time_total_s: 516.4608044624329\n",
+      "  timers:\n",
+      "    learn_throughput: 9977.798\n",
+      "    learn_time_ms: 16215.201\n",
+      "    sample_throughput: 19793.078\n",
+      "    sample_time_ms: 8174.171\n",
+      "    update_time_ms: 32.464\n",
+      "  timestamp: 1602166991\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     21 |          516.461 | 3397632 |  240.709 |              290.242 |              115.788 |            804.728 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-23-36\n",
+      "  done: false\n",
+      "  episode_len_mean: 803.1457812144644\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 241.09711855879692\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 289\n",
+      "  episodes_total: 4397\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.755255714058876\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005404739850200712\n",
+      "        model: {}\n",
+      "        policy_loss: -0.019464567000977696\n",
+      "        total_loss: 3.0453175783157347\n",
+      "        vf_explained_var: 0.9953736066818237\n",
+      "        vf_loss: 3.0637012124061584\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.010344827586216\n",
+      "    gpu_util_percent0: 0.25551724137931037\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.748275862068967\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15706065795015647\n",
+      "    mean_env_wait_ms: 1.6971458462496418\n",
+      "    mean_inference_ms: 4.686353824274288\n",
+      "    mean_raw_obs_processing_ms: 0.41688654879158077\n",
+      "  time_since_restore: 541.0245015621185\n",
+      "  time_this_iter_s: 24.56369709968567\n",
+      "  time_total_s: 541.0245015621185\n",
+      "  timers:\n",
+      "    learn_throughput: 9974.186\n",
+      "    learn_time_ms: 16221.074\n",
+      "    sample_throughput: 19914.903\n",
+      "    sample_time_ms: 8124.167\n",
+      "    update_time_ms: 32.124\n",
+      "  timestamp: 1602167016\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     22 |          541.025 | 3559424 |  241.097 |              290.242 |              115.788 |            803.146 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-24-00\n",
+      "  done: false\n",
+      "  episode_len_mean: 802.2247926669577\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 241.27666671075653\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 185\n",
+      "  episodes_total: 4582\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7225345104932785\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005478021572344005\n",
+      "        model: {}\n",
+      "        policy_loss: -0.022186438925564288\n",
+      "        total_loss: 1.9642526030540466\n",
+      "        vf_explained_var: 0.9957612752914429\n",
+      "        vf_loss: 1.9853434622287751\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.33793103448276\n",
+      "    gpu_util_percent0: 0.43206896551724133\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.762068965517242\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1569378381550041\n",
+      "    mean_env_wait_ms: 1.698596232047108\n",
+      "    mean_inference_ms: 4.679417530334113\n",
+      "    mean_raw_obs_processing_ms: 0.4165376750547412\n",
+      "  time_since_restore: 565.687112569809\n",
+      "  time_this_iter_s: 24.66261100769043\n",
+      "  time_total_s: 565.687112569809\n",
+      "  timers:\n",
+      "    learn_throughput: 9968.382\n",
+      "    learn_time_ms: 16230.518\n",
+      "    sample_throughput: 19860.374\n",
+      "    sample_time_ms: 8146.473\n",
+      "    update_time_ms: 32.606\n",
+      "  timestamp: 1602167040\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     23 |          565.687 | 3721216 |  241.277 |              290.242 |              115.788 |            802.225 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-24-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 801.512447257384\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 241.5184460640156\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4740\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7451686680316925\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005771003756672144\n",
+      "        model: {}\n",
+      "        policy_loss: -0.024150656536221504\n",
+      "        total_loss: 1.7480961799621582\n",
+      "        vf_explained_var: 0.9958817362785339\n",
+      "        vf_loss: 1.7710926413536072\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.81071428571429\n",
+      "    gpu_util_percent0: 0.16499999999999998\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.782142857142857\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15683784552145583\n",
+      "    mean_env_wait_ms: 1.6997744080868349\n",
+      "    mean_inference_ms: 4.673850092393118\n",
+      "    mean_raw_obs_processing_ms: 0.4162613145590402\n",
+      "  time_since_restore: 590.1530044078827\n",
+      "  time_this_iter_s: 24.46589183807373\n",
+      "  time_total_s: 590.1530044078827\n",
+      "  timers:\n",
+      "    learn_throughput: 9968.406\n",
+      "    learn_time_ms: 16230.478\n",
+      "    sample_throughput: 19802.656\n",
+      "    sample_time_ms: 8170.217\n",
+      "    update_time_ms: 35.007\n",
+      "  timestamp: 1602167065\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     24 |          590.153 | 3883008 |  241.518 |              290.242 |              115.788 |            801.512 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_91b37_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3125.0\n",
+      "  date: 2020-10-08_14-24-50\n",
+      "  done: true\n",
+      "  episode_len_mean: 800.4764492753624\n",
+      "  episode_reward_max: 290.2424242424239\n",
+      "  episode_reward_mean: 241.8013874656386\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 228\n",
+      "  episodes_total: 4968\n",
+      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7212436735630036\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.00533560358453542\n",
+      "        model: {}\n",
+      "        policy_loss: -0.020342798670753837\n",
+      "        total_loss: 2.63335440158844\n",
+      "        vf_explained_var: 0.9957489967346191\n",
+      "        vf_loss: 2.65263010263443\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.09666666666667\n",
+      "    gpu_util_percent0: 0.22766666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.746666666666668\n",
+      "    vram_util_percent0: 0.2682026894063627\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 756\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15670386391308977\n",
+      "    mean_env_wait_ms: 1.7014434824573494\n",
+      "    mean_inference_ms: 4.66638510128689\n",
+      "    mean_raw_obs_processing_ms: 0.41590574797057145\n",
+      "  time_since_restore: 614.7696187496185\n",
+      "  time_this_iter_s: 24.61661434173584\n",
+      "  time_total_s: 614.7696187496185\n",
+      "  timers:\n",
+      "    learn_throughput: 9960.015\n",
+      "    learn_time_ms: 16244.153\n",
+      "    sample_throughput: 19778.628\n",
+      "    sample_time_ms: 8180.143\n",
+      "    update_time_ms: 36.793\n",
+      "  timestamp: 1602167090\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 91b37_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | TERMINATED |       |     25 |           614.77 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_91b37_00000 | TERMINATED |       |     25 |           614.77 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 502\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_141421-fpfrymi0/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_141421-fpfrymi0/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3125.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 629\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602167090\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 290.24242\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 235.34277\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1738\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 9\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/fpfrymi0\u001b[0m\n",
+      "2020-10-08 14:25:03,027 - wandb.wandb_agent - INFO - Cleaning up finished run: fpfrymi0\n",
+      "2020-10-08 14:25:03,372 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-08 14:25:03,372 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.2\n",
+      "\tlambda: 0.95\n",
+      "\tlr: 0.0001\n",
+      "\tnum_envs_per_worker: 2\n",
+      "\tnum_sgd_iter: 20\n",
+      "\tsgd_minibatch_size: 16384\n",
+      "2020-10-08 14:25:03,376 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=16384\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmajor-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/w8c2p6ff\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_142505-w8c2p6ff\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-08 14:25:07,555\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
+      "2020-10-08 14:25:08,410 - wandb.wandb_agent - INFO - Running runs: ['w8c2p6ff']\n",
+      "== Status ==\n",
+      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=33202)\u001b[0m 2020-10-08 14:25:10,570\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=33230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33185)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33185)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33246)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33246)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33192)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33192)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33208)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33208)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33188)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33188)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33095)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33095)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33175)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33175)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33196)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33196)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33186)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33186)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33100)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33098)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33098)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33183)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33183)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33211)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33211)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33180)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33180)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33093)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33093)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33179)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33179)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33193)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33193)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33189)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33189)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33172)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33172)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=33194)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=33194)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3279.0\n",
+      "  date: 2020-10-08_14-25-42\n",
+      "  done: false\n",
+      "  episode_len_mean: 877.1708860759494\n",
+      "  episode_reward_max: 273.13131313131294\n",
+      "  episode_reward_mean: 224.28870988364636\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.1623204231262207\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.0048057976178824905\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00972368239890784\n",
+      "        total_loss: 8.319466400146485\n",
+      "        vf_explained_var: 0.7498777508735657\n",
+      "        vf_loss: 8.328228569030761\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 37.63333333333333\n",
+      "    gpu_util_percent0: 0.26266666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0003333333333333333\n",
+      "    ram_util_percent: 9.49\n",
+      "    vram_util_percent0: 0.2729856783644911\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.17678140968259154\n",
+      "    mean_env_wait_ms: 1.6502532711659141\n",
+      "    mean_inference_ms: 5.870735121936333\n",
+      "    mean_raw_obs_processing_ms: 0.4788182656976241\n",
+      "  time_since_restore: 25.622228860855103\n",
+      "  time_this_iter_s: 25.622228860855103\n",
+      "  time_total_s: 25.622228860855103\n",
+      "  timers:\n",
+      "    learn_throughput: 10340.312\n",
+      "    learn_time_ms: 15646.724\n",
+      "    sample_throughput: 16338.488\n",
+      "    sample_time_ms: 9902.507\n",
+      "    update_time_ms: 42.975\n",
+      "  timestamp: 1602167142\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 72.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      1 |          25.6222 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3217.0\n",
+      "  date: 2020-10-08_14-26-06\n",
+      "  done: false\n",
+      "  episode_len_mean: 870.7974683544304\n",
+      "  episode_reward_max: 278.3535353535354\n",
+      "  episode_reward_mean: 226.3724267996418\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.138706338405609\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006825200421735645\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01274334719637409\n",
+      "        total_loss: 7.690042400360108\n",
+      "        vf_explained_var: 0.8869457244873047\n",
+      "        vf_loss: 7.702103328704834\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 35.425925925925924\n",
+      "    gpu_util_percent0: 0.3437037037037037\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.73703703703704\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.17196632938280343\n",
+      "    mean_env_wait_ms: 1.646491991621751\n",
+      "    mean_inference_ms: 5.588687582318563\n",
+      "    mean_raw_obs_processing_ms: 0.467505042931231\n",
+      "  time_since_restore: 49.39094591140747\n",
+      "  time_this_iter_s: 23.768717050552368\n",
+      "  time_total_s: 49.39094591140747\n",
+      "  timers:\n",
+      "    learn_throughput: 10452.268\n",
+      "    learn_time_ms: 15479.129\n",
+      "    sample_throughput: 17702.943\n",
+      "    sample_time_ms: 9139.271\n",
+      "    update_time_ms: 38.137\n",
+      "  timestamp: 1602167166\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      2 |          49.3909 | 323584 |  226.372 |              278.354 |              115.788 |            870.797 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3217.0\n",
+      "  date: 2020-10-08_14-26-30\n",
+      "  done: false\n",
+      "  episode_len_mean: 866.331223628692\n",
+      "  episode_reward_max: 278.3535353535354\n",
+      "  episode_reward_mean: 226.87126539658163\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.1217446804046631\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.007683717552572489\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014337884564884006\n",
+      "        total_loss: 8.763248443603516\n",
+      "        vf_explained_var: 0.9284197092056274\n",
+      "        vf_loss: 8.77681770324707\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.08620689655172\n",
+      "    gpu_util_percent0: 0.3172413793103448\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.755172413793105\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16894469760208242\n",
+      "    mean_env_wait_ms: 1.6450424063300917\n",
+      "    mean_inference_ms: 5.427040881695507\n",
+      "    mean_raw_obs_processing_ms: 0.45877313240781425\n",
+      "  time_since_restore: 73.57178139686584\n",
+      "  time_this_iter_s: 24.180835485458374\n",
+      "  time_total_s: 73.57178139686584\n",
+      "  timers:\n",
+      "    learn_throughput: 10452.901\n",
+      "    learn_time_ms: 15478.191\n",
+      "    sample_throughput: 18089.282\n",
+      "    sample_time_ms: 8944.081\n",
+      "    update_time_ms: 56.055\n",
+      "  timestamp: 1602167190\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      3 |          73.5718 | 485376 |  226.871 |              278.354 |              115.788 |            866.331 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3217.0\n",
+      "  date: 2020-10-08_14-26-54\n",
+      "  done: false\n",
+      "  episode_len_mean: 861.253164556962\n",
+      "  episode_reward_max: 278.3535353535354\n",
+      "  episode_reward_mean: 227.7450294080039\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.0939712405204773\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.009209706541150808\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015771377924829723\n",
+      "        total_loss: 8.429035234451295\n",
+      "        vf_explained_var: 0.9521434903144836\n",
+      "        vf_loss: 8.443885612487794\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 35.03333333333334\n",
+      "    gpu_util_percent0: 0.2777777777777778\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.751851851851852\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16676384022481172\n",
+      "    mean_env_wait_ms: 1.6466515242102222\n",
+      "    mean_inference_ms: 5.307577815654116\n",
+      "    mean_raw_obs_processing_ms: 0.4522795805237597\n",
+      "  time_since_restore: 97.21736693382263\n",
+      "  time_this_iter_s: 23.645585536956787\n",
+      "  time_total_s: 97.21736693382263\n",
+      "  timers:\n",
+      "    learn_throughput: 10478.311\n",
+      "    learn_time_ms: 15440.657\n",
+      "    sample_throughput: 18466.869\n",
+      "    sample_time_ms: 8761.204\n",
+      "    update_time_ms: 52.666\n",
+      "  timestamp: 1602167214\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      4 |          97.2174 | 647168 |  227.745 |              278.354 |              115.788 |            861.253 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3217.0\n",
+      "  date: 2020-10-08_14-27-17\n",
+      "  done: false\n",
+      "  episode_len_mean: 849.2613882863341\n",
+      "  episode_reward_max: 278.3535353535354\n",
+      "  episode_reward_mean: 228.4696860141544\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 290\n",
+      "  episodes_total: 922\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.0592716097831727\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.007743995590135455\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014329827937763185\n",
+      "        total_loss: 12.433664703369141\n",
+      "        vf_explained_var: 0.967904269695282\n",
+      "        vf_loss: 12.447219848632812\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.35357142857143\n",
+      "    gpu_util_percent0: 0.2582142857142857\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.746428571428572\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16431055835082262\n",
+      "    mean_env_wait_ms: 1.6540874340682217\n",
+      "    mean_inference_ms: 5.1659246506223315\n",
+      "    mean_raw_obs_processing_ms: 0.4451297976580212\n",
+      "  time_since_restore: 120.98013472557068\n",
+      "  time_this_iter_s: 23.762767791748047\n",
+      "  time_total_s: 120.98013472557068\n",
+      "  timers:\n",
+      "    learn_throughput: 10471.141\n",
+      "    learn_time_ms: 15451.229\n",
+      "    sample_throughput: 18710.121\n",
+      "    sample_time_ms: 8647.299\n",
+      "    update_time_ms: 46.768\n",
+      "  timestamp: 1602167237\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      5 |           120.98 | 808960 |   228.47 |              278.354 |              115.788 |            849.261 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3217.0\n",
+      "  date: 2020-10-08_14-27-41\n",
+      "  done: false\n",
+      "  episode_len_mean: 842.2649186256781\n",
+      "  episode_reward_max: 278.3535353535354\n",
+      "  episode_reward_mean: 228.83911447202573\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 184\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.0483574509620666\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.007546161720529199\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015934903593733906\n",
+      "        total_loss: 6.211568450927734\n",
+      "        vf_explained_var: 0.979483425617218\n",
+      "        vf_loss: 6.22674880027771\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.42962962962963\n",
+      "    gpu_util_percent0: 0.23518518518518516\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.762962962962964\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16320835121240662\n",
+      "    mean_env_wait_ms: 1.658072254904595\n",
+      "    mean_inference_ms: 5.101929976377745\n",
+      "    mean_raw_obs_processing_ms: 0.44197622201871506\n",
+      "  time_since_restore: 144.46361637115479\n",
+      "  time_this_iter_s: 23.483481645584106\n",
+      "  time_total_s: 144.46361637115479\n",
+      "  timers:\n",
+      "    learn_throughput: 10482.756\n",
+      "    learn_time_ms: 15434.108\n",
+      "    sample_throughput: 18930.618\n",
+      "    sample_time_ms: 8546.578\n",
+      "    update_time_ms: 45.48\n",
+      "  timestamp: 1602167261\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      6 |          144.464 | 970752 |  228.839 |              278.354 |              115.788 |            842.265 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-28-05\n",
+      "  done: false\n",
+      "  episode_len_mean: 837.381329113924\n",
+      "  episode_reward_max: 279.83838383838383\n",
+      "  episode_reward_mean: 228.88543664493022\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.0276257395744324\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006892968993633985\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01625481452792883\n",
+      "        total_loss: 5.934515047073364\n",
+      "        vf_explained_var: 0.9834254384040833\n",
+      "        vf_loss: 5.950080394744873\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.47777777777778\n",
+      "    gpu_util_percent0: 0.2955555555555555\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.755555555555556\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16243749898577767\n",
+      "    mean_env_wait_ms: 1.6615503416153818\n",
+      "    mean_inference_ms: 5.056720554339727\n",
+      "    mean_raw_obs_processing_ms: 0.439742077717109\n",
+      "  time_since_restore: 168.09322547912598\n",
+      "  time_this_iter_s: 23.62960910797119\n",
+      "  time_total_s: 168.09322547912598\n",
+      "  timers:\n",
+      "    learn_throughput: 10486.247\n",
+      "    learn_time_ms: 15428.971\n",
+      "    sample_throughput: 19063.221\n",
+      "    sample_time_ms: 8487.128\n",
+      "    update_time_ms: 45.241\n",
+      "  timestamp: 1602167285\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      7 |          168.093 | 1132544 |  228.885 |              279.838 |              115.788 |            837.381 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-28-28\n",
+      "  done: false\n",
+      "  episode_len_mean: 833.6736990154711\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 229.3878233814942\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9920619606971741\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.0067844231147319075\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01662699868902564\n",
+      "        total_loss: 5.330079460144043\n",
+      "        vf_explained_var: 0.9873720407485962\n",
+      "        vf_loss: 5.346027898788452\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.72222222222223\n",
+      "    gpu_util_percent0: 0.2811111111111111\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.755555555555556\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16179048159969586\n",
+      "    mean_env_wait_ms: 1.664834322637065\n",
+      "    mean_inference_ms: 5.017627986563437\n",
+      "    mean_raw_obs_processing_ms: 0.43762471876215703\n",
+      "  time_since_restore: 191.7211263179779\n",
+      "  time_this_iter_s: 23.62790083885193\n",
+      "  time_total_s: 191.7211263179779\n",
+      "  timers:\n",
+      "    learn_throughput: 10499.739\n",
+      "    learn_time_ms: 15409.145\n",
+      "    sample_throughput: 19126.146\n",
+      "    sample_time_ms: 8459.205\n",
+      "    update_time_ms: 44.366\n",
+      "  timestamp: 1602167308\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      8 |          191.721 | 1294336 |  229.388 |              281.606 |              115.788 |            833.674 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-28-52\n",
+      "  done: false\n",
+      "  episode_len_mean: 827.9994246260069\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 229.99320593739455\n",
+      "  episode_reward_min: 114.74747474747485\n",
+      "  episodes_this_iter: 316\n",
+      "  episodes_total: 1738\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9606243968009949\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005957465758547187\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013455570582300425\n",
+      "        total_loss: 7.494734096527099\n",
+      "        vf_explained_var: 0.9888100624084473\n",
+      "        vf_loss: 7.5075939178466795\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.90357142857143\n",
+      "    gpu_util_percent0: 0.26678571428571424\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.746428571428572\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16076244116115793\n",
+      "    mean_env_wait_ms: 1.6704480394177186\n",
+      "    mean_inference_ms: 4.955192966914281\n",
+      "    mean_raw_obs_processing_ms: 0.4343471050403994\n",
+      "  time_since_restore: 215.57324147224426\n",
+      "  time_this_iter_s: 23.852115154266357\n",
+      "  time_total_s: 215.57324147224426\n",
+      "  timers:\n",
+      "    learn_throughput: 10506.415\n",
+      "    learn_time_ms: 15399.353\n",
+      "    sample_throughput: 19131.856\n",
+      "    sample_time_ms: 8456.681\n",
+      "    update_time_ms: 41.666\n",
+      "  timestamp: 1602167332\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      9 |          215.573 | 1456128 |  229.993 |              281.606 |              114.747 |            827.999 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-29-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 826.5395569620254\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 230.1556546477432\n",
+      "  episode_reward_min: 114.74747474747485\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9285854279994965\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.0062581704463809725\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016021200059913098\n",
+      "        total_loss: 3.8204103231430055\n",
+      "        vf_explained_var: 0.9922056198120117\n",
+      "        vf_loss: 3.835805630683899\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.096296296296295\n",
+      "    gpu_util_percent0: 0.25592592592592595\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.762962962962964\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1603412050605606\n",
+      "    mean_env_wait_ms: 1.6728638400028686\n",
+      "    mean_inference_ms: 4.929926052491426\n",
+      "    mean_raw_obs_processing_ms: 0.4330192737930434\n",
+      "  time_since_restore: 238.919837474823\n",
+      "  time_this_iter_s: 23.346596002578735\n",
+      "  time_total_s: 238.919837474823\n",
+      "  timers:\n",
+      "    learn_throughput: 10519.707\n",
+      "    learn_time_ms: 15379.897\n",
+      "    sample_throughput: 19222.536\n",
+      "    sample_time_ms: 8416.788\n",
+      "    update_time_ms: 40.812\n",
+      "  timestamp: 1602167356\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     10 |           238.92 | 1617920 |  230.156 |              281.606 |              114.747 |             826.54 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-29-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 825.4615384615385\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 230.21514069615333\n",
+      "  episode_reward_min: 114.74747474747485\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2054\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.9235042989253998\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005789411393925548\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014859883906319737\n",
+      "        total_loss: 4.004831600189209\n",
+      "        vf_explained_var: 0.9919689893722534\n",
+      "        vf_loss: 4.019112539291382\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.4\n",
+      "    gpu_util_percent0: 0.3125925925925926\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.755555555555556\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15996985034496003\n",
+      "    mean_env_wait_ms: 1.675007114196491\n",
+      "    mean_inference_ms: 4.907016710777437\n",
+      "    mean_raw_obs_processing_ms: 0.4317794077781022\n",
+      "  time_since_restore: 262.4391770362854\n",
+      "  time_this_iter_s: 23.519339561462402\n",
+      "  time_total_s: 262.4391770362854\n",
+      "  timers:\n",
+      "    learn_throughput: 10544.089\n",
+      "    learn_time_ms: 15344.332\n",
+      "    sample_throughput: 19638.715\n",
+      "    sample_time_ms: 8238.421\n",
+      "    update_time_ms: 40.485\n",
+      "  timestamp: 1602167379\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     11 |          262.439 | 1779712 |  230.215 |              281.606 |              114.747 |            825.462 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-30-03\n",
+      "  done: false\n",
+      "  episode_len_mean: 824.152428057554\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 230.18242224402292\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 170\n",
+      "  episodes_total: 2224\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.8818272411823272\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005413110228255391\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013095138547942042\n",
+      "        total_loss: 5.083396100997925\n",
+      "        vf_explained_var: 0.9921062588691711\n",
+      "        vf_loss: 5.0959498405456545\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.042857142857144\n",
+      "    gpu_util_percent0: 0.1942857142857143\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.757142857142858\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15960744702974256\n",
+      "    mean_env_wait_ms: 1.677271579492208\n",
+      "    mean_inference_ms: 4.884761150099492\n",
+      "    mean_raw_obs_processing_ms: 0.4305594741365648\n",
+      "  time_since_restore: 286.0365300178528\n",
+      "  time_this_iter_s: 23.597352981567383\n",
+      "  time_total_s: 286.0365300178528\n",
+      "  timers:\n",
+      "    learn_throughput: 10540.17\n",
+      "    learn_time_ms: 15350.038\n",
+      "    sample_throughput: 19693.201\n",
+      "    sample_time_ms: 8215.627\n",
+      "    update_time_ms: 39.264\n",
+      "  timestamp: 1602167403\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     12 |          286.037 | 1941504 |  230.182 |              281.606 |              99.1212 |            824.152 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-30-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 822.2670094936709\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 230.69313387034907\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 304\n",
+      "  episodes_total: 2528\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.8522311568260192\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005159769672900438\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012773643853142858\n",
+      "        total_loss: 5.1331462383270265\n",
+      "        vf_explained_var: 0.9925912618637085\n",
+      "        vf_loss: 5.145403909683227\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.01481481481482\n",
+      "    gpu_util_percent0: 0.30111111111111116\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.751851851851852\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15905681990758594\n",
+      "    mean_env_wait_ms: 1.68066117965344\n",
+      "    mean_inference_ms: 4.850479242048183\n",
+      "    mean_raw_obs_processing_ms: 0.4287066632526924\n",
+      "  time_since_restore: 309.50186347961426\n",
+      "  time_this_iter_s: 23.465333461761475\n",
+      "  time_total_s: 309.50186347961426\n",
+      "  timers:\n",
+      "    learn_throughput: 10553.501\n",
+      "    learn_time_ms: 15330.648\n",
+      "    sample_throughput: 19829.166\n",
+      "    sample_time_ms: 8159.294\n",
+      "    update_time_ms: 40.29\n",
+      "  timestamp: 1602167427\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     13 |          309.502 | 2103296 |  230.693 |              281.606 |              99.1212 |            822.267 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-30-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 821.4538346984364\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 230.94512511563886\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.8369874477386474\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005370886158198118\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01467731585726142\n",
+      "        total_loss: 3.154995489120483\n",
+      "        vf_explained_var: 0.9942510724067688\n",
+      "        vf_loss: 3.1691357612609865\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.181481481481484\n",
+      "    gpu_util_percent0: 0.3040740740740741\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.766666666666667\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1588082507195649\n",
+      "    mean_env_wait_ms: 1.6822641931487865\n",
+      "    mean_inference_ms: 4.835116455543884\n",
+      "    mean_raw_obs_processing_ms: 0.42786989591003743\n",
+      "  time_since_restore: 332.9755485057831\n",
+      "  time_this_iter_s: 23.473685026168823\n",
+      "  time_total_s: 332.9755485057831\n",
+      "  timers:\n",
+      "    learn_throughput: 10555.883\n",
+      "    learn_time_ms: 15327.187\n",
+      "    sample_throughput: 19878.044\n",
+      "    sample_time_ms: 8139.232\n",
+      "    update_time_ms: 45.711\n",
+      "  timestamp: 1602167450\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     14 |          332.976 | 2265088 |  230.945 |              281.606 |              99.1212 |            821.454 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-31-14\n",
+      "  done: false\n",
+      "  episode_len_mean: 820.854781997187\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 231.2064917813863\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.827689278125763\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005339382635429502\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014263017289340495\n",
+      "        total_loss: 3.00002179145813\n",
+      "        vf_explained_var: 0.9941463470458984\n",
+      "        vf_loss: 3.0137508869171143\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.57037037037037\n",
+      "    gpu_util_percent0: 0.2274074074074074\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.77037037037037\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15857855076630387\n",
+      "    mean_env_wait_ms: 1.6837618809370547\n",
+      "    mean_inference_ms: 4.820936656490715\n",
+      "    mean_raw_obs_processing_ms: 0.4270767088680792\n",
+      "  time_since_restore: 356.605441570282\n",
+      "  time_this_iter_s: 23.6298930644989\n",
+      "  time_total_s: 356.605441570282\n",
+      "  timers:\n",
+      "    learn_throughput: 10553.654\n",
+      "    learn_time_ms: 15330.425\n",
+      "    sample_throughput: 19924.68\n",
+      "    sample_time_ms: 8120.181\n",
+      "    update_time_ms: 47.653\n",
+      "  timestamp: 1602167474\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     15 |          356.605 | 2426880 |  231.206 |              281.606 |              99.1212 |            820.855 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-31-38\n",
+      "  done: false\n",
+      "  episode_len_mean: 820.0182767624021\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 231.22214310203864\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 220\n",
+      "  episodes_total: 3064\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7918125212192535\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.004892151476815343\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012084704916924238\n",
+      "        total_loss: 4.1488186597824095\n",
+      "        vf_explained_var: 0.9942665100097656\n",
+      "        vf_loss: 4.160414218902588\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.81481481481482\n",
+      "    gpu_util_percent0: 0.3077777777777778\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.74814814814815\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.158297804116007\n",
+      "    mean_env_wait_ms: 1.6859562656031242\n",
+      "    mean_inference_ms: 4.803618536248515\n",
+      "    mean_raw_obs_processing_ms: 0.42616514556223817\n",
+      "  time_since_restore: 380.0873718261719\n",
+      "  time_this_iter_s: 23.481930255889893\n",
+      "  time_total_s: 380.0873718261719\n",
+      "  timers:\n",
+      "    learn_throughput: 10556.149\n",
+      "    learn_time_ms: 15326.802\n",
+      "    sample_throughput: 19915.022\n",
+      "    sample_time_ms: 8124.119\n",
+      "    update_time_ms: 46.174\n",
+      "  timestamp: 1602167498\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     16 |          380.087 | 2588672 |  231.222 |              281.606 |              99.1212 |            820.018 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-32-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 819.2076552139844\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 231.34207049396923\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 254\n",
+      "  episodes_total: 3318\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7639730334281921\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.004952558875083923\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011812644638121128\n",
+      "        total_loss: 3.641219711303711\n",
+      "        vf_explained_var: 0.9940530061721802\n",
+      "        vf_loss: 3.6527847766876222\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.58928571428571\n",
+      "    gpu_util_percent0: 0.33428571428571435\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.746428571428572\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1579861428053209\n",
+      "    mean_env_wait_ms: 1.6878268274425987\n",
+      "    mean_inference_ms: 4.784786851610141\n",
+      "    mean_raw_obs_processing_ms: 0.4251258149287427\n",
+      "  time_since_restore: 403.5224757194519\n",
+      "  time_this_iter_s: 23.43510389328003\n",
+      "  time_total_s: 403.5224757194519\n",
+      "  timers:\n",
+      "    learn_throughput: 10564.477\n",
+      "    learn_time_ms: 15314.719\n",
+      "    sample_throughput: 19933.192\n",
+      "    sample_time_ms: 8116.713\n",
+      "    update_time_ms: 45.777\n",
+      "  timestamp: 1602167521\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     17 |          403.522 | 2750464 |  231.342 |              281.606 |              99.1212 |            819.208 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-32-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 818.5304948216341\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 231.56991956387816\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7660917460918426\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005422895355150103\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013137935660779476\n",
+      "        total_loss: 2.9323360919952393\n",
+      "        vf_explained_var: 0.9942866563796997\n",
+      "        vf_loss: 2.94533851146698\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.25925925925925\n",
+      "    gpu_util_percent0: 0.36148148148148146\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.759259259259261\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15781721284272957\n",
+      "    mean_env_wait_ms: 1.6890502862525536\n",
+      "    mean_inference_ms: 4.774409463690571\n",
+      "    mean_raw_obs_processing_ms: 0.4245721837690542\n",
+      "  time_since_restore: 426.88156366348267\n",
+      "  time_this_iter_s: 23.35908794403076\n",
+      "  time_total_s: 426.88156366348267\n",
+      "  timers:\n",
+      "    learn_throughput: 10562.111\n",
+      "    learn_time_ms: 15318.149\n",
+      "    sample_throughput: 20027.117\n",
+      "    sample_time_ms: 8078.647\n",
+      "    update_time_ms: 51.49\n",
+      "  timestamp: 1602167545\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     18 |          426.882 | 2912256 |   231.57 |              281.606 |              99.1212 |             818.53 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-32-49\n",
+      "  done: false\n",
+      "  episode_len_mean: 817.8346629986245\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 231.78994900865604\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 159\n",
+      "  episodes_total: 3635\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.761504179239273\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.00561123825609684\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01371184946037829\n",
+      "        total_loss: 2.586661458015442\n",
+      "        vf_explained_var: 0.9948149919509888\n",
+      "        vf_loss: 2.6002331018447875\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.98518518518519\n",
+      "    gpu_util_percent0: 0.25\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.762962962962964\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1576552038626758\n",
+      "    mean_env_wait_ms: 1.6902745430630273\n",
+      "    mean_inference_ms: 4.764639495963006\n",
+      "    mean_raw_obs_processing_ms: 0.42404147010851506\n",
+      "  time_since_restore: 450.4647214412689\n",
+      "  time_this_iter_s: 23.583157777786255\n",
+      "  time_total_s: 450.4647214412689\n",
+      "  timers:\n",
+      "    learn_throughput: 10558.952\n",
+      "    learn_time_ms: 15322.733\n",
+      "    sample_throughput: 20107.322\n",
+      "    sample_time_ms: 8046.422\n",
+      "    update_time_ms: 53.421\n",
+      "  timestamp: 1602167569\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     19 |          450.465 | 3074048 |   231.79 |              281.606 |              99.1212 |            817.835 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-33-12\n",
+      "  done: false\n",
+      "  episode_len_mean: 816.6687881873727\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 232.22543664753442\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 293\n",
+      "  episodes_total: 3928\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.025\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7176933705806732\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.004935431573539972\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011507348460145294\n",
+      "        total_loss: 3.7333247661590576\n",
+      "        vf_explained_var: 0.9947683215141296\n",
+      "        vf_loss: 3.744708704948425\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.92962962962963\n",
+      "    gpu_util_percent0: 0.22925925925925927\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.751851851851852\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15738510281829127\n",
+      "    mean_env_wait_ms: 1.6923950386450304\n",
+      "    mean_inference_ms: 4.748233050103123\n",
+      "    mean_raw_obs_processing_ms: 0.4231474863161252\n",
+      "  time_since_restore: 473.9994788169861\n",
+      "  time_this_iter_s: 23.534757375717163\n",
+      "  time_total_s: 473.9994788169861\n",
+      "  timers:\n",
+      "    learn_throughput: 10546.772\n",
+      "    learn_time_ms: 15340.429\n",
+      "    sample_throughput: 20112.723\n",
+      "    sample_time_ms: 8044.261\n",
+      "    update_time_ms: 53.96\n",
+      "  timestamp: 1602167592\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     20 |          473.999 | 3235840 |  232.225 |              281.606 |              99.1212 |            816.669 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-33-36\n",
+      "  done: false\n",
+      "  episode_len_mean: 815.9362220058423\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 232.68833171048362\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 180\n",
+      "  episodes_total: 4108\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.0125\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.6961194634437561\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.0054001738782972096\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013575149234384298\n",
+      "        total_loss: 2.1967584609985353\n",
+      "        vf_explained_var: 0.9954622387886047\n",
+      "        vf_loss: 2.210266089439392\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.440740740740736\n",
+      "    gpu_util_percent0: 0.29666666666666663\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.762962962962964\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15722895249997093\n",
+      "    mean_env_wait_ms: 1.6936030533075188\n",
+      "    mean_inference_ms: 4.738907510439971\n",
+      "    mean_raw_obs_processing_ms: 0.42262820408828605\n",
+      "  time_since_restore: 497.52709674835205\n",
+      "  time_this_iter_s: 23.527617931365967\n",
+      "  time_total_s: 497.52709674835205\n",
+      "  timers:\n",
+      "    learn_throughput: 10537.753\n",
+      "    learn_time_ms: 15353.558\n",
+      "    sample_throughput: 20139.989\n",
+      "    sample_time_ms: 8033.371\n",
+      "    update_time_ms: 52.995\n",
+      "  timestamp: 1602167616\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     21 |          497.527 | 3397632 |  232.688 |              281.606 |              99.1212 |            815.936 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-34-00\n",
+      "  done: false\n",
+      "  episode_len_mean: 815.2585560243788\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 232.9339172313856\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.0125\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.7063014328479766\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005521039292216301\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013345666276291013\n",
+      "        total_loss: 2.40686240196228\n",
+      "        vf_explained_var: 0.994661808013916\n",
+      "        vf_loss: 2.4201390743255615\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.3\n",
+      "    gpu_util_percent0: 0.3596428571428571\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.760714285714286\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15710538677505165\n",
+      "    mean_env_wait_ms: 1.694637493002915\n",
+      "    mean_inference_ms: 4.731284261187251\n",
+      "    mean_raw_obs_processing_ms: 0.42220494507105216\n",
+      "  time_since_restore: 521.2907056808472\n",
+      "  time_this_iter_s: 23.763608932495117\n",
+      "  time_total_s: 521.2907056808472\n",
+      "  timers:\n",
+      "    learn_throughput: 10529.291\n",
+      "    learn_time_ms: 15365.897\n",
+      "    sample_throughput: 20152.527\n",
+      "    sample_time_ms: 8028.373\n",
+      "    update_time_ms: 60.563\n",
+      "  timestamp: 1602167640\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     22 |          521.291 | 3559424 |  232.934 |              281.606 |              99.1212 |            815.259 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-34-24\n",
+      "  done: false\n",
+      "  episode_len_mean: 814.5122444394518\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 233.18438711990723\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 185\n",
+      "  episodes_total: 4451\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.0125\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.687007212638855\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005151082994416356\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0136242700740695\n",
+      "        total_loss: 2.3987212419509887\n",
+      "        vf_explained_var: 0.9956458210945129\n",
+      "        vf_loss: 2.412281060218811\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.87777777777778\n",
+      "    gpu_util_percent0: 0.32259259259259254\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.755555555555556\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15697868978775206\n",
+      "    mean_env_wait_ms: 1.6959996633636125\n",
+      "    mean_inference_ms: 4.723299684373984\n",
+      "    mean_raw_obs_processing_ms: 0.42177767922029563\n",
+      "  time_since_restore: 544.7509255409241\n",
+      "  time_this_iter_s: 23.460219860076904\n",
+      "  time_total_s: 544.7509255409241\n",
+      "  timers:\n",
+      "    learn_throughput: 10523.637\n",
+      "    learn_time_ms: 15374.152\n",
+      "    sample_throughput: 20153.695\n",
+      "    sample_time_ms: 8027.908\n",
+      "    update_time_ms: 54.413\n",
+      "  timestamp: 1602167664\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     23 |          544.751 | 3721216 |  233.184 |              281.606 |              99.1212 |            814.512 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-34-48\n",
+      "  done: false\n",
+      "  episode_len_mean: 813.3535864978903\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 233.57533989685885\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 289\n",
+      "  episodes_total: 4740\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.0125\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.6324166178703308\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.0048749387264251706\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011797640426084399\n",
+      "        total_loss: 2.6533204078674317\n",
+      "        vf_explained_var: 0.9955232739448547\n",
+      "        vf_loss: 2.66505708694458\n",
+      "    num_steps_sampled: 3883008\n",
+      "    num_steps_trained: 3883008\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.074074074074076\n",
+      "    gpu_util_percent0: 0.3251851851851852\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.74814814814815\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15677630383088909\n",
+      "    mean_env_wait_ms: 1.6975983446472827\n",
+      "    mean_inference_ms: 4.710750302441915\n",
+      "    mean_raw_obs_processing_ms: 0.421060709542158\n",
+      "  time_since_restore: 568.4359018802643\n",
+      "  time_this_iter_s: 23.68497633934021\n",
+      "  time_total_s: 568.4359018802643\n",
+      "  timers:\n",
+      "    learn_throughput: 10517.772\n",
+      "    learn_time_ms: 15382.726\n",
+      "    sample_throughput: 20124.264\n",
+      "    sample_time_ms: 8039.648\n",
+      "    update_time_ms: 48.571\n",
+      "  timestamp: 1602167688\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3883008\n",
+      "  training_iteration: 24\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     24 |          568.436 | 3883008 |  233.575 |              281.606 |              99.1212 |            813.354 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-35-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 812.6929358922009\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 233.80383252698485\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4898\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.00625\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.6476718962192536\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.004980697343125939\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012937380420044064\n",
+      "        total_loss: 2.2160698890686037\n",
+      "        vf_explained_var: 0.9949172735214233\n",
+      "        vf_loss: 2.2289761781692503\n",
+      "    num_steps_sampled: 4044800\n",
+      "    num_steps_trained: 4044800\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.93703703703704\n",
+      "    gpu_util_percent0: 0.2511111111111111\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.762962962962964\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15667803602924033\n",
+      "    mean_env_wait_ms: 1.6985389146300989\n",
+      "    mean_inference_ms: 4.704622565044838\n",
+      "    mean_raw_obs_processing_ms: 0.420720785257639\n",
+      "  time_since_restore: 592.1190402507782\n",
+      "  time_this_iter_s: 23.683138370513916\n",
+      "  time_total_s: 592.1190402507782\n",
+      "  timers:\n",
+      "    learn_throughput: 10525.475\n",
+      "    learn_time_ms: 15371.468\n",
+      "    sample_throughput: 20083.377\n",
+      "    sample_time_ms: 8056.016\n",
+      "    update_time_ms: 47.817\n",
+      "  timestamp: 1602167711\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4044800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     25 |          592.119 | 4044800 |  233.804 |              281.606 |              99.1212 |            812.693 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_11823_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3204.0\n",
+      "  date: 2020-10-08_14-35-35\n",
+      "  done: true\n",
+      "  episode_len_mean: 812.0104784499803\n",
+      "  episode_reward_max: 281.6060606060598\n",
+      "  episode_reward_mean: 234.07366667864886\n",
+      "  episode_reward_min: 99.12121212121178\n",
+      "  episodes_this_iter: 160\n",
+      "  episodes_total: 5058\n",
+      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.003125\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 0.6387091696262359\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.00521918865852058\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013382896583061665\n",
+      "        total_loss: 2.0056067228317263\n",
+      "        vf_explained_var: 0.9955011606216431\n",
+      "        vf_loss: 2.0189733505249023\n",
+      "    num_steps_sampled: 4206592\n",
+      "    num_steps_trained: 4206592\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.729629629629635\n",
+      "    gpu_util_percent0: 0.267037037037037\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.766666666666667\n",
+      "    vram_util_percent0: 0.29673663496228275\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 33202\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15658306876779257\n",
+      "    mean_env_wait_ms: 1.6995085455679213\n",
+      "    mean_inference_ms: 4.6987769399539845\n",
+      "    mean_raw_obs_processing_ms: 0.42039589930108456\n",
+      "  time_since_restore: 615.6618909835815\n",
+      "  time_this_iter_s: 23.542850732803345\n",
+      "  time_total_s: 615.6618909835815\n",
+      "  timers:\n",
+      "    learn_throughput: 10524.21\n",
+      "    learn_time_ms: 15373.315\n",
+      "    sample_throughput: 20076.608\n",
+      "    sample_time_ms: 8058.732\n",
+      "    update_time_ms: 48.59\n",
+      "  timestamp: 1602167735\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 4206592\n",
+      "  training_iteration: 26\n",
+      "  trial_id: '11823_00000'\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 32990\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_142505-w8c2p6ff/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_142505-w8c2p6ff/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3204.0\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 630\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602167735\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 279.83838\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 228.88544\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1264\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmajor-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/w8c2p6ff\u001b[0m\n",
+      "2020-10-08 14:35:46,970 - wandb.wandb_agent - INFO - Cleaning up finished run: w8c2p6ff\n",
+      "2020-10-08 14:35:47,283 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-08 14:35:47,283 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.2\n",
+      "\tlambda: 0.95\n",
+      "\tlr: 0.0001\n",
+      "\tnum_envs_per_worker: 2\n",
+      "\tnum_sgd_iter: 20\n",
+      "\tsgd_minibatch_size: 32768\n",
+      "2020-10-08 14:35:47,287 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=32768\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvibrant-sweep-4\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/y6ys1sgz\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_143549-y6ys1sgz\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-08 14:35:51,552\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
+      "2020-10-08 14:35:52,322 - wandb.wandb_agent - INFO - Running runs: ['y6ys1sgz']\n",
+      "== Status ==\n",
+      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_915d0_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=62403)\u001b[0m 2020-10-08 14:35:54,588\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=62386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62376)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62376)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62383)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62383)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62371)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62371)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62368)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62368)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62342)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62342)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62365)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62365)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62267)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62267)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62280)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62280)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62286)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62286)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62356)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62356)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62406)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62406)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62276)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62276)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62375)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62375)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62287)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62287)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62336)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62336)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62264)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62264)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62281)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62281)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62333)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62333)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62341)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62341)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62339)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62339)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62289)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62289)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62288)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62288)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62334)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62334)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62377)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62377)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62270)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62270)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62331)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62331)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62344)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62344)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62284)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62284)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62262)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62262)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62328)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62328)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=62338)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=62338)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_915d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3279.0\n",
+      "  date: 2020-10-08_14-36-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 877.1708860759494\n",
+      "  episode_reward_max: 273.13131313131294\n",
+      "  episode_reward_mean: 224.28870988364636\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.1634249687194824\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.0036954283714294434\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006869117938913405\n",
+      "        total_loss: 9.30032901763916\n",
+      "        vf_explained_var: 0.7174946069717407\n",
+      "        vf_loss: 9.306459045410156\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 39.282758620689656\n",
+      "    gpu_util_percent0: 0.27758620689655167\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0003448275862068966\n",
+      "    ram_util_percent: 9.486206896551723\n",
+      "    vram_util_percent0: 0.30692086721480194\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 62403\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1757240295410156\n",
+      "    mean_env_wait_ms: 1.64632514878238\n",
+      "    mean_inference_ms: 5.702464303031089\n",
+      "    mean_raw_obs_processing_ms: 0.4785182454697177\n",
+      "  time_since_restore: 24.381270170211792\n",
+      "  time_this_iter_s: 24.381270170211792\n",
+      "  time_total_s: 24.381270170211792\n",
+      "  timers:\n",
+      "    learn_throughput: 10955.585\n",
+      "    learn_time_ms: 14767.992\n",
+      "    sample_throughput: 16976.731\n",
+      "    sample_time_ms: 9530.221\n",
+      "    update_time_ms: 49.441\n",
+      "  timestamp: 1602167785\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: 915d0_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 72.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      1 |          24.3813 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_915d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3152.0\n",
+      "  date: 2020-10-08_14-36-48\n",
+      "  done: false\n",
+      "  episode_len_mean: 867.5569620253165\n",
+      "  episode_reward_max: 287.616161616161\n",
+      "  episode_reward_mean: 226.67721518987318\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.1362101554870605\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006970350444316864\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009705625101923942\n",
+      "        total_loss: 10.32210750579834\n",
+      "        vf_explained_var: 0.8451136350631714\n",
+      "        vf_loss: 10.331116104125977\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 36.548148148148144\n",
+      "    gpu_util_percent0: 0.2866666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.733333333333334\n",
+      "    vram_util_percent0: 0.355608396195474\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 62403\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.17100616576939356\n",
+      "    mean_env_wait_ms: 1.647485749663841\n",
+      "    mean_inference_ms: 5.449976105277291\n",
+      "    mean_raw_obs_processing_ms: 0.4667153357279003\n",
+      "  time_since_restore: 47.252567291259766\n",
+      "  time_this_iter_s: 22.871297121047974\n",
+      "  time_total_s: 47.252567291259766\n",
+      "  timers:\n",
+      "    learn_throughput: 11041.238\n",
+      "    learn_time_ms: 14653.429\n",
+      "    sample_throughput: 18199.954\n",
+      "    sample_time_ms: 8889.693\n",
+      "    update_time_ms: 42.206\n",
+      "  timestamp: 1602167808\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: 915d0_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      2 |          47.2526 | 323584 |  226.677 |              287.616 |              115.788 |            867.557 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_915d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3152.0\n",
+      "  date: 2020-10-08_14-37-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 859.824894514768\n",
+      "  episode_reward_max: 287.616161616161\n",
+      "  episode_reward_mean: 228.24830584324238\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.12405526638031\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006674189120531082\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010977230872958899\n",
+      "        total_loss: 12.676021194458007\n",
+      "        vf_explained_var: 0.8899718523025513\n",
+      "        vf_loss: 12.686330986022949\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 36.05555555555555\n",
+      "    gpu_util_percent0: 0.2644444444444444\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.751851851851852\n",
+      "    vram_util_percent0: 0.355608396195474\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 62403\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16808367664964877\n",
+      "    mean_env_wait_ms: 1.6489405832417077\n",
+      "    mean_inference_ms: 5.307994845910706\n",
+      "    mean_raw_obs_processing_ms: 0.45738673020424264\n",
+      "  time_since_restore: 70.47958087921143\n",
+      "  time_this_iter_s: 23.22701358795166\n",
+      "  time_total_s: 70.47958087921143\n",
+      "  timers:\n",
+      "    learn_throughput: 11042.229\n",
+      "    learn_time_ms: 14652.115\n",
+      "    sample_throughput: 18479.026\n",
+      "    sample_time_ms: 8755.44\n",
+      "    update_time_ms: 41.454\n",
+      "  timestamp: 1602167831\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: 915d0_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      3 |          70.4796 | 485376 |  228.248 |              287.616 |              115.788 |            859.825 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_915d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3152.0\n",
+      "  date: 2020-10-08_14-37-34\n",
+      "  done: false\n",
+      "  episode_len_mean: 853.2689873417721\n",
+      "  episode_reward_max: 287.616161616161\n",
+      "  episode_reward_mean: 228.76543920214786\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.0947366952896118\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.005848201550543308\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01150441262871027\n",
+      "        total_loss: 13.476828002929688\n",
+      "        vf_explained_var: 0.9183750152587891\n",
+      "        vf_loss: 13.487747383117675\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 35.855555555555554\n",
+      "    gpu_util_percent0: 0.27814814814814814\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.744444444444445\n",
+      "    vram_util_percent0: 0.355608396195474\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 62403\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16618084056987167\n",
+      "    mean_env_wait_ms: 1.652121993019246\n",
+      "    mean_inference_ms: 5.206010003773685\n",
+      "    mean_raw_obs_processing_ms: 0.45115332512960615\n",
+      "  time_since_restore: 93.41903614997864\n",
+      "  time_this_iter_s: 22.939455270767212\n",
+      "  time_total_s: 93.41903614997864\n",
+      "  timers:\n",
+      "    learn_throughput: 11054.503\n",
+      "    learn_time_ms: 14635.845\n",
+      "    sample_throughput: 18733.219\n",
+      "    sample_time_ms: 8636.637\n",
+      "    update_time_ms: 36.312\n",
+      "  timestamp: 1602167854\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: 915d0_00000\n",
+      "  \n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "WARNING:root:NaN or Inf found in input tensor.\n",
+      "== Status ==\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      4 |           93.419 | 647168 |  228.765 |              287.616 |              115.788 |            853.269 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_915d0_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: .inf\n",
+      "    time_step_mean: .inf\n",
+      "    time_step_min: 3152.0\n",
+      "  date: 2020-10-08_14-37-57\n",
+      "  done: false\n",
+      "  episode_len_mean: 842.2431289640592\n",
+      "  episode_reward_max: 287.616161616161\n",
+      "  episode_reward_mean: 228.57511691972567\n",
+      "  episode_reward_min: 115.78787878787875\n",
+      "  episodes_this_iter: 314\n",
+      "  episodes_total: 946\n",
+      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 0.0001\n",
+      "        entropy: 1.0704583883285523\n",
+      "        entropy_coeff: 0.0\n",
+      "        kl: 0.006159011553972959\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01097527714446187\n",
+      "        total_loss: 18.48041114807129\n",
+      "        vf_explained_var: 0.9505600929260254\n",
+      "        vf_loss: 18.490771102905274\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.67142857142857\n",
+      "    gpu_util_percent0: 0.34750000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 9.739285714285716\n",
+      "    vram_util_percent0: 0.355608396195474\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 62403\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1637216679032345\n",
+      "    mean_env_wait_ms: 1.6595417244788717\n",
+      "    mean_inference_ms: 5.075327722233796\n",
+      "    mean_raw_obs_processing_ms: 0.443719930951552\n",
+      "  time_since_restore: 116.6165714263916\n",
+      "  time_this_iter_s: 23.197535276412964\n",
+      "  time_total_s: 116.6165714263916\n",
+      "  timers:\n",
+      "    learn_throughput: 11077.95\n",
+      "    learn_time_ms: 14604.868\n",
+      "    sample_throughput: 18764.263\n",
+      "    sample_time_ms: 8622.347\n",
+      "    update_time_ms: 48.444\n",
+      "  timestamp: 1602167877\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: 915d0_00000\n",
       "  \n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 33.4/754.6 GiB\n",
+      "Memory usage on this node: 73.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/550.39 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/PPO\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_4898a_00000 | RUNNING  | 172.17.0.4:22161 |      2 |          50.5818 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |\n",
+      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      5 |          116.617 | 808960 |  228.575 |              287.616 |              115.788 |            842.243 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n"
@@ -2551,7 +7471,7 @@
     }
    ],
    "source": [
-    "!wandb agent mq1j5yvs"
+    "!wandb agent rfs7la4y"
    ]
   },
   {
diff --git a/JSS/train.py b/JSS/train.py
index f228f49..863e891 100644
--- a/JSS/train.py
+++ b/JSS/train.py
@@ -46,11 +46,13 @@ def train_func():
     config.pop('layer_nb', None)
 
     ray.init()
+    
     stop = {
         "time_total_s": 600,
     }
+    
     analysis = tune.run(PPOTrainer, config=config, stop=stop, name="ppo-jss")
-    result = analysis.dataframe().to_dict('index')[0]
+    result = analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').to_dict('index')[0]
     wandb.log({'time_step_min': result['custom_metrics/time_step_min']})
     if result['custom_metrics/time_step_max'] != float('inf'):
         wandb.log({'time_step_max': result['custom_metrics/time_step_max']})
