2020-10-08 18:55:40,347	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_dcff1_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=41864)[0m 2020-10-08 18:55:43,318	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=41854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41874)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41874)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41903)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41766)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41766)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41767)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41767)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41771)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41771)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41764)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41764)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41857)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41857)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41769)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41769)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41776)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41776)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41777)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41777)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41770)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41770)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41765)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41765)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41768)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41768)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41773)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41773)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=41875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=41875)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-08_18-56-12
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1632079601287841
        entropy_coeff: 0.0
        kl: 0.003907537506893277
        model: {}
        policy_loss: -0.004460063856095075
        total_loss: 18.520051956176758
        vf_explained_var: 0.4154719412326813
        vf_loss: 18.52373161315918
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 40.4357142857143
    gpu_util_percent0: 0.30214285714285716
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.00035714285714285714
    ram_util_percent: 9.482142857142856
    vram_util_percent0: 0.30808110387480675
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17616001092640474
    mean_env_wait_ms: 1.6536582594633324
    mean_inference_ms: 5.82865276024569
    mean_raw_obs_processing_ms: 0.4792711329187792
  time_since_restore: 23.7476863861084
  time_this_iter_s: 23.7476863861084
  time_total_s: 23.7476863861084
  timers:
    learn_throughput: 11491.161
    learn_time_ms: 14079.692
    sample_throughput: 16861.401
    sample_time_ms: 9595.407
    update_time_ms: 42.437
  timestamp: 1602183372
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |      1 |          23.7477 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3211.0
  date: 2020-10-08_18-56-35
  done: false
  episode_len_mean: 869.7721518987341
  episode_reward_max: 278.0202020202015
  episode_reward_mean: 227.49875335634806
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1358473777770997
        entropy_coeff: 0.0
        kl: 0.00623575896024704
        model: {}
        policy_loss: -0.006461900379508734
        total_loss: 10.688738822937012
        vf_explained_var: 0.7615079879760742
        vf_loss: 10.694576835632324
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 37.55
    gpu_util_percent0: 0.2846153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.73076923076923
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17254855118842735
    mean_env_wait_ms: 1.649923988527531
    mean_inference_ms: 5.5833340901987505
    mean_raw_obs_processing_ms: 0.47063111210391295
  time_since_restore: 46.292282819747925
  time_this_iter_s: 22.544596433639526
  time_total_s: 46.292282819747925
  timers:
    learn_throughput: 11574.89
    learn_time_ms: 13977.843
    sample_throughput: 17795.95
    sample_time_ms: 9091.507
    update_time_ms: 38.059
  timestamp: 1602183395
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |      2 |          46.2923 | 323584 |  227.499 |               278.02 |              115.788 |            869.772 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3211.0
  date: 2020-10-08_18-56-58
  done: false
  episode_len_mean: 861.2658227848101
  episode_reward_max: 278.0202020202015
  episode_reward_mean: 229.57445765673594
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1234236478805542
        entropy_coeff: 0.0
        kl: 0.008180051390081645
        model: {}
        policy_loss: -0.006987640098668635
        total_loss: 12.557469940185547
        vf_explained_var: 0.8431194424629211
        vf_loss: 12.563639259338379
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.65185185185185
    gpu_util_percent0: 0.3077777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.74814814814815
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16981684336232106
    mean_env_wait_ms: 1.6489065819935116
    mean_inference_ms: 5.444736220623828
    mean_raw_obs_processing_ms: 0.46275023842877866
  time_since_restore: 68.8423969745636
  time_this_iter_s: 22.550114154815674
  time_total_s: 68.8423969745636
  timers:
    learn_throughput: 11616.617
    learn_time_ms: 13927.635
    sample_throughput: 18090.311
    sample_time_ms: 8943.572
    update_time_ms: 33.19
  timestamp: 1602183418
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |      3 |          68.8424 | 485376 |  229.574 |               278.02 |              115.788 |            861.266 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3211.0
  date: 2020-10-08_18-57-20
  done: false
  episode_len_mean: 854.0348101265823
  episode_reward_max: 281.7878787878787
  episode_reward_mean: 230.51310574095365
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0997141122817993
        entropy_coeff: 0.0
        kl: 0.004700190294533968
        model: {}
        policy_loss: -0.005964774644598947
        total_loss: 14.946365356445312
        vf_explained_var: 0.8814449310302734
        vf_loss: 14.951860427856445
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.76538461538462
    gpu_util_percent0: 0.3392307692307692
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.750000000000002
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16773416743091987
    mean_env_wait_ms: 1.651354297196567
    mean_inference_ms: 5.336765843920324
    mean_raw_obs_processing_ms: 0.456571018567438
  time_since_restore: 91.23282766342163
  time_this_iter_s: 22.390430688858032
  time_total_s: 91.23282766342163
  timers:
    learn_throughput: 11620.119
    learn_time_ms: 13923.438
    sample_throughput: 18370.311
    sample_time_ms: 8807.254
    update_time_ms: 33.159
  timestamp: 1602183440
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |      4 |          91.2328 | 647168 |  230.513 |              281.788 |              115.788 |            854.035 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_18-57-42
  done: false
  episode_len_mean: 840.4831223628692
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 231.1913970932957
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 948
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 1.0783706665039063
        entropy_coeff: 0.0
        kl: 0.006109740398824215
        model: {}
        policy_loss: -0.006475119944661855
        total_loss: 21.488145065307616
        vf_explained_var: 0.9276508092880249
        vf_loss: 21.494314193725586
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.804
    gpu_util_percent0: 0.3696
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.744000000000002
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1650728228304239
    mean_env_wait_ms: 1.6584366257375454
    mean_inference_ms: 5.195352224276533
    mean_raw_obs_processing_ms: 0.4486074694452826
  time_since_restore: 113.37966203689575
  time_this_iter_s: 22.14683437347412
  time_total_s: 113.37966203689575
  timers:
    learn_throughput: 11651.314
    learn_time_ms: 13886.159
    sample_throughput: 18572.832
    sample_time_ms: 8711.219
    update_time_ms: 32.803
  timestamp: 1602183462
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |      5 |           113.38 | 808960 |  231.191 |              287.677 |              115.788 |            840.483 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_18-58-05
  done: false
  episode_len_mean: 835.0244122965642
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 231.86685115166117
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1106
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 1.057872748374939
        entropy_coeff: 0.0
        kl: 0.005763864424079656
        model: {}
        policy_loss: -0.007133494643494487
        total_loss: 14.214896202087402
        vf_explained_var: 0.9405567049980164
        vf_loss: 14.22174129486084
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.3423076923077
    gpu_util_percent0: 0.30692307692307697
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765384615384617
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16416246881264382
    mean_env_wait_ms: 1.661433449357447
    mean_inference_ms: 5.144509842358989
    mean_raw_obs_processing_ms: 0.44580427581991167
  time_since_restore: 135.57384753227234
  time_this_iter_s: 22.194185495376587
  time_total_s: 135.57384753227234
  timers:
    learn_throughput: 11652.37
    learn_time_ms: 13884.9
    sample_throughput: 18746.737
    sample_time_ms: 8630.409
    update_time_ms: 33.599
  timestamp: 1602183485
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |      6 |          135.574 | 970752 |  231.867 |              287.677 |              115.788 |            835.024 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_18-58-27
  done: false
  episode_len_mean: 830.3148734177215
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 231.70398606316317
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 1.0320964813232423
        entropy_coeff: 0.0
        kl: 0.005260239448398351
        model: {}
        policy_loss: -0.006560518406331539
        total_loss: 13.530745315551759
        vf_explained_var: 0.9546114802360535
        vf_loss: 13.537043190002441
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.31923076923077
    gpu_util_percent0: 0.2865384615384615
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16337037738435528
    mean_env_wait_ms: 1.6644974080462043
    mean_inference_ms: 5.100058589760906
    mean_raw_obs_processing_ms: 0.44333762067893595
  time_since_restore: 157.7366976737976
  time_this_iter_s: 22.16285014152527
  time_total_s: 157.7366976737976
  timers:
    learn_throughput: 11656.298
    learn_time_ms: 13880.222
    sample_throughput: 18885.272
    sample_time_ms: 8567.099
    update_time_ms: 32.055
  timestamp: 1602183507
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |      7 |          157.737 | 1132544 |  231.704 |              287.677 |              115.788 |            830.315 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_18-58-49
  done: false
  episode_len_mean: 826.4336592178771
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 232.0401007279498
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 168
  episodes_total: 1432
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.9752742052078247
        entropy_coeff: 0.0
        kl: 0.004915670771151781
        model: {}
        policy_loss: -0.006356713874265551
        total_loss: 12.484763145446777
        vf_explained_var: 0.9723867177963257
        vf_loss: 12.490873908996582
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.01538461538462
    gpu_util_percent0: 0.31461538461538463
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16262325950378306
    mean_env_wait_ms: 1.6677843394163345
    mean_inference_ms: 5.058275467393997
    mean_raw_obs_processing_ms: 0.44091248754794493
  time_since_restore: 180.02415490150452
  time_this_iter_s: 22.28745722770691
  time_total_s: 180.02415490150452
  timers:
    learn_throughput: 11666.179
    learn_time_ms: 13868.466
    sample_throughput: 18928.893
    sample_time_ms: 8547.357
    update_time_ms: 31.009
  timestamp: 1602183529
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |      8 |          180.024 | 1294336 |   232.04 |              287.677 |              115.788 |            826.434 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_18-59-12
  done: false
  episode_len_mean: 820.3642117376295
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 231.55046436749538
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 306
  episodes_total: 1738
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 5.0e-05
        entropy: 0.95462406873703
        entropy_coeff: 0.0
        kl: 0.00525198383256793
        model: {}
        policy_loss: -0.00580661790445447
        total_loss: 14.162160491943359
        vf_explained_var: 0.9729663729667664
        vf_loss: 14.16783561706543
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.78846153846154
    gpu_util_percent0: 0.2730769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.742307692307692
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1616231441835068
    mean_env_wait_ms: 1.6735661661355332
    mean_inference_ms: 4.999406551132084
    mean_raw_obs_processing_ms: 0.4376674677961981
  time_since_restore: 202.23516130447388
  time_this_iter_s: 22.21100640296936
  time_total_s: 202.23516130447388
  timers:
    learn_throughput: 11674.868
    learn_time_ms: 13858.144
    sample_throughput: 18977.805
    sample_time_ms: 8525.327
    update_time_ms: 29.987
  timestamp: 1602183552
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |      9 |          202.235 | 1456128 |   231.55 |              287.677 |              115.788 |            820.364 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_18-59-34
  done: false
  episode_len_mean: 817.9973628691984
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 231.8614414184034
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 5.0e-05
        entropy: 0.9206790447235107
        entropy_coeff: 0.0
        kl: 0.0051714561879634855
        model: {}
        policy_loss: -0.006536533520556986
        total_loss: 7.366583251953125
        vf_explained_var: 0.9835587739944458
        vf_loss: 7.372990512847901
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.61153846153846
    gpu_util_percent0: 0.31500000000000006
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1611807642538597
    mean_env_wait_ms: 1.6760568186505982
    mean_inference_ms: 4.974018522083588
    mean_raw_obs_processing_ms: 0.43624590338782077
  time_since_restore: 224.3972988128662
  time_this_iter_s: 22.162137508392334
  time_total_s: 224.3972988128662
  timers:
    learn_throughput: 11681.024
    learn_time_ms: 13850.841
    sample_throughput: 19033.969
    sample_time_ms: 8500.171
    update_time_ms: 30.628
  timestamp: 1602183574
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     10 |          224.397 | 1617920 |  231.861 |              287.677 |              115.788 |            817.997 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_18-59-56
  done: false
  episode_len_mean: 816.0331061343719
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 232.2334051321393
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 5.0e-05
        entropy: 0.8867992043495179
        entropy_coeff: 0.0
        kl: 0.0047233859077095985
        model: {}
        policy_loss: -0.005529919289983809
        total_loss: 6.578928756713867
        vf_explained_var: 0.9863384366035461
        vf_loss: 6.5843404769897464
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.934615384615384
    gpu_util_percent0: 0.3376923076923077
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16079486085649344
    mean_env_wait_ms: 1.6784728630004773
    mean_inference_ms: 4.950835795156515
    mean_raw_obs_processing_ms: 0.43491293754491783
  time_since_restore: 246.66380834579468
  time_this_iter_s: 22.266509532928467
  time_total_s: 246.66380834579468
  timers:
    learn_throughput: 11695.211
    learn_time_ms: 13834.039
    sample_throughput: 19334.55
    sample_time_ms: 8368.025
    update_time_ms: 28.589
  timestamp: 1602183596
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     11 |          246.664 | 1779712 |  232.233 |              287.677 |              115.788 |            816.033 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-00-19
  done: false
  episode_len_mean: 813.0147741663149
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 232.6083076437656
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 315
  episodes_total: 2369
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 5.0e-05
        entropy: 0.8506338119506835
        entropy_coeff: 0.0
        kl: 0.004405431542545557
        model: {}
        policy_loss: -0.005285447416827083
        total_loss: 8.572434043884277
        vf_explained_var: 0.9884788393974304
        vf_loss: 8.577664756774903
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.94230769230769
    gpu_util_percent0: 0.3792307692307692
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.738461538461538
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16014995856573305
    mean_env_wait_ms: 1.6829598999136073
    mean_inference_ms: 4.9114728963724685
    mean_raw_obs_processing_ms: 0.43269104175647993
  time_since_restore: 268.94818806648254
  time_this_iter_s: 22.284379720687866
  time_total_s: 268.94818806648254
  timers:
    learn_throughput: 11703.052
    learn_time_ms: 13824.77
    sample_throughput: 19388.405
    sample_time_ms: 8344.781
    update_time_ms: 27.815
  timestamp: 1602183619
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     12 |          268.948 | 1941504 |  232.608 |              287.677 |              115.788 |            813.015 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-00-41
  done: false
  episode_len_mean: 811.6673259493671
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 232.7125407556578
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 159
  episodes_total: 2528
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00625
        cur_lr: 5.0e-05
        entropy: 0.8144669890403747
        entropy_coeff: 0.0
        kl: 0.003742838092148304
        model: {}
        policy_loss: -0.0056933843530714515
        total_loss: 5.034724235534668
        vf_explained_var: 0.9903847575187683
        vf_loss: 5.040394401550293
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.944
    gpu_util_percent0: 0.3204
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.756
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1598672631524061
    mean_env_wait_ms: 1.6849819907010315
    mean_inference_ms: 4.894406673492646
    mean_raw_obs_processing_ms: 0.431741183177335
  time_since_restore: 290.99462962150574
  time_this_iter_s: 22.046441555023193
  time_total_s: 290.99462962150574
  timers:
    learn_throughput: 11699.712
    learn_time_ms: 13828.717
    sample_throughput: 19517.423
    sample_time_ms: 8289.619
    update_time_ms: 28.129
  timestamp: 1602183641
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     13 |          290.995 | 2103296 |  232.713 |              287.677 |              115.788 |            811.667 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-01-03
  done: false
  episode_len_mean: 810.3827252419956
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 232.84513790172767
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.003125
        cur_lr: 5.0e-05
        entropy: 0.7968274235725403
        entropy_coeff: 0.0
        kl: 0.0037655991036444902
        model: {}
        policy_loss: -0.0053449268219992515
        total_loss: 4.289617824554443
        vf_explained_var: 0.9914034605026245
        vf_loss: 4.29495096206665
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.011538461538464
    gpu_util_percent0: 0.27153846153846156
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75769230769231
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15960335526365788
    mean_env_wait_ms: 1.6869425195829408
    mean_inference_ms: 4.878839069733291
    mean_raw_obs_processing_ms: 0.43086595823483304
  time_since_restore: 313.1924684047699
  time_this_iter_s: 22.19783878326416
  time_total_s: 313.1924684047699
  timers:
    learn_throughput: 11706.845
    learn_time_ms: 13820.291
    sample_throughput: 19546.586
    sample_time_ms: 8277.251
    update_time_ms: 27.689
  timestamp: 1602183663
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     14 |          313.192 | 2265088 |  232.845 |              287.677 |              115.788 |            810.383 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-01-25
  done: false
  episode_len_mean: 808.88
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 232.892286972287
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 239
  episodes_total: 2925
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625
        cur_lr: 5.0e-05
        entropy: 0.7791933059692383
        entropy_coeff: 0.0
        kl: 0.00365413180552423
        model: {}
        policy_loss: -0.005100129637867212
        total_loss: 4.8105544090271
        vf_explained_var: 0.9931920170783997
        vf_loss: 4.81564884185791
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.269230769230774
    gpu_util_percent0: 0.31807692307692303
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.742307692307692
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15923410984393627
    mean_env_wait_ms: 1.6897584345078425
    mean_inference_ms: 4.857432101260162
    mean_raw_obs_processing_ms: 0.4296455716424235
  time_since_restore: 335.2794749736786
  time_this_iter_s: 22.08700656890869
  time_total_s: 335.2794749736786
  timers:
    learn_throughput: 11698.737
    learn_time_ms: 13829.869
    sample_throughput: 19586.331
    sample_time_ms: 8260.455
    update_time_ms: 28.132
  timestamp: 1602183685
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     15 |          335.279 | 2426880 |  232.892 |              287.677 |              115.788 |             808.88 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-01-48
  done: false
  episode_len_mean: 807.6262658227848
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 233.22533243830713
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 235
  episodes_total: 3160
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00078125
        cur_lr: 5.0e-05
        entropy: 0.7422739624977112
        entropy_coeff: 0.0
        kl: 0.003451108653098345
        model: {}
        policy_loss: -0.004641538998112082
        total_loss: 4.6552387237548825
        vf_explained_var: 0.9917858242988586
        vf_loss: 4.659877490997315
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.864
    gpu_util_percent0: 0.306
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.74
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15892247315308403
    mean_env_wait_ms: 1.6923305726480002
    mean_inference_ms: 4.838941725912047
    mean_raw_obs_processing_ms: 0.42863881351039423
  time_since_restore: 357.4105303287506
  time_this_iter_s: 22.13105535507202
  time_total_s: 357.4105303287506
  timers:
    learn_throughput: 11712.847
    learn_time_ms: 13813.209
    sample_throughput: 19560.007
    sample_time_ms: 8271.572
    update_time_ms: 26.144
  timestamp: 1602183708
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     16 |          357.411 | 2588672 |  233.225 |              287.677 |              115.788 |            807.626 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-02-10
  done: false
  episode_len_mean: 806.6546112115732
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 233.29617452402263
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.000390625
        cur_lr: 5.0e-05
        entropy: 0.7261692523956299
        entropy_coeff: 0.0
        kl: 0.0033950806595385075
        model: {}
        policy_loss: -0.00490052392706275
        total_loss: 3.9001873970031737
        vf_explained_var: 0.9921219944953918
        vf_loss: 3.9050865173339844
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.03076923076923
    gpu_util_percent0: 0.3496153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1587243944221497
    mean_env_wait_ms: 1.6939247402472515
    mean_inference_ms: 4.827542344786286
    mean_raw_obs_processing_ms: 0.4280134085759734
  time_since_restore: 379.67479515075684
  time_this_iter_s: 22.264264822006226
  time_total_s: 379.67479515075684
  timers:
    learn_throughput: 11717.944
    learn_time_ms: 13807.201
    sample_throughput: 19511.57
    sample_time_ms: 8292.106
    update_time_ms: 25.748
  timestamp: 1602183730
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     17 |          379.675 | 2750464 |  233.296 |              287.677 |              115.788 |            806.655 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-02-33
  done: false
  episode_len_mean: 805.5737657864523
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 233.45314801284954
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 166
  episodes_total: 3484
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0001953125
        cur_lr: 5.0e-05
        entropy: 0.7140410780906677
        entropy_coeff: 0.0
        kl: 0.003266756609082222
        model: {}
        policy_loss: -0.004764636373147368
        total_loss: 3.617857027053833
        vf_explained_var: 0.9934865832328796
        vf_loss: 3.622620964050293
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.47037037037037
    gpu_util_percent0: 0.3066666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.755555555555556
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15852877688737732
    mean_env_wait_ms: 1.6955850255657958
    mean_inference_ms: 4.81624698361648
    mean_raw_obs_processing_ms: 0.42738534344647283
  time_since_restore: 402.06082582473755
  time_this_iter_s: 22.386030673980713
  time_total_s: 402.06082582473755
  timers:
    learn_throughput: 11712.77
    learn_time_ms: 13813.299
    sample_throughput: 19518.864
    sample_time_ms: 8289.007
    update_time_ms: 26.644
  timestamp: 1602183753
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     18 |          402.061 | 2912256 |  233.453 |              287.677 |              115.788 |            805.574 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-02-55
  done: false
  episode_len_mean: 803.4694092827004
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 233.91750042620302
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 308
  episodes_total: 3792
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625e-05
        cur_lr: 5.0e-05
        entropy: 0.6773772835731506
        entropy_coeff: 0.0
        kl: 0.0032168947160243987
        model: {}
        policy_loss: -0.004545739106833935
        total_loss: 4.489740085601807
        vf_explained_var: 0.9929680824279785
        vf_loss: 4.494285297393799
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.14230769230769
    gpu_util_percent0: 0.3480769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15820154322773472
    mean_env_wait_ms: 1.698603854505851
    mean_inference_ms: 4.797271598837702
    mean_raw_obs_processing_ms: 0.4263704584233668
  time_since_restore: 424.28833079338074
  time_this_iter_s: 22.22750496864319
  time_total_s: 424.28833079338074
  timers:
    learn_throughput: 11707.446
    learn_time_ms: 13819.581
    sample_throughput: 19533.96
    sample_time_ms: 8282.601
    update_time_ms: 28.306
  timestamp: 1602183775
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     19 |          424.288 | 3074048 |  233.918 |              287.677 |              115.788 |            803.469 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-03-18
  done: false
  episode_len_mean: 802.5225316455696
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 234.26007671653247
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3950
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.8828125e-05
        cur_lr: 5.0e-05
        entropy: 0.6649715304374695
        entropy_coeff: 0.0
        kl: 0.0029606542084366083
        model: {}
        policy_loss: -0.005351405194960535
        total_loss: 2.7396381378173826
        vf_explained_var: 0.9939627647399902
        vf_loss: 2.744989538192749
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.43076923076923
    gpu_util_percent0: 0.3126923076923077
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15804590305907376
    mean_env_wait_ms: 1.7000466089107062
    mean_inference_ms: 4.788391926987383
    mean_raw_obs_processing_ms: 0.42588067150214654
  time_since_restore: 446.66310954093933
  time_this_iter_s: 22.374778747558594
  time_total_s: 446.66310954093933
  timers:
    learn_throughput: 11702.201
    learn_time_ms: 13825.775
    sample_throughput: 19510.014
    sample_time_ms: 8292.767
    update_time_ms: 26.735
  timestamp: 1602183798
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     20 |          446.663 | 3235840 |   234.26 |              287.677 |              115.788 |            802.523 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-03-40
  done: false
  episode_len_mean: 801.5808179162609
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 234.51055098207001
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4108
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.44140625e-05
        cur_lr: 5.0e-05
        entropy: 0.6665697574615479
        entropy_coeff: 0.0
        kl: 0.0029551679734140636
        model: {}
        policy_loss: -0.005083349347114563
        total_loss: 2.6531893253326415
        vf_explained_var: 0.9942454099655151
        vf_loss: 2.658272695541382
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.144
    gpu_util_percent0: 0.33880000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.756
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1578953865454773
    mean_env_wait_ms: 1.701495677533401
    mean_inference_ms: 4.7799313962897
    mean_raw_obs_processing_ms: 0.42541097660682226
  time_since_restore: 468.94309997558594
  time_this_iter_s: 22.279990434646606
  time_total_s: 468.94309997558594
  timers:
    learn_throughput: 11710.23
    learn_time_ms: 13816.296
    sample_throughput: 19491.029
    sample_time_ms: 8300.844
    update_time_ms: 28.422
  timestamp: 1602183820
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     21 |          468.943 | 3397632 |  234.511 |              287.677 |              115.788 |            801.581 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-04-02
  done: false
  episode_len_mean: 799.8322784810126
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 235.07868924324626
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 4424
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.220703125e-05
        cur_lr: 5.0e-05
        entropy: 0.6223801493644714
        entropy_coeff: 0.0
        kl: 0.0035765801090747117
        model: {}
        policy_loss: -0.004758940264582634
        total_loss: 3.6109875679016112
        vf_explained_var: 0.9942353963851929
        vf_loss: 3.61574649810791
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.25
    gpu_util_percent0: 0.29
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1576219818461712
    mean_env_wait_ms: 1.7042588558397507
    mean_inference_ms: 4.764430617878244
    mean_raw_obs_processing_ms: 0.42456269833772453
  time_since_restore: 491.1012125015259
  time_this_iter_s: 22.15811252593994
  time_total_s: 491.1012125015259
  timers:
    learn_throughput: 11704.785
    learn_time_ms: 13822.723
    sample_throughput: 19524.8
    sample_time_ms: 8286.487
    update_time_ms: 28.912
  timestamp: 1602183842
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     22 |          491.101 | 3559424 |  235.079 |              287.677 |              115.788 |            799.832 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-04-25
  done: false
  episode_len_mean: 799.0401571366216
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 235.39285037189887
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4582
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 6.103515625e-06
        cur_lr: 5.0e-05
        entropy: 0.603718900680542
        entropy_coeff: 0.0
        kl: 0.0030057870782911776
        model: {}
        policy_loss: -0.005257947416976094
        total_loss: 2.2937647819519045
        vf_explained_var: 0.9946199655532837
        vf_loss: 2.2990227699279786
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.93846153846154
    gpu_util_percent0: 0.2673076923076923
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15749606669398902
    mean_env_wait_ms: 1.705549012210358
    mean_inference_ms: 4.757293774954288
    mean_raw_obs_processing_ms: 0.4241712276954158
  time_since_restore: 513.5518679618835
  time_this_iter_s: 22.450655460357666
  time_total_s: 513.5518679618835
  timers:
    learn_throughput: 11702.725
    learn_time_ms: 13825.156
    sample_throughput: 19440.435
    sample_time_ms: 8322.448
    update_time_ms: 29.735
  timestamp: 1602183865
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     23 |          513.552 | 3721216 |  235.393 |              287.677 |              115.788 |             799.04 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-04-47
  done: false
  episode_len_mean: 798.2575949367089
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 235.68872266973543
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4740
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.0517578125e-06
        cur_lr: 5.0e-05
        entropy: 0.6091554522514343
        entropy_coeff: 0.0
        kl: 0.003107953676953912
        model: {}
        policy_loss: -0.0054215784184634686
        total_loss: 2.393711042404175
        vf_explained_var: 0.9941954612731934
        vf_loss: 2.39913272857666
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.21153846153846
    gpu_util_percent0: 0.35038461538461535
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15737598048427814
    mean_env_wait_ms: 1.7068230259475667
    mean_inference_ms: 4.750459433466079
    mean_raw_obs_processing_ms: 0.4237881535879942
  time_since_restore: 535.9312405586243
  time_this_iter_s: 22.379372596740723
  time_total_s: 535.9312405586243
  timers:
    learn_throughput: 11705.359
    learn_time_ms: 13822.045
    sample_throughput: 19395.249
    sample_time_ms: 8341.837
    update_time_ms: 30.852
  timestamp: 1602183887
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     24 |          535.931 | 3883008 |  235.689 |              287.677 |              115.788 |            798.258 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-05-10
  done: false
  episode_len_mean: 796.7258511480602
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 236.14702248134557
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 312
  episodes_total: 5052
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.52587890625e-06
        cur_lr: 5.0e-05
        entropy: 0.5726983189582825
        entropy_coeff: 0.0
        kl: 0.0025286524556577205
        model: {}
        policy_loss: -0.0038937932811677458
        total_loss: 3.4365397453308106
        vf_explained_var: 0.9943183064460754
        vf_loss: 3.4404335021972656
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.9
    gpu_util_percent0: 0.3515384615384616
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746153846153847
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15715657267542596
    mean_env_wait_ms: 1.7092647419500935
    mean_inference_ms: 4.737981007453622
    mean_raw_obs_processing_ms: 0.42310037119057825
  time_since_restore: 558.1441659927368
  time_this_iter_s: 22.21292543411255
  time_total_s: 558.1441659927368
  timers:
    learn_throughput: 11705.452
    learn_time_ms: 13821.935
    sample_throughput: 19374.582
    sample_time_ms: 8350.735
    update_time_ms: 33.299
  timestamp: 1602183910
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     25 |          558.144 | 4044800 |  236.147 |              287.677 |              115.788 |            796.726 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-05-32
  done: false
  episode_len_mean: 795.963751438435
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 236.43599787673443
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 162
  episodes_total: 5214
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 7.62939453125e-07
        cur_lr: 5.0e-05
        entropy: 0.5572451710700989
        entropy_coeff: 0.0
        kl: 0.0025988975539803505
        model: {}
        policy_loss: -0.005028961459174752
        total_loss: 2.2736677169799804
        vf_explained_var: 0.9943487048149109
        vf_loss: 2.278696584701538
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.51538461538462
    gpu_util_percent0: 0.34538461538461535
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1570515192637772
    mean_env_wait_ms: 1.7104379797437415
    mean_inference_ms: 4.731904568588237
    mean_raw_obs_processing_ms: 0.42276060832315066
  time_since_restore: 580.6514890193939
  time_this_iter_s: 22.507323026657104
  time_total_s: 580.6514890193939
  timers:
    learn_throughput: 11699.122
    learn_time_ms: 13829.414
    sample_throughput: 19314.14
    sample_time_ms: 8376.868
    update_time_ms: 35.21
  timestamp: 1602183932
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | RUNNING  | 172.17.0.4:41864 |     26 |          580.651 | 4206592 |  236.436 |              287.677 |              115.788 |            795.964 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_dcff1_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_19-05-55
  done: true
  episode_len_mean: 795.2494415487714
  episode_reward_max: 287.67676767676744
  episode_reward_mean: 236.72190068969675
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 5372
  experiment_id: 0d5bb80a568e4502aea60b950b09343b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.814697265625e-07
        cur_lr: 5.0e-05
        entropy: 0.5595737218856811
        entropy_coeff: 0.0
        kl: 0.0028197331354022025
        model: {}
        policy_loss: -0.005059309082571417
        total_loss: 2.1114970207214356
        vf_explained_var: 0.9944856762886047
        vf_loss: 2.1165563106536864
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.98846153846154
    gpu_util_percent0: 0.31384615384615383
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 41864
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1569528378091061
    mean_env_wait_ms: 1.711586580040922
    mean_inference_ms: 4.726269208052895
    mean_raw_obs_processing_ms: 0.4224447473507885
  time_since_restore: 602.8413729667664
  time_this_iter_s: 22.189883947372437
  time_total_s: 602.8413729667664
  timers:
    learn_throughput: 11695.395
    learn_time_ms: 13833.821
    sample_throughput: 19362.547
    sample_time_ms: 8355.925
    update_time_ms: 37.259
  timestamp: 1602183955
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: dcff1_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | TERMINATED |       |     27 |          602.841 | 4368384 |  236.722 |              287.677 |              115.788 |            795.249 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_dcff1_00000 | TERMINATED |       |     27 |          602.841 | 4368384 |  236.722 |              287.677 |              115.788 |            795.249 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


