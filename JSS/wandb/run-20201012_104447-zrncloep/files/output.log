2020-10-12 10:44:51,511	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_f5b28_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=27951)[0m 2020-10-12 10:44:54,244	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=27941)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27941)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27922)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27922)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27944)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27944)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27917)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27917)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27912)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27912)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27923)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27923)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27817)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27817)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27886)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27886)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27939)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27939)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27935)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27935)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27835)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27835)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27918)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27918)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27946)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27946)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27920)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27920)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27903)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27822)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27929)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27820)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27820)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27829)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27829)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27901)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27901)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27924)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27924)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27921)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27921)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27830)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27830)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27894)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27884)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27884)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=27880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=27880)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-12_10-45-32
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1846147278944652
        entropy_coeff: 0.0005000000000000001
        kl: 0.004924804321490228
        model: {}
        policy_loss: -0.010641525208484381
        total_loss: 502.23648834228516
        vf_explained_var: 0.5664147734642029
        vf_loss: 502.24672444661456
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.06578947368421
    gpu_util_percent0: 0.23210526315789473
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.581578947368421
    vram_util_percent0: 0.08847163004263696
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1715364924328089
    mean_env_wait_ms: 1.1764125023111955
    mean_inference_ms: 6.053061519150528
    mean_raw_obs_processing_ms: 0.4638343403537392
  time_since_restore: 32.95468473434448
  time_this_iter_s: 32.95468473434448
  time_total_s: 32.95468473434448
  timers:
    learn_throughput: 6948.182
    learn_time_ms: 23285.516
    sample_throughput: 16871.285
    sample_time_ms: 9589.785
    update_time_ms: 44.906
  timestamp: 1602499532
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 27.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      1 |          32.9547 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4185
    time_step_mean: 3622.6423611111113
    time_step_min: 3341
  date: 2020-10-12_10-46-03
  done: false
  episode_len_mean: 890.2246835443038
  episode_reward_max: 262.6868686868683
  episode_reward_mean: 216.1472637770104
  episode_reward_min: 131.9292929292925
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1507324576377869
        entropy_coeff: 0.0005000000000000001
        kl: 0.007903704070486128
        model: {}
        policy_loss: -0.010593259202626845
        total_loss: 127.33559099833171
        vf_explained_var: 0.8138229846954346
        vf_loss: 127.34597078959148
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.180555555555557
    gpu_util_percent0: 0.26916666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666668
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16686884579590536
    mean_env_wait_ms: 1.1726176230359397
    mean_inference_ms: 5.762905636344878
    mean_raw_obs_processing_ms: 0.4520184496332657
  time_since_restore: 63.70615220069885
  time_this_iter_s: 30.75146746635437
  time_total_s: 63.70615220069885
  timers:
    learn_throughput: 7022.83
    learn_time_ms: 23038.005
    sample_throughput: 18514.195
    sample_time_ms: 8738.808
    update_time_ms: 35.829
  timestamp: 1602499563
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      2 |          63.7062 | 323584 |  216.147 |              262.687 |              131.929 |            890.225 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4185
    time_step_mean: 3625.3340807174886
    time_step_min: 3341
  date: 2020-10-12_10-46-33
  done: false
  episode_len_mean: 885.3924050632911
  episode_reward_max: 262.6868686868683
  episode_reward_mean: 216.5537015726887
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1411346793174744
        entropy_coeff: 0.0005000000000000001
        kl: 0.009678286267444491
        model: {}
        policy_loss: -0.014822538554047545
        total_loss: 59.26638380686442
        vf_explained_var: 0.9010727405548096
        vf_loss: 59.28081130981445
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.72285714285714
    gpu_util_percent0: 0.278
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16389218629932192
    mean_env_wait_ms: 1.1723028183524362
    mean_inference_ms: 5.549334093675588
    mean_raw_obs_processing_ms: 0.44287348924922826
  time_since_restore: 93.79876685142517
  time_this_iter_s: 30.09261465072632
  time_total_s: 93.79876685142517
  timers:
    learn_throughput: 7048.038
    learn_time_ms: 22955.609
    sample_throughput: 19641.219
    sample_time_ms: 8237.371
    update_time_ms: 31.797
  timestamp: 1602499593
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      3 |          93.7988 | 485376 |  216.554 |              262.687 |               88.596 |            885.392 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4214
    time_step_mean: 3625.890728476821
    time_step_min: 3319
  date: 2020-10-12_10-47-03
  done: false
  episode_len_mean: 881.0474683544304
  episode_reward_max: 263.1414141414135
  episode_reward_mean: 216.6672580232705
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1199288368225098
        entropy_coeff: 0.0005000000000000001
        kl: 0.008813565596938133
        model: {}
        policy_loss: -0.01598833860286201
        total_loss: 43.194626808166504
        vf_explained_var: 0.9295213222503662
        vf_loss: 43.21029249827067
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.75277777777778
    gpu_util_percent0: 0.2755555555555556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775000000000001
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16171133782142091
    mean_env_wait_ms: 1.172442399851389
    mean_inference_ms: 5.393240447801279
    mean_raw_obs_processing_ms: 0.43569823102312366
  time_since_restore: 124.19757580757141
  time_this_iter_s: 30.39880895614624
  time_total_s: 124.19757580757141
  timers:
    learn_throughput: 7029.44
    learn_time_ms: 23016.343
    sample_throughput: 20329.92
    sample_time_ms: 7958.32
    update_time_ms: 32.048
  timestamp: 1602499623
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      4 |          124.198 | 647168 |  216.667 |              263.141 |               88.596 |            881.047 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4270
    time_step_mean: 3617.989501312336
    time_step_min: 3319
  date: 2020-10-12_10-47-34
  done: false
  episode_len_mean: 876.6645569620254
  episode_reward_max: 266.4747474747477
  episode_reward_mean: 217.92468993734798
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0852691729863484
        entropy_coeff: 0.0005000000000000001
        kl: 0.008571949942658344
        model: {}
        policy_loss: -0.015522021086023111
        total_loss: 32.49041668574015
        vf_explained_var: 0.9495692253112793
        vf_loss: 32.50562445322672
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.04857142857143
    gpu_util_percent0: 0.28485714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857143
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16012965724921266
    mean_env_wait_ms: 1.1736239690286292
    mean_inference_ms: 5.2755181225819605
    mean_raw_obs_processing_ms: 0.42999393542261516
  time_since_restore: 154.43998551368713
  time_this_iter_s: 30.242409706115723
  time_total_s: 154.43998551368713
  timers:
    learn_throughput: 7022.643
    learn_time_ms: 23038.62
    sample_throughput: 20815.054
    sample_time_ms: 7772.836
    update_time_ms: 32.127
  timestamp: 1602499654
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      5 |           154.44 | 808960 |  217.925 |              266.475 |               88.596 |            876.665 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3598.4014869888474
    time_step_min: 3287
  date: 2020-10-12_10-48-04
  done: false
  episode_len_mean: 867.0471014492754
  episode_reward_max: 267.98989898989913
  episode_reward_mean: 220.5384826526129
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 314
  episodes_total: 1104
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0762771268685658
        entropy_coeff: 0.0005000000000000001
        kl: 0.00847935164347291
        model: {}
        policy_loss: -0.014069491167902015
        total_loss: 36.22017447153727
        vf_explained_var: 0.9600384831428528
        vf_loss: 36.23393313090006
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.274285714285714
    gpu_util_percent0: 0.35999999999999993
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.157985195797773
    mean_env_wait_ms: 1.176888885605026
    mean_inference_ms: 5.117378266251005
    mean_raw_obs_processing_ms: 0.4225404292097058
  time_since_restore: 184.78620219230652
  time_this_iter_s: 30.346216678619385
  time_total_s: 184.78620219230652
  timers:
    learn_throughput: 7013.777
    learn_time_ms: 23067.743
    sample_throughput: 21143.968
    sample_time_ms: 7651.922
    update_time_ms: 32.739
  timestamp: 1602499684
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      6 |          184.786 | 970752 |  220.538 |               267.99 |               88.596 |            867.047 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3586.6108414239484
    time_step_min: 3287
  date: 2020-10-12_10-48-35
  done: false
  episode_len_mean: 862.6424050632911
  episode_reward_max: 272.53535353535324
  episode_reward_mean: 222.52336657716384
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 160
  episodes_total: 1264
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0611263513565063
        entropy_coeff: 0.0005000000000000001
        kl: 0.00855419528670609
        model: {}
        policy_loss: -0.01313585601747036
        total_loss: 17.229157129923504
        vf_explained_var: 0.9695212244987488
        vf_loss: 17.24196783701579
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.344444444444445
    gpu_util_percent0: 0.3055555555555556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7805555555555554
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15721883999003455
    mean_env_wait_ms: 1.1784417316102376
    mean_inference_ms: 5.059418580537698
    mean_raw_obs_processing_ms: 0.41974201605546413
  time_since_restore: 215.12676668167114
  time_this_iter_s: 30.340564489364624
  time_total_s: 215.12676668167114
  timers:
    learn_throughput: 7013.954
    learn_time_ms: 23067.159
    sample_throughput: 21358.13
    sample_time_ms: 7575.195
    update_time_ms: 33.358
  timestamp: 1602499715
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      7 |          215.127 | 1132544 |  222.523 |              272.535 |               88.596 |            862.642 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3574.7453371592537
    time_step_min: 3224
  date: 2020-10-12_10-49-05
  done: false
  episode_len_mean: 858.2257383966245
  episode_reward_max: 277.5353535353528
  episode_reward_mean: 224.2597707028085
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0459068516890209
        entropy_coeff: 0.0005000000000000001
        kl: 0.007586693585229416
        model: {}
        policy_loss: -0.01487944574910216
        total_loss: 17.728309154510498
        vf_explained_var: 0.9674603343009949
        vf_loss: 17.742952823638916
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.362857142857145
    gpu_util_percent0: 0.3745714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142865
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15656386820306947
    mean_env_wait_ms: 1.1799183178085746
    mean_inference_ms: 5.009826195708607
    mean_raw_obs_processing_ms: 0.41727490601484446
  time_since_restore: 245.46431922912598
  time_this_iter_s: 30.337552547454834
  time_total_s: 245.46431922912598
  timers:
    learn_throughput: 7013.118
    learn_time_ms: 23069.91
    sample_throughput: 21502.897
    sample_time_ms: 7524.195
    update_time_ms: 33.171
  timestamp: 1602499745
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      8 |          245.464 | 1294336 |   224.26 |              277.535 |               88.596 |            858.226 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3562.860824742268
    time_step_min: 3224
  date: 2020-10-12_10-49-35
  done: false
  episode_len_mean: 854.1151898734178
  episode_reward_max: 277.5353535353528
  episode_reward_mean: 226.03343562204307
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.009189561009407
        entropy_coeff: 0.0005000000000000001
        kl: 0.008226582664065063
        model: {}
        policy_loss: -0.015366594326527169
        total_loss: 15.938408533732096
        vf_explained_var: 0.9702828526496887
        vf_loss: 15.953457037607828
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.262857142857147
    gpu_util_percent0: 0.32799999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15599313435917495
    mean_env_wait_ms: 1.1813674882165615
    mean_inference_ms: 4.966630800288264
    mean_raw_obs_processing_ms: 0.41506544527338496
  time_since_restore: 275.5794014930725
  time_this_iter_s: 30.115082263946533
  time_total_s: 275.5794014930725
  timers:
    learn_throughput: 7017.998
    learn_time_ms: 23053.868
    sample_throughput: 21639.369
    sample_time_ms: 7476.743
    update_time_ms: 32.887
  timestamp: 1602499775
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      9 |          275.579 | 1456128 |  226.033 |              277.535 |               88.596 |            854.115 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3538.880580957504
    time_step_min: 3206
  date: 2020-10-12_10-50-06
  done: false
  episode_len_mean: 847.3190249072602
  episode_reward_max: 280.2626262626269
  episode_reward_mean: 229.68314303608406
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 307
  episodes_total: 1887
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9917601197957993
        entropy_coeff: 0.0005000000000000001
        kl: 0.00740070086127768
        model: {}
        policy_loss: -0.013341124024009332
        total_loss: 19.074730396270752
        vf_explained_var: 0.9753614068031311
        vf_loss: 19.08782688776652
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.191666666666663
    gpu_util_percent0: 0.30111111111111105
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222226
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1550921774885076
    mean_env_wait_ms: 1.1841642257143155
    mean_inference_ms: 4.898659841728468
    mean_raw_obs_processing_ms: 0.4116808708719114
  time_since_restore: 305.95650362968445
  time_this_iter_s: 30.37710213661194
  time_total_s: 305.95650362968445
  timers:
    learn_throughput: 7015.346
    learn_time_ms: 23062.584
    sample_throughput: 21757.544
    sample_time_ms: 7436.133
    update_time_ms: 33.038
  timestamp: 1602499806
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     10 |          305.957 | 1617920 |  229.683 |              280.263 |               88.596 |            847.319 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3528.9536031589337
    time_step_min: 3206
  date: 2020-10-12_10-50-36
  done: false
  episode_len_mean: 844.2448880233691
  episode_reward_max: 280.2626262626269
  episode_reward_mean: 231.221140322406
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 167
  episodes_total: 2054
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9727244724829992
        entropy_coeff: 0.0005000000000000001
        kl: 0.0071904356591403484
        model: {}
        policy_loss: -0.014005071396240965
        total_loss: 11.84699296951294
        vf_explained_var: 0.9785725474357605
        vf_loss: 11.860765298207602
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.597142857142856
    gpu_util_percent0: 0.3817142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.788571428571429
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15469427227659796
    mean_env_wait_ms: 1.1855035444070465
    mean_inference_ms: 4.868324146809752
    mean_raw_obs_processing_ms: 0.410149660829387
  time_since_restore: 336.20317029953003
  time_this_iter_s: 30.24666666984558
  time_total_s: 336.20317029953003
  timers:
    learn_throughput: 7024.762
    learn_time_ms: 23031.671
    sample_throughput: 22484.123
    sample_time_ms: 7195.833
    update_time_ms: 31.936
  timestamp: 1602499836
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     11 |          336.203 | 1779712 |  231.221 |              280.263 |               88.596 |            844.245 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3520.5668498168498
    time_step_min: 3206
  date: 2020-10-12_10-51-06
  done: false
  episode_len_mean: 841.4041591320072
  episode_reward_max: 280.2626262626269
  episode_reward_mean: 232.48480282024573
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9606796552737554
        entropy_coeff: 0.0005000000000000001
        kl: 0.007471592941631873
        model: {}
        policy_loss: -0.015197008498944342
        total_loss: 13.117705742518107
        vf_explained_var: 0.9743028283119202
        vf_loss: 13.132635911305746
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.165714285714287
    gpu_util_percent0: 0.3628571428571429
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857143
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15435514340299025
    mean_env_wait_ms: 1.186665990444814
    mean_inference_ms: 4.842549195167609
    mean_raw_obs_processing_ms: 0.4087971802318489
  time_since_restore: 366.355286359787
  time_this_iter_s: 30.152116060256958
  time_total_s: 366.355286359787
  timers:
    learn_throughput: 7018.363
    learn_time_ms: 23052.67
    sample_throughput: 22740.933
    sample_time_ms: 7114.572
    update_time_ms: 31.556
  timestamp: 1602499866
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     12 |          366.355 | 1941504 |  232.485 |              280.263 |               88.596 |            841.404 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3511.8174872665536
    time_step_min: 3206
  date: 2020-10-12_10-51-37
  done: false
  episode_len_mean: 838.8875838926175
  episode_reward_max: 284.20202020202026
  episode_reward_mean: 233.88233848552625
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 172
  episodes_total: 2384
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9221795598665873
        entropy_coeff: 0.0005000000000000001
        kl: 0.007596092570262651
        model: {}
        policy_loss: -0.015219444719453653
        total_loss: 13.35711113611857
        vf_explained_var: 0.977639377117157
        vf_loss: 13.372032086054483
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.697142857142858
    gpu_util_percent0: 0.29714285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15402548836072014
    mean_env_wait_ms: 1.187927580487614
    mean_inference_ms: 4.817554249564923
    mean_raw_obs_processing_ms: 0.40744852108449703
  time_since_restore: 396.4389011859894
  time_this_iter_s: 30.083614826202393
  time_total_s: 396.4389011859894
  timers:
    learn_throughput: 7011.034
    learn_time_ms: 23076.768
    sample_throughput: 22827.071
    sample_time_ms: 7087.725
    update_time_ms: 32.421
  timestamp: 1602499897
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     13 |          396.439 | 2103296 |  233.882 |              284.202 |               88.596 |            838.888 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3498.1188863807374
    time_step_min: 3188
  date: 2020-10-12_10-52-07
  done: false
  episode_len_mean: 834.5979151154132
  episode_reward_max: 284.20202020202026
  episode_reward_mean: 235.96700813044805
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 302
  episodes_total: 2686
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9214861939350764
        entropy_coeff: 0.0005000000000000001
        kl: 0.0071946926570187015
        model: {}
        policy_loss: -0.013351308540829146
        total_loss: 14.835413376490274
        vf_explained_var: 0.979828417301178
        vf_loss: 14.848505894343058
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.805714285714288
    gpu_util_percent0: 0.36428571428571427
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285714
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15351155806648764
    mean_env_wait_ms: 1.190011853534101
    mean_inference_ms: 4.778664218564182
    mean_raw_obs_processing_ms: 0.405442385544107
  time_since_restore: 426.4023401737213
  time_this_iter_s: 29.963438987731934
  time_total_s: 426.4023401737213
  timers:
    learn_throughput: 7017.406
    learn_time_ms: 23055.812
    sample_throughput: 22903.105
    sample_time_ms: 7064.195
    update_time_ms: 32.756
  timestamp: 1602499927
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     14 |          426.402 | 2265088 |  235.967 |              284.202 |               88.596 |            834.598 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3491.8394886363635
    time_step_min: 3188
  date: 2020-10-12_10-52-37
  done: false
  episode_len_mean: 832.3867791842475
  episode_reward_max: 284.20202020202026
  episode_reward_mean: 236.9671717171716
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9004226724306742
        entropy_coeff: 0.0005000000000000001
        kl: 0.007208069786429405
        model: {}
        policy_loss: -0.013761558337137103
        total_loss: 10.551711877187094
        vf_explained_var: 0.9797658324241638
        vf_loss: 10.565202951431274
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.92571428571428
    gpu_util_percent0: 0.27685714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.788571428571429
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15327906662279647
    mean_env_wait_ms: 1.1910056333044456
    mean_inference_ms: 4.761055339662379
    mean_raw_obs_processing_ms: 0.40451655661329533
  time_since_restore: 456.6521706581116
  time_this_iter_s: 30.24983048439026
  time_total_s: 456.6521706581116
  timers:
    learn_throughput: 7020.873
    learn_time_ms: 23044.428
    sample_throughput: 22861.865
    sample_time_ms: 7076.938
    update_time_ms: 31.497
  timestamp: 1602499957
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     15 |          456.652 | 2426880 |  236.967 |              284.202 |               88.596 |            832.387 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3485.892064559516
    time_step_min: 3188
  date: 2020-10-12_10-53-07
  done: false
  episode_len_mean: 830.3870752831446
  episode_reward_max: 287.98989898989873
  episode_reward_mean: 237.99570320123274
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.883683979511261
        entropy_coeff: 0.0005000000000000001
        kl: 0.006876855467756589
        model: {}
        policy_loss: -0.015000158843273917
        total_loss: 9.659654299418131
        vf_explained_var: 0.9799847602844238
        vf_loss: 9.674408833185831
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.666666666666668
    gpu_util_percent0: 0.4347222222222223
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7916666666666674
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15306299362268355
    mean_env_wait_ms: 1.191954532027558
    mean_inference_ms: 4.744688514554501
    mean_raw_obs_processing_ms: 0.40362988460399163
  time_since_restore: 487.09628772735596
  time_this_iter_s: 30.444117069244385
  time_total_s: 487.09628772735596
  timers:
    learn_throughput: 7017.009
    learn_time_ms: 23057.118
    sample_throughput: 22879.197
    sample_time_ms: 7071.577
    update_time_ms: 32.472
  timestamp: 1602499987
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     16 |          487.096 | 2588672 |  237.996 |               287.99 |               88.596 |            830.387 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3475.6844047985237
    time_step_min: 3167
  date: 2020-10-12_10-53-38
  done: false
  episode_len_mean: 827.1854223848734
  episode_reward_max: 287.98989898989873
  episode_reward_mean: 239.62352712855906
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 277
  episodes_total: 3279
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8587738970915476
        entropy_coeff: 0.0005000000000000001
        kl: 0.006916678316580753
        model: {}
        policy_loss: -0.012511584752549728
        total_loss: 14.398477554321289
        vf_explained_var: 0.9803693890571594
        vf_loss: 14.41072670618693
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.645714285714284
    gpu_util_percent0: 0.37799999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7714285714285714
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15273481962961288
    mean_env_wait_ms: 1.1936538248240764
    mean_inference_ms: 4.7192378919427
    mean_raw_obs_processing_ms: 0.40228302607192723
  time_since_restore: 517.2829170227051
  time_this_iter_s: 30.18662929534912
  time_total_s: 517.2829170227051
  timers:
    learn_throughput: 7016.909
    learn_time_ms: 23057.447
    sample_throughput: 22903.263
    sample_time_ms: 7064.146
    update_time_ms: 30.629
  timestamp: 1602500018
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     17 |          517.283 | 2750464 |  239.624 |               287.99 |               88.596 |            827.185 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3469.3190255220416
    time_step_min: 3144
  date: 2020-10-12_10-54-08
  done: false
  episode_len_mean: 824.9479286536249
  episode_reward_max: 289.65656565656536
  episode_reward_mean: 240.624545222071
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 197
  episodes_total: 3476
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8442238519589106
        entropy_coeff: 0.0005000000000000001
        kl: 0.007084058636489014
        model: {}
        policy_loss: -0.014629053592216223
        total_loss: 10.824065446853638
        vf_explained_var: 0.9808571338653564
        vf_loss: 10.83840799331665
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.057142857142853
    gpu_util_percent0: 0.3442857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142865
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15250983796903406
    mean_env_wait_ms: 1.194694048196607
    mean_inference_ms: 4.70271967975275
    mean_raw_obs_processing_ms: 0.4014121366382054
  time_since_restore: 547.3402900695801
  time_this_iter_s: 30.057373046875
  time_total_s: 547.3402900695801
  timers:
    learn_throughput: 7017.142
    learn_time_ms: 23056.679
    sample_throughput: 23001.567
    sample_time_ms: 7033.956
    update_time_ms: 32.23
  timestamp: 1602500048
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     18 |           547.34 | 2912256 |  240.625 |              289.657 |               88.596 |            824.948 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3465.189961175818
    time_step_min: 3144
  date: 2020-10-12_10-54-38
  done: false
  episode_len_mean: 823.5038525041277
  episode_reward_max: 289.65656565656536
  episode_reward_mean: 241.21011713169108
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8410505006710688
        entropy_coeff: 0.0005000000000000001
        kl: 0.007028338382951915
        model: {}
        policy_loss: -0.012794313098614415
        total_loss: 10.480183601379395
        vf_explained_var: 0.9795172810554504
        vf_loss: 10.492695411046347
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.87142857142857
    gpu_util_percent0: 0.4517142857142856
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7800000000000002
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15234923422949861
    mean_env_wait_ms: 1.1954980474610577
    mean_inference_ms: 4.690587971836767
    mean_raw_obs_processing_ms: 0.4007655976235748
  time_since_restore: 577.2354960441589
  time_this_iter_s: 29.895205974578857
  time_total_s: 577.2354960441589
  timers:
    learn_throughput: 7018.912
    learn_time_ms: 23050.867
    sample_throughput: 23055.833
    sample_time_ms: 7017.4
    update_time_ms: 32.148
  timestamp: 1602500078
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     19 |          577.235 | 3074048 |   241.21 |              289.657 |               88.596 |            823.504 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f5b28_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3460.29231581727
    time_step_min: 3144
  date: 2020-10-12_10-55-08
  done: true
  episode_len_mean: 822.3347313237222
  episode_reward_max: 289.65656565656536
  episode_reward_mean: 241.98501396666526
  episode_reward_min: 88.59595959595944
  episodes_this_iter: 181
  episodes_total: 3815
  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8101343264182409
        entropy_coeff: 0.0005000000000000001
        kl: 0.007008894269044201
        model: {}
        policy_loss: -0.014301851236571869
        total_loss: 10.842975616455078
        vf_explained_var: 0.9824185371398926
        vf_loss: 10.856981674830118
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.217142857142857
    gpu_util_percent0: 0.3108571428571429
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857144
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 27951
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1521794438483494
    mean_env_wait_ms: 1.196420012756342
    mean_inference_ms: 4.677725917597975
    mean_raw_obs_processing_ms: 0.400067930451597
  time_since_restore: 607.449939250946
  time_this_iter_s: 30.21444320678711
  time_total_s: 607.449939250946
  timers:
    learn_throughput: 7020.345
    learn_time_ms: 23046.161
    sample_throughput: 23073.191
    sample_time_ms: 7012.121
    update_time_ms: 32.424
  timestamp: 1602500108
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: f5b28_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | TERMINATED |       |     20 |           607.45 | 3235840 |  241.985 |              289.657 |               88.596 |            822.335 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f5b28_00000 | TERMINATED |       |     20 |           607.45 | 3235840 |  241.985 |              289.657 |               88.596 |            822.335 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


