2020-10-12 13:23:46,380	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_28eda_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=26711)[0m 2020-10-12 13:23:49,139	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=26640)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26640)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26630)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26630)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26691)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26691)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26627)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26627)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26623)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26623)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26633)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26633)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26632)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26632)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26660)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26660)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26625)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26625)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26655)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26655)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26723)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26723)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26637)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26637)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26641)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26641)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26688)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26688)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26639)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26639)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26638)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26638)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26686)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26686)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26737)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26737)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26652)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26652)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26645)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26645)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26622)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26622)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26628)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26628)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26745)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26745)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26750)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26750)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26620)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26620)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26631)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26631)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26692)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26692)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26654)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26654)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26690)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26690)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26634)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26634)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26731)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26731)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26697)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26697)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26657)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26657)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26624)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26624)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26626)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26626)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26651)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26651)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26689)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26689)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26659)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26659)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26621)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26621)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26693)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26693)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26685)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26685)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26684)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26684)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=26687)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=26687)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3924
    time_step_mean: 3604.0258620689656
    time_step_min: 3359
  date: 2020-10-12_13-24-23
  done: false
  episode_len_mean: 901.8924050632911
  episode_reward_max: 263.14141414141426
  episode_reward_mean: 220.7612837233088
  episode_reward_min: 158.89898989898953
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1577822069327037
        entropy_coeff: 0.0005000000000000001
        kl: 0.007974052064431211
        model: {}
        policy_loss: -0.010702087223762646
        total_loss: 406.156244913737
        vf_explained_var: 0.5482549071311951
        vf_loss: 406.1659342447917
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 29.419444444444437
    gpu_util_percent0: 0.35805555555555557
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5555555555555554
    vram_util_percent0: 0.08582504281913926
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16818739374908043
    mean_env_wait_ms: 1.1503327426515857
    mean_inference_ms: 5.905737018614649
    mean_raw_obs_processing_ms: 0.44989975413704913
  time_since_restore: 28.89452838897705
  time_this_iter_s: 28.89452838897705
  time_total_s: 28.89452838897705
  timers:
    learn_throughput: 8304.478
    learn_time_ms: 19482.502
    sample_throughput: 17350.034
    sample_time_ms: 9325.169
    update_time_ms: 50.767
  timestamp: 1602509063
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |      1 |          28.8945 | 161792 |  220.761 |              263.141 |              158.899 |            901.892 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3599.317518248175
    time_step_min: 3307
  date: 2020-10-12_13-24-50
  done: false
  episode_len_mean: 900.382911392405
  episode_reward_max: 270.41414141414066
  episode_reward_mean: 221.22350083109552
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.130442609389623
        entropy_coeff: 0.0005000000000000001
        kl: 0.009984310561170181
        model: {}
        policy_loss: -0.011673752499821907
        total_loss: 93.71640841166179
        vf_explained_var: 0.8160074353218079
        vf_loss: 93.72665023803711
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.3125
    gpu_util_percent0: 0.32718749999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.75625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16377639146619294
    mean_env_wait_ms: 1.1505433557989881
    mean_inference_ms: 5.611467429604164
    mean_raw_obs_processing_ms: 0.4377999278751047
  time_since_restore: 55.94182848930359
  time_this_iter_s: 27.047300100326538
  time_total_s: 55.94182848930359
  timers:
    learn_throughput: 8345.67
    learn_time_ms: 19386.339
    sample_throughput: 19021.531
    sample_time_ms: 8505.729
    update_time_ms: 35.071
  timestamp: 1602509090
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |      2 |          55.9418 | 323584 |  221.224 |              270.414 |               146.02 |            900.383 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3594.3310185185187
    time_step_min: 3307
  date: 2020-10-12_13-25-17
  done: false
  episode_len_mean: 894.3438818565401
  episode_reward_max: 270.41414141414066
  episode_reward_mean: 223.17082214550547
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1209635237852733
        entropy_coeff: 0.0005000000000000001
        kl: 0.011104556343828639
        model: {}
        policy_loss: -0.014280915034002343
        total_loss: 44.900482495625816
        vf_explained_var: 0.8932671546936035
        vf_loss: 44.91310246785482
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.040625
    gpu_util_percent0: 0.335625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.771875
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16094490074931717
    mean_env_wait_ms: 1.152378110807545
    mean_inference_ms: 5.402965210734106
    mean_raw_obs_processing_ms: 0.42950428862247647
  time_since_restore: 82.33920454978943
  time_this_iter_s: 26.39737606048584
  time_total_s: 82.33920454978943
  timers:
    learn_throughput: 8377.388
    learn_time_ms: 19312.94
    sample_throughput: 20081.084
    sample_time_ms: 8056.936
    update_time_ms: 31.457
  timestamp: 1602509117
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |      3 |          82.3392 | 485376 |  223.171 |              270.414 |               146.02 |            894.344 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3584.5440677966103
    time_step_min: 3305
  date: 2020-10-12_13-25-43
  done: false
  episode_len_mean: 887.9762658227849
  episode_reward_max: 270.41414141414066
  episode_reward_mean: 224.4115522311723
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.107910732428233
        entropy_coeff: 0.0005000000000000001
        kl: 0.009899645810946822
        model: {}
        policy_loss: -0.01377540077858915
        total_loss: 34.22407786051432
        vf_explained_var: 0.9192401766777039
        vf_loss: 34.23642762502035
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.728125
    gpu_util_percent0: 0.279375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15895116135450013
    mean_env_wait_ms: 1.1549909024270786
    mean_inference_ms: 5.254389042145187
    mean_raw_obs_processing_ms: 0.42329434454450976
  time_since_restore: 108.71083235740662
  time_this_iter_s: 26.371627807617188
  time_total_s: 108.71083235740662
  timers:
    learn_throughput: 8385.81
    learn_time_ms: 19293.544
    sample_throughput: 20720.131
    sample_time_ms: 7808.445
    update_time_ms: 29.485
  timestamp: 1602509143
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |      4 |          108.711 | 647168 |  224.412 |              270.414 |               146.02 |            887.976 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3575.597593582888
    time_step_min: 3283
  date: 2020-10-12_13-26-10
  done: false
  episode_len_mean: 882.2050632911393
  episode_reward_max: 270.41414141414066
  episode_reward_mean: 225.44981460171314
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0689985553423564
        entropy_coeff: 0.0005000000000000001
        kl: 0.009458384787042936
        model: {}
        policy_loss: -0.012625596466629455
        total_loss: 28.309775193532307
        vf_explained_var: 0.9349555969238281
        vf_loss: 28.321044127146404
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.637499999999996
    gpu_util_percent0: 0.29312499999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15747743196878808
    mean_env_wait_ms: 1.1576957857225982
    mean_inference_ms: 5.144009185244415
    mean_raw_obs_processing_ms: 0.41840268718415397
  time_since_restore: 135.23158264160156
  time_this_iter_s: 26.520750284194946
  time_total_s: 135.23158264160156
  timers:
    learn_throughput: 8369.89
    learn_time_ms: 19330.242
    sample_throughput: 21185.309
    sample_time_ms: 7636.991
    update_time_ms: 31.675
  timestamp: 1602509170
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |      5 |          135.232 | 808960 |   225.45 |              270.414 |               146.02 |            882.205 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3563.728652751423
    time_step_min: 3232
  date: 2020-10-12_13-26-36
  done: false
  episode_len_mean: 870.4169708029198
  episode_reward_max: 276.929292929293
  episode_reward_mean: 227.17522856300212
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 306
  episodes_total: 1096
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0312041242917378
        entropy_coeff: 0.0005000000000000001
        kl: 0.011227375827729702
        model: {}
        policy_loss: -0.008348616004999107
        total_loss: 34.995848655700684
        vf_explained_var: 0.9504281878471375
        vf_loss: 35.00246779123942
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.409374999999997
    gpu_util_percent0: 0.32875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15557366670403328
    mean_env_wait_ms: 1.1636540258440549
    mean_inference_ms: 5.000662771136572
    mean_raw_obs_processing_ms: 0.41216091272870464
  time_since_restore: 161.85358715057373
  time_this_iter_s: 26.622004508972168
  time_total_s: 161.85358715057373
  timers:
    learn_throughput: 8351.147
    learn_time_ms: 19373.626
    sample_throughput: 21512.175
    sample_time_ms: 7520.95
    update_time_ms: 33.126
  timestamp: 1602509196
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |      6 |          161.854 | 970752 |  227.175 |              276.929 |               146.02 |            870.417 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3558.021276595745
    time_step_min: 3232
  date: 2020-10-12_13-27-03
  done: false
  episode_len_mean: 865.9746835443038
  episode_reward_max: 276.929292929293
  episode_reward_mean: 228.16970336274116
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 168
  episodes_total: 1264
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0412850081920624
        entropy_coeff: 0.0005000000000000001
        kl: 0.010061129927635193
        model: {}
        policy_loss: -0.013738354221762469
        total_loss: 19.529515902201336
        vf_explained_var: 0.9575727581977844
        vf_loss: 19.541762669881184
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.715625
    gpu_util_percent0: 0.31875000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15482076501459033
    mean_env_wait_ms: 1.1660505731455626
    mean_inference_ms: 4.94399176078033
    mean_raw_obs_processing_ms: 0.40965317775720356
  time_since_restore: 188.38126802444458
  time_this_iter_s: 26.52768087387085
  time_total_s: 188.38126802444458
  timers:
    learn_throughput: 8348.46
    learn_time_ms: 19379.862
    sample_throughput: 21711.766
    sample_time_ms: 7451.812
    update_time_ms: 31.752
  timestamp: 1602509223
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |      7 |          188.381 | 1132544 |   228.17 |              276.929 |               146.02 |            865.975 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3548.258695652174
    time_step_min: 3186
  date: 2020-10-12_13-27-30
  done: false
  episode_len_mean: 860.9268635724331
  episode_reward_max: 283.89898989898967
  episode_reward_mean: 229.8586924093252
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0231580138206482
        entropy_coeff: 0.0005000000000000001
        kl: 0.009551459224894643
        model: {}
        policy_loss: -0.011909822331896672
        total_loss: 15.297824382781982
        vf_explained_var: 0.9614291191101074
        vf_loss: 15.308335542678833
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.25625
    gpu_util_percent0: 0.37593750000000004
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7687500000000003
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15421817502467217
    mean_env_wait_ms: 1.168314201819963
    mean_inference_ms: 4.898545005695752
    mean_raw_obs_processing_ms: 0.40758750129163734
  time_since_restore: 214.77340126037598
  time_this_iter_s: 26.392133235931396
  time_total_s: 214.77340126037598
  timers:
    learn_throughput: 8346.323
    learn_time_ms: 19384.824
    sample_throughput: 21919.951
    sample_time_ms: 7381.038
    update_time_ms: 32.079
  timestamp: 1602509250
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |      8 |          214.773 | 1294336 |  229.859 |              283.899 |               146.02 |            860.927 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3537.7256176853057
    time_step_min: 3186
  date: 2020-10-12_13-27-56
  done: false
  episode_len_mean: 855.7512658227848
  episode_reward_max: 286.1717171717173
  episode_reward_mean: 231.41289477048957
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9772098908821741
        entropy_coeff: 0.0005000000000000001
        kl: 0.010164682442943255
        model: {}
        policy_loss: -0.011146233468025457
        total_loss: 16.91525189081828
        vf_explained_var: 0.9580321311950684
        vf_loss: 16.924853483835857
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.790322580645164
    gpu_util_percent0: 0.34967741935483865
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15369821847467885
    mean_env_wait_ms: 1.1706020621446265
    mean_inference_ms: 4.859043571920758
    mean_raw_obs_processing_ms: 0.40574169946660493
  time_since_restore: 240.94137907028198
  time_this_iter_s: 26.167977809906006
  time_total_s: 240.94137907028198
  timers:
    learn_throughput: 8354.129
    learn_time_ms: 19366.711
    sample_throughput: 22090.721
    sample_time_ms: 7323.98
    update_time_ms: 31.199
  timestamp: 1602509276
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |      9 |          240.941 | 1456128 |  231.413 |              286.172 |               146.02 |            855.751 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3522.061346362649
    time_step_min: 3186
  date: 2020-10-12_13-28-22
  done: false
  episode_len_mean: 847.7054140127389
  episode_reward_max: 286.1717171717173
  episode_reward_mean: 233.56451457247627
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 304
  episodes_total: 1884
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9378941059112549
        entropy_coeff: 0.0005000000000000001
        kl: 0.00900879641994834
        model: {}
        policy_loss: -0.011332211123468975
        total_loss: 21.231327374776203
        vf_explained_var: 0.9681181311607361
        vf_loss: 21.241326332092285
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.31875
    gpu_util_percent0: 0.341875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7593750000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1528807401826732
    mean_env_wait_ms: 1.1747987624364291
    mean_inference_ms: 4.797381346605882
    mean_raw_obs_processing_ms: 0.402934604663809
  time_since_restore: 267.05320978164673
  time_this_iter_s: 26.111830711364746
  time_total_s: 267.05320978164673
  timers:
    learn_throughput: 8363.246
    learn_time_ms: 19345.599
    sample_throughput: 22225.037
    sample_time_ms: 7279.718
    update_time_ms: 30.157
  timestamp: 1602509302
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |     10 |          267.053 | 1617920 |  233.565 |              286.172 |               146.02 |            847.705 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3513.856361829026
    time_step_min: 3186
  date: 2020-10-12_13-28-48
  done: false
  episode_len_mean: 843.7444011684518
  episode_reward_max: 288.59595959595987
  episode_reward_mean: 234.87166701090746
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 170
  episodes_total: 2054
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9362979332605997
        entropy_coeff: 0.0005000000000000001
        kl: 0.008529635999972621
        model: {}
        policy_loss: -0.014047437890743216
        total_loss: 14.01085869471232
        vf_explained_var: 0.9673862457275391
        vf_loss: 14.02366820971171
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.893749999999997
    gpu_util_percent0: 0.415
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15250129464733173
    mean_env_wait_ms: 1.1767741773890545
    mean_inference_ms: 4.768725040817193
    mean_raw_obs_processing_ms: 0.4016250697528929
  time_since_restore: 293.3396384716034
  time_this_iter_s: 26.286428689956665
  time_total_s: 293.3396384716034
  timers:
    learn_throughput: 8370.823
    learn_time_ms: 19328.088
    sample_throughput: 23013.004
    sample_time_ms: 7030.46
    update_time_ms: 27.656
  timestamp: 1602509328
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |     11 |           293.34 | 1779712 |  234.872 |              288.596 |               146.02 |            843.744 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3505.7755760368664
    time_step_min: 3162
  date: 2020-10-12_13-29-15
  done: false
  episode_len_mean: 840.133363471971
  episode_reward_max: 288.59595959595987
  episode_reward_mean: 236.12993406031373
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9275808284680048
        entropy_coeff: 0.0005000000000000001
        kl: 0.008662145584821701
        model: {}
        policy_loss: -0.013475577133552482
        total_loss: 12.239488045374552
        vf_explained_var: 0.968559741973877
        vf_loss: 12.251695156097412
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.341935483870973
    gpu_util_percent0: 0.29580645161290325
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15218748141365726
    mean_env_wait_ms: 1.1785544413177902
    mean_inference_ms: 4.744927391165203
    mean_raw_obs_processing_ms: 0.4004951634501237
  time_since_restore: 319.6604561805725
  time_this_iter_s: 26.320817708969116
  time_total_s: 319.6604561805725
  timers:
    learn_throughput: 8370.999
    learn_time_ms: 19327.681
    sample_throughput: 23252.563
    sample_time_ms: 6958.029
    update_time_ms: 27.568
  timestamp: 1602509355
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |     12 |           319.66 | 1941504 |   236.13 |              288.596 |               146.02 |            840.133 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3495.8475147430495
    time_step_min: 3162
  date: 2020-10-12_13-29-41
  done: false
  episode_len_mean: 836.0277317880794
  episode_reward_max: 288.59595959595987
  episode_reward_mean: 237.55698959796635
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 204
  episodes_total: 2416
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8751329282919565
        entropy_coeff: 0.0005000000000000001
        kl: 0.00935250629360477
        model: {}
        policy_loss: -0.011467601851715395
        total_loss: 16.92379554112752
        vf_explained_var: 0.968468964099884
        vf_loss: 16.933830340703327
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.821875
    gpu_util_percent0: 0.2509375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7718750000000005
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15183339227778006
    mean_env_wait_ms: 1.1808851427793414
    mean_inference_ms: 4.717888003414328
    mean_raw_obs_processing_ms: 0.39919421164669067
  time_since_restore: 345.9937837123871
  time_this_iter_s: 26.333327531814575
  time_total_s: 345.9937837123871
  timers:
    learn_throughput: 8363.207
    learn_time_ms: 19345.69
    sample_throughput: 23337.667
    sample_time_ms: 6932.655
    update_time_ms: 27.945
  timestamp: 1602509381
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |     13 |          345.994 | 2103296 |  237.557 |              288.596 |               146.02 |            836.028 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3482.9599092284416
    time_step_min: 3152
  date: 2020-10-12_13-30-08
  done: false
  episode_len_mean: 831.4765450483991
  episode_reward_max: 290.11111111111137
  episode_reward_mean: 239.5114247463465
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 270
  episodes_total: 2686
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8735535989205042
        entropy_coeff: 0.0005000000000000001
        kl: 0.008357047219760716
        model: {}
        policy_loss: -0.010335837388993241
        total_loss: 13.7554558912913
        vf_explained_var: 0.9730379581451416
        vf_loss: 13.764557361602783
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.621875
    gpu_util_percent0: 0.3625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7593750000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15141324136723774
    mean_env_wait_ms: 1.1835037520530636
    mean_inference_ms: 4.686361302605163
    mean_raw_obs_processing_ms: 0.3977354486978166
  time_since_restore: 372.341908454895
  time_this_iter_s: 26.348124742507935
  time_total_s: 372.341908454895
  timers:
    learn_throughput: 8359.278
    learn_time_ms: 19354.781
    sample_throughput: 23378.124
    sample_time_ms: 6920.658
    update_time_ms: 27.667
  timestamp: 1602509408
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |     14 |          372.342 | 2265088 |  239.511 |              290.111 |               146.02 |            831.477 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3475.9900071377588
    time_step_min: 3152
  date: 2020-10-12_13-30-34
  done: false
  episode_len_mean: 829.475035161744
  episode_reward_max: 295.1111111111108
  episode_reward_mean: 240.50817244171665
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8740518043438593
        entropy_coeff: 0.0005000000000000001
        kl: 0.009047126630321145
        model: {}
        policy_loss: -0.01301321837430199
        total_loss: 10.851001739501953
        vf_explained_var: 0.9730932712554932
        vf_loss: 10.862642129262289
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.721874999999997
    gpu_util_percent0: 0.34625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15120095275395595
    mean_env_wait_ms: 1.1848987064899472
    mean_inference_ms: 4.670253887066568
    mean_raw_obs_processing_ms: 0.396982349190477
  time_since_restore: 398.8328626155853
  time_this_iter_s: 26.490954160690308
  time_total_s: 398.8328626155853
  timers:
    learn_throughput: 8360.977
    learn_time_ms: 19350.849
    sample_throughput: 23372.706
    sample_time_ms: 6922.262
    update_time_ms: 26.337
  timestamp: 1602509434
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |     15 |          398.833 | 2426880 |  240.508 |              295.111 |               146.02 |            829.475 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3469.8234301147872
    time_step_min: 3152
  date: 2020-10-12_13-31-01
  done: false
  episode_len_mean: 827.1924101198402
  episode_reward_max: 295.1111111111108
  episode_reward_mean: 241.42642806224694
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 160
  episodes_total: 3004
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8350455115238825
        entropy_coeff: 0.0005000000000000001
        kl: 0.009088770874465505
        model: {}
        policy_loss: -0.012644322996493429
        total_loss: 11.974854707717896
        vf_explained_var: 0.9724969863891602
        vf_loss: 11.986098051071167
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.35625
    gpu_util_percent0: 0.4096875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15100012777505195
    mean_env_wait_ms: 1.1862690181067919
    mean_inference_ms: 4.655092960935467
    mean_raw_obs_processing_ms: 0.3962588629925616
  time_since_restore: 425.1549913883209
  time_this_iter_s: 26.322128772735596
  time_total_s: 425.1549913883209
  timers:
    learn_throughput: 8373.99
    learn_time_ms: 19320.779
    sample_throughput: 23390.563
    sample_time_ms: 6916.978
    update_time_ms: 30.999
  timestamp: 1602509461
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |     16 |          425.155 | 2588672 |  241.426 |              295.111 |               146.02 |            827.192 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3457.108868501529
    time_step_min: 3121
  date: 2020-10-12_13-31-27
  done: false
  episode_len_mean: 823.0250603864735
  episode_reward_max: 295.1111111111108
  episode_reward_mean: 243.15138705899574
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 308
  episodes_total: 3312
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7950431803862253
        entropy_coeff: 0.0005000000000000001
        kl: 0.007505748110512893
        model: {}
        policy_loss: -0.01098721646364235
        total_loss: 15.154636144638062
        vf_explained_var: 0.975196361541748
        vf_loss: 15.164520184199015
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.183870967741935
    gpu_util_percent0: 0.31903225806451607
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15065972899070595
    mean_env_wait_ms: 1.1887875230301286
    mean_inference_ms: 4.629322322086719
    mean_raw_obs_processing_ms: 0.3950518225612895
  time_since_restore: 451.40321159362793
  time_this_iter_s: 26.248220205307007
  time_total_s: 451.40321159362793
  timers:
    learn_throughput: 8376.767
    learn_time_ms: 19314.373
    sample_throughput: 23467.734
    sample_time_ms: 6894.232
    update_time_ms: 31.233
  timestamp: 1602509487
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |     17 |          451.403 | 2750464 |  243.151 |              295.111 |               146.02 |            823.025 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3450.533488642982
    time_step_min: 3100
  date: 2020-10-12_13-31-53
  done: false
  episode_len_mean: 820.8754315304948
  episode_reward_max: 296.9292929292929
  episode_reward_mean: 244.089342795039
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 164
  episodes_total: 3476
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8070346216360728
        entropy_coeff: 0.0005000000000000001
        kl: 0.0076538678258657455
        model: {}
        policy_loss: -0.01276342243848679
        total_loss: 9.00830078125
        vf_explained_var: 0.9768871665000916
        vf_loss: 9.019936879475912
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.328125
    gpu_util_percent0: 0.3071875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15049562569205352
    mean_env_wait_ms: 1.1899637384215964
    mean_inference_ms: 4.616976030049967
    mean_raw_obs_processing_ms: 0.3944568072231354
  time_since_restore: 477.5191493034363
  time_this_iter_s: 26.11593770980835
  time_total_s: 477.5191493034363
  timers:
    learn_throughput: 8388.136
    learn_time_ms: 19288.195
    sample_throughput: 23470.949
    sample_time_ms: 6893.287
    update_time_ms: 29.851
  timestamp: 1602509513
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |     18 |          477.519 | 2912256 |  244.089 |              296.929 |               146.02 |            820.875 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3445.440857222377
    time_step_min: 3100
  date: 2020-10-12_13-32-20
  done: false
  episode_len_mean: 818.8049518569463
  episode_reward_max: 296.9292929292929
  episode_reward_mean: 244.85864143498256
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 159
  episodes_total: 3635
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7837956696748734
        entropy_coeff: 0.0005000000000000001
        kl: 0.009773722073684135
        model: {}
        policy_loss: -0.013699290536654493
        total_loss: 11.026997645696005
        vf_explained_var: 0.972923755645752
        vf_loss: 11.03913402557373
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.553125
    gpu_util_percent0: 0.4021875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15034805900537337
    mean_env_wait_ms: 1.191091891723379
    mean_inference_ms: 4.605815342990539
    mean_raw_obs_processing_ms: 0.3939134709223726
  time_since_restore: 503.89424204826355
  time_this_iter_s: 26.37509274482727
  time_total_s: 503.89424204826355
  timers:
    learn_throughput: 8388.32
    learn_time_ms: 19287.771
    sample_throughput: 23425.004
    sample_time_ms: 6906.808
    update_time_ms: 29.702
  timestamp: 1602509540
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |     19 |          503.894 | 3074048 |  244.859 |              296.929 |               146.02 |            818.805 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3437.3884043099024
    time_step_min: 3100
  date: 2020-10-12_13-32-47
  done: false
  episode_len_mean: 815.1203045685279
  episode_reward_max: 296.9292929292929
  episode_reward_mean: 246.11188022355535
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 305
  episodes_total: 3940
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7442883600791296
        entropy_coeff: 0.0005000000000000001
        kl: 0.006699709066500266
        model: {}
        policy_loss: -0.010608940002081605
        total_loss: 13.607330242792765
        vf_explained_var: 0.9777317047119141
        vf_loss: 13.616971492767334
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.728125
    gpu_util_percent0: 0.3784375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.765625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1500905346590714
    mean_env_wait_ms: 1.193200108747879
    mean_inference_ms: 4.586519363748517
    mean_raw_obs_processing_ms: 0.3929945862150039
  time_since_restore: 530.4394161701202
  time_this_iter_s: 26.54517412185669
  time_total_s: 530.4394161701202
  timers:
    learn_throughput: 8373.767
    learn_time_ms: 19321.291
    sample_throughput: 23401.357
    sample_time_ms: 6913.787
    update_time_ms: 31.695
  timestamp: 1602509567
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |     20 |          530.439 | 3235840 |  246.112 |              296.929 |               146.02 |             815.12 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3432.6837186424004
    time_step_min: 3100
  date: 2020-10-12_13-33-13
  done: false
  episode_len_mean: 813.2373417721519
  episode_reward_max: 296.9292929292929
  episode_reward_mean: 246.82255367698406
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 168
  episodes_total: 4108
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7484339972337087
        entropy_coeff: 0.0005000000000000001
        kl: 0.0077777299253890915
        model: {}
        policy_loss: -0.012642340754003575
        total_loss: 8.89560834566752
        vf_explained_var: 0.9776120781898499
        vf_loss: 8.907069444656372
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.61875
    gpu_util_percent0: 0.38
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.778125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1499610322690389
    mean_env_wait_ms: 1.1942548927021193
    mean_inference_ms: 4.57680185445093
    mean_raw_obs_processing_ms: 0.3925277384688413
  time_since_restore: 557.0663895606995
  time_this_iter_s: 26.626973390579224
  time_total_s: 557.0663895606995
  timers:
    learn_throughput: 8361.304
    learn_time_ms: 19350.092
    sample_throughput: 23364.501
    sample_time_ms: 6924.693
    update_time_ms: 31.413
  timestamp: 1602509593
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |     21 |          557.066 | 3397632 |  246.823 |              296.929 |               146.02 |            813.237 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3427.9147928994084
    time_step_min: 3097
  date: 2020-10-12_13-33-40
  done: false
  episode_len_mean: 811.6411999062573
  episode_reward_max: 297.38383838383817
  episode_reward_mean: 247.50229503850315
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 159
  episodes_total: 4267
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7348756094773611
        entropy_coeff: 0.0005000000000000001
        kl: 0.009018306309978167
        model: {}
        policy_loss: -0.01537672511767596
        total_loss: 10.235094865163168
        vf_explained_var: 0.9737517237663269
        vf_loss: 10.249035278956095
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.7375
    gpu_util_percent0: 0.3540625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.149847242531897
    mean_env_wait_ms: 1.195225969864744
    mean_inference_ms: 4.568213544056943
    mean_raw_obs_processing_ms: 0.3921094293632083
  time_since_restore: 583.5504724979401
  time_this_iter_s: 26.4840829372406
  time_total_s: 583.5504724979401
  timers:
    learn_throughput: 8352.376
    learn_time_ms: 19370.775
    sample_throughput: 23384.52
    sample_time_ms: 6918.765
    update_time_ms: 31.665
  timestamp: 1602509620
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | RUNNING  | 172.17.0.4:26711 |     22 |           583.55 | 3559424 |  247.502 |              297.384 |               146.02 |            811.641 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_28eda_00000:
  custom_metrics:
    time_step_max: 3935
    time_step_mean: 3420.9011037527594
    time_step_min: 3097
  date: 2020-10-12_13-34-06
  done: true
  episode_len_mean: 808.7276902887139
  episode_reward_max: 297.38383838383817
  episode_reward_mean: 248.6839457567804
  episode_reward_min: 146.02020202020182
  episodes_this_iter: 305
  episodes_total: 4572
  experiment_id: 4b38c4353231477780b2536b23db8ef9
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6970376074314117
        entropy_coeff: 0.0005000000000000001
        kl: 0.006695165066048503
        model: {}
        policy_loss: -0.009383258836654326
        total_loss: 15.095372994740805
        vf_explained_var: 0.9745573401451111
        vf_loss: 15.103765487670898
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.674999999999997
    gpu_util_percent0: 0.3878125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7625
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 26711
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1496440492943101
    mean_env_wait_ms: 1.1970487570242028
    mean_inference_ms: 4.55308123709658
    mean_raw_obs_processing_ms: 0.3913907070382919
  time_since_restore: 609.8542997837067
  time_this_iter_s: 26.3038272857666
  time_total_s: 609.8542997837067
  timers:
    learn_throughput: 8359.46
    learn_time_ms: 19354.36
    sample_throughput: 23348.36
    sample_time_ms: 6929.48
    update_time_ms: 33.192
  timestamp: 1602509646
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 28eda_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | TERMINATED |       |     23 |          609.854 | 3721216 |  248.684 |              297.384 |               146.02 |            808.728 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_28eda_00000 | TERMINATED |       |     23 |          609.854 | 3721216 |  248.684 |              297.384 |               146.02 |            808.728 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


