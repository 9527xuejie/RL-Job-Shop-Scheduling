2020-10-12 12:51:36,152	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_aa70a_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=29850)[0m 2020-10-12 12:51:38,983	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=29826)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29826)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29836)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29836)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29797)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29835)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29835)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29778)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29824)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29824)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29750)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29750)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29745)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29745)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29747)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29747)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29741)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29741)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29762)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29762)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29752)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29752)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29811)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29811)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29723)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29723)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29817)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29817)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29737)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29737)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29721)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29721)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29820)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29820)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29790)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29790)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29738)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29738)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29726)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29726)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29729)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29729)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29739)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29739)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29789)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29730)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3669
    time_step_mean: 3363.603448275862
    time_step_min: 3125
  date: 2020-10-12_12-52-13
  done: false
  episode_len_mean: 881.5316455696203
  episode_reward_max: 283.8080808080806
  episode_reward_mean: 244.05069684183616
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.168799618879954
        entropy_coeff: 0.0005000000000000001
        kl: 0.006794407032430172
        model: {}
        policy_loss: -0.009109810149918
        total_loss: 516.1749394734701
        vf_explained_var: 0.4896630346775055
        vf_loss: 516.1832809448242
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.47352941176471
    gpu_util_percent0: 0.365
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5647058823529414
    vram_util_percent0: 0.08659541218914593
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17456833761980148
    mean_env_wait_ms: 1.1592157139532284
    mean_inference_ms: 6.008951638207903
    mean_raw_obs_processing_ms: 0.46979988088722624
  time_since_restore: 28.843284130096436
  time_this_iter_s: 28.843284130096436
  time_total_s: 28.843284130096436
  timers:
    learn_throughput: 8269.135
    learn_time_ms: 19565.772
    sample_throughput: 17587.206
    sample_time_ms: 9199.414
    update_time_ms: 51.056
  timestamp: 1602507133
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |      1 |          28.8433 | 161792 |  244.051 |              283.808 |              164.414 |            881.532 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3769
    time_step_mean: 3384.204379562044
    time_step_min: 3125
  date: 2020-10-12_12-52-40
  done: false
  episode_len_mean: 882.0126582278481
  episode_reward_max: 283.8080808080806
  episode_reward_mean: 241.3315752461323
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1391384502251942
        entropy_coeff: 0.0005000000000000001
        kl: 0.006648974299120407
        model: {}
        policy_loss: -0.00803058904906114
        total_loss: 139.35251998901367
        vf_explained_var: 0.790362536907196
        vf_loss: 139.35979207356772
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.72903225806452
    gpu_util_percent0: 0.412258064516129
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7548387096774185
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16866988355178147
    mean_env_wait_ms: 1.1500903689142998
    mean_inference_ms: 5.697825289008051
    mean_raw_obs_processing_ms: 0.4532382493434955
  time_since_restore: 55.72741222381592
  time_this_iter_s: 26.884128093719482
  time_total_s: 55.72741222381592
  timers:
    learn_throughput: 8327.187
    learn_time_ms: 19429.371
    sample_throughput: 19368.344
    sample_time_ms: 8353.425
    update_time_ms: 44.876
  timestamp: 1602507160
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |      2 |          55.7274 | 323584 |  241.332 |              283.808 |              164.414 |            882.013 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3769
    time_step_mean: 3387.7685185185187
    time_step_min: 3104
  date: 2020-10-12_12-53-06
  done: false
  episode_len_mean: 882.6075949367089
  episode_reward_max: 284.86868686868706
  episode_reward_mean: 241.6315688530879
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1276984612147014
        entropy_coeff: 0.0005000000000000001
        kl: 0.008798213598007957
        model: {}
        policy_loss: -0.011616275577883547
        total_loss: 56.40268643697103
        vf_explained_var: 0.885094165802002
        vf_loss: 56.4131072362264
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.935483870967747
    gpu_util_percent0: 0.40290322580645166
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16508095460508415
    mean_env_wait_ms: 1.1455902444931876
    mean_inference_ms: 5.476722861038996
    mean_raw_obs_processing_ms: 0.44208836098769244
  time_since_restore: 82.33950543403625
  time_this_iter_s: 26.612093210220337
  time_total_s: 82.33950543403625
  timers:
    learn_throughput: 8321.021
    learn_time_ms: 19443.768
    sample_throughput: 20429.082
    sample_time_ms: 7919.69
    update_time_ms: 42.693
  timestamp: 1602507186
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |      3 |          82.3395 | 485376 |  241.632 |              284.869 |              164.414 |            882.608 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3383.0508474576272
    time_step_min: 3071
  date: 2020-10-12_12-53-33
  done: false
  episode_len_mean: 880.3575949367089
  episode_reward_max: 289.86868686868684
  episode_reward_mean: 242.97546669223894
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.117651065190633
        entropy_coeff: 0.0005000000000000001
        kl: 0.010729409366225203
        model: {}
        policy_loss: -0.014740587833027044
        total_loss: 42.30433781941732
        vf_explained_var: 0.9108259081840515
        vf_loss: 42.31748994191488
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.338709677419356
    gpu_util_percent0: 0.24806451612903227
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16263900651457144
    mean_env_wait_ms: 1.1432505280923206
    mean_inference_ms: 5.321423810768896
    mean_raw_obs_processing_ms: 0.4341568806409571
  time_since_restore: 108.94008326530457
  time_this_iter_s: 26.60057783126831
  time_total_s: 108.94008326530457
  timers:
    learn_throughput: 8315.214
    learn_time_ms: 19457.346
    sample_throughput: 21029.647
    sample_time_ms: 7693.52
    update_time_ms: 42.759
  timestamp: 1602507213
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |      4 |           108.94 | 647168 |  242.975 |              289.869 |              164.414 |            880.358 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3373.0561497326203
    time_step_min: 3071
  date: 2020-10-12_12-54-00
  done: false
  episode_len_mean: 875.8189873417722
  episode_reward_max: 296.838383838384
  episode_reward_mean: 244.78660017900535
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.080569823582967
        entropy_coeff: 0.0005000000000000001
        kl: 0.009577392290035883
        model: {}
        policy_loss: -0.01238335077262794
        total_loss: 32.96067603429159
        vf_explained_var: 0.9334585666656494
        vf_loss: 32.97168413798014
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.83870967741936
    gpu_util_percent0: 0.3100000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16089027876496179
    mean_env_wait_ms: 1.1427990992122328
    mean_inference_ms: 5.206062774337344
    mean_raw_obs_processing_ms: 0.42799595520002914
  time_since_restore: 135.44153094291687
  time_this_iter_s: 26.501447677612305
  time_total_s: 135.44153094291687
  timers:
    learn_throughput: 8324.384
    learn_time_ms: 19435.913
    sample_throughput: 21416.295
    sample_time_ms: 7554.621
    update_time_ms: 40.04
  timestamp: 1602507240
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |      5 |          135.442 | 808960 |  244.787 |              296.838 |              164.414 |            875.819 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3356.31326434619
    time_step_min: 3057
  date: 2020-10-12_12-54-27
  done: false
  episode_len_mean: 865.5900452488688
  episode_reward_max: 296.838383838384
  episode_reward_mean: 247.14100278806166
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 315
  episodes_total: 1105
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0676262180010478
        entropy_coeff: 0.0005000000000000001
        kl: 0.009680427766094605
        model: {}
        policy_loss: -0.012698806830788575
        total_loss: 30.4976487159729
        vf_explained_var: 0.9575604796409607
        vf_loss: 30.508944829305012
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.877419354838704
    gpu_util_percent0: 0.32064516129032256
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15856954164565096
    mean_env_wait_ms: 1.144489648145803
    mean_inference_ms: 5.052844623057225
    mean_raw_obs_processing_ms: 0.42018014647463375
  time_since_restore: 162.1651930809021
  time_this_iter_s: 26.72366213798523
  time_total_s: 162.1651930809021
  timers:
    learn_throughput: 8324.991
    learn_time_ms: 19434.496
    sample_throughput: 21578.77
    sample_time_ms: 7497.74
    update_time_ms: 39.29
  timestamp: 1602507267
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |      6 |          162.165 | 970752 |  247.141 |              296.838 |              164.414 |             865.59 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3349.2324058919803
    time_step_min: 3040
  date: 2020-10-12_12-54-53
  done: false
  episode_len_mean: 860.6566455696203
  episode_reward_max: 296.838383838384
  episode_reward_mean: 248.45278736734446
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 159
  episodes_total: 1264
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0596419076124828
        entropy_coeff: 0.0005000000000000001
        kl: 0.010161610164990028
        model: {}
        policy_loss: -0.016104797037163127
        total_loss: 15.93123428026835
        vf_explained_var: 0.9655768871307373
        vf_loss: 15.945836305618286
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.28333333333334
    gpu_util_percent0: 0.2896666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7799999999999994
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15773014975577046
    mean_env_wait_ms: 1.1454115528026543
    mean_inference_ms: 4.9980081697309835
    mean_raw_obs_processing_ms: 0.4173820058176491
  time_since_restore: 188.61088919639587
  time_this_iter_s: 26.445696115493774
  time_total_s: 188.61088919639587
  timers:
    learn_throughput: 8327.031
    learn_time_ms: 19429.735
    sample_throughput: 21800.345
    sample_time_ms: 7421.534
    update_time_ms: 38.712
  timestamp: 1602507293
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |      7 |          188.611 | 1132544 |  248.453 |              296.838 |              164.414 |            860.657 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3341.308695652174
    time_step_min: 3000
  date: 2020-10-12_12-55-20
  done: false
  episode_len_mean: 855.9331926863572
  episode_reward_max: 300.62626262626264
  episode_reward_mean: 249.67657588543676
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.03820139169693
        entropy_coeff: 0.0005000000000000001
        kl: 0.010571143977964917
        model: {}
        policy_loss: -0.015180300086891899
        total_loss: 15.344871044158936
        vf_explained_var: 0.9647813439369202
        vf_loss: 15.358456134796143
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.396774193548385
    gpu_util_percent0: 0.33451612903225797
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15702328224619258
    mean_env_wait_ms: 1.1464607884994682
    mean_inference_ms: 4.951286609183476
    mean_raw_obs_processing_ms: 0.41495439440728454
  time_since_restore: 215.09737992286682
  time_this_iter_s: 26.486490726470947
  time_total_s: 215.09737992286682
  timers:
    learn_throughput: 8327.296
    learn_time_ms: 19429.117
    sample_throughput: 21963.15
    sample_time_ms: 7366.521
    update_time_ms: 37.728
  timestamp: 1602507320
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |      8 |          215.097 | 1294336 |  249.677 |              300.626 |              164.414 |            855.933 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3332.9369720597792
    time_step_min: 3000
  date: 2020-10-12_12-55-46
  done: false
  episode_len_mean: 851.7912713472485
  episode_reward_max: 300.62626262626264
  episode_reward_mean: 250.8239702528129
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 159
  episodes_total: 1581
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9944668610890707
        entropy_coeff: 0.0005000000000000001
        kl: 0.009636153699830174
        model: {}
        policy_loss: -0.013683678349480033
        total_loss: 15.825680096944174
        vf_explained_var: 0.9664711356163025
        vf_loss: 15.837933699289957
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.241935483870968
    gpu_util_percent0: 0.28838709677419355
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15640526415195943
    mean_env_wait_ms: 1.1477008504714938
    mean_inference_ms: 4.91051475866449
    mean_raw_obs_processing_ms: 0.4127870753213642
  time_since_restore: 241.77311635017395
  time_this_iter_s: 26.67573642730713
  time_total_s: 241.77311635017395
  timers:
    learn_throughput: 8324.452
    learn_time_ms: 19435.755
    sample_throughput: 22054.381
    sample_time_ms: 7336.048
    update_time_ms: 38.373
  timestamp: 1602507346
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |      9 |          241.773 | 1456128 |  250.824 |              300.626 |              164.414 |            851.791 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3320.7521598272137
    time_step_min: 3000
  date: 2020-10-12_12-56-13
  done: false
  episode_len_mean: 843.4894403379092
  episode_reward_max: 300.62626262626264
  episode_reward_mean: 252.3686068712469
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 313
  episodes_total: 1894
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9803410271803538
        entropy_coeff: 0.0005000000000000001
        kl: 0.008541637643550834
        model: {}
        policy_loss: -0.012379768799291924
        total_loss: 20.35350513458252
        vf_explained_var: 0.9704427719116211
        vf_loss: 20.364667415618896
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.054838709677412
    gpu_util_percent0: 0.3493548387096774
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.76774193548387
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1554328867542616
    mean_env_wait_ms: 1.1505574853253757
    mean_inference_ms: 4.846059734266961
    mean_raw_obs_processing_ms: 0.409474908914507
  time_since_restore: 268.40470600128174
  time_this_iter_s: 26.631589651107788
  time_total_s: 268.40470600128174
  timers:
    learn_throughput: 8317.876
    learn_time_ms: 19451.119
    sample_throughput: 22169.103
    sample_time_ms: 7298.085
    update_time_ms: 37.876
  timestamp: 1602507373
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |     10 |          268.405 | 1617920 |  252.369 |              300.626 |              164.414 |            843.489 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3318.0337972167
    time_step_min: 3000
  date: 2020-10-12_12-56-40
  done: false
  episode_len_mean: 838.9951314508277
  episode_reward_max: 300.62626262626264
  episode_reward_mean: 252.90348961867963
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 160
  episodes_total: 2054
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9654052903254827
        entropy_coeff: 0.0005000000000000001
        kl: 0.008852113038301468
        model: {}
        policy_loss: -0.01596694823820144
        total_loss: 12.95206061999003
        vf_explained_var: 0.9717339873313904
        vf_loss: 12.966739734013876
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.477419354838716
    gpu_util_percent0: 0.2661290322580645
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15502422482229555
    mean_env_wait_ms: 1.1519708109008986
    mean_inference_ms: 4.818884084196573
    mean_raw_obs_processing_ms: 0.4080654841622468
  time_since_restore: 295.1123888492584
  time_this_iter_s: 26.707682847976685
  time_total_s: 295.1123888492584
  timers:
    learn_throughput: 8322.943
    learn_time_ms: 19439.279
    sample_throughput: 22804.242
    sample_time_ms: 7094.82
    update_time_ms: 36.782
  timestamp: 1602507400
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |     11 |          295.112 | 1779712 |  252.903 |              300.626 |              164.414 |            838.995 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3314.3092165898615
    time_step_min: 3000
  date: 2020-10-12_12-57-07
  done: false
  episode_len_mean: 835.381555153707
  episode_reward_max: 300.62626262626264
  episode_reward_mean: 253.6233446581549
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9576482673486074
        entropy_coeff: 0.0005000000000000001
        kl: 0.007239541271701455
        model: {}
        policy_loss: -0.0113961934694089
        total_loss: 12.409526824951172
        vf_explained_var: 0.9709665179252625
        vf_loss: 12.41995358467102
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.11290322580646
    gpu_util_percent0: 0.22258064516129034
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.154656041538573
    mean_env_wait_ms: 1.153392953741236
    mean_inference_ms: 4.794738203787765
    mean_raw_obs_processing_ms: 0.4067823792007186
  time_since_restore: 321.993798494339
  time_this_iter_s: 26.881409645080566
  time_total_s: 321.993798494339
  timers:
    learn_throughput: 8301.019
    learn_time_ms: 19490.62
    sample_throughput: 22974.789
    sample_time_ms: 7042.154
    update_time_ms: 36.991
  timestamp: 1602507427
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |     12 |          321.994 | 1941504 |  253.623 |              300.626 |              164.414 |            835.382 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3307.1037581699347
    time_step_min: 3000
  date: 2020-10-12_12-57-33
  done: false
  episode_len_mean: 830.0381526104418
  episode_reward_max: 304.8686868686868
  episode_reward_mean: 254.55640744797387
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 278
  episodes_total: 2490
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9107856601476669
        entropy_coeff: 0.0005000000000000001
        kl: 0.009169460041448474
        model: {}
        policy_loss: -0.011665622839548936
        total_loss: 17.314420064290363
        vf_explained_var: 0.9738726019859314
        vf_loss: 17.324707349141438
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.306451612903224
    gpu_util_percent0: 0.27774193548387094
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15409563069065116
    mean_env_wait_ms: 1.156062804565885
    mean_inference_ms: 4.758111849955369
    mean_raw_obs_processing_ms: 0.40484482289849266
  time_since_restore: 348.5337452888489
  time_this_iter_s: 26.539946794509888
  time_total_s: 348.5337452888489
  timers:
    learn_throughput: 8303.499
    learn_time_ms: 19484.799
    sample_throughput: 22980.574
    sample_time_ms: 7040.381
    update_time_ms: 36.767
  timestamp: 1602507453
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |     13 |          348.534 | 2103296 |  254.556 |              304.869 |              164.414 |            830.038 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3301.3846444780634
    time_step_min: 3000
  date: 2020-10-12_12-58-00
  done: false
  episode_len_mean: 826.8205510052122
  episode_reward_max: 304.8686868686868
  episode_reward_mean: 255.35431380070258
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 196
  episodes_total: 2686
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.903229683637619
        entropy_coeff: 0.0005000000000000001
        kl: 0.007866927810634175
        model: {}
        policy_loss: -0.011833757557421146
        total_loss: 10.215125640233358
        vf_explained_var: 0.9779519438743591
        vf_loss: 10.225837469100952
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.389999999999993
    gpu_util_percent0: 0.33666666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15374873452605747
    mean_env_wait_ms: 1.1576645934666503
    mean_inference_ms: 4.735380235793094
    mean_raw_obs_processing_ms: 0.40364452597002226
  time_since_restore: 375.00587582588196
  time_this_iter_s: 26.47213053703308
  time_total_s: 375.00587582588196
  timers:
    learn_throughput: 8303.62
    learn_time_ms: 19484.514
    sample_throughput: 23017.99
    sample_time_ms: 7028.937
    update_time_ms: 34.615
  timestamp: 1602507480
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |     14 |          375.006 | 2265088 |  255.354 |              304.869 |              164.414 |            826.821 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3298.0995717344754
    time_step_min: 3000
  date: 2020-10-12_12-58-27
  done: false
  episode_len_mean: 824.2728551336146
  episode_reward_max: 304.8686868686868
  episode_reward_mean: 255.87969356007343
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8989825199047724
        entropy_coeff: 0.0005000000000000001
        kl: 0.007596341349805395
        model: {}
        policy_loss: -0.01373945282830391
        total_loss: 10.28798254330953
        vf_explained_var: 0.9751877784729004
        vf_loss: 10.300652027130127
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.203225806451613
    gpu_util_percent0: 0.4087096774193549
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15349503713043786
    mean_env_wait_ms: 1.1589798591900533
    mean_inference_ms: 4.718858667464135
    mean_raw_obs_processing_ms: 0.402760060527188
  time_since_restore: 401.65560364723206
  time_this_iter_s: 26.649727821350098
  time_total_s: 401.65560364723206
  timers:
    learn_throughput: 8293.501
    learn_time_ms: 19508.287
    sample_throughput: 23032.069
    sample_time_ms: 7024.64
    update_time_ms: 36.483
  timestamp: 1602507507
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |     15 |          401.656 | 2426880 |   255.88 |              304.869 |              164.414 |            824.273 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3293.2634017207147
    time_step_min: 3000
  date: 2020-10-12_12-58-54
  done: false
  episode_len_mean: 821.0182767624021
  episode_reward_max: 304.8686868686868
  episode_reward_mean: 256.5255129625235
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 220
  episodes_total: 3064
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.850812499721845
        entropy_coeff: 0.0005000000000000001
        kl: 0.007763688103295863
        model: {}
        policy_loss: -0.012930358837669095
        total_loss: 13.201678593953451
        vf_explained_var: 0.9771398901939392
        vf_loss: 13.213481585184732
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.5
    gpu_util_percent0: 0.3587096774193549
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15318343105291496
    mean_env_wait_ms: 1.1609157790604883
    mean_inference_ms: 4.698161497656122
    mean_raw_obs_processing_ms: 0.4016597888170301
  time_since_restore: 428.2997045516968
  time_this_iter_s: 26.64410090446472
  time_total_s: 428.2997045516968
  timers:
    learn_throughput: 8288.796
    learn_time_ms: 19519.361
    sample_throughput: 23102.635
    sample_time_ms: 7003.184
    update_time_ms: 37.914
  timestamp: 1602507534
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |     16 |            428.3 | 2588672 |  256.526 |              304.869 |              164.414 |            821.018 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3288.1761294261296
    time_step_min: 3000
  date: 2020-10-12_12-59-20
  done: false
  episode_len_mean: 817.7745629897529
  episode_reward_max: 304.8686868686868
  episode_reward_mean: 257.28439001223825
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 254
  episodes_total: 3318
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.843670646349589
        entropy_coeff: 0.0005000000000000001
        kl: 0.008520666509866714
        model: {}
        policy_loss: -0.012594705641580125
        total_loss: 10.012202262878418
        vf_explained_var: 0.9807496666908264
        vf_loss: 10.023514906565348
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.45161290322581
    gpu_util_percent0: 0.2958064516129032
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15284648031399248
    mean_env_wait_ms: 1.1628379397021578
    mean_inference_ms: 4.676446475811893
    mean_raw_obs_processing_ms: 0.40049439091552347
  time_since_restore: 454.9990077018738
  time_this_iter_s: 26.699303150177002
  time_total_s: 454.9990077018738
  timers:
    learn_throughput: 8282.626
    learn_time_ms: 19533.903
    sample_throughput: 23071.328
    sample_time_ms: 7012.687
    update_time_ms: 37.881
  timestamp: 1602507560
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |     17 |          454.999 | 2750464 |  257.284 |              304.869 |              164.414 |            817.775 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3284.2216074548633
    time_step_min: 3000
  date: 2020-10-12_12-59-47
  done: false
  episode_len_mean: 815.7465477560414
  episode_reward_max: 304.8686868686868
  episode_reward_mean: 257.7815177087331
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8496881127357483
        entropy_coeff: 0.0005000000000000001
        kl: 0.008243096681932608
        model: {}
        policy_loss: -0.014313313933295527
        total_loss: 9.743167479832968
        vf_explained_var: 0.9755610823631287
        vf_loss: 9.756256818771362
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.712903225806453
    gpu_util_percent0: 0.32838709677419353
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1526612267848313
    mean_env_wait_ms: 1.1640143804769587
    mean_inference_ms: 4.664325603057179
    mean_raw_obs_processing_ms: 0.3998516103644934
  time_since_restore: 481.5171935558319
  time_this_iter_s: 26.51818585395813
  time_total_s: 481.5171935558319
  timers:
    learn_throughput: 8279.46
    learn_time_ms: 19541.37
    sample_throughput: 23092.563
    sample_time_ms: 7006.238
    update_time_ms: 39.0
  timestamp: 1602507587
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |     18 |          481.517 | 2912256 |  257.782 |              304.869 |              164.414 |            815.747 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3280.283081155433
    time_step_min: 2998
  date: 2020-10-12_13-00-14
  done: false
  episode_len_mean: 813.4152841990754
  episode_reward_max: 304.8686868686868
  episode_reward_mean: 258.4388321617042
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 201
  episodes_total: 3677
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8071251610914866
        entropy_coeff: 0.0005000000000000001
        kl: 0.008401203628939887
        model: {}
        policy_loss: -0.010734575373741487
        total_loss: 12.29520026842753
        vf_explained_var: 0.976015031337738
        vf_loss: 12.304657936096191
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.74516129032259
    gpu_util_percent0: 0.27225806451612905
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15244377898332598
    mean_env_wait_ms: 1.1655570784315377
    mean_inference_ms: 4.6500682058173455
    mean_raw_obs_processing_ms: 0.39909608958866877
  time_since_restore: 508.1810646057129
  time_this_iter_s: 26.66387104988098
  time_total_s: 508.1810646057129
  timers:
    learn_throughput: 8276.685
    learn_time_ms: 19547.923
    sample_throughput: 23115.965
    sample_time_ms: 6999.146
    update_time_ms: 37.443
  timestamp: 1602507614
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |     19 |          508.181 | 3074048 |  258.439 |              304.869 |              164.414 |            813.415 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3274.3011770726716
    time_step_min: 2998
  date: 2020-10-12_13-00-40
  done: false
  episode_len_mean: 810.3810126582279
  episode_reward_max: 304.8686868686868
  episode_reward_mean: 259.29189361974187
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 273
  episodes_total: 3950
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.799735963344574
        entropy_coeff: 0.0005000000000000001
        kl: 0.005907233494023482
        model: {}
        policy_loss: -0.00781547870913831
        total_loss: 11.616284449895224
        vf_explained_var: 0.9789537787437439
        vf_loss: 11.623318433761597
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.554838709677412
    gpu_util_percent0: 0.3396774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1521704131380631
    mean_env_wait_ms: 1.1674142116507376
    mean_inference_ms: 4.632356021725466
    mean_raw_obs_processing_ms: 0.3981553249567854
  time_since_restore: 534.6874220371246
  time_this_iter_s: 26.506357431411743
  time_total_s: 534.6874220371246
  timers:
    learn_throughput: 8283.209
    learn_time_ms: 19532.528
    sample_throughput: 23108.14
    sample_time_ms: 7001.515
    update_time_ms: 36.769
  timestamp: 1602507640
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |     20 |          534.687 | 3235840 |  259.292 |              304.869 |              164.414 |            810.381 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3271.1576487948846
    time_step_min: 2998
  date: 2020-10-12_13-01-07
  done: false
  episode_len_mean: 808.7144595910419
  episode_reward_max: 304.8686868686868
  episode_reward_mean: 259.86156845966985
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 158
  episodes_total: 4108
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.810770774881045
        entropy_coeff: 0.0005000000000000001
        kl: 0.00756658516669025
        model: {}
        policy_loss: -0.012811145570594817
        total_loss: 8.51444443066915
        vf_explained_var: 0.977470874786377
        vf_loss: 8.526147683461508
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.883870967741935
    gpu_util_percent0: 0.33032258064516123
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15202529288154873
    mean_env_wait_ms: 1.1684498983839915
    mean_inference_ms: 4.623000080176359
    mean_raw_obs_processing_ms: 0.39765868527485554
  time_since_restore: 561.3477647304535
  time_this_iter_s: 26.660342693328857
  time_total_s: 561.3477647304535
  timers:
    learn_throughput: 8281.928
    learn_time_ms: 19535.548
    sample_throughput: 23135.62
    sample_time_ms: 6993.199
    update_time_ms: 36.6
  timestamp: 1602507667
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |     21 |          561.348 | 3397632 |  259.862 |              304.869 |              164.414 |            808.714 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3267.210255209553
    time_step_min: 2981
  date: 2020-10-12_13-01-34
  done: false
  episode_len_mean: 806.7145838163691
  episode_reward_max: 304.8686868686868
  episode_reward_mean: 260.4612224728155
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 205
  episodes_total: 4313
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7573234935601553
        entropy_coeff: 0.0005000000000000001
        kl: 0.008564375806599855
        model: {}
        policy_loss: -0.012547681641687328
        total_loss: 11.752562761306763
        vf_explained_var: 0.976997435092926
        vf_loss: 11.763776143391928
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.338709677419352
    gpu_util_percent0: 0.3467741935483872
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1518469474634826
    mean_env_wait_ms: 1.1698156085766769
    mean_inference_ms: 4.611579501031315
    mean_raw_obs_processing_ms: 0.3970550926754749
  time_since_restore: 587.9613890647888
  time_this_iter_s: 26.613624334335327
  time_total_s: 587.9613890647888
  timers:
    learn_throughput: 8294.086
    learn_time_ms: 19506.912
    sample_throughput: 23130.159
    sample_time_ms: 6994.85
    update_time_ms: 35.956
  timestamp: 1602507694
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | RUNNING  | 172.17.0.4:29850 |     22 |          587.961 | 3559424 |  260.461 |              304.869 |              164.414 |            806.715 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_aa70a_00000:
  custom_metrics:
    time_step_max: 3848
    time_step_mean: 3261.3920704845814
    time_step_min: 2981
  date: 2020-10-12_13-02-01
  done: true
  episode_len_mean: 804.4923614142295
  episode_reward_max: 304.8686868686868
  episode_reward_mean: 261.19819760238806
  episode_reward_min: 164.4141414141411
  episodes_this_iter: 269
  episodes_total: 4582
  experiment_id: 6d28373fc4b04bb2bae6eaf55509448f
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7572875668605169
        entropy_coeff: 0.0005000000000000001
        kl: 0.00706625923824807
        model: {}
        policy_loss: -0.011514672000582019
        total_loss: 10.171034892400106
        vf_explained_var: 0.981252133846283
        vf_loss: 10.181515216827393
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.080645161290327
    gpu_util_percent0: 0.28193548387096773
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29850
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15163580116978723
    mean_env_wait_ms: 1.1714323584352406
    mean_inference_ms: 4.597910529412008
    mean_raw_obs_processing_ms: 0.39632749591752187
  time_since_restore: 614.7572581768036
  time_this_iter_s: 26.79586911201477
  time_total_s: 614.7572581768036
  timers:
    learn_throughput: 8281.354
    learn_time_ms: 19536.903
    sample_throughput: 23144.001
    sample_time_ms: 6990.667
    update_time_ms: 34.721
  timestamp: 1602507721
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: aa70a_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | TERMINATED |       |     23 |          614.757 | 3721216 |  261.198 |              304.869 |              164.414 |            804.492 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_aa70a_00000 | TERMINATED |       |     23 |          614.757 | 3721216 |  261.198 |              304.869 |              164.414 |            804.492 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


