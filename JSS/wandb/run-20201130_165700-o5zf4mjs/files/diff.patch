diff --git a/JSS.egg-info/SOURCES.txt b/JSS.egg-info/SOURCES.txt
index 26a5070..f15aace 100644
--- a/JSS.egg-info/SOURCES.txt
+++ b/JSS.egg-info/SOURCES.txt
@@ -18,6 +18,7 @@ JSS/multiprocessing_env.py
 JSS/random_loop.py
 JSS/train.py
 JSS/train_wandb.py
+JSS/train_wandb_impala.py
 JSS.egg-info/PKG-INFO
 JSS.egg-info/SOURCES.txt
 JSS.egg-info/dependency_links.txt
diff --git a/JSS/.ipynb_checkpoints/models-checkpoint.py b/JSS/.ipynb_checkpoints/models-checkpoint.py
index 933b659..3db6ad6 100644
--- a/JSS/.ipynb_checkpoints/models-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/models-checkpoint.py
@@ -32,8 +32,9 @@ class FCMaskedActionsModelTF(DistributionalQTFModel, TFModelV2):
         raw_actions, _ = self.action_embed_model({
             "obs": input_dict["obs"]["real_obs"]
         })
-        inf_mask = tf.maximum(tf.math.log(action_mask), tf.float32.min)
-        return raw_actions + inf_mask, state
+        #inf_mask = tf.maximum(tf.math.log(action_mask), tf.float32.min)
+        logits = tf.where(tf.math.equal(action_mask, 1), raw_actions,  tf.float32.min)
+        return logits, state
 
     def value_function(self):
         return self.action_embed_model.value_function()
\ No newline at end of file
diff --git a/JSS/.ipynb_checkpoints/train_wandb-checkpoint.py b/JSS/.ipynb_checkpoints/train_wandb-checkpoint.py
index aec3dba..8a30023 100644
--- a/JSS/.ipynb_checkpoints/train_wandb-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/train_wandb-checkpoint.py
@@ -75,14 +75,14 @@ def train_func():
         'num_workers': mp.cpu_count(),
         'layer_nb': 2,
         'train_batch_size': 32001,
-        'num_envs_per_worker': 1, # TO TUNE
-        'rollout_fragment_length': 512, # TO TUNE
-        'sgd_minibatch_size': 56, # TO TUNE
-        'layer_size': 1024, # TO TUNE
-        'lr': 1e-4, # TO TUNE
-        'entropy_coeff': 1e-5, # TO TUNE
-        'clip_param': 0.3, # TO TUNE
-        'vf_clip_param': 15.0, # TO TUNE
+        'num_envs_per_worker': 2, # TO TUNE
+        'rollout_fragment_length': 1064, # TO TUNE
+        'sgd_minibatch_size': 5443, # TO TUNE
+        'layer_size': 853, # TO TUNE
+        'lr': 0.0001798, # TO TUNE
+        'entropy_coeff': 0.00007394, # TO TUNE
+        'clip_param': 0.2604, # TO TUNE
+        'vf_clip_param': 20.0, # TO TUNE
         'kl_target': 0.2, # TO TUNE
         'num_sgd_iter': 25, # TO TUNE
         "vf_loss_coeff": 0.7, # TO TUNE
diff --git a/JSS/__pycache__/models.cpython-38.pyc b/JSS/__pycache__/models.cpython-38.pyc
index b92e3ad..80b44cf 100644
Binary files a/JSS/__pycache__/models.cpython-38.pyc and b/JSS/__pycache__/models.cpython-38.pyc differ
diff --git a/JSS/models.py b/JSS/models.py
index 933b659..3db6ad6 100644
--- a/JSS/models.py
+++ b/JSS/models.py
@@ -32,8 +32,9 @@ class FCMaskedActionsModelTF(DistributionalQTFModel, TFModelV2):
         raw_actions, _ = self.action_embed_model({
             "obs": input_dict["obs"]["real_obs"]
         })
-        inf_mask = tf.maximum(tf.math.log(action_mask), tf.float32.min)
-        return raw_actions + inf_mask, state
+        #inf_mask = tf.maximum(tf.math.log(action_mask), tf.float32.min)
+        logits = tf.where(tf.math.equal(action_mask, 1), raw_actions,  tf.float32.min)
+        return logits, state
 
     def value_function(self):
         return self.action_embed_model.value_function()
\ No newline at end of file
diff --git a/JSS/train_wandb.py b/JSS/train_wandb.py
index aec3dba..7c48ee2 100644
--- a/JSS/train_wandb.py
+++ b/JSS/train_wandb.py
@@ -75,18 +75,18 @@ def train_func():
         'num_workers': mp.cpu_count(),
         'layer_nb': 2,
         'train_batch_size': 32001,
-        'num_envs_per_worker': 1, # TO TUNE
-        'rollout_fragment_length': 512, # TO TUNE
-        'sgd_minibatch_size': 56, # TO TUNE
-        'layer_size': 1024, # TO TUNE
-        'lr': 1e-4, # TO TUNE
-        'entropy_coeff': 1e-5, # TO TUNE
-        'clip_param': 0.3, # TO TUNE
-        'vf_clip_param': 15.0, # TO TUNE
-        'kl_target': 0.2, # TO TUNE
-        'num_sgd_iter': 25, # TO TUNE
-        "vf_loss_coeff": 0.7, # TO TUNE
-        "kl_coeff": 0.4, # TO TUNE
+        'num_envs_per_worker': 2, # TO TUNE
+        'rollout_fragment_length': 1064, # TO TUNE
+        'sgd_minibatch_size': 5443, # TO TUNE
+        'layer_size': 853, # TO TUNE
+        'lr': 0.0001798, # TO TUNE
+        'entropy_coeff': 0.00007394, # TO TUNE
+        'clip_param': 0.2604, # TO TUNE
+        'vf_clip_param': 20.0, # TO TUNE
+        'kl_target': 0.2088, # TO TUNE
+        'num_sgd_iter': 22, # TO TUNE
+        "vf_loss_coeff": 0.9394, # TO TUNE
+        "kl_coeff": 0.5021, # TO TUNE
         "batch_mode": "truncate_episodes", # TO TUNE
         'lambda': 1.0,
         "grad_clip": None,
diff --git a/JSS/wandb/debug-internal.log b/JSS/wandb/debug-internal.log
index 94b082e..d043d47 120000
--- a/JSS/wandb/debug-internal.log
+++ b/JSS/wandb/debug-internal.log
@@ -1 +1 @@
-run-20201130_152536-4dm99na4/logs/debug-internal.log
\ No newline at end of file
+run-20201130_165700-o5zf4mjs/logs/debug-internal.log
\ No newline at end of file
diff --git a/JSS/wandb/debug.log b/JSS/wandb/debug.log
index 789d6a4..e6915e7 120000
--- a/JSS/wandb/debug.log
+++ b/JSS/wandb/debug.log
@@ -1 +1 @@
-run-20201130_152536-4dm99na4/logs/debug.log
\ No newline at end of file
+run-20201130_165700-o5zf4mjs/logs/debug.log
\ No newline at end of file
diff --git a/JSS/wandb/latest-run b/JSS/wandb/latest-run
index 6159873..82ccbb8 120000
--- a/JSS/wandb/latest-run
+++ b/JSS/wandb/latest-run
@@ -1 +1 @@
-run-20201130_152536-4dm99na4
\ No newline at end of file
+run-20201130_165700-o5zf4mjs
\ No newline at end of file
