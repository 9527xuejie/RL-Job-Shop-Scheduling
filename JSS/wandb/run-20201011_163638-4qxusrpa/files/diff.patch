diff --git a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
index a6d8e00..bfacbf2 100644
--- a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
@@ -2,14 +2,15 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 7,
    "metadata": {},
    "outputs": [
     {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "I have detected 80 CPUs here, so I'm going to create 79 actors\n"
+     "ename": "SyntaxError",
+     "evalue": "invalid syntax (<ipython-input-7-814fb116f5ad>, line 57)",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-814fb116f5ad>\"\u001b[0;36m, line \u001b[0;32m57\u001b[0m\n\u001b[0;31m    'sgd_minibatch_size': {\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
      ]
     }
    ],
@@ -29,13 +30,29 @@
     "from ray.tune.integration.wandb import WandbLogger\n",
     "\n",
     "from JSS.env_wrapper import BestActionsWrapper\n",
-    "\n",
+    "2\n",
     "from JSS.models import FCMaskedActionsModel\n",
     "\n",
     "pio.orca.config.use_xvfb = True\n",
     "import wandb\n",
     "\n",
-    "\n",
+    "'''\n",
+    "            'lr': {\n",
+    "                'values': [5e-5, 1e-5]\n",
+    "            },\n",
+    "            'lambda': {\n",
+    "                'values': [0.90, 0.95, 1.0]\n",
+    "            },\n",
+    "            'clip_param': {\n",
+    "                'values': [0.2, 0.3, 0.4]\n",
+    "            },\n",
+    "            'num_sgd_iter': {\n",
+    "                'values': [30, 35, 40]\n",
+    "            },\n",
+    "            'entropy_coeff': {\n",
+    "                'values': [0.0, 1e-4]\n",
+    "            }\n",
+    "'''\n",
     "\n",
     "if __name__ == \"__main__\":\n",
     "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
@@ -49,60 +66,29 @@
     "        },\n",
     "        'parameters': {\n",
     "            'num_envs_per_worker': {\n",
-    "                'values': [4, 6, 8]\n",
-    "            },\n",
-    "            'sgd_minibatch_size': {\n",
-    "                'values': [2**13, 2**13 + 2**12, 2**14, 2**14 + 2**13]\n",
-    "            },\n",
-    "            'lr': {\n",
-    "                'values': [5e-5, 1e-5]\n",
-    "            },\n",
-    "            'lambda': {\n",
-    "                'values': [0.90, 0.95, 1.0]\n",
-    "            },\n",
-    "            'clip_param': {\n",
-    "                'values': [0.2, 0.3, 0.4]\n",
+    "                'values': [1, 2]\n",
     "            },\n",
-    "            'num_sgd_iter': {\n",
-    "                'values': [30, 40]\n",
+    "            'rollout_fragment_length': {\n",
+    "                'values': [768, 1024]\n",
     "            },\n",
+    "            'sgd_minibatch_size': {\n",
+    "                'values': [12384, 18384]\n",
+    "            }\n",
     "        }\n",
     "    }"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 5,
    "metadata": {},
    "outputs": [
     {
-     "ename": "CommError",
-     "evalue": "Variable \"entityName\" has invalid value null.\nExpected type \"String!\", found null.",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 response = self.gql(\n\u001b[0m\u001b[1;32m   1397\u001b[0m                     \u001b[0mmutation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# Only print resolved attempts once every minute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;31mException\u001b[0m: {'message': 'Variable \"entityName\" has invalid value null.\\nExpected type \"String!\", found null.', 'locations': [{'line': 1, 'column': 70}]}",
-      "\nDuring handling of the above exception, another exception occurred:\n",
-      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[0;32m<ipython-input-4-e4d446407002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RLLIB_SWEEP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36msweep\u001b[0;34m(sweep, entity, project)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0mwandb_sdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_login\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_silent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInternalApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Create sweep with ID:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0msweep_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sweep_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/internal.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCommError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Whoa, you found a bug.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCommError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0msweep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"upsertSweep\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sweep\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmutation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmutation_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_old\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 response = self.gql(\n\u001b[0m\u001b[1;32m   1397\u001b[0m                     \u001b[0mmutation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                     variable_values={\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# Only print resolved attempts once every minute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_print\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminutes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m\"\"\"Wrapper around execute that logs in cases of failure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;31mCommError\u001b[0m: Variable \"entityName\" has invalid value null.\nExpected type \"String!\", found null."
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Create sweep with ID: 8x5lxuul\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/8x5lxuul\n"
      ]
     }
    ],
@@ -112,7 +98,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 6,
    "metadata": {},
    "outputs": [
     {
@@ -120,213 +106,206 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent 🕵️\n",
-      "2020-10-08 14:03:50,854 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 4096\n",
-      "2020-10-08 14:03:51,192 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
+      "2020-10-11 14:47:13,579 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-11 14:47:13,876 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 14:47:13,877 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tnum_envs_per_worker: 1\n",
+      "\trollout_fragment_length: 768\n",
+      "2020-10-11 14:47:13,879 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --num_envs_per_worker=1 --rollout_fragment_length=768\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-08 14:03:56,246 - wandb.wandb_agent - INFO - Running runs: ['5nvugt1y']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-1\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_140356-5nvugt1y\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlegendary-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/8x5lxuul\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/l3ysm1iu\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_144715-l3ysm1iu\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 14:03:58,257\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8271\u001b[39m\u001b[22m\n",
+      "2020-10-11 14:47:18,896 - wandb.wandb_agent - INFO - Running runs: ['l3ysm1iu']\n",
+      "2020-10-11 14:47:19,495\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 77.4/754.6 GiB\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=57899)\u001b[0m 2020-10-08 14:04:01,486\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-04-38\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "\u001b[2m\u001b[36m(pid=30378)\u001b[0m 2020-10-11 14:47:22,295\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=30277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30346)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30346)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30334)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30334)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30331)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30331)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30368)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30368)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30265)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30265)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30333)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30333)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30267)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30267)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30314)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30314)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30284)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30284)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30271)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30271)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30338)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30338)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30317)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30317)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30275)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30275)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30380)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30380)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30356)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30356)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30289)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30289)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30402)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30402)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30342)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30342)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30262)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30262)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30326)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30326)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30379)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30379)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30341)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30341)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30330)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30330)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30344)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30344)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30286)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30286)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30287)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30287)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30339)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30339)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30385)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30385)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30288)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30288)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30328)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30328)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30280)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30280)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30270)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30270)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30358)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30358)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30290)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30290)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30292)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30292)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30281)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30281)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30371)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30371)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30282)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30282)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30276)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30276)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30324)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30324)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30369)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30369)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30352)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30352)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30311)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30311)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=30382)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=30382)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
+      "  custom_metrics: {}\n",
+      "  date: 2020-10-11_14-47-43\n",
+      "  done: false\n",
+      "  episode_len_mean: .nan\n",
+      "  episode_reward_max: .nan\n",
+      "  episode_reward_mean: .nan\n",
+      "  episode_reward_min: .nan\n",
+      "  episodes_this_iter: 0\n",
+      "  episodes_total: 0\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -334,83 +313,77 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1603952676057816\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006529558636248112\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01697929573711008\n",
-      "        total_loss: 6.624263763427734\n",
-      "        vf_explained_var: 0.8197423815727234\n",
-      "        vf_loss: 6.639937055110932\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1914540827274323\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007823126390576363\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015033794334158301\n",
+      "        total_loss: 562.9246368408203\n",
+      "        vf_explained_var: -0.7487409114837646\n",
+      "        vf_loss: 562.938232421875\n",
+      "    num_steps_sampled: 60672\n",
+      "    num_steps_trained: 60672\n",
       "  iterations_since_restore: 1\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.00833333333333\n",
-      "    gpu_util_percent0: 0.3225\n",
+      "    cpu_util_percent: 36.126315789473686\n",
+      "    gpu_util_percent0: 0.2715789473684211\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0002777777777777778\n",
-      "    ram_util_percent: 10.413888888888891\n",
-      "    vram_util_percent0: 0.27462328267920266\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.321052631578947\n",
+      "    vram_util_percent0: 0.08482936596986071\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.18350994266746734\n",
-      "    mean_env_wait_ms: 1.6865222444501913\n",
-      "    mean_inference_ms: 5.985971555624452\n",
-      "    mean_raw_obs_processing_ms: 0.49480385234157925\n",
-      "  time_since_restore: 30.92910385131836\n",
-      "  time_this_iter_s: 30.92910385131836\n",
-      "  time_total_s: 30.92910385131836\n",
+      "  sampler_perf: {}\n",
+      "  time_since_restore: 16.101393938064575\n",
+      "  time_this_iter_s: 16.101393938064575\n",
+      "  time_total_s: 16.101393938064575\n",
       "  timers:\n",
-      "    learn_throughput: 7789.468\n",
-      "    learn_time_ms: 20770.611\n",
-      "    sample_throughput: 16046.653\n",
-      "    sample_time_ms: 10082.601\n",
-      "    update_time_ms: 36.409\n",
-      "  timestamp: 1602165878\n",
+      "    learn_throughput: 7147.299\n",
+      "    learn_time_ms: 8488.802\n",
+      "    sample_throughput: 8107.298\n",
+      "    sample_time_ms: 7483.628\n",
+      "    update_time_ms: 40.196\n",
+      "  timestamp: 1602427663\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
+      "  timesteps_total: 60672\n",
       "  training_iteration: 1\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.8/754.6 GiB\n",
+      "Memory usage on this node: 25.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      1 |          30.9291 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |      1 |          16.1014 | 60672 |      nan |                  nan |                  nan |                nan |\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-05-08\n",
+      "    time_step_max: 4058\n",
+      "    time_step_mean: 3611.3670886075947\n",
+      "    time_step_min: 3306\n",
+      "  date: 2020-10-11_14-47-57\n",
       "  done: false\n",
-      "  episode_len_mean: 869.3417721518987\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.90004475131036\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 886.0379746835443\n",
+      "  episode_reward_max: 265.11111111111086\n",
+      "  episode_reward_mean: 218.84337041299042\n",
+      "  episode_reward_min: 151.1717171717169\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 79\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -418,83 +391,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1352683365345002\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007792104431428015\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020531148964073508\n",
-      "        total_loss: 5.638339829444885\n",
-      "        vf_explained_var: 0.9249752759933472\n",
-      "        vf_loss: 5.657312452793121\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1658275425434113\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005513080162927508\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010292008926626295\n",
+      "        total_loss: 595.6605682373047\n",
+      "        vf_explained_var: 0.18877363204956055\n",
+      "        vf_loss: 595.6699066162109\n",
+      "    num_steps_sampled: 121344\n",
+      "    num_steps_trained: 121344\n",
       "  iterations_since_restore: 2\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.90294117647059\n",
-      "    gpu_util_percent0: 0.26941176470588235\n",
+      "    cpu_util_percent: 35.35333333333333\n",
+      "    gpu_util_percent0: 0.18400000000000002\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.747058823529413\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17676173480204843\n",
-      "    mean_env_wait_ms: 1.6752662514608032\n",
-      "    mean_inference_ms: 5.6785297305935405\n",
-      "    mean_raw_obs_processing_ms: 0.4787812236414886\n",
-      "  time_since_restore: 59.91080617904663\n",
-      "  time_this_iter_s: 28.98170232772827\n",
-      "  time_total_s: 59.91080617904663\n",
+      "    mean_action_processing_ms: 0.1353082761870322\n",
+      "    mean_env_wait_ms: 0.649634201882847\n",
+      "    mean_inference_ms: 5.982030458370913\n",
+      "    mean_raw_obs_processing_ms: 0.3024412316962542\n",
+      "  time_since_restore: 30.174316883087158\n",
+      "  time_this_iter_s: 14.072922945022583\n",
+      "  time_total_s: 30.174316883087158\n",
       "  timers:\n",
-      "    learn_throughput: 7835.536\n",
-      "    learn_time_ms: 20648.493\n",
-      "    sample_throughput: 17536.73\n",
-      "    sample_time_ms: 9225.893\n",
-      "    update_time_ms: 38.294\n",
-      "  timestamp: 1602165908\n",
+      "    learn_throughput: 7229.464\n",
+      "    learn_time_ms: 8392.323\n",
+      "    sample_throughput: 9193.229\n",
+      "    sample_time_ms: 6599.639\n",
+      "    update_time_ms: 28.913\n",
+      "  timestamp: 1602427677\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
+      "  timesteps_total: 121344\n",
       "  training_iteration: 2\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      2 |          59.9108 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |      2 |          30.1743 | 121344 |  218.843 |              265.111 |              151.172 |            886.038 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_14-05-37\n",
+      "    time_step_max: 4159\n",
+      "    time_step_mean: 3614.0443037974683\n",
+      "    time_step_min: 3306\n",
+      "  date: 2020-10-11_14-48-11\n",
       "  done: false\n",
-      "  episode_len_mean: 864.6983122362869\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.52218386395583\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 880.4050632911392\n",
+      "  episode_reward_max: 265.11111111111086\n",
+      "  episode_reward_mean: 218.43773174785815\n",
+      "  episode_reward_min: 135.8686868686869\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -502,83 +473,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1208289206027984\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008471710339654237\n",
-      "        model: {}\n",
-      "        policy_loss: -0.024524397612549365\n",
-      "        total_loss: 4.379646378755569\n",
-      "        vf_explained_var: 0.9663649797439575\n",
-      "        vf_loss: 4.4024763882160185\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1451095044612885\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006658109603449702\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009628374013118446\n",
+      "        total_loss: 343.8333053588867\n",
+      "        vf_explained_var: 0.582950234413147\n",
+      "        vf_loss: 343.8417205810547\n",
+      "    num_steps_sampled: 182016\n",
+      "    num_steps_trained: 182016\n",
       "  iterations_since_restore: 3\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.057142857142864\n",
-      "    gpu_util_percent0: 0.2717142857142857\n",
+      "    cpu_util_percent: 31.606250000000003\n",
+      "    gpu_util_percent0: 0.27625\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762857142857143\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.4\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17253118731808845\n",
-      "    mean_env_wait_ms: 1.669123154241675\n",
-      "    mean_inference_ms: 5.508714332828136\n",
-      "    mean_raw_obs_processing_ms: 0.46803146600593976\n",
-      "  time_since_restore: 89.00577521324158\n",
-      "  time_this_iter_s: 29.094969034194946\n",
-      "  time_total_s: 89.00577521324158\n",
+      "    mean_action_processing_ms: 0.13283139408501185\n",
+      "    mean_env_wait_ms: 0.6483184285076065\n",
+      "    mean_inference_ms: 5.788295846912503\n",
+      "    mean_raw_obs_processing_ms: 0.2956042049387476\n",
+      "  time_since_restore: 43.59142303466797\n",
+      "  time_this_iter_s: 13.41710615158081\n",
+      "  time_total_s: 43.59142303466797\n",
       "  timers:\n",
-      "    learn_throughput: 7852.583\n",
-      "    learn_time_ms: 20603.665\n",
-      "    sample_throughput: 18018.223\n",
-      "    sample_time_ms: 8979.354\n",
-      "    update_time_ms: 41.291\n",
-      "  timestamp: 1602165937\n",
+      "    learn_throughput: 7291.419\n",
+      "    learn_time_ms: 8321.014\n",
+      "    sample_throughput: 9949.588\n",
+      "    sample_time_ms: 6097.941\n",
+      "    update_time_ms: 54.955\n",
+      "  timestamp: 1602427691\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
+      "  timesteps_total: 182016\n",
       "  training_iteration: 3\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 25.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      3 |          89.0058 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |      3 |          43.5914 | 182016 |  218.438 |              265.111 |              135.869 |            880.405 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_14-06-05\n",
+      "    time_step_max: 4213\n",
+      "    time_step_mean: 3624.0\n",
+      "    time_step_min: 3306\n",
+      "  date: 2020-10-11_14-48-24\n",
       "  done: false\n",
-      "  episode_len_mean: 860.242088607595\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.50586561820717\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 877.9535864978903\n",
+      "  episode_reward_max: 265.11111111111086\n",
+      "  episode_reward_mean: 216.92929292929279\n",
+      "  episode_reward_min: 127.68686868686834\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 237\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -586,83 +555,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0932798445224763\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.009407231188379227\n",
-      "        model: {}\n",
-      "        policy_loss: -0.026628604688448833\n",
-      "        total_loss: 4.111228054761886\n",
-      "        vf_explained_var: 0.9783345460891724\n",
-      "        vf_loss: 4.135975193977356\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1370092332363129\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0060931689804419875\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015206624171696603\n",
+      "        total_loss: 237.94325637817383\n",
+      "        vf_explained_var: 0.7285435795783997\n",
+      "        vf_loss: 237.95736694335938\n",
+      "    num_steps_sampled: 242688\n",
+      "    num_steps_trained: 242688\n",
       "  iterations_since_restore: 4\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.938235294117646\n",
-      "    gpu_util_percent0: 0.24941176470588236\n",
+      "    cpu_util_percent: 32.760000000000005\n",
+      "    gpu_util_percent0: 0.32599999999999996\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.761764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16972262222291365\n",
-      "    mean_env_wait_ms: 1.6663911084469907\n",
-      "    mean_inference_ms: 5.381286213374226\n",
-      "    mean_raw_obs_processing_ms: 0.46035908038467466\n",
-      "  time_since_restore: 117.6076283454895\n",
-      "  time_this_iter_s: 28.601853132247925\n",
-      "  time_total_s: 117.6076283454895\n",
+      "    mean_action_processing_ms: 0.131088020562995\n",
+      "    mean_env_wait_ms: 0.6481277160168207\n",
+      "    mean_inference_ms: 5.63176925772184\n",
+      "    mean_raw_obs_processing_ms: 0.29100826100299026\n",
+      "  time_since_restore: 56.75381684303284\n",
+      "  time_this_iter_s: 13.162393808364868\n",
+      "  time_total_s: 56.75381684303284\n",
       "  timers:\n",
-      "    learn_throughput: 7898.804\n",
-      "    learn_time_ms: 20483.102\n",
-      "    sample_throughput: 18320.006\n",
-      "    sample_time_ms: 8831.438\n",
-      "    update_time_ms: 41.53\n",
-      "  timestamp: 1602165965\n",
+      "    learn_throughput: 7303.971\n",
+      "    learn_time_ms: 8306.714\n",
+      "    sample_throughput: 10495.447\n",
+      "    sample_time_ms: 5780.792\n",
+      "    update_time_ms: 51.0\n",
+      "  timestamp: 1602427704\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
+      "  timesteps_total: 242688\n",
       "  training_iteration: 4\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      4 |          117.608 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |      4 |          56.7538 | 242688 |  216.929 |              265.111 |              127.687 |            877.954 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_14-06-34\n",
+      "    time_step_max: 4220\n",
+      "    time_step_mean: 3626.240506329114\n",
+      "    time_step_min: 3306\n",
+      "  date: 2020-10-11_14-48-37\n",
       "  done: false\n",
-      "  episode_len_mean: 853.6054421768707\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 226.6438076914266\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 250\n",
-      "  episodes_total: 882\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 876.5949367088608\n",
+      "  episode_reward_max: 265.11111111111086\n",
+      "  episode_reward_mean: 216.58982227336645\n",
+      "  episode_reward_min: 126.62626262626257\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -670,83 +637,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0601136475801467\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008663335489109159\n",
-      "        model: {}\n",
-      "        policy_loss: -0.029689956549555065\n",
-      "        total_loss: 5.979247343540192\n",
-      "        vf_explained_var: 0.9847942590713501\n",
-      "        vf_loss: 6.007204520702362\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.12206369638443\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006890057120472193\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011395521811209619\n",
+      "        total_loss: 132.92739486694336\n",
+      "        vf_explained_var: 0.8328981995582581\n",
+      "        vf_loss: 132.9375228881836\n",
+      "    num_steps_sampled: 303360\n",
+      "    num_steps_trained: 303360\n",
       "  iterations_since_restore: 5\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.05\n",
-      "    gpu_util_percent0: 0.27676470588235297\n",
+      "    cpu_util_percent: 31.926666666666666\n",
+      "    gpu_util_percent0: 0.4253333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1668569945682094\n",
-      "    mean_env_wait_ms: 1.6661518036410352\n",
-      "    mean_inference_ms: 5.245339771382172\n",
-      "    mean_raw_obs_processing_ms: 0.45204585691645865\n",
-      "  time_since_restore: 146.34429287910461\n",
-      "  time_this_iter_s: 28.736664533615112\n",
-      "  time_total_s: 146.34429287910461\n",
+      "    mean_action_processing_ms: 0.12977563879098883\n",
+      "    mean_env_wait_ms: 0.6484338119868207\n",
+      "    mean_inference_ms: 5.507404139768565\n",
+      "    mean_raw_obs_processing_ms: 0.2876684028763285\n",
+      "  time_since_restore: 69.77894926071167\n",
+      "  time_this_iter_s: 13.025132417678833\n",
+      "  time_total_s: 69.77894926071167\n",
       "  timers:\n",
-      "    learn_throughput: 7912.652\n",
-      "    learn_time_ms: 20447.253\n",
-      "    sample_throughput: 18556.235\n",
-      "    sample_time_ms: 8719.01\n",
-      "    update_time_ms: 53.489\n",
-      "  timestamp: 1602165994\n",
+      "    learn_throughput: 7305.841\n",
+      "    learn_time_ms: 8304.588\n",
+      "    sample_throughput: 10916.428\n",
+      "    sample_time_ms: 5557.862\n",
+      "    update_time_ms: 45.848\n",
+      "  timestamp: 1602427717\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
+      "  timesteps_total: 303360\n",
       "  training_iteration: 5\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      5 |          146.344 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |      5 |          69.7789 | 303360 |   216.59 |              265.111 |              126.626 |            876.595 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_14-07-03\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3624.9088607594936\n",
+      "    time_step_min: 3306\n",
+      "  date: 2020-10-11_14-48-50\n",
       "  done: false\n",
-      "  episode_len_mean: 847.8264014466546\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 227.10596927685518\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 224\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 873.2886075949367\n",
+      "  episode_reward_max: 265.11111111111086\n",
+      "  episode_reward_mean: 216.7915867536119\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 395\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -754,83 +719,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0766338467597962\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008614842919632793\n",
-      "        model: {}\n",
-      "        policy_loss: -0.030333096848335118\n",
-      "        total_loss: 4.108908116817474\n",
-      "        vf_explained_var: 0.987047553062439\n",
-      "        vf_loss: 4.137518179416657\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1141673624515533\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006491948966868222\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012061259825713933\n",
+      "        total_loss: 95.29883575439453\n",
+      "        vf_explained_var: 0.8731156587600708\n",
+      "        vf_loss: 95.30970764160156\n",
+      "    num_steps_sampled: 364032\n",
+      "    num_steps_trained: 364032\n",
       "  iterations_since_restore: 6\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.087878787878783\n",
-      "    gpu_util_percent0: 0.2751515151515152\n",
+      "    cpu_util_percent: 33.36428571428572\n",
+      "    gpu_util_percent0: 0.3792857142857144\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751515151515152\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.11634962282715648\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16521363319543925\n",
-      "    mean_env_wait_ms: 1.6677695579501226\n",
-      "    mean_inference_ms: 5.160918708210536\n",
-      "    mean_raw_obs_processing_ms: 0.4472775860567577\n",
-      "  time_since_restore: 174.83844447135925\n",
-      "  time_this_iter_s: 28.49415159225464\n",
-      "  time_total_s: 174.83844447135925\n",
+      "    mean_action_processing_ms: 0.1287156511526069\n",
+      "    mean_env_wait_ms: 0.6488228309557317\n",
+      "    mean_inference_ms: 5.4062742835181306\n",
+      "    mean_raw_obs_processing_ms: 0.28500371357615617\n",
+      "  time_since_restore: 82.6038908958435\n",
+      "  time_this_iter_s: 12.824941635131836\n",
+      "  time_total_s: 82.6038908958435\n",
       "  timers:\n",
-      "    learn_throughput: 7937.482\n",
-      "    learn_time_ms: 20383.289\n",
-      "    sample_throughput: 18693.433\n",
-      "    sample_time_ms: 8655.018\n",
-      "    update_time_ms: 51.581\n",
-      "  timestamp: 1602166023\n",
+      "    learn_throughput: 7323.161\n",
+      "    learn_time_ms: 8284.947\n",
+      "    sample_throughput: 11250.121\n",
+      "    sample_time_ms: 5393.008\n",
+      "    update_time_ms: 44.266\n",
+      "  timestamp: 1602427730\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
+      "  timesteps_total: 364032\n",
       "  training_iteration: 6\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      6 |          174.838 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |      6 |          82.6039 | 364032 |  216.792 |              265.111 |              118.293 |            873.289 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-07-31\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3619.0021097046415\n",
+      "    time_step_min: 3289\n",
+      "  date: 2020-10-11_14-49-03\n",
       "  done: false\n",
-      "  episode_len_mean: 844.1083860759494\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.6303302007414\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 868.9451476793249\n",
+      "  episode_reward_max: 267.6868686868684\n",
+      "  episode_reward_mean: 217.68654903465014\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -838,83 +801,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0495809823274613\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008355090976692736\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03242016874719411\n",
-      "        total_loss: 3.189230865240097\n",
-      "        vf_explained_var: 0.9909769296646118\n",
-      "        vf_loss: 3.2199800491333006\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0996873378753662\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007531901705078781\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010992132098181173\n",
+      "        total_loss: 71.36981773376465\n",
+      "        vf_explained_var: 0.8989866375923157\n",
+      "        vf_loss: 71.3794174194336\n",
+      "    num_steps_sampled: 424704\n",
+      "    num_steps_trained: 424704\n",
       "  iterations_since_restore: 7\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.423529411764708\n",
-      "    gpu_util_percent0: 0.25617647058823534\n",
+      "    cpu_util_percent: 31.793333333333337\n",
+      "    gpu_util_percent0: 0.29600000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16428938352115002\n",
-      "    mean_env_wait_ms: 1.6688146539398103\n",
-      "    mean_inference_ms: 5.1135213379920055\n",
-      "    mean_raw_obs_processing_ms: 0.4445629925416077\n",
-      "  time_since_restore: 203.33799719810486\n",
-      "  time_this_iter_s: 28.499552726745605\n",
-      "  time_total_s: 203.33799719810486\n",
+      "    mean_action_processing_ms: 0.12785548063034805\n",
+      "    mean_env_wait_ms: 0.6493148476274758\n",
+      "    mean_inference_ms: 5.322844403613065\n",
+      "    mean_raw_obs_processing_ms: 0.28287895450910405\n",
+      "  time_since_restore: 95.52371096611023\n",
+      "  time_this_iter_s: 12.919820070266724\n",
+      "  time_total_s: 95.52371096611023\n",
       "  timers:\n",
-      "    learn_throughput: 7953.152\n",
-      "    learn_time_ms: 20343.13\n",
-      "    sample_throughput: 18800.381\n",
-      "    sample_time_ms: 8605.783\n",
-      "    update_time_ms: 48.851\n",
-      "  timestamp: 1602166051\n",
+      "    learn_throughput: 7324.942\n",
+      "    learn_time_ms: 8282.933\n",
+      "    sample_throughput: 11494.883\n",
+      "    sample_time_ms: 5278.175\n",
+      "    update_time_ms: 42.136\n",
+      "  timestamp: 1602427743\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
+      "  timesteps_total: 424704\n",
       "  training_iteration: 7\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      7 |          203.338 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |      7 |          95.5237 | 424704 |  217.687 |              267.687 |              118.293 |            868.945 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-00\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3617.5623869801084\n",
+      "    time_step_min: 3289\n",
+      "  date: 2020-10-11_14-49-16\n",
       "  done: false\n",
-      "  episode_len_mean: 840.8741209563995\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.87909332424087\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 863.7233273056058\n",
+      "  episode_reward_max: 267.6868686868684\n",
+      "  episode_reward_mean: 217.9046888413976\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 553\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -922,83 +883,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0188148379325868\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008204545732587576\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03408731806557626\n",
-      "        total_loss: 3.0473277091979982\n",
-      "        vf_explained_var: 0.9921058416366577\n",
-      "        vf_loss: 3.079774135351181\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.080336093902588\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00649541465099901\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014029796118848026\n",
+      "        total_loss: 65.09321212768555\n",
+      "        vf_explained_var: 0.9129441976547241\n",
+      "        vf_loss: 65.10604953765869\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 8\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.724242424242426\n",
-      "    gpu_util_percent0: 0.2678787878787879\n",
+      "    cpu_util_percent: 31.31333333333333\n",
+      "    gpu_util_percent0: 0.35133333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.763636363636364\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.4333333333333327\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16348854866217513\n",
-      "    mean_env_wait_ms: 1.6700574598453726\n",
-      "    mean_inference_ms: 5.072164794599845\n",
-      "    mean_raw_obs_processing_ms: 0.44213624402114293\n",
-      "  time_since_restore: 231.6390438079834\n",
-      "  time_this_iter_s: 28.30104660987854\n",
-      "  time_total_s: 231.6390438079834\n",
+      "    mean_action_processing_ms: 0.12714315858196026\n",
+      "    mean_env_wait_ms: 0.6499228345088768\n",
+      "    mean_inference_ms: 5.252964204882852\n",
+      "    mean_raw_obs_processing_ms: 0.2811312550628777\n",
+      "  time_since_restore: 108.57829403877258\n",
+      "  time_this_iter_s: 13.054583072662354\n",
+      "  time_total_s: 108.57829403877258\n",
       "  timers:\n",
-      "    learn_throughput: 7959.464\n",
-      "    learn_time_ms: 20326.997\n",
-      "    sample_throughput: 18968.066\n",
-      "    sample_time_ms: 8529.705\n",
-      "    update_time_ms: 47.225\n",
-      "  timestamp: 1602166080\n",
+      "    learn_throughput: 7312.975\n",
+      "    learn_time_ms: 8296.486\n",
+      "    sample_throughput: 11684.656\n",
+      "    sample_time_ms: 5192.451\n",
+      "    update_time_ms: 41.438\n",
+      "  timestamp: 1602427756\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
+      "  timesteps_total: 485376\n",
       "  training_iteration: 8\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      8 |          231.639 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |      8 |          108.578 | 485376 |  217.905 |              267.687 |              118.293 |            863.723 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-28\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3613.845276872964\n",
+      "    time_step_min: 3289\n",
+      "  date: 2020-10-11_14-49-29\n",
       "  done: false\n",
-      "  episode_len_mean: 835.0944055944055\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.1691507146051\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 1716\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 860.5602605863193\n",
+      "  episode_reward_max: 267.6868686868684\n",
+      "  episode_reward_mean: 218.46788734248003\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 61\n",
+      "  episodes_total: 614\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1006,83 +965,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9918270707130432\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007521937682759017\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03050975254736841\n",
-      "        total_loss: 5.504689037799835\n",
-      "        vf_explained_var: 0.9918516874313354\n",
-      "        vf_loss: 5.53369448184967\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0620779395103455\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0070233645383268595\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011862239392939955\n",
+      "        total_loss: 53.99057388305664\n",
+      "        vf_explained_var: 0.9240583181381226\n",
+      "        vf_loss: 54.00113868713379\n",
+      "    num_steps_sampled: 546048\n",
+      "    num_steps_trained: 546048\n",
       "  iterations_since_restore: 9\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.59705882352941\n",
-      "    gpu_util_percent0: 0.25941176470588234\n",
+      "    cpu_util_percent: 29.933333333333337\n",
+      "    gpu_util_percent0: 0.30133333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.162284443845516\n",
-      "    mean_env_wait_ms: 1.6727489665801578\n",
-      "    mean_inference_ms: 5.009821132584934\n",
-      "    mean_raw_obs_processing_ms: 0.4384857629606629\n",
-      "  time_since_restore: 259.97689414024353\n",
-      "  time_this_iter_s: 28.337850332260132\n",
-      "  time_total_s: 259.97689414024353\n",
+      "    mean_action_processing_ms: 0.1266455878797975\n",
+      "    mean_env_wait_ms: 0.6503698409329477\n",
+      "    mean_inference_ms: 5.20612271537529\n",
+      "    mean_raw_obs_processing_ms: 0.2799062414992872\n",
+      "  time_since_restore: 121.55057454109192\n",
+      "  time_this_iter_s: 12.972280502319336\n",
+      "  time_total_s: 121.55057454109192\n",
       "  timers:\n",
-      "    learn_throughput: 7968.61\n",
-      "    learn_time_ms: 20303.667\n",
-      "    sample_throughput: 19067.411\n",
-      "    sample_time_ms: 8485.263\n",
-      "    update_time_ms: 45.663\n",
-      "  timestamp: 1602166108\n",
+      "    learn_throughput: 7316.869\n",
+      "    learn_time_ms: 8292.072\n",
+      "    sample_throughput: 11842.208\n",
+      "    sample_time_ms: 5123.369\n",
+      "    update_time_ms: 48.014\n",
+      "  timestamp: 1602427769\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
+      "  timesteps_total: 546048\n",
       "  training_iteration: 9\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      9 |          259.977 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |      9 |          121.551 | 546048 |  218.468 |              267.687 |              118.293 |             860.56 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-57\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3611.2753846153846\n",
+      "    time_step_min: 3289\n",
+      "  date: 2020-10-11_14-49-42\n",
       "  done: false\n",
-      "  episode_len_mean: 832.079641350211\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.59731279035063\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 859.0492307692308\n",
+      "  episode_reward_max: 267.6868686868684\n",
+      "  episode_reward_mean: 218.85726495726487\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 36\n",
+      "  episodes_total: 650\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1090,83 +1047,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9763310596346855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007896899722982197\n",
-      "        model: {}\n",
-      "        policy_loss: -0.033220290520694105\n",
-      "        total_loss: 2.953149896860123\n",
-      "        vf_explained_var: 0.993627667427063\n",
-      "        vf_loss: 2.98479083776474\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0485284924507141\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006600828724913299\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017158268485218287\n",
+      "        total_loss: 33.94167709350586\n",
+      "        vf_explained_var: 0.9404016137123108\n",
+      "        vf_loss: 33.95761775970459\n",
+      "    num_steps_sampled: 606720\n",
+      "    num_steps_trained: 606720\n",
       "  iterations_since_restore: 10\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.339393939393936\n",
-      "    gpu_util_percent0: 0.29575757575757583\n",
+      "    cpu_util_percent: 31.90666666666667\n",
+      "    gpu_util_percent0: 0.348\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16170883141459513\n",
-      "    mean_env_wait_ms: 1.6746347609608598\n",
-      "    mean_inference_ms: 4.978956771385591\n",
-      "    mean_raw_obs_processing_ms: 0.43667186446988804\n",
-      "  time_since_restore: 288.5126984119415\n",
-      "  time_this_iter_s: 28.535804271697998\n",
-      "  time_total_s: 288.5126984119415\n",
+      "    mean_action_processing_ms: 0.1264161972479877\n",
+      "    mean_env_wait_ms: 0.6508235562773642\n",
+      "    mean_inference_ms: 5.1787589908961555\n",
+      "    mean_raw_obs_processing_ms: 0.2792088672252598\n",
+      "  time_since_restore: 134.47225499153137\n",
+      "  time_this_iter_s: 12.921680450439453\n",
+      "  time_total_s: 134.47225499153137\n",
       "  timers:\n",
-      "    learn_throughput: 7972.454\n",
-      "    learn_time_ms: 20293.877\n",
-      "    sample_throughput: 19124.35\n",
-      "    sample_time_ms: 8460.0\n",
-      "    update_time_ms: 44.735\n",
-      "  timestamp: 1602166137\n",
+      "    learn_throughput: 7327.027\n",
+      "    learn_time_ms: 8280.575\n",
+      "    sample_throughput: 11960.916\n",
+      "    sample_time_ms: 5072.521\n",
+      "    update_time_ms: 52.722\n",
+      "  timestamp: 1602427782\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
+      "  timesteps_total: 606720\n",
       "  training_iteration: 10\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     10 |          288.513 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     10 |          134.472 | 606720 |  218.857 |              267.687 |              118.293 |            859.049 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-09-25\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3606.5876577840113\n",
+      "    time_step_min: 3289\n",
+      "  date: 2020-10-11_14-49-55\n",
       "  done: false\n",
-      "  episode_len_mean: 830.1703992210321\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 229.0675253017024\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 856.6143057503506\n",
+      "  episode_reward_max: 267.6868686868684\n",
+      "  episode_reward_mean: 219.56752659838202\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 63\n",
+      "  episodes_total: 713\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1174,83 +1129,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9670185938477516\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007682974718045443\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03496774770319462\n",
-      "        total_loss: 2.589013671875\n",
-      "        vf_explained_var: 0.9946534037590027\n",
-      "        vf_loss: 2.622444784641266\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0584369599819183\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005829800385981798\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01342546020168811\n",
+      "        total_loss: 33.587894439697266\n",
+      "        vf_explained_var: 0.931602954864502\n",
+      "        vf_loss: 33.60025978088379\n",
+      "    num_steps_sampled: 667392\n",
+      "    num_steps_trained: 667392\n",
       "  iterations_since_restore: 11\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.45151515151515\n",
-      "    gpu_util_percent0: 0.2739393939393939\n",
+      "    cpu_util_percent: 32.306666666666665\n",
+      "    gpu_util_percent0: 0.20533333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.763636363636364\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16125382205207386\n",
-      "    mean_env_wait_ms: 1.6761243985903949\n",
-      "    mean_inference_ms: 4.954596343237678\n",
-      "    mean_raw_obs_processing_ms: 0.4352361222242559\n",
-      "  time_since_restore: 316.5878527164459\n",
-      "  time_this_iter_s: 28.075154304504395\n",
-      "  time_total_s: 316.5878527164459\n",
+      "    mean_action_processing_ms: 0.12595370785638055\n",
+      "    mean_env_wait_ms: 0.6511042667730063\n",
+      "    mean_inference_ms: 5.136032815902064\n",
+      "    mean_raw_obs_processing_ms: 0.2780245787968382\n",
+      "  time_since_restore: 147.44169783592224\n",
+      "  time_this_iter_s: 12.96944284439087\n",
+      "  time_total_s: 147.44169783592224\n",
       "  timers:\n",
-      "    learn_throughput: 8000.406\n",
-      "    learn_time_ms: 20222.974\n",
-      "    sample_throughput: 19629.04\n",
-      "    sample_time_ms: 8242.482\n",
-      "    update_time_ms: 45.435\n",
-      "  timestamp: 1602166165\n",
+      "    learn_throughput: 7342.154\n",
+      "    learn_time_ms: 8263.515\n",
+      "    sample_throughput: 12688.941\n",
+      "    sample_time_ms: 4781.486\n",
+      "    update_time_ms: 53.012\n",
+      "  timestamp: 1602427795\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
+      "  timesteps_total: 667392\n",
       "  training_iteration: 11\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     11 |          316.588 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     11 |          147.442 | 667392 |  219.568 |              267.687 |              118.293 |            856.614 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-09-54\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3600.558227848101\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_14-50-08\n",
       "  done: false\n",
-      "  episode_len_mean: 828.50904159132\n",
-      "  episode_reward_max: 287.9191919191919\n",
-      "  episode_reward_mean: 229.5476966774434\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 853.659493670886\n",
+      "  episode_reward_max: 275.86868686868684\n",
+      "  episode_reward_mean: 220.48107658867144\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 77\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1258,83 +1211,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.940390695631504\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007805287896189839\n",
-      "        model: {}\n",
-      "        policy_loss: -0.035866627853829415\n",
-      "        total_loss: 2.6927455008029937\n",
-      "        vf_explained_var: 0.9949959516525269\n",
-      "        vf_loss: 2.7270510613918306\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.044329285621643\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0065484626684337854\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014785136096179485\n",
+      "        total_loss: 35.80673599243164\n",
+      "        vf_explained_var: 0.9390555024147034\n",
+      "        vf_loss: 35.820316314697266\n",
+      "    num_steps_sampled: 728064\n",
+      "    num_steps_trained: 728064\n",
       "  iterations_since_restore: 12\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.993939393939392\n",
-      "    gpu_util_percent0: 0.26969696969696966\n",
+      "    cpu_util_percent: 33.278571428571425\n",
+      "    gpu_util_percent0: 0.4357142857142856\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757575757575758\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.4214285714285713\n",
+      "    vram_util_percent0: 0.11634962282715648\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16085250209822033\n",
-      "    mean_env_wait_ms: 1.6775510346401423\n",
-      "    mean_inference_ms: 4.932401985457557\n",
-      "    mean_raw_obs_processing_ms: 0.4338907507677086\n",
-      "  time_since_restore: 345.2145109176636\n",
-      "  time_this_iter_s: 28.62665820121765\n",
-      "  time_total_s: 345.2145109176636\n",
+      "    mean_action_processing_ms: 0.12547292705254384\n",
+      "    mean_env_wait_ms: 0.6516200365130129\n",
+      "    mean_inference_ms: 5.08991119095177\n",
+      "    mean_raw_obs_processing_ms: 0.276733398682132\n",
+      "  time_since_restore: 160.31700205802917\n",
+      "  time_this_iter_s: 12.875304222106934\n",
+      "  time_total_s: 160.31700205802917\n",
       "  timers:\n",
-      "    learn_throughput: 8013.686\n",
-      "    learn_time_ms: 20189.46\n",
-      "    sample_throughput: 19635.364\n",
-      "    sample_time_ms: 8239.827\n",
-      "    update_time_ms: 45.402\n",
-      "  timestamp: 1602166194\n",
+      "    learn_throughput: 7339.2\n",
+      "    learn_time_ms: 8266.841\n",
+      "    sample_throughput: 13024.14\n",
+      "    sample_time_ms: 4658.426\n",
+      "    update_time_ms: 53.389\n",
+      "  timestamp: 1602427808\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
+      "  timesteps_total: 728064\n",
       "  training_iteration: 12\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     12 |          345.215 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     12 |          160.317 | 728064 |  220.481 |              275.869 |              118.293 |            853.659 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-10-22\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3593.910241657077\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_14-50-21\n",
       "  done: false\n",
-      "  episode_len_mean: 825.9173259493671\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 230.737545550441\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 850.2543153049482\n",
+      "  episode_reward_max: 275.86868686868684\n",
+      "  episode_reward_mean: 221.48834722367513\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 869\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1342,83 +1293,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9119029730558396\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007374470541253686\n",
-      "        model: {}\n",
-      "        policy_loss: -0.031025875953491776\n",
-      "        total_loss: 3.626113736629486\n",
-      "        vf_explained_var: 0.9953392744064331\n",
-      "        vf_loss: 3.655664700269699\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0323504209518433\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005593539914116263\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007711198413744569\n",
+      "        total_loss: 33.82645511627197\n",
+      "        vf_explained_var: 0.9453220367431641\n",
+      "        vf_loss: 33.83315181732178\n",
+      "    num_steps_sampled: 788736\n",
+      "    num_steps_trained: 788736\n",
       "  iterations_since_restore: 13\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.370588235294115\n",
-      "    gpu_util_percent0: 0.2747058823529412\n",
+      "    cpu_util_percent: 31.926666666666662\n",
+      "    gpu_util_percent0: 0.3453333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.75294117647059\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16017287678084888\n",
-      "    mean_env_wait_ms: 1.6802277086992836\n",
-      "    mean_inference_ms: 4.89439148640374\n",
-      "    mean_raw_obs_processing_ms: 0.4316389620412026\n",
-      "  time_since_restore: 373.45997977256775\n",
-      "  time_this_iter_s: 28.245468854904175\n",
-      "  time_total_s: 373.45997977256775\n",
+      "    mean_action_processing_ms: 0.12503921943097748\n",
+      "    mean_env_wait_ms: 0.652143801885267\n",
+      "    mean_inference_ms: 5.048366292008042\n",
+      "    mean_raw_obs_processing_ms: 0.27555612622309206\n",
+      "  time_since_restore: 173.18758249282837\n",
+      "  time_this_iter_s: 12.870580434799194\n",
+      "  time_total_s: 173.18758249282837\n",
       "  timers:\n",
-      "    learn_throughput: 8026.419\n",
-      "    learn_time_ms: 20157.433\n",
-      "    sample_throughput: 19763.446\n",
-      "    sample_time_ms: 8186.427\n",
-      "    update_time_ms: 44.475\n",
-      "  timestamp: 1602166222\n",
+      "    learn_throughput: 7329.535\n",
+      "    learn_time_ms: 8277.742\n",
+      "    sample_throughput: 13186.176\n",
+      "    sample_time_ms: 4601.182\n",
+      "    update_time_ms: 45.127\n",
+      "  timestamp: 1602427821\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
+      "  timesteps_total: 788736\n",
       "  training_iteration: 13\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     13 |           373.46 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     13 |          173.188 | 788736 |  221.488 |              275.869 |              118.293 |            850.254 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-10-50\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3588.6867088607596\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_14-50-34\n",
       "  done: false\n",
-      "  episode_len_mean: 824.9274013402829\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.18682355949656\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 847.3449367088608\n",
+      "  episode_reward_max: 275.86868686868684\n",
+      "  episode_reward_mean: 222.2797915867535\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 948\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1426,83 +1375,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8989204004406929\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0074366391287185255\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03388760575326159\n",
-      "        total_loss: 2.3619153201580048\n",
-      "        vf_explained_var: 0.9957093000411987\n",
-      "        vf_loss: 2.394315606355667\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.013579249382019\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0068066451931372285\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014376593055203557\n",
+      "        total_loss: 28.295745849609375\n",
+      "        vf_explained_var: 0.9575772881507874\n",
+      "        vf_loss: 28.308862686157227\n",
+      "    num_steps_sampled: 849408\n",
+      "    num_steps_trained: 849408\n",
       "  iterations_since_restore: 14\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.312121212121212\n",
-      "    gpu_util_percent0: 0.26151515151515153\n",
+      "    cpu_util_percent: 32.21333333333333\n",
+      "    gpu_util_percent0: 0.2753333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.772727272727275\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.4199999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15988462752258317\n",
-      "    mean_env_wait_ms: 1.6814425515145586\n",
-      "    mean_inference_ms: 4.878041025826835\n",
-      "    mean_raw_obs_processing_ms: 0.430664812314108\n",
-      "  time_since_restore: 401.80727195739746\n",
-      "  time_this_iter_s: 28.347292184829712\n",
-      "  time_total_s: 401.80727195739746\n",
+      "    mean_action_processing_ms: 0.12465345866675773\n",
+      "    mean_env_wait_ms: 0.6526681348875534\n",
+      "    mean_inference_ms: 5.011768356592469\n",
+      "    mean_raw_obs_processing_ms: 0.2745004617109849\n",
+      "  time_since_restore: 185.90577864646912\n",
+      "  time_this_iter_s: 12.718196153640747\n",
+      "  time_total_s: 185.90577864646912\n",
       "  timers:\n",
-      "    learn_throughput: 8023.866\n",
-      "    learn_time_ms: 20163.846\n",
-      "    sample_throughput: 19841.783\n",
-      "    sample_time_ms: 8154.106\n",
-      "    update_time_ms: 44.12\n",
-      "  timestamp: 1602166250\n",
+      "    learn_throughput: 7334.234\n",
+      "    learn_time_ms: 8272.438\n",
+      "    sample_throughput: 13294.576\n",
+      "    sample_time_ms: 4563.666\n",
+      "    update_time_ms: 43.107\n",
+      "  timestamp: 1602427834\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
+      "  timesteps_total: 849408\n",
       "  training_iteration: 14\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     14 |          401.807 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     14 |          185.906 | 849408 |   222.28 |              275.869 |              118.293 |            847.345 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-11-19\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3583.4829600778967\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_14-50-47\n",
       "  done: false\n",
-      "  episode_len_mean: 824.0777074542897\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.63322749293204\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 844.6426484907497\n",
+      "  episode_reward_max: 275.86868686868684\n",
+      "  episode_reward_mean: 223.06823837203578\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1027\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1510,83 +1457,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.895898899435997\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007697970513254404\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03602396983187646\n",
-      "        total_loss: 1.9372931450605393\n",
-      "        vf_explained_var: 0.9962417483329773\n",
-      "        vf_loss: 1.9717775255441665\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9933836460113525\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00562152813654393\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011437032371759415\n",
+      "        total_loss: 25.94105339050293\n",
+      "        vf_explained_var: 0.9608175158500671\n",
+      "        vf_loss: 25.951465129852295\n",
+      "    num_steps_sampled: 910080\n",
+      "    num_steps_trained: 910080\n",
       "  iterations_since_restore: 15\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.59705882352941\n",
-      "    gpu_util_percent0: 0.27\n",
+      "    cpu_util_percent: 31.666666666666675\n",
+      "    gpu_util_percent0: 0.3526666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.761764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.413333333333333\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15962256586295442\n",
-      "    mean_env_wait_ms: 1.6825632050368664\n",
-      "    mean_inference_ms: 4.862887505621167\n",
-      "    mean_raw_obs_processing_ms: 0.42975456496408376\n",
-      "  time_since_restore: 430.180118560791\n",
-      "  time_this_iter_s: 28.372846603393555\n",
-      "  time_total_s: 430.180118560791\n",
+      "    mean_action_processing_ms: 0.12431285493161397\n",
+      "    mean_env_wait_ms: 0.6532080179815016\n",
+      "    mean_inference_ms: 4.979332084217276\n",
+      "    mean_raw_obs_processing_ms: 0.27356378945775\n",
+      "  time_since_restore: 198.81229877471924\n",
+      "  time_this_iter_s: 12.906520128250122\n",
+      "  time_total_s: 198.81229877471924\n",
       "  timers:\n",
-      "    learn_throughput: 8029.244\n",
-      "    learn_time_ms: 20150.342\n",
-      "    sample_throughput: 19898.49\n",
-      "    sample_time_ms: 8130.868\n",
-      "    update_time_ms: 37.742\n",
-      "  timestamp: 1602166279\n",
+      "    learn_throughput: 7339.963\n",
+      "    learn_time_ms: 8265.981\n",
+      "    sample_throughput: 13310.697\n",
+      "    sample_time_ms: 4558.138\n",
+      "    update_time_ms: 43.736\n",
+      "  timestamp: 1602427847\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
+      "  timesteps_total: 910080\n",
       "  training_iteration: 15\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     15 |           430.18 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     15 |          198.812 | 910080 |  223.068 |              275.869 |              118.293 |            844.643 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-11-48\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3577.5723327305604\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_14-51-00\n",
       "  done: false\n",
-      "  episode_len_mean: 822.9910447761195\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 232.33685444829712\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 171\n",
-      "  episodes_total: 3015\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 841.9891500904159\n",
+      "  episode_reward_max: 275.86868686868684\n",
+      "  episode_reward_mean: 223.963787970117\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1594,83 +1539,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8683042243123055\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007607861259020865\n",
-      "        model: {}\n",
-      "        policy_loss: -0.036039730068296194\n",
-      "        total_loss: 2.116857588291168\n",
-      "        vf_explained_var: 0.9965157508850098\n",
-      "        vf_loss: 2.1513757526874544\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9824153780937195\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005990388686768711\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007877310505136847\n",
+      "        total_loss: 21.027120113372803\n",
+      "        vf_explained_var: 0.9672377705574036\n",
+      "        vf_loss: 21.033896446228027\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 16\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.03030303030303\n",
-      "    gpu_util_percent0: 0.28878787878787876\n",
+      "    cpu_util_percent: 31.58\n",
+      "    gpu_util_percent0: 0.3606666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76060606060606\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15936424957771478\n",
-      "    mean_env_wait_ms: 1.6837075606485503\n",
-      "    mean_inference_ms: 4.8476482100837615\n",
-      "    mean_raw_obs_processing_ms: 0.4288385279340961\n",
-      "  time_since_restore: 458.61421608924866\n",
-      "  time_this_iter_s: 28.43409752845764\n",
-      "  time_total_s: 458.61421608924866\n",
+      "    mean_action_processing_ms: 0.12400905884143851\n",
+      "    mean_env_wait_ms: 0.6537594747037538\n",
+      "    mean_inference_ms: 4.9502559467252825\n",
+      "    mean_raw_obs_processing_ms: 0.27271462310642164\n",
+      "  time_since_restore: 211.76999950408936\n",
+      "  time_this_iter_s: 12.957700729370117\n",
+      "  time_total_s: 211.76999950408936\n",
       "  timers:\n",
-      "    learn_throughput: 8025.775\n",
-      "    learn_time_ms: 20159.051\n",
-      "    sample_throughput: 19933.741\n",
-      "    sample_time_ms: 8116.489\n",
-      "    update_time_ms: 36.891\n",
-      "  timestamp: 1602166308\n",
+      "    learn_throughput: 7334.729\n",
+      "    learn_time_ms: 8271.88\n",
+      "    sample_throughput: 13308.725\n",
+      "    sample_time_ms: 4558.814\n",
+      "    update_time_ms: 42.298\n",
+      "  timestamp: 1602427860\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
+      "  timesteps_total: 970752\n",
       "  training_iteration: 16\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     16 |          458.614 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     16 |           211.77 | 970752 |  223.964 |              275.869 |              118.293 |            841.989 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-12-16\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3572.2556962025315\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_14-51-13\n",
       "  done: false\n",
-      "  episode_len_mean: 821.0216998191681\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.1551683197252\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 303\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 839.464135021097\n",
+      "  episode_reward_max: 275.86868686868684\n",
+      "  episode_reward_mean: 224.76933895921235\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1185\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1678,83 +1621,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8348902150988579\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00740289380773902\n",
-      "        model: {}\n",
-      "        policy_loss: -0.029998348827939482\n",
-      "        total_loss: 2.5100847482681274\n",
-      "        vf_explained_var: 0.9960853457450867\n",
-      "        vf_loss: 2.538602519035339\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9703270643949509\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005524565000087023\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01052850013365969\n",
+      "        total_loss: 24.28107976913452\n",
+      "        vf_explained_var: 0.9627320766448975\n",
+      "        vf_loss: 24.290600299835205\n",
+      "    num_steps_sampled: 1031424\n",
+      "    num_steps_trained: 1031424\n",
       "  iterations_since_restore: 17\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.170588235294122\n",
-      "    gpu_util_percent0: 0.22911764705882354\n",
+      "    cpu_util_percent: 33.385714285714286\n",
+      "    gpu_util_percent0: 0.34142857142857136\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.75294117647059\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.11634962282715648\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1589481712029165\n",
-      "    mean_env_wait_ms: 1.6856610626461734\n",
-      "    mean_inference_ms: 4.823647348850542\n",
-      "    mean_raw_obs_processing_ms: 0.4273782452417025\n",
-      "  time_since_restore: 486.7920489311218\n",
-      "  time_this_iter_s: 28.17783284187317\n",
-      "  time_total_s: 486.7920489311218\n",
+      "    mean_action_processing_ms: 0.1237347073052231\n",
+      "    mean_env_wait_ms: 0.6543202270320436\n",
+      "    mean_inference_ms: 4.9240364808609\n",
+      "    mean_raw_obs_processing_ms: 0.2719430279370468\n",
+      "  time_since_restore: 224.54811787605286\n",
+      "  time_this_iter_s: 12.778118371963501\n",
+      "  time_total_s: 224.54811787605286\n",
       "  timers:\n",
-      "    learn_throughput: 8025.414\n",
-      "    learn_time_ms: 20159.958\n",
-      "    sample_throughput: 20020.205\n",
-      "    sample_time_ms: 8081.436\n",
-      "    update_time_ms: 37.784\n",
-      "  timestamp: 1602166336\n",
+      "    learn_throughput: 7339.12\n",
+      "    learn_time_ms: 8266.931\n",
+      "    sample_throughput: 13333.696\n",
+      "    sample_time_ms: 4550.276\n",
+      "    update_time_ms: 41.151\n",
+      "  timestamp: 1602427873\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
+      "  timesteps_total: 1031424\n",
       "  training_iteration: 17\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     17 |          486.792 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     17 |          224.548 | 1031424 |  224.769 |              275.869 |              118.293 |            839.464 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-12-44\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3566.5245253164558\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_14-51-26\n",
       "  done: false\n",
-      "  episode_len_mean: 820.0376869965478\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.58232206995146\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 837.506329113924\n",
+      "  episode_reward_max: 275.86868686868684\n",
+      "  episode_reward_mean: 225.63769818437535\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1762,83 +1703,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8338133722543717\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007797137019224465\n",
-      "        model: {}\n",
-      "        policy_loss: -0.0366627115290612\n",
-      "        total_loss: 1.7475906014442444\n",
-      "        vf_explained_var: 0.9965535998344421\n",
-      "        vf_loss: 1.7826938778162003\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9576845765113831\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006472750450484455\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01621266547590494\n",
+      "        total_loss: 19.243000507354736\n",
+      "        vf_explained_var: 0.9701140522956848\n",
+      "        vf_loss: 19.258015155792236\n",
+      "    num_steps_sampled: 1092096\n",
+      "    num_steps_trained: 1092096\n",
       "  iterations_since_restore: 18\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.263636363636362\n",
-      "    gpu_util_percent0: 0.2739393939393939\n",
+      "    cpu_util_percent: 31.953333333333333\n",
+      "    gpu_util_percent0: 0.316\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.42\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15875079551526766\n",
-      "    mean_env_wait_ms: 1.6865974079727117\n",
-      "    mean_inference_ms: 4.812393081904589\n",
-      "    mean_raw_obs_processing_ms: 0.42669712128025067\n",
-      "  time_since_restore: 515.002126455307\n",
-      "  time_this_iter_s: 28.21007752418518\n",
-      "  time_total_s: 515.002126455307\n",
+      "    mean_action_processing_ms: 0.1234859061171375\n",
+      "    mean_env_wait_ms: 0.6548650697834195\n",
+      "    mean_inference_ms: 4.90020685495471\n",
+      "    mean_raw_obs_processing_ms: 0.27124150206018965\n",
+      "  time_since_restore: 237.47010207176208\n",
+      "  time_this_iter_s: 12.921984195709229\n",
+      "  time_total_s: 237.47010207176208\n",
       "  timers:\n",
-      "    learn_throughput: 8034.771\n",
-      "    learn_time_ms: 20136.48\n",
-      "    sample_throughput: 19987.012\n",
-      "    sample_time_ms: 8094.857\n",
-      "    update_time_ms: 37.274\n",
-      "  timestamp: 1602166364\n",
+      "    learn_throughput: 7351.781\n",
+      "    learn_time_ms: 8252.695\n",
+      "    sample_throughput: 13327.926\n",
+      "    sample_time_ms: 4552.246\n",
+      "    update_time_ms: 39.23\n",
+      "  timestamp: 1602427886\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
+      "  timesteps_total: 1092096\n",
       "  training_iteration: 18\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     18 |          515.002 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     18 |           237.47 | 1092096 |  225.638 |              275.869 |              118.293 |            837.506 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-13-13\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3560.9985107967236\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-11_14-51-39\n",
       "  done: false\n",
-      "  episode_len_mean: 819.1164006604292\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.0312925623877\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 835.8816083395384\n",
+      "  episode_reward_max: 280.26262626262593\n",
+      "  episode_reward_mean: 226.47497311160745\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1343\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1846,83 +1785,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8341425269842148\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007575143571011722\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03457739797886461\n",
-      "        total_loss: 1.834545186161995\n",
-      "        vf_explained_var: 0.9961616396903992\n",
-      "        vf_loss: 1.8676075398921967\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9319173842668533\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006037887651473284\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012360059190541506\n",
+      "        total_loss: 18.858981609344482\n",
+      "        vf_explained_var: 0.971014678478241\n",
+      "        vf_loss: 18.87022590637207\n",
+      "    num_steps_sampled: 1152768\n",
+      "    num_steps_trained: 1152768\n",
       "  iterations_since_restore: 19\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.017647058823528\n",
-      "    gpu_util_percent0: 0.2832352941176471\n",
+      "    cpu_util_percent: 30.946666666666662\n",
+      "    gpu_util_percent0: 0.37333333333333335\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15856558726293105\n",
-      "    mean_env_wait_ms: 1.6874969155605837\n",
-      "    mean_inference_ms: 4.801814859500953\n",
-      "    mean_raw_obs_processing_ms: 0.42604884838564067\n",
-      "  time_since_restore: 543.3891928195953\n",
-      "  time_this_iter_s: 28.38706636428833\n",
-      "  time_total_s: 543.3891928195953\n",
+      "    mean_action_processing_ms: 0.12325786261858288\n",
+      "    mean_env_wait_ms: 0.6553831537708115\n",
+      "    mean_inference_ms: 4.878422743818669\n",
+      "    mean_raw_obs_processing_ms: 0.27059673978998283\n",
+      "  time_since_restore: 250.22734022140503\n",
+      "  time_this_iter_s: 12.757238149642944\n",
+      "  time_total_s: 250.22734022140503\n",
       "  timers:\n",
-      "    learn_throughput: 8037.512\n",
-      "    learn_time_ms: 20129.612\n",
-      "    sample_throughput: 19971.836\n",
-      "    sample_time_ms: 8101.008\n",
-      "    update_time_ms: 41.201\n",
-      "  timestamp: 1602166393\n",
+      "    learn_throughput: 7358.864\n",
+      "    learn_time_ms: 8244.751\n",
+      "    sample_throughput: 13365.577\n",
+      "    sample_time_ms: 4539.422\n",
+      "    update_time_ms: 38.92\n",
+      "  timestamp: 1602427899\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
+      "  timesteps_total: 1152768\n",
       "  training_iteration: 19\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     19 |          543.389 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     19 |          250.227 | 1152768 |  226.475 |              280.263 |              118.293 |            835.882 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-13-42\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3557.6068917018283\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-11_14-51-52\n",
       "  done: false\n",
-      "  episode_len_mean: 817.554763117677\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.8146184205786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 292\n",
-      "  episodes_total: 3926\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 834.2637130801688\n",
+      "  episode_reward_max: 280.26262626262593\n",
+      "  episode_reward_mean: 226.9888547926522\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1930,83 +1867,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7916461393237114\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007353159273043275\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03166137257358059\n",
-      "        total_loss: 2.4200849175453185\n",
-      "        vf_explained_var: 0.9965318441390991\n",
-      "        vf_loss: 2.450275695323944\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9170082658529282\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005881667952053249\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009232628857716918\n",
+      "        total_loss: 21.077390670776367\n",
+      "        vf_explained_var: 0.9689568877220154\n",
+      "        vf_loss: 21.0855393409729\n",
+      "    num_steps_sampled: 1213440\n",
+      "    num_steps_trained: 1213440\n",
       "  iterations_since_restore: 20\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.500000000000007\n",
-      "    gpu_util_percent0: 0.2582352941176471\n",
+      "    cpu_util_percent: 31.75714285714286\n",
+      "    gpu_util_percent0: 0.20785714285714282\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.414285714285714\n",
+      "    vram_util_percent0: 0.11634962282715648\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15824728170515573\n",
-      "    mean_env_wait_ms: 1.689080359464987\n",
-      "    mean_inference_ms: 4.783977737237845\n",
-      "    mean_raw_obs_processing_ms: 0.4249789923662631\n",
-      "  time_since_restore: 572.0331726074219\n",
-      "  time_this_iter_s: 28.643979787826538\n",
-      "  time_total_s: 572.0331726074219\n",
+      "    mean_action_processing_ms: 0.12304888683912533\n",
+      "    mean_env_wait_ms: 0.6558821895833474\n",
+      "    mean_inference_ms: 4.858389563488416\n",
+      "    mean_raw_obs_processing_ms: 0.2700032545267339\n",
+      "  time_since_restore: 262.96310806274414\n",
+      "  time_this_iter_s: 12.735767841339111\n",
+      "  time_total_s: 262.96310806274414\n",
       "  timers:\n",
-      "    learn_throughput: 8035.517\n",
-      "    learn_time_ms: 20134.61\n",
-      "    sample_throughput: 19976.949\n",
-      "    sample_time_ms: 8098.935\n",
-      "    update_time_ms: 46.558\n",
-      "  timestamp: 1602166422\n",
+      "    learn_throughput: 7357.534\n",
+      "    learn_time_ms: 8246.241\n",
+      "    sample_throughput: 13403.312\n",
+      "    sample_time_ms: 4526.642\n",
+      "    update_time_ms: 31.452\n",
+      "  timestamp: 1602427912\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
+      "  timesteps_total: 1213440\n",
       "  training_iteration: 20\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     20 |          572.033 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     20 |          262.963 | 1213440 |  226.989 |              280.263 |              118.293 |            834.264 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-14-10\n",
-      "  done: true\n",
-      "  episode_len_mean: 816.6701557935735\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.22827594346575\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 182\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3553.070619586942\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-11_14-52-05\n",
+      "  done: false\n",
+      "  episode_len_mean: 832.6069287141905\n",
+      "  episode_reward_max: 280.26262626262593\n",
+      "  episode_reward_mean: 227.67616874945318\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1501\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2014,2655 +1949,2513 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7638061985373497\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007330618624109775\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03147139406064525\n",
-      "        total_loss: 1.8828283458948136\n",
-      "        vf_explained_var: 0.9963488578796387\n",
-      "        vf_loss: 1.912833634018898\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9074065536260605\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005816309945657849\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015069264685735106\n",
+      "        total_loss: 16.58755850791931\n",
+      "        vf_explained_var: 0.9737280011177063\n",
+      "        vf_loss: 16.601556301116943\n",
+      "    num_steps_sampled: 1274112\n",
+      "    num_steps_trained: 1274112\n",
       "  iterations_since_restore: 21\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.76060606060606\n",
-      "    gpu_util_percent0: 0.25030303030303036\n",
+      "    cpu_util_percent: 31.513333333333335\n",
+      "    gpu_util_percent0: 0.14533333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15806698356889384\n",
-      "    mean_env_wait_ms: 1.6900183481280247\n",
-      "    mean_inference_ms: 4.773945395364269\n",
-      "    mean_raw_obs_processing_ms: 0.42436064467246504\n",
-      "  time_since_restore: 600.5207903385162\n",
-      "  time_this_iter_s: 28.48761773109436\n",
-      "  time_total_s: 600.5207903385162\n",
+      "    mean_action_processing_ms: 0.12285460119718666\n",
+      "    mean_env_wait_ms: 0.6563595525384185\n",
+      "    mean_inference_ms: 4.839865820264126\n",
+      "    mean_raw_obs_processing_ms: 0.2694527426779773\n",
+      "  time_since_restore: 275.8283269405365\n",
+      "  time_this_iter_s: 12.865218877792358\n",
+      "  time_total_s: 275.8283269405365\n",
       "  timers:\n",
-      "    learn_throughput: 8034.641\n",
-      "    learn_time_ms: 20136.804\n",
-      "    sample_throughput: 19881.19\n",
-      "    sample_time_ms: 8137.943\n",
-      "    update_time_ms: 46.415\n",
-      "  timestamp: 1602166450\n",
+      "    learn_throughput: 7351.45\n",
+      "    learn_time_ms: 8253.066\n",
+      "    sample_throughput: 13454.156\n",
+      "    sample_time_ms: 4509.536\n",
+      "    update_time_ms: 31.093\n",
+      "  timestamp: 1602427925\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
+      "  timesteps_total: 1274112\n",
       "  training_iteration: 21\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | TERMINATED |       |     21 |          600.521 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | TERMINATED |       |     21 |          600.521 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 57594\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_140356-5nvugt1y/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_140356-5nvugt1y/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3176.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 614\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602166450\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 282.48485\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 227.63033\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1264\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▄▅▇█\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
-      "2020-10-08 14:14:19,138 - wandb.wandb_agent - INFO - Cleaning up finished run: 5nvugt1y\n",
-      "2020-10-08 14:14:19,448 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:14:19,448 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 8192\n",
-      "2020-10-08 14:14:19,452 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=8192\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/fpfrymi0\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_141421-fpfrymi0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 14:14:23,731\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:14:24,486 - wandb.wandb_agent - INFO - Running runs: ['fpfrymi0']\n",
-      "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     21 |          275.828 | 1274112 |  227.676 |              280.263 |              118.293 |            832.607 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=756)\u001b[0m 2020-10-08 14:14:26,675\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=710)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=734)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=734)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=742)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=742)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=711)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=696)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=696)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=731)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=731)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=679)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=679)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=725)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=725)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=718)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=718)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=697)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=697)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=723)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=723)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=687)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=687)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=707)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=707)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=703)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=703)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=699)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=699)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=730)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=730)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=684)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=684)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=700)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=700)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=612)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=612)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=650)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=650)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=689)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=689)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=733)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=733)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=691)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=691)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=615)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=615)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=649)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=649)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=686)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=686)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=712)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=712)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=646)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=646)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=629)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=629)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=702)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=702)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=638)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=638)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=688)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=688)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=608)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=608)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=606)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=606)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=620)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=620)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=690)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=690)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=698)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=698)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=678)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=678)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=692)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=692)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=683)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=683)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=727)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=727)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=626)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=626)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=609)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=609)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=695)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=695)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=720)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=720)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=680)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=680)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=641)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=641)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=682)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=682)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=607)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=607)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=715)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=715)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=623)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=623)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=622)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=622)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=705)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=705)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=624)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=624)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=611)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=611)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=685)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=685)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=621)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=621)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-14-58\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3546.6664556962023\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-11_14-52-17\n",
+      "  done: false\n",
+      "  episode_len_mean: 831.3810126582279\n",
+      "  episode_reward_max: 280.26262626262593\n",
+      "  episode_reward_mean: 228.64649661168644\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1611746549606323\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005718740075826645\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8895199149847031\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006235960638150573\n",
       "        model: {}\n",
-      "        policy_loss: -0.013096390827558934\n",
-      "        total_loss: 7.403090405464172\n",
-      "        vf_explained_var: 0.7892305254936218\n",
-      "        vf_loss: 7.415043115615845\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
+      "        policy_loss: -0.016274704947136343\n",
+      "        total_loss: 14.437464952468872\n",
+      "        vf_explained_var: 0.9757154583930969\n",
+      "        vf_loss: 14.45258092880249\n",
+      "    num_steps_sampled: 1334784\n",
+      "    num_steps_trained: 1334784\n",
+      "  iterations_since_restore: 22\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 37.735483870967734\n",
-      "    gpu_util_percent0: 0.051935483870967754\n",
-      "    gpu_util_percent1: 0.0003225806451612903\n",
-      "    gpu_util_percent2: 0.0003225806451612903\n",
-      "    ram_util_percent: 9.529032258064516\n",
-      "    vram_util_percent0: 0.25613104243591234\n",
+      "    cpu_util_percent: 31.640000000000004\n",
+      "    gpu_util_percent0: 0.4166666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17423707785964127\n",
-      "    mean_env_wait_ms: 1.645963223637825\n",
-      "    mean_inference_ms: 5.692081848902995\n",
-      "    mean_raw_obs_processing_ms: 0.4677243687628816\n",
-      "  time_since_restore: 26.03303360939026\n",
-      "  time_this_iter_s: 26.03303360939026\n",
-      "  time_total_s: 26.03303360939026\n",
+      "    mean_action_processing_ms: 0.12267414774631347\n",
+      "    mean_env_wait_ms: 0.6568038344783947\n",
+      "    mean_inference_ms: 4.822673854077089\n",
+      "    mean_raw_obs_processing_ms: 0.26893973005150973\n",
+      "  time_since_restore: 288.69322776794434\n",
+      "  time_this_iter_s: 12.864900827407837\n",
+      "  time_total_s: 288.69322776794434\n",
       "  timers:\n",
-      "    learn_throughput: 9842.911\n",
-      "    learn_time_ms: 16437.413\n",
-      "    sample_throughput: 17001.439\n",
-      "    sample_time_ms: 9516.371\n",
-      "    update_time_ms: 39.605\n",
-      "  timestamp: 1602166498\n",
+      "    learn_throughput: 7359.24\n",
+      "    learn_time_ms: 8244.329\n",
+      "    sample_throughput: 13451.748\n",
+      "    sample_time_ms: 4510.343\n",
+      "    update_time_ms: 37.968\n",
+      "  timestamp: 1602427937\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1334784\n",
+      "  training_iteration: 22\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.7/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      1 |           26.033 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     22 |          288.693 | 1334784 |  228.646 |              280.263 |              118.293 |            831.381 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_14-15-23\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3541.2525617842075\n",
+      "    time_step_min: 3199\n",
+      "  date: 2020-10-11_14-52-30\n",
       "  done: false\n",
-      "  episode_len_mean: 873.4715189873418\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 227.3690384861269\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 829.9795057263411\n",
+      "  episode_reward_max: 281.3232323232324\n",
+      "  episode_reward_mean: 229.46678356804938\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1659\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.132627922296524\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006706285546533764\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8658313006162643\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005380009184591472\n",
       "        model: {}\n",
-      "        policy_loss: -0.016248987091239543\n",
-      "        total_loss: 5.631959009170532\n",
-      "        vf_explained_var: 0.9176143407821655\n",
-      "        vf_loss: 5.646866726875305\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
+      "        policy_loss: -0.008646945061627775\n",
+      "        total_loss: 20.08211898803711\n",
+      "        vf_explained_var: 0.9681438207626343\n",
+      "        vf_loss: 20.08977699279785\n",
+      "    num_steps_sampled: 1395456\n",
+      "    num_steps_trained: 1395456\n",
+      "  iterations_since_restore: 23\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.220689655172414\n",
-      "    gpu_util_percent0: 0.019655172413793106\n",
+      "    cpu_util_percent: 33.050000000000004\n",
+      "    gpu_util_percent0: 0.4414285714285714\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74137931034483\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.414285714285714\n",
+      "    vram_util_percent0: 0.11634962282715648\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17038163777984144\n",
-      "    mean_env_wait_ms: 1.6424572254451888\n",
-      "    mean_inference_ms: 5.447572680731352\n",
-      "    mean_raw_obs_processing_ms: 0.4584056950467155\n",
-      "  time_since_restore: 50.949177742004395\n",
-      "  time_this_iter_s: 24.916144132614136\n",
-      "  time_total_s: 50.949177742004395\n",
+      "    mean_action_processing_ms: 0.12250588645121233\n",
+      "    mean_env_wait_ms: 0.6572267549415766\n",
+      "    mean_inference_ms: 4.806699588903894\n",
+      "    mean_raw_obs_processing_ms: 0.2684630946614512\n",
+      "  time_since_restore: 301.44871520996094\n",
+      "  time_this_iter_s: 12.755487442016602\n",
+      "  time_total_s: 301.44871520996094\n",
       "  timers:\n",
-      "    learn_throughput: 9861.266\n",
-      "    learn_time_ms: 16406.818\n",
-      "    sample_throughput: 18024.658\n",
-      "    sample_time_ms: 8976.148\n",
-      "    update_time_ms: 38.131\n",
-      "  timestamp: 1602166523\n",
+      "    learn_throughput: 7362.785\n",
+      "    learn_time_ms: 8240.36\n",
+      "    sample_throughput: 13479.091\n",
+      "    sample_time_ms: 4501.194\n",
+      "    update_time_ms: 38.936\n",
+      "  timestamp: 1602427950\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1395456\n",
+      "  training_iteration: 23\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      2 |          50.9492 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     23 |          301.449 | 1395456 |  229.467 |              281.323 |              118.293 |             829.98 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_14-15-48\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3536.58918296893\n",
+      "    time_step_min: 3199\n",
+      "  date: 2020-10-11_14-52-43\n",
       "  done: false\n",
-      "  episode_len_mean: 867.8713080168776\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 228.246196138601\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 829.3107019562716\n",
+      "  episode_reward_max: 281.3232323232324\n",
+      "  episode_reward_mean: 230.1733561158187\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1738\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1271256804466248\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007389193354174495\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8665132224559784\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005198416416533291\n",
       "        model: {}\n",
-      "        policy_loss: -0.018508310522884132\n",
-      "        total_loss: 6.457739639282226\n",
-      "        vf_explained_var: 0.9464155435562134\n",
-      "        vf_loss: 6.4747700691223145\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
+      "        policy_loss: -0.011439272901043296\n",
+      "        total_loss: 17.11276149749756\n",
+      "        vf_explained_var: 0.9721271991729736\n",
+      "        vf_loss: 17.12324619293213\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 24\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.61379310344827\n",
-      "    gpu_util_percent0: 0.21344827586206902\n",
+      "    cpu_util_percent: 30.426666666666666\n",
+      "    gpu_util_percent0: 0.24066666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4466666666666663\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16769761323536675\n",
-      "    mean_env_wait_ms: 1.6416986329657957\n",
-      "    mean_inference_ms: 5.306852272749373\n",
-      "    mean_raw_obs_processing_ms: 0.4500760030355006\n",
-      "  time_since_restore: 75.78218650817871\n",
-      "  time_this_iter_s: 24.833008766174316\n",
-      "  time_total_s: 75.78218650817871\n",
+      "    mean_action_processing_ms: 0.12234825149070479\n",
+      "    mean_env_wait_ms: 0.6576126991689294\n",
+      "    mean_inference_ms: 4.791808475892309\n",
+      "    mean_raw_obs_processing_ms: 0.26801903209083283\n",
+      "  time_since_restore: 314.25941705703735\n",
+      "  time_this_iter_s: 12.810701847076416\n",
+      "  time_total_s: 314.25941705703735\n",
       "  timers:\n",
-      "    learn_throughput: 9901.992\n",
-      "    learn_time_ms: 16339.339\n",
-      "    sample_throughput: 18316.884\n",
-      "    sample_time_ms: 8832.943\n",
-      "    update_time_ms: 36.895\n",
-      "  timestamp: 1602166548\n",
+      "    learn_throughput: 7353.007\n",
+      "    learn_time_ms: 8251.319\n",
+      "    sample_throughput: 13494.35\n",
+      "    sample_time_ms: 4496.104\n",
+      "    update_time_ms: 40.548\n",
+      "  timestamp: 1602427963\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 24\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      3 |          75.7822 | 485376 |  228.246 |              274.859 |              115.788 |            867.871 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     24 |          314.259 | 1456128 |  230.173 |              281.323 |              118.293 |            829.311 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3230.0\n",
-      "  date: 2020-10-08_14-16-13\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3531.2894881673087\n",
+      "    time_step_min: 3199\n",
+      "  date: 2020-10-11_14-52-56\n",
       "  done: false\n",
-      "  episode_len_mean: 862.3544303797469\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 230.3964326812426\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 828.4171711612548\n",
+      "  episode_reward_max: 281.3232323232324\n",
+      "  episode_reward_mean: 230.9763401766704\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1817\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0996861219406129\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008276985818520188\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8617505133152008\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0055166283855214715\n",
       "        model: {}\n",
-      "        policy_loss: -0.020328705292195083\n",
-      "        total_loss: 5.005046558380127\n",
-      "        vf_explained_var: 0.9697187542915344\n",
-      "        vf_loss: 5.023719763755798\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
+      "        policy_loss: -0.012109191156923771\n",
+      "        total_loss: 12.609570026397705\n",
+      "        vf_explained_var: 0.9781627655029297\n",
+      "        vf_loss: 12.620662212371826\n",
+      "    num_steps_sampled: 1516800\n",
+      "    num_steps_trained: 1516800\n",
+      "  iterations_since_restore: 25\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.723333333333336\n",
-      "    gpu_util_percent0: 0.4343333333333333\n",
+      "    cpu_util_percent: 32.94285714285714\n",
+      "    gpu_util_percent0: 0.23500000000000001\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.442857142857143\n",
+      "    vram_util_percent0: 0.11634962282715648\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1657578301907817\n",
-      "    mean_env_wait_ms: 1.6430517247856948\n",
-      "    mean_inference_ms: 5.2018997182402025\n",
-      "    mean_raw_obs_processing_ms: 0.44406851617825566\n",
-      "  time_since_restore: 100.74394655227661\n",
-      "  time_this_iter_s: 24.9617600440979\n",
-      "  time_total_s: 100.74394655227661\n",
+      "    mean_action_processing_ms: 0.12220007626450559\n",
+      "    mean_env_wait_ms: 0.6579674778371506\n",
+      "    mean_inference_ms: 4.777886453814694\n",
+      "    mean_raw_obs_processing_ms: 0.26760158411270163\n",
+      "  time_since_restore: 327.11176109313965\n",
+      "  time_this_iter_s: 12.852344036102295\n",
+      "  time_total_s: 327.11176109313965\n",
       "  timers:\n",
-      "    learn_throughput: 9911.992\n",
-      "    learn_time_ms: 16322.854\n",
-      "    sample_throughput: 18445.327\n",
-      "    sample_time_ms: 8771.436\n",
-      "    update_time_ms: 36.541\n",
-      "  timestamp: 1602166573\n",
+      "    learn_throughput: 7343.737\n",
+      "    learn_time_ms: 8261.734\n",
+      "    sample_throughput: 13546.238\n",
+      "    sample_time_ms: 4478.882\n",
+      "    update_time_ms: 41.285\n",
+      "  timestamp: 1602427976\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1516800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      4 |          100.744 | 647168 |  230.396 |              278.707 |              115.788 |            862.354 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     25 |          327.112 | 1516800 |  230.976 |              281.323 |              118.293 |            828.417 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3223.0\n",
-      "  date: 2020-10-08_14-16-38\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3525.5443505807816\n",
+      "    time_step_min: 3199\n",
+      "  date: 2020-10-11_14-53-09\n",
       "  done: false\n",
-      "  episode_len_mean: 852.6247216035634\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 231.18069334773102\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 266\n",
-      "  episodes_total: 898\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 827.2967265047519\n",
+      "  episode_reward_max: 281.3232323232324\n",
+      "  episode_reward_mean: 231.84681556856845\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 77\n",
+      "  episodes_total: 1894\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0624429881572723\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0077964670956134794\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8505872040987015\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005504266591742635\n",
       "        model: {}\n",
-      "        policy_loss: -0.02084309732308611\n",
-      "        total_loss: 7.683893799781799\n",
-      "        vf_explained_var: 0.9791978597640991\n",
-      "        vf_loss: 7.703177666664123\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
+      "        policy_loss: -0.013713978929445148\n",
+      "        total_loss: 14.596449613571167\n",
+      "        vf_explained_var: 0.9737269878387451\n",
+      "        vf_loss: 14.609147310256958\n",
+      "    num_steps_sampled: 1577472\n",
+      "    num_steps_trained: 1577472\n",
+      "  iterations_since_restore: 26\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.225\n",
-      "    gpu_util_percent0: 0.25178571428571433\n",
+      "    cpu_util_percent: 29.860000000000003\n",
+      "    gpu_util_percent0: 0.30466666666666664\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.42\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16364555568838862\n",
-      "    mean_env_wait_ms: 1.649353801806338\n",
-      "    mean_inference_ms: 5.083644859595276\n",
-      "    mean_raw_obs_processing_ms: 0.4376329609722663\n",
-      "  time_since_restore: 125.15412139892578\n",
-      "  time_this_iter_s: 24.41017484664917\n",
-      "  time_total_s: 125.15412139892578\n",
+      "    mean_action_processing_ms: 0.12206247307375404\n",
+      "    mean_env_wait_ms: 0.6582994622828627\n",
+      "    mean_inference_ms: 4.765167746679992\n",
+      "    mean_raw_obs_processing_ms: 0.2672237938965896\n",
+      "  time_since_restore: 339.92621898651123\n",
+      "  time_this_iter_s: 12.814457893371582\n",
+      "  time_total_s: 339.92621898651123\n",
       "  timers:\n",
-      "    learn_throughput: 9921.993\n",
-      "    learn_time_ms: 16306.401\n",
-      "    sample_throughput: 18736.645\n",
-      "    sample_time_ms: 8635.057\n",
-      "    update_time_ms: 35.191\n",
-      "  timestamp: 1602166598\n",
+      "    learn_throughput: 7341.174\n",
+      "    learn_time_ms: 8264.618\n",
+      "    sample_throughput: 13575.839\n",
+      "    sample_time_ms: 4469.116\n",
+      "    update_time_ms: 41.007\n",
+      "  timestamp: 1602427989\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1577472\n",
+      "  training_iteration: 26\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      5 |          125.154 | 808960 |  231.181 |              278.707 |              115.788 |            852.625 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     26 |          339.926 | 1577472 |  231.847 |              281.323 |              118.293 |            827.297 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3223.0\n",
-      "  date: 2020-10-08_14-17-02\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3521.043279022403\n",
+      "    time_step_min: 3199\n",
+      "  date: 2020-10-11_14-53-22\n",
       "  done: false\n",
-      "  episode_len_mean: 846.0479204339964\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 231.96029919447625\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 208\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 826.1883910386965\n",
+      "  episode_reward_max: 281.3232323232324\n",
+      "  episode_reward_mean: 232.52879610771666\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 70\n",
+      "  episodes_total: 1964\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0738083600997925\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007217544643208384\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8386607617139816\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006047990289516747\n",
       "        model: {}\n",
-      "        policy_loss: -0.02225890466943383\n",
-      "        total_loss: 4.545075726509094\n",
-      "        vf_explained_var: 0.9842392206192017\n",
-      "        vf_loss: 4.565891194343567\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
+      "        policy_loss: -0.015535812475718558\n",
+      "        total_loss: 14.120278358459473\n",
+      "        vf_explained_var: 0.9748682379722595\n",
+      "        vf_loss: 14.134687900543213\n",
+      "    num_steps_sampled: 1638144\n",
+      "    num_steps_trained: 1638144\n",
+      "  iterations_since_restore: 27\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.55517241379311\n",
-      "    gpu_util_percent0: 0.4293103448275861\n",
+      "    cpu_util_percent: 30.946666666666665\n",
+      "    gpu_util_percent0: 0.3626666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4133333333333327\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16251990142651115\n",
-      "    mean_env_wait_ms: 1.6530343779974206\n",
-      "    mean_inference_ms: 5.018380813854082\n",
-      "    mean_raw_obs_processing_ms: 0.43409996967266995\n",
-      "  time_since_restore: 149.7096438407898\n",
-      "  time_this_iter_s: 24.555522441864014\n",
-      "  time_total_s: 149.7096438407898\n",
+      "    mean_action_processing_ms: 0.12194517256059809\n",
+      "    mean_env_wait_ms: 0.6585797022373939\n",
+      "    mean_inference_ms: 4.75417602343179\n",
+      "    mean_raw_obs_processing_ms: 0.2668919473907244\n",
+      "  time_since_restore: 352.8753459453583\n",
+      "  time_this_iter_s: 12.949126958847046\n",
+      "  time_total_s: 352.8753459453583\n",
       "  timers:\n",
-      "    learn_throughput: 9912.286\n",
-      "    learn_time_ms: 16322.371\n",
-      "    sample_throughput: 18942.241\n",
-      "    sample_time_ms: 8541.334\n",
-      "    update_time_ms: 33.368\n",
-      "  timestamp: 1602166622\n",
+      "    learn_throughput: 7333.696\n",
+      "    learn_time_ms: 8273.045\n",
+      "    sample_throughput: 13559.318\n",
+      "    sample_time_ms: 4474.561\n",
+      "    update_time_ms: 43.736\n",
+      "  timestamp: 1602428002\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1638144\n",
+      "  training_iteration: 27\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      6 |           149.71 | 970752 |   231.96 |              278.707 |              115.788 |            846.048 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     27 |          352.875 | 1638144 |  232.529 |              281.323 |              118.293 |            826.188 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3170.0\n",
-      "  date: 2020-10-08_14-17-27\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3516.673720472441\n",
+      "    time_step_min: 3199\n",
+      "  date: 2020-10-11_14-53-35\n",
       "  done: false\n",
-      "  episode_len_mean: 841.3995253164557\n",
-      "  episode_reward_max: 284.4040404040406\n",
-      "  episode_reward_mean: 232.7926815624599\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 825.3661417322835\n",
+      "  episode_reward_max: 281.3232323232324\n",
+      "  episode_reward_mean: 233.19085043346854\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 68\n",
+      "  episodes_total: 2032\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0473353922367097\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006994991353712976\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8244215697050095\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005533277872018516\n",
       "        model: {}\n",
-      "        policy_loss: -0.022564191045239566\n",
-      "        total_loss: 4.000831997394561\n",
-      "        vf_explained_var: 0.9874190092086792\n",
-      "        vf_loss: 4.021997082233429\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
+      "        policy_loss: -0.01628575964423362\n",
+      "        total_loss: 14.40134334564209\n",
+      "        vf_explained_var: 0.974392294883728\n",
+      "        vf_loss: 14.41660475730896\n",
+      "    num_steps_sampled: 1698816\n",
+      "    num_steps_trained: 1698816\n",
+      "  iterations_since_restore: 28\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.59655172413793\n",
-      "    gpu_util_percent0: 0.4562068965517241\n",
+      "    cpu_util_percent: 33.17857142857144\n",
+      "    gpu_util_percent0: 0.30142857142857143\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.758620689655174\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.428571428571428\n",
+      "    vram_util_percent0: 0.11634962282715648\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16183355318977655\n",
-      "    mean_env_wait_ms: 1.656038102133309\n",
-      "    mean_inference_ms: 4.9782716342931606\n",
-      "    mean_raw_obs_processing_ms: 0.4319914234530791\n",
-      "  time_since_restore: 174.1368727684021\n",
-      "  time_this_iter_s: 24.427228927612305\n",
-      "  time_total_s: 174.1368727684021\n",
+      "    mean_action_processing_ms: 0.12183073386559173\n",
+      "    mean_env_wait_ms: 0.6588753102214618\n",
+      "    mean_inference_ms: 4.744120508750853\n",
+      "    mean_raw_obs_processing_ms: 0.26658921663103674\n",
+      "  time_since_restore: 365.65469121932983\n",
+      "  time_this_iter_s: 12.779345273971558\n",
+      "  time_total_s: 365.65469121932983\n",
       "  timers:\n",
-      "    learn_throughput: 9918.301\n",
-      "    learn_time_ms: 16312.471\n",
-      "    sample_throughput: 19088.76\n",
-      "    sample_time_ms: 8475.773\n",
-      "    update_time_ms: 33.238\n",
-      "  timestamp: 1602166647\n",
+      "    learn_throughput: 7332.967\n",
+      "    learn_time_ms: 8273.868\n",
+      "    sample_throughput: 13606.1\n",
+      "    sample_time_ms: 4459.176\n",
+      "    update_time_ms: 43.874\n",
+      "  timestamp: 1602428015\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1698816\n",
+      "  training_iteration: 28\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      7 |          174.137 | 1132544 |  232.793 |              284.404 |              115.788 |              841.4 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     28 |          365.655 | 1698816 |  233.191 |              281.323 |              118.293 |            825.366 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3170.0\n",
-      "  date: 2020-10-08_14-17-51\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3512.8546927108146\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-53-48\n",
       "  done: false\n",
-      "  episode_len_mean: 837.3713080168776\n",
-      "  episode_reward_max: 284.4040404040406\n",
-      "  episode_reward_mean: 233.61432184006011\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 824.6441162458314\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 233.7694910034119\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 67\n",
+      "  episodes_total: 2099\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.01868434548378\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007189809367991984\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8053620457649231\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.004583484609611332\n",
       "        model: {}\n",
-      "        policy_loss: -0.023347471375018358\n",
-      "        total_loss: 3.781139385700226\n",
-      "        vf_explained_var: 0.9891014099121094\n",
-      "        vf_loss: 3.803048861026764\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
+      "        policy_loss: -0.011118872789666057\n",
+      "        total_loss: 10.728185892105103\n",
+      "        vf_explained_var: 0.979694128036499\n",
+      "        vf_loss: 10.738468647003174\n",
+      "    num_steps_sampled: 1759488\n",
+      "    num_steps_trained: 1759488\n",
+      "  iterations_since_restore: 29\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.625\n",
-      "    gpu_util_percent0: 0.04107142857142857\n",
+      "    cpu_util_percent: 30.76\n",
+      "    gpu_util_percent0: 0.28933333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.771428571428572\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4199999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16125876245924115\n",
-      "    mean_env_wait_ms: 1.6590341255429097\n",
-      "    mean_inference_ms: 4.943515953135972\n",
-      "    mean_raw_obs_processing_ms: 0.430128591449942\n",
-      "  time_since_restore: 198.50214219093323\n",
-      "  time_this_iter_s: 24.365269422531128\n",
-      "  time_total_s: 198.50214219093323\n",
+      "    mean_action_processing_ms: 0.12173404020161536\n",
+      "    mean_env_wait_ms: 0.6591291266650579\n",
+      "    mean_inference_ms: 4.734578217333354\n",
+      "    mean_raw_obs_processing_ms: 0.2663074777346303\n",
+      "  time_since_restore: 378.49544954299927\n",
+      "  time_this_iter_s: 12.840758323669434\n",
+      "  time_total_s: 378.49544954299927\n",
       "  timers:\n",
-      "    learn_throughput: 9923.421\n",
-      "    learn_time_ms: 16304.054\n",
-      "    sample_throughput: 19218.701\n",
-      "    sample_time_ms: 8418.467\n",
-      "    update_time_ms: 34.044\n",
-      "  timestamp: 1602166671\n",
+      "    learn_throughput: 7329.739\n",
+      "    learn_time_ms: 8277.511\n",
+      "    sample_throughput: 13573.324\n",
+      "    sample_time_ms: 4469.944\n",
+      "    update_time_ms: 37.662\n",
+      "  timestamp: 1602428028\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1759488\n",
+      "  training_iteration: 29\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      8 |          198.502 | 1294336 |  233.614 |              284.404 |              115.788 |            837.371 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     29 |          378.495 | 1759488 |  233.769 |              294.657 |              118.293 |            824.644 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-18-15\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3509.5301982480405\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-54-01\n",
       "  done: false\n",
-      "  episode_len_mean: 829.8141542002302\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 235.34277179156337\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 1738\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 823.8326417704011\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 234.2732022856504\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 70\n",
+      "  episodes_total: 2169\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9904811769723892\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006311689200811088\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8010383099317551\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005840748781338334\n",
       "        model: {}\n",
-      "        policy_loss: -0.020997717510908842\n",
-      "        total_loss: 5.1504497051239015\n",
-      "        vf_explained_var: 0.9909344911575317\n",
-      "        vf_loss: 5.170185089111328\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
+      "        policy_loss: -0.00798800599295646\n",
+      "        total_loss: 11.50804591178894\n",
+      "        vf_explained_var: 0.9788138270378113\n",
+      "        vf_loss: 11.515530347824097\n",
+      "    num_steps_sampled: 1820160\n",
+      "    num_steps_trained: 1820160\n",
+      "  iterations_since_restore: 30\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.78928571428572\n",
-      "    gpu_util_percent0: 0.30821428571428566\n",
+      "    cpu_util_percent: 30.842857142857138\n",
+      "    gpu_util_percent0: 0.4235714285714285\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.11634962282715648\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.160369309924211\n",
-      "    mean_env_wait_ms: 1.6650071130850876\n",
-      "    mean_inference_ms: 4.888377085687167\n",
-      "    mean_raw_obs_processing_ms: 0.42729617584826485\n",
-      "  time_since_restore: 222.59675359725952\n",
-      "  time_this_iter_s: 24.094611406326294\n",
-      "  time_total_s: 222.59675359725952\n",
+      "    mean_action_processing_ms: 0.12163288460882281\n",
+      "    mean_env_wait_ms: 0.6593830453234737\n",
+      "    mean_inference_ms: 4.725118458976588\n",
+      "    mean_raw_obs_processing_ms: 0.2660189862136188\n",
+      "  time_since_restore: 391.29025769233704\n",
+      "  time_this_iter_s: 12.794808149337769\n",
+      "  time_total_s: 391.29025769233704\n",
       "  timers:\n",
-      "    learn_throughput: 9938.553\n",
-      "    learn_time_ms: 16279.231\n",
-      "    sample_throughput: 19342.706\n",
-      "    sample_time_ms: 8364.497\n",
-      "    update_time_ms: 33.218\n",
-      "  timestamp: 1602166695\n",
+      "    learn_throughput: 7323.283\n",
+      "    learn_time_ms: 8284.809\n",
+      "    sample_throughput: 13582.945\n",
+      "    sample_time_ms: 4466.778\n",
+      "    update_time_ms: 39.261\n",
+      "  timestamp: 1602428041\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1820160\n",
+      "  training_iteration: 30\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      9 |          222.597 | 1456128 |  235.343 |              290.242 |              115.788 |            829.814 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     30 |           391.29 | 1820160 |  234.273 |              294.657 |              118.293 |            823.833 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-18-40\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3506.5406976744184\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-54-14\n",
       "  done: false\n",
-      "  episode_len_mean: 826.4541139240506\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 235.7108905510803\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 823.0178890876565\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 234.7261569180174\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 67\n",
+      "  episodes_total: 2236\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9730047971010208\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006372990598902106\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7931597828865051\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00602615880779922\n",
       "        model: {}\n",
-      "        policy_loss: -0.022790615819394587\n",
-      "        total_loss: 3.343014180660248\n",
-      "        vf_explained_var: 0.9915106892585754\n",
-      "        vf_loss: 3.3645302057266235\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
+      "        policy_loss: -0.007323025201912969\n",
+      "        total_loss: 12.5483980178833\n",
+      "        vf_explained_var: 0.9768276810646057\n",
+      "        vf_loss: 12.555197715759277\n",
+      "    num_steps_sampled: 1880832\n",
+      "    num_steps_trained: 1880832\n",
+      "  iterations_since_restore: 31\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.324137931034485\n",
-      "    gpu_util_percent0: 0.2775862068965517\n",
+      "    cpu_util_percent: 29.980000000000004\n",
+      "    gpu_util_percent0: 0.43000000000000005\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4399999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16000657164975352\n",
-      "    mean_env_wait_ms: 1.6678046661692965\n",
-      "    mean_inference_ms: 4.86599024622493\n",
-      "    mean_raw_obs_processing_ms: 0.42614775920547227\n",
-      "  time_since_restore: 246.9238064289093\n",
-      "  time_this_iter_s: 24.32705283164978\n",
-      "  time_total_s: 246.9238064289093\n",
+      "    mean_action_processing_ms: 0.1215348891564357\n",
+      "    mean_env_wait_ms: 0.6596170927931669\n",
+      "    mean_inference_ms: 4.716433072692993\n",
+      "    mean_raw_obs_processing_ms: 0.2657620108508695\n",
+      "  time_since_restore: 404.21544122695923\n",
+      "  time_this_iter_s: 12.925183534622192\n",
+      "  time_total_s: 404.21544122695923\n",
       "  timers:\n",
-      "    learn_throughput: 9939.106\n",
-      "    learn_time_ms: 16278.326\n",
-      "    sample_throughput: 19435.411\n",
-      "    sample_time_ms: 8324.599\n",
-      "    update_time_ms: 33.566\n",
-      "  timestamp: 1602166720\n",
+      "    learn_throughput: 7322.775\n",
+      "    learn_time_ms: 8285.384\n",
+      "    sample_throughput: 13567.329\n",
+      "    sample_time_ms: 4471.919\n",
+      "    update_time_ms: 38.899\n",
+      "  timestamp: 1602428054\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1880832\n",
+      "  training_iteration: 31\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     10 |          246.924 | 1617920 |  235.711 |              290.242 |              115.788 |            826.454 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     31 |          404.215 | 1880832 |  234.726 |              294.657 |              118.293 |            823.018 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-04\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3503.4176062445795\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-54-27\n",
       "  done: false\n",
-      "  episode_len_mean: 823.6002921129503\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 236.65748035368276\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 822.153512575889\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 235.19935258920518\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 70\n",
+      "  episodes_total: 2306\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9577732890844345\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006211055861786008\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7887319028377533\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006466412800364196\n",
       "        model: {}\n",
-      "        policy_loss: -0.022765795403392984\n",
-      "        total_loss: 3.0192813992500307\n",
-      "        vf_explained_var: 0.9923363924026489\n",
-      "        vf_loss: 3.0408049702644346\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
+      "        policy_loss: -0.011869820766150951\n",
+      "        total_loss: 10.237318277359009\n",
+      "        vf_explained_var: 0.9808382987976074\n",
+      "        vf_loss: 10.248620510101318\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 32\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.706896551724135\n",
-      "    gpu_util_percent0: 0.43068965517241387\n",
+      "    cpu_util_percent: 31.253333333333334\n",
+      "    gpu_util_percent0: 0.3353333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1596848966715417\n",
-      "    mean_env_wait_ms: 1.6704675074629387\n",
-      "    mean_inference_ms: 4.845793508809106\n",
-      "    mean_raw_obs_processing_ms: 0.42510446710641553\n",
-      "  time_since_restore: 271.42553091049194\n",
-      "  time_this_iter_s: 24.50172448158264\n",
-      "  time_total_s: 271.42553091049194\n",
+      "    mean_action_processing_ms: 0.12143859271709237\n",
+      "    mean_env_wait_ms: 0.6598490910078433\n",
+      "    mean_inference_ms: 4.707725523268732\n",
+      "    mean_raw_obs_processing_ms: 0.2654865415242206\n",
+      "  time_since_restore: 417.0642886161804\n",
+      "  time_this_iter_s: 12.848847389221191\n",
+      "  time_total_s: 417.0642886161804\n",
       "  timers:\n",
-      "    learn_throughput: 9946.653\n",
-      "    learn_time_ms: 16265.974\n",
-      "    sample_throughput: 19772.529\n",
-      "    sample_time_ms: 8182.666\n",
-      "    update_time_ms: 32.542\n",
-      "  timestamp: 1602166744\n",
+      "    learn_throughput: 7325.106\n",
+      "    learn_time_ms: 8282.747\n",
+      "    sample_throughput: 13575.538\n",
+      "    sample_time_ms: 4469.215\n",
+      "    update_time_ms: 40.018\n",
+      "  timestamp: 1602428067\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 32\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     11 |          271.426 | 1779712 |  236.657 |              290.242 |              115.788 |              823.6 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     32 |          417.064 | 1941504 |  235.199 |              294.657 |              118.293 |            822.154 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-29\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3499.610012620951\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-54-40\n",
       "  done: false\n",
-      "  episode_len_mean: 820.2957437472576\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 237.36838769440774\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 225\n",
-      "  episodes_total: 2279\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 821.4859066049643\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 235.77626071399737\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 71\n",
+      "  episodes_total: 2377\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9244333893060684\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006004941323772073\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7735395282506943\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006109715439379215\n",
       "        model: {}\n",
-      "        policy_loss: -0.021168453525751828\n",
-      "        total_loss: 4.074023377895355\n",
-      "        vf_explained_var: 0.9932994842529297\n",
-      "        vf_loss: 4.093990921974182\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
+      "        policy_loss: -0.013684868696145713\n",
+      "        total_loss: 9.02634072303772\n",
+      "        vf_explained_var: 0.9823529720306396\n",
+      "        vf_loss: 9.039491653442383\n",
+      "    num_steps_sampled: 2002176\n",
+      "    num_steps_trained: 2002176\n",
+      "  iterations_since_restore: 33\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.251724137931035\n",
-      "    gpu_util_percent0: 0.39206896551724135\n",
+      "    cpu_util_percent: 31.759999999999998\n",
+      "    gpu_util_percent0: 0.2733333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.744827586206897\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.42\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1592619934185692\n",
-      "    mean_env_wait_ms: 1.6739541868498113\n",
-      "    mean_inference_ms: 4.819806265535011\n",
-      "    mean_raw_obs_processing_ms: 0.42372078258183\n",
-      "  time_since_restore: 296.40609192848206\n",
-      "  time_this_iter_s: 24.980561017990112\n",
-      "  time_total_s: 296.40609192848206\n",
+      "    mean_action_processing_ms: 0.12135047465721231\n",
+      "    mean_env_wait_ms: 0.660079740919627\n",
+      "    mean_inference_ms: 4.699384408095418\n",
+      "    mean_raw_obs_processing_ms: 0.2652290656408341\n",
+      "  time_since_restore: 429.9861912727356\n",
+      "  time_this_iter_s: 12.921902656555176\n",
+      "  time_total_s: 429.9861912727356\n",
       "  timers:\n",
-      "    learn_throughput: 9957.289\n",
-      "    learn_time_ms: 16248.6\n",
-      "    sample_throughput: 19727.515\n",
-      "    sample_time_ms: 8201.337\n",
-      "    update_time_ms: 32.973\n",
-      "  timestamp: 1602166769\n",
+      "    learn_throughput: 7315.582\n",
+      "    learn_time_ms: 8293.53\n",
+      "    sample_throughput: 13578.974\n",
+      "    sample_time_ms: 4468.084\n",
+      "    update_time_ms: 39.873\n",
+      "  timestamp: 1602428080\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2002176\n",
+      "  training_iteration: 33\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     12 |          296.406 | 1941504 |  237.368 |              290.242 |              115.788 |            820.296 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     33 |          429.986 | 2002176 |  235.776 |              294.657 |              118.293 |            821.486 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-54\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3495.8756117455137\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-54-53\n",
       "  done: false\n",
-      "  episode_len_mean: 817.5490506329114\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.05452068149842\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 249\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 820.7389885807504\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 236.34207902845748\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 75\n",
+      "  episodes_total: 2452\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9116032361984253\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0059999656863510605\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7676493227481842\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006269674748182297\n",
       "        model: {}\n",
-      "        policy_loss: -0.020421561488183214\n",
-      "        total_loss: 3.2677656054496764\n",
-      "        vf_explained_var: 0.9931272268295288\n",
-      "        vf_loss: 3.2869871616363526\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
+      "        policy_loss: -0.01027127931592986\n",
+      "        total_loss: 10.94404411315918\n",
+      "        vf_explained_var: 0.9788558483123779\n",
+      "        vf_loss: 10.953765153884888\n",
+      "    num_steps_sampled: 2062848\n",
+      "    num_steps_trained: 2062848\n",
+      "  iterations_since_restore: 34\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.02857142857143\n",
-      "    gpu_util_percent0: 0.06035714285714285\n",
+      "    cpu_util_percent: 31.920000000000005\n",
+      "    gpu_util_percent0: 0.18800000000000006\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.764285714285716\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.44\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15888263499780286\n",
-      "    mean_env_wait_ms: 1.677646536061787\n",
-      "    mean_inference_ms: 4.796171409815506\n",
-      "    mean_raw_obs_processing_ms: 0.42253131691795703\n",
-      "  time_since_restore: 320.67564845085144\n",
-      "  time_this_iter_s: 24.269556522369385\n",
-      "  time_total_s: 320.67564845085144\n",
+      "    mean_action_processing_ms: 0.12125829544826763\n",
+      "    mean_env_wait_ms: 0.660303209874392\n",
+      "    mean_inference_ms: 4.690864363293233\n",
+      "    mean_raw_obs_processing_ms: 0.26495963661088284\n",
+      "  time_since_restore: 442.88846588134766\n",
+      "  time_this_iter_s: 12.90227460861206\n",
+      "  time_total_s: 442.88846588134766\n",
       "  timers:\n",
-      "    learn_throughput: 9954.003\n",
-      "    learn_time_ms: 16253.963\n",
-      "    sample_throughput: 19876.989\n",
-      "    sample_time_ms: 8139.664\n",
-      "    update_time_ms: 31.685\n",
-      "  timestamp: 1602166794\n",
+      "    learn_throughput: 7322.409\n",
+      "    learn_time_ms: 8285.798\n",
+      "    sample_throughput: 13547.139\n",
+      "    sample_time_ms: 4478.584\n",
+      "    update_time_ms: 40.131\n",
+      "  timestamp: 1602428093\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2062848\n",
+      "  training_iteration: 34\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     13 |          320.676 | 2103296 |  238.055 |              290.242 |              115.788 |            817.549 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     34 |          442.888 | 2062848 |  236.342 |              294.657 |              118.293 |            820.739 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-20-18\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3492.986956521739\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-55-06\n",
       "  done: false\n",
-      "  episode_len_mean: 816.2442293373045\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.46138225140444\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 819.8332015810277\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 236.77975406236274\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 78\n",
+      "  episodes_total: 2530\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9013321816921234\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006421135948039591\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7546486258506775\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0058147438103333116\n",
       "        model: {}\n",
-      "        policy_loss: -0.021805241936817765\n",
-      "        total_loss: 2.9366058349609374\n",
-      "        vf_explained_var: 0.9931826591491699\n",
-      "        vf_loss: 2.9571268558502197\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
+      "        policy_loss: -0.012304193340241909\n",
+      "        total_loss: 10.538083553314209\n",
+      "        vf_explained_var: 0.980566680431366\n",
+      "        vf_loss: 10.549881935119629\n",
+      "    num_steps_sampled: 2123520\n",
+      "    num_steps_trained: 2123520\n",
+      "  iterations_since_restore: 35\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.642857142857146\n",
-      "    gpu_util_percent0: 0.30678571428571433\n",
+      "    cpu_util_percent: 33.042857142857144\n",
+      "    gpu_util_percent0: 0.285\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757142857142858\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.11634962282715648\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15866013164662812\n",
-      "    mean_env_wait_ms: 1.6796736234314602\n",
-      "    mean_inference_ms: 4.782626736230756\n",
-      "    mean_raw_obs_processing_ms: 0.42183995211689523\n",
-      "  time_since_restore: 344.8741044998169\n",
-      "  time_this_iter_s: 24.198456048965454\n",
-      "  time_total_s: 344.8741044998169\n",
+      "    mean_action_processing_ms: 0.1211656984847536\n",
+      "    mean_env_wait_ms: 0.6605341194347947\n",
+      "    mean_inference_ms: 4.682443660025644\n",
+      "    mean_raw_obs_processing_ms: 0.26469004825660664\n",
+      "  time_since_restore: 455.58453154563904\n",
+      "  time_this_iter_s: 12.696065664291382\n",
+      "  time_total_s: 455.58453154563904\n",
       "  timers:\n",
-      "    learn_throughput: 9964.721\n",
-      "    learn_time_ms: 16236.481\n",
-      "    sample_throughput: 20015.961\n",
-      "    sample_time_ms: 8083.149\n",
-      "    update_time_ms: 29.819\n",
-      "  timestamp: 1602166818\n",
+      "    learn_throughput: 7333.085\n",
+      "    learn_time_ms: 8273.735\n",
+      "    sample_throughput: 13553.674\n",
+      "    sample_time_ms: 4476.425\n",
+      "    update_time_ms: 38.036\n",
+      "  timestamp: 1602428106\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2123520\n",
+      "  training_iteration: 35\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     14 |          344.874 | 2265088 |  238.461 |              290.242 |              115.788 |            816.244 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     35 |          455.585 | 2123520 |   236.78 |              294.657 |              118.293 |            819.833 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-20-43\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3488.9290916059795\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-55-19\n",
       "  done: false\n",
-      "  episode_len_mean: 814.502106741573\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.95662736919752\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 162\n",
-      "  episodes_total: 2848\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 818.9126101954772\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 237.39458207990214\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 2609\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8737345904111862\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005880716699175536\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7400196939706802\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0058068325743079185\n",
       "        model: {}\n",
-      "        policy_loss: -0.023541058914270253\n",
-      "        total_loss: 2.77874299287796\n",
-      "        vf_explained_var: 0.9943079948425293\n",
-      "        vf_loss: 2.801107919216156\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
+      "        policy_loss: -0.013815922429785132\n",
+      "        total_loss: 10.05512261390686\n",
+      "        vf_explained_var: 0.9806376099586487\n",
+      "        vf_loss: 10.068431377410889\n",
+      "    num_steps_sampled: 2184192\n",
+      "    num_steps_trained: 2184192\n",
+      "  iterations_since_restore: 36\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.53793103448275\n",
-      "    gpu_util_percent0: 0.09275862068965515\n",
+      "    cpu_util_percent: 30.40666666666667\n",
+      "    gpu_util_percent0: 0.5099999999999999\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.77241379310345\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4066666666666663\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15844943627409838\n",
-      "    mean_env_wait_ms: 1.6816497328437465\n",
-      "    mean_inference_ms: 4.769681731783559\n",
-      "    mean_raw_obs_processing_ms: 0.42115262835775236\n",
-      "  time_since_restore: 369.2295935153961\n",
-      "  time_this_iter_s: 24.355489015579224\n",
-      "  time_total_s: 369.2295935153961\n",
+      "    mean_action_processing_ms: 0.12107590653974439\n",
+      "    mean_env_wait_ms: 0.6607655107133611\n",
+      "    mean_inference_ms: 4.674335427180369\n",
+      "    mean_raw_obs_processing_ms: 0.2644309335817367\n",
+      "  time_since_restore: 468.476092338562\n",
+      "  time_this_iter_s: 12.891560792922974\n",
+      "  time_total_s: 468.476092338562\n",
       "  timers:\n",
-      "    learn_throughput: 9970.424\n",
-      "    learn_time_ms: 16227.193\n",
-      "    sample_throughput: 20006.648\n",
-      "    sample_time_ms: 8086.912\n",
-      "    update_time_ms: 28.747\n",
-      "  timestamp: 1602166843\n",
+      "    learn_throughput: 7324.24\n",
+      "    learn_time_ms: 8283.727\n",
+      "    sample_throughput: 13568.691\n",
+      "    sample_time_ms: 4471.47\n",
+      "    update_time_ms: 39.449\n",
+      "  timestamp: 1602428119\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2184192\n",
+      "  training_iteration: 36\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     15 |           369.23 | 2426880 |  238.957 |              290.242 |              115.788 |            814.502 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     36 |          468.476 | 2184192 |  237.395 |              294.657 |              118.293 |            818.913 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-07\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3485.9352678571427\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-55-32\n",
       "  done: false\n",
-      "  episode_len_mean: 811.5661392405063\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.56847270170044\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 312\n",
-      "  episodes_total: 3160\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 818.0517113095239\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 237.84819173881675\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 2688\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.836417630314827\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005600748467259109\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7301702946424484\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005751452641561627\n",
       "        model: {}\n",
-      "        policy_loss: -0.019153478858061134\n",
-      "        total_loss: 3.4916038155555724\n",
-      "        vf_explained_var: 0.9944165349006653\n",
-      "        vf_loss: 3.5096370816230773\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
+      "        policy_loss: -0.013575302669778466\n",
+      "        total_loss: 9.521034479141235\n",
+      "        vf_explained_var: 0.982122540473938\n",
+      "        vf_loss: 9.534107208251953\n",
+      "    num_steps_sampled: 2244864\n",
+      "    num_steps_trained: 2244864\n",
+      "  iterations_since_restore: 37\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.9551724137931\n",
-      "    gpu_util_percent0: 0.43275862068965526\n",
+      "    cpu_util_percent: 30.453333333333333\n",
+      "    gpu_util_percent0: 0.37\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15809978406417496\n",
-      "    mean_env_wait_ms: 1.6853761096348427\n",
-      "    mean_inference_ms: 4.748027409045223\n",
-      "    mean_raw_obs_processing_ms: 0.42003623239671906\n",
-      "  time_since_restore: 393.7941789627075\n",
-      "  time_this_iter_s: 24.5645854473114\n",
-      "  time_total_s: 393.7941789627075\n",
+      "    mean_action_processing_ms: 0.12099014109422618\n",
+      "    mean_env_wait_ms: 0.6609919616885195\n",
+      "    mean_inference_ms: 4.666600035578396\n",
+      "    mean_raw_obs_processing_ms: 0.2641818136224133\n",
+      "  time_since_restore: 481.48514008522034\n",
+      "  time_this_iter_s: 13.009047746658325\n",
+      "  time_total_s: 481.48514008522034\n",
       "  timers:\n",
-      "    learn_throughput: 9977.021\n",
-      "    learn_time_ms: 16216.464\n",
-      "    sample_throughput: 19987.267\n",
-      "    sample_time_ms: 8094.753\n",
-      "    update_time_ms: 30.454\n",
-      "  timestamp: 1602166867\n",
+      "    learn_throughput: 7315.257\n",
+      "    learn_time_ms: 8293.899\n",
+      "    sample_throughput: 13581.942\n",
+      "    sample_time_ms: 4467.108\n",
+      "    update_time_ms: 39.054\n",
+      "  timestamp: 1602428132\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2244864\n",
+      "  training_iteration: 37\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     16 |          393.794 | 2588672 |  239.568 |              290.242 |              115.788 |            811.566 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     37 |          481.485 | 2244864 |  237.848 |              294.657 |              118.293 |            818.052 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-32\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3482.712942877802\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-55-45\n",
       "  done: false\n",
-      "  episode_len_mean: 810.3282097649186\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.7355501975754\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 817.2541576283442\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 238.33642279629268\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 78\n",
+      "  episodes_total: 2766\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8335719257593155\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006123062083497643\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7123904228210449\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006374098709784448\n",
       "        model: {}\n",
-      "        policy_loss: -0.020987965818494558\n",
-      "        total_loss: 2.507720983028412\n",
-      "        vf_explained_var: 0.9944343566894531\n",
-      "        vf_loss: 2.5274842858314512\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
+      "        policy_loss: -0.013502237037755549\n",
+      "        total_loss: 11.306285858154297\n",
+      "        vf_explained_var: 0.9792220592498779\n",
+      "        vf_loss: 11.319222211837769\n",
+      "    num_steps_sampled: 2305536\n",
+      "    num_steps_trained: 2305536\n",
+      "  iterations_since_restore: 38\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.18275862068966\n",
-      "    gpu_util_percent0: 0.27655172413793105\n",
+      "    cpu_util_percent: 31.77857142857142\n",
+      "    gpu_util_percent0: 0.3378571428571428\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.758620689655173\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.407142857142856\n",
+      "    vram_util_percent0: 0.11634962282715648\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15794348066077543\n",
-      "    mean_env_wait_ms: 1.687080352601384\n",
-      "    mean_inference_ms: 4.7382363513709365\n",
-      "    mean_raw_obs_processing_ms: 0.41954097731825146\n",
-      "  time_since_restore: 418.4777216911316\n",
-      "  time_this_iter_s: 24.683542728424072\n",
-      "  time_total_s: 418.4777216911316\n",
+      "    mean_action_processing_ms: 0.12090944212907186\n",
+      "    mean_env_wait_ms: 0.661212187696142\n",
+      "    mean_inference_ms: 4.659301530913864\n",
+      "    mean_raw_obs_processing_ms: 0.26394518537259776\n",
+      "  time_since_restore: 494.3030438423157\n",
+      "  time_this_iter_s: 12.817903757095337\n",
+      "  time_total_s: 494.3030438423157\n",
       "  timers:\n",
-      "    learn_throughput: 9984.096\n",
-      "    learn_time_ms: 16204.972\n",
-      "    sample_throughput: 19915.659\n",
-      "    sample_time_ms: 8123.859\n",
-      "    update_time_ms: 31.876\n",
-      "  timestamp: 1602166892\n",
+      "    learn_throughput: 7310.474\n",
+      "    learn_time_ms: 8299.325\n",
+      "    sample_throughput: 13589.213\n",
+      "    sample_time_ms: 4464.718\n",
+      "    update_time_ms: 40.492\n",
+      "  timestamp: 1602428145\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2305536\n",
+      "  training_iteration: 38\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     17 |          418.478 | 2750464 |  239.736 |              290.242 |              115.788 |            810.328 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-57\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     38 |          494.303 | 2305536 |  238.336 |              294.657 |              118.293 |            817.254 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3479.0738137082603\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-55-58\n",
       "  done: false\n",
-      "  episode_len_mean: 809.0097813578826\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.89810649649536\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 816.4987697715289\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 238.887806003799\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 2845\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.830751609802246\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005981297581456602\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7063906639814377\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006619708146899939\n",
       "        model: {}\n",
-      "        policy_loss: -0.023448871518485247\n",
-      "        total_loss: 2.440117084980011\n",
-      "        vf_explained_var: 0.994672954082489\n",
-      "        vf_loss: 2.462369680404663\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
+      "        policy_loss: -0.008540161070413888\n",
+      "        total_loss: 10.110114336013794\n",
+      "        vf_explained_var: 0.9805809855461121\n",
+      "        vf_loss: 10.118062973022461\n",
+      "    num_steps_sampled: 2366208\n",
+      "    num_steps_trained: 2366208\n",
+      "  iterations_since_restore: 39\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.78928571428572\n",
-      "    gpu_util_percent0: 0.04142857142857143\n",
+      "    cpu_util_percent: 31.06\n",
+      "    gpu_util_percent0: 0.2793333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.792857142857144\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15779369461228313\n",
-      "    mean_env_wait_ms: 1.6887300269221321\n",
-      "    mean_inference_ms: 4.729069241301459\n",
-      "    mean_raw_obs_processing_ms: 0.419066132995007\n",
-      "  time_since_restore: 442.8714327812195\n",
-      "  time_this_iter_s: 24.39371109008789\n",
-      "  time_total_s: 442.8714327812195\n",
+      "    mean_action_processing_ms: 0.12083054580488334\n",
+      "    mean_env_wait_ms: 0.6614261407606844\n",
+      "    mean_inference_ms: 4.652212114091645\n",
+      "    mean_raw_obs_processing_ms: 0.2637147061382379\n",
+      "  time_since_restore: 507.125301361084\n",
+      "  time_this_iter_s: 12.82225751876831\n",
+      "  time_total_s: 507.125301361084\n",
       "  timers:\n",
-      "    learn_throughput: 9977.82\n",
-      "    learn_time_ms: 16215.165\n",
-      "    sample_throughput: 19931.133\n",
-      "    sample_time_ms: 8117.551\n",
-      "    update_time_ms: 31.094\n",
-      "  timestamp: 1602166917\n",
+      "    learn_throughput: 7298.762\n",
+      "    learn_time_ms: 8312.643\n",
+      "    sample_throughput: 13637.273\n",
+      "    sample_time_ms: 4448.983\n",
+      "    update_time_ms: 40.687\n",
+      "  timestamp: 1602428158\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2366208\n",
+      "  training_iteration: 39\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     18 |          442.871 | 2912256 |  239.898 |              290.242 |              115.788 |             809.01 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     39 |          507.125 | 2366208 |  238.888 |              294.657 |              118.293 |            816.499 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-22-21\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3476.669859733151\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-56-11\n",
       "  done: false\n",
-      "  episode_len_mean: 806.8230485232068\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.2267639474917\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 815.7071501881628\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 239.25204145457312\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 78\n",
+      "  episodes_total: 2923\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7929262965917587\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005467748525552452\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6949535459280014\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005586441489867866\n",
       "        model: {}\n",
-      "        policy_loss: -0.018968340079300105\n",
-      "        total_loss: 3.431827688217163\n",
-      "        vf_explained_var: 0.9950782060623169\n",
-      "        vf_loss: 3.4497024059295653\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
+      "        policy_loss: -0.009916623908793554\n",
+      "        total_loss: 12.35196328163147\n",
+      "        vf_explained_var: 0.9776116609573364\n",
+      "        vf_loss: 12.361390352249146\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 40\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.99655172413794\n",
-      "    gpu_util_percent0: 0.27379310344827584\n",
+      "    cpu_util_percent: 30.84666666666667\n",
+      "    gpu_util_percent0: 0.328\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15751807790452294\n",
-      "    mean_env_wait_ms: 1.6918670821992567\n",
-      "    mean_inference_ms: 4.71261405039136\n",
-      "    mean_raw_obs_processing_ms: 0.41822277427376653\n",
-      "  time_since_restore: 467.25490164756775\n",
-      "  time_this_iter_s: 24.383468866348267\n",
-      "  time_total_s: 467.25490164756775\n",
+      "    mean_action_processing_ms: 0.12075583387622384\n",
+      "    mean_env_wait_ms: 0.6616118662427545\n",
+      "    mean_inference_ms: 4.645521398644301\n",
+      "    mean_raw_obs_processing_ms: 0.2634973274986382\n",
+      "  time_since_restore: 519.9028582572937\n",
+      "  time_this_iter_s: 12.777556896209717\n",
+      "  time_total_s: 519.9028582572937\n",
       "  timers:\n",
-      "    learn_throughput: 9975.719\n",
-      "    learn_time_ms: 16218.58\n",
-      "    sample_throughput: 19874.518\n",
-      "    sample_time_ms: 8140.676\n",
-      "    update_time_ms: 32.327\n",
-      "  timestamp: 1602166941\n",
+      "    learn_throughput: 7295.11\n",
+      "    learn_time_ms: 8316.804\n",
+      "    sample_throughput: 13658.482\n",
+      "    sample_time_ms: 4442.075\n",
+      "    update_time_ms: 41.178\n",
+      "  timestamp: 1602428171\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 40\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     19 |          467.255 | 3074048 |  240.227 |              290.242 |              115.788 |            806.823 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     40 |          519.903 | 2426880 |  239.252 |              294.657 |              118.293 |            815.707 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-22-46\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3473.2671552298466\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-56-23\n",
       "  done: false\n",
-      "  episode_len_mean: 805.7225316455696\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.49984400971735\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3950\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 814.9037308461026\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 239.76760274295256\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3002\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7794228792190552\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005526655982248485\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6896779984235764\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00545170099940151\n",
       "        model: {}\n",
-      "        policy_loss: -0.023039081250317395\n",
-      "        total_loss: 2.078591358661652\n",
-      "        vf_explained_var: 0.9953739047050476\n",
-      "        vf_loss: 2.1005250751972198\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
+      "        policy_loss: -0.006760447518900037\n",
+      "        total_loss: 10.799469709396362\n",
+      "        vf_explained_var: 0.9795577526092529\n",
+      "        vf_loss: 10.805754661560059\n",
+      "    num_steps_sampled: 2487552\n",
+      "    num_steps_trained: 2487552\n",
+      "  iterations_since_restore: 41\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.92068965517242\n",
-      "    gpu_util_percent0: 0.4165517241379311\n",
+      "    cpu_util_percent: 32.27142857142857\n",
+      "    gpu_util_percent0: 0.315\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.414285714285714\n",
+      "    vram_util_percent0: 0.11634962282715648\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1573904574836841\n",
-      "    mean_env_wait_ms: 1.6933221569620878\n",
-      "    mean_inference_ms: 4.705165325354333\n",
-      "    mean_raw_obs_processing_ms: 0.4178457110788417\n",
-      "  time_since_restore: 491.8251175880432\n",
-      "  time_this_iter_s: 24.570215940475464\n",
-      "  time_total_s: 491.8251175880432\n",
+      "    mean_action_processing_ms: 0.12068299758383619\n",
+      "    mean_env_wait_ms: 0.6618155184073969\n",
+      "    mean_inference_ms: 4.639004157673648\n",
+      "    mean_raw_obs_processing_ms: 0.26328312205898957\n",
+      "  time_since_restore: 532.7221517562866\n",
+      "  time_this_iter_s: 12.81929349899292\n",
+      "  time_total_s: 532.7221517562866\n",
       "  timers:\n",
-      "    learn_throughput: 9972.19\n",
-      "    learn_time_ms: 16224.319\n",
-      "    sample_throughput: 19829.965\n",
-      "    sample_time_ms: 8158.965\n",
-      "    update_time_ms: 31.231\n",
-      "  timestamp: 1602166966\n",
+      "    learn_throughput: 7307.809\n",
+      "    learn_time_ms: 8302.351\n",
+      "    sample_throughput: 13647.004\n",
+      "    sample_time_ms: 4445.811\n",
+      "    update_time_ms: 41.117\n",
+      "  timestamp: 1602428183\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2487552\n",
+      "  training_iteration: 41\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     20 |          491.825 | 3235840 |    240.5 |              290.242 |              115.788 |            805.723 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     41 |          532.722 | 2487552 |  239.768 |              294.657 |              118.293 |            814.904 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-23-11\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3469.998052580331\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-56-36\n",
       "  done: false\n",
-      "  episode_len_mean: 804.7280915287245\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.70876486382807\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 814.205452775073\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 240.26292132621253\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3081\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7865538984537125\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005757506913505494\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6865971684455872\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005908183171413839\n",
       "        model: {}\n",
-      "        policy_loss: -0.02310952057596296\n",
-      "        total_loss: 1.973700213432312\n",
-      "        vf_explained_var: 0.9953605532646179\n",
-      "        vf_loss: 1.9956582367420197\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
+      "        policy_loss: -0.013723642565310001\n",
+      "        total_loss: 10.921100378036499\n",
+      "        vf_explained_var: 0.9789117574691772\n",
+      "        vf_loss: 10.934301376342773\n",
+      "    num_steps_sampled: 2548224\n",
+      "    num_steps_trained: 2548224\n",
+      "  iterations_since_restore: 42\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.99655172413794\n",
-      "    gpu_util_percent0: 0.4148275862068965\n",
+      "    cpu_util_percent: 30.9\n",
+      "    gpu_util_percent0: 0.3646666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15726970308067142\n",
-      "    mean_env_wait_ms: 1.6947178273814376\n",
-      "    mean_inference_ms: 4.698130026253491\n",
-      "    mean_raw_obs_processing_ms: 0.4174790686263623\n",
-      "  time_since_restore: 516.4608044624329\n",
-      "  time_this_iter_s: 24.63568687438965\n",
-      "  time_total_s: 516.4608044624329\n",
+      "    mean_action_processing_ms: 0.12061345458390671\n",
+      "    mean_env_wait_ms: 0.6620150578185433\n",
+      "    mean_inference_ms: 4.632758214341117\n",
+      "    mean_raw_obs_processing_ms: 0.26307767477043403\n",
+      "  time_since_restore: 545.5967059135437\n",
+      "  time_this_iter_s: 12.87455415725708\n",
+      "  time_total_s: 545.5967059135437\n",
       "  timers:\n",
-      "    learn_throughput: 9977.798\n",
-      "    learn_time_ms: 16215.201\n",
-      "    sample_throughput: 19793.078\n",
-      "    sample_time_ms: 8174.171\n",
-      "    update_time_ms: 32.464\n",
-      "  timestamp: 1602166991\n",
+      "    learn_throughput: 7307.2\n",
+      "    learn_time_ms: 8303.043\n",
+      "    sample_throughput: 13609.269\n",
+      "    sample_time_ms: 4458.138\n",
+      "    update_time_ms: 32.909\n",
+      "  timestamp: 1602428196\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2548224\n",
+      "  training_iteration: 42\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     21 |          516.461 | 3397632 |  240.709 |              290.242 |              115.788 |            804.728 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     42 |          545.597 | 2548224 |  240.263 |              294.657 |              118.293 |            814.205 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-23-36\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3466.8977848101267\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-56-49\n",
       "  done: false\n",
-      "  episode_len_mean: 803.1457812144644\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.09711855879692\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 289\n",
-      "  episodes_total: 4397\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 813.7351265822784\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 240.73265886715257\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3160\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.755255714058876\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005404739850200712\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.673320397734642\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005441875662654638\n",
       "        model: {}\n",
-      "        policy_loss: -0.019464567000977696\n",
-      "        total_loss: 3.0453175783157347\n",
-      "        vf_explained_var: 0.9953736066818237\n",
-      "        vf_loss: 3.0637012124061584\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
+      "        policy_loss: -0.01596468430943787\n",
+      "        total_loss: 9.379735231399536\n",
+      "        vf_explained_var: 0.9821313619613647\n",
+      "        vf_loss: 9.395222902297974\n",
+      "    num_steps_sampled: 2608896\n",
+      "    num_steps_trained: 2608896\n",
+      "  iterations_since_restore: 43\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.010344827586216\n",
-      "    gpu_util_percent0: 0.25551724137931037\n",
+      "    cpu_util_percent: 32.01428571428571\n",
+      "    gpu_util_percent0: 0.3864285714285714\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4357142857142855\n",
+      "    vram_util_percent0: 0.11634962282715648\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15706065795015647\n",
-      "    mean_env_wait_ms: 1.6971458462496418\n",
-      "    mean_inference_ms: 4.686353824274288\n",
-      "    mean_raw_obs_processing_ms: 0.41688654879158077\n",
-      "  time_since_restore: 541.0245015621185\n",
-      "  time_this_iter_s: 24.56369709968567\n",
-      "  time_total_s: 541.0245015621185\n",
+      "    mean_action_processing_ms: 0.12054719299088809\n",
+      "    mean_env_wait_ms: 0.6622107411404029\n",
+      "    mean_inference_ms: 4.626774104338643\n",
+      "    mean_raw_obs_processing_ms: 0.262880171655244\n",
+      "  time_since_restore: 558.4876661300659\n",
+      "  time_this_iter_s: 12.890960216522217\n",
+      "  time_total_s: 558.4876661300659\n",
       "  timers:\n",
-      "    learn_throughput: 9974.186\n",
-      "    learn_time_ms: 16221.074\n",
-      "    sample_throughput: 19914.903\n",
-      "    sample_time_ms: 8124.167\n",
-      "    update_time_ms: 32.124\n",
-      "  timestamp: 1602167016\n",
+      "    learn_throughput: 7309.357\n",
+      "    learn_time_ms: 8300.593\n",
+      "    sample_throughput: 13590.475\n",
+      "    sample_time_ms: 4464.303\n",
+      "    update_time_ms: 32.743\n",
+      "  timestamp: 1602428209\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2608896\n",
+      "  training_iteration: 43\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     22 |          541.025 | 3559424 |  241.097 |              290.242 |              115.788 |            803.146 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     43 |          558.488 | 2608896 |  240.733 |              294.657 |              118.293 |            813.735 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-00\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3464.2837295461563\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-57-02\n",
       "  done: false\n",
-      "  episode_len_mean: 802.2247926669577\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.27666671075653\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 185\n",
-      "  episodes_total: 4582\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 813.19851806113\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 241.128727846542\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3239\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7225345104932785\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005478021572344005\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6631857454776764\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005600042990408838\n",
       "        model: {}\n",
-      "        policy_loss: -0.022186438925564288\n",
-      "        total_loss: 1.9642526030540466\n",
-      "        vf_explained_var: 0.9957612752914429\n",
-      "        vf_loss: 1.9853434622287751\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
-      "  iterations_since_restore: 23\n",
+      "        policy_loss: -0.013800082611851394\n",
+      "        total_loss: 8.741819620132446\n",
+      "        vf_explained_var: 0.983812153339386\n",
+      "        vf_loss: 8.755126237869263\n",
+      "    num_steps_sampled: 2669568\n",
+      "    num_steps_trained: 2669568\n",
+      "  iterations_since_restore: 44\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.33793103448276\n",
-      "    gpu_util_percent0: 0.43206896551724133\n",
+      "    cpu_util_percent: 31.633333333333326\n",
+      "    gpu_util_percent0: 0.24733333333333332\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.42\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1569378381550041\n",
-      "    mean_env_wait_ms: 1.698596232047108\n",
-      "    mean_inference_ms: 4.679417530334113\n",
-      "    mean_raw_obs_processing_ms: 0.4165376750547412\n",
-      "  time_since_restore: 565.687112569809\n",
-      "  time_this_iter_s: 24.66261100769043\n",
-      "  time_total_s: 565.687112569809\n",
+      "    mean_action_processing_ms: 0.12048383742756033\n",
+      "    mean_env_wait_ms: 0.6624026104425397\n",
+      "    mean_inference_ms: 4.621022230831381\n",
+      "    mean_raw_obs_processing_ms: 0.26269015779477184\n",
+      "  time_since_restore: 571.2364234924316\n",
+      "  time_this_iter_s: 12.748757362365723\n",
+      "  time_total_s: 571.2364234924316\n",
       "  timers:\n",
-      "    learn_throughput: 9968.382\n",
-      "    learn_time_ms: 16230.518\n",
-      "    sample_throughput: 19860.374\n",
-      "    sample_time_ms: 8146.473\n",
-      "    update_time_ms: 32.606\n",
-      "  timestamp: 1602167040\n",
+      "    learn_throughput: 7312.235\n",
+      "    learn_time_ms: 8297.326\n",
+      "    sample_throughput: 13605.7\n",
+      "    sample_time_ms: 4459.308\n",
+      "    update_time_ms: 32.534\n",
+      "  timestamp: 1602428222\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
-      "  training_iteration: 23\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2669568\n",
+      "  training_iteration: 44\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     23 |          565.687 | 3721216 |  241.277 |              290.242 |              115.788 |            802.225 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     44 |          571.236 | 2669568 |  241.129 |              294.657 |              118.293 |            813.199 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-25\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3461.2525617842075\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-57-15\n",
       "  done: false\n",
-      "  episode_len_mean: 801.512447257384\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.5184460640156\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4740\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 812.5304400241109\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 241.58799568926156\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3318\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7451686680316925\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005771003756672144\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6549868285655975\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.004678940866142511\n",
       "        model: {}\n",
-      "        policy_loss: -0.024150656536221504\n",
-      "        total_loss: 1.7480961799621582\n",
-      "        vf_explained_var: 0.9958817362785339\n",
-      "        vf_loss: 1.7710926413536072\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
+      "        policy_loss: -0.012409038899932057\n",
+      "        total_loss: 8.848819255828857\n",
+      "        vf_explained_var: 0.9826209545135498\n",
+      "        vf_loss: 8.860825538635254\n",
+      "    num_steps_sampled: 2730240\n",
+      "    num_steps_trained: 2730240\n",
+      "  iterations_since_restore: 45\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.81071428571429\n",
-      "    gpu_util_percent0: 0.16499999999999998\n",
+      "    cpu_util_percent: 31.566666666666666\n",
+      "    gpu_util_percent0: 0.364\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.782142857142857\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15683784552145583\n",
-      "    mean_env_wait_ms: 1.6997744080868349\n",
-      "    mean_inference_ms: 4.673850092393118\n",
-      "    mean_raw_obs_processing_ms: 0.4162613145590402\n",
-      "  time_since_restore: 590.1530044078827\n",
-      "  time_this_iter_s: 24.46589183807373\n",
-      "  time_total_s: 590.1530044078827\n",
+      "    mean_action_processing_ms: 0.12042257631144071\n",
+      "    mean_env_wait_ms: 0.6625899771759679\n",
+      "    mean_inference_ms: 4.615485161038933\n",
+      "    mean_raw_obs_processing_ms: 0.2625069356077095\n",
+      "  time_since_restore: 584.0689632892609\n",
+      "  time_this_iter_s: 12.832539796829224\n",
+      "  time_total_s: 584.0689632892609\n",
       "  timers:\n",
-      "    learn_throughput: 9968.406\n",
-      "    learn_time_ms: 16230.478\n",
-      "    sample_throughput: 19802.656\n",
-      "    sample_time_ms: 8170.217\n",
-      "    update_time_ms: 35.007\n",
-      "  timestamp: 1602167065\n",
+      "    learn_throughput: 7303.409\n",
+      "    learn_time_ms: 8307.354\n",
+      "    sample_throughput: 13601.312\n",
+      "    sample_time_ms: 4460.746\n",
+      "    update_time_ms: 34.857\n",
+      "  timestamp: 1602428235\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2730240\n",
+      "  training_iteration: 45\n",
+      "  trial_id: aa989_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     45 |          584.069 | 2730240 |  241.588 |              294.657 |              118.293 |             812.53 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3458.4942596408596\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-57-28\n",
+      "  done: false\n",
+      "  episode_len_mean: 811.9428907859876\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 242.00592025643545\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3397\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6498712301254272\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006043577450327575\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013496566331014037\n",
+      "        total_loss: 10.97796106338501\n",
+      "        vf_explained_var: 0.9792823791503906\n",
+      "        vf_loss: 10.991219997406006\n",
+      "    num_steps_sampled: 2790912\n",
+      "    num_steps_trained: 2790912\n",
+      "  iterations_since_restore: 46\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.646666666666665\n",
+      "    gpu_util_percent0: 0.38466666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 30378\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1203635101345648\n",
+      "    mean_env_wait_ms: 0.6627730494240113\n",
+      "    mean_inference_ms: 4.610156389481937\n",
+      "    mean_raw_obs_processing_ms: 0.26233076077496337\n",
+      "  time_since_restore: 596.9440293312073\n",
+      "  time_this_iter_s: 12.875066041946411\n",
+      "  time_total_s: 596.9440293312073\n",
+      "  timers:\n",
+      "    learn_throughput: 7315.02\n",
+      "    learn_time_ms: 8294.167\n",
+      "    sample_throughput: 13584.312\n",
+      "    sample_time_ms: 4466.329\n",
+      "    update_time_ms: 41.192\n",
+      "  timestamp: 1602428248\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2790912\n",
+      "  training_iteration: 46\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     24 |          590.153 | 3883008 |  241.518 |              290.242 |              115.788 |            801.512 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_aa989_00000 | RUNNING  | 172.17.0.4:30378 |     46 |          596.944 | 2790912 |  242.006 |              294.657 |              118.293 |            811.943 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_aa989_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-50\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3455.911104718067\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_14-57-41\n",
       "  done: true\n",
-      "  episode_len_mean: 800.4764492753624\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.8013874656386\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 228\n",
-      "  episodes_total: 4968\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 811.5350978135788\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 242.39730736594953\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: ba5f3505c1d7476591d2835c30dfda72\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7212436735630036\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00533560358453542\n",
+      "        cur_kl_coeff: 0.05\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6342495381832123\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006048538372851908\n",
       "        model: {}\n",
-      "        policy_loss: -0.020342798670753837\n",
-      "        total_loss: 2.63335440158844\n",
-      "        vf_explained_var: 0.9957489967346191\n",
-      "        vf_loss: 2.65263010263443\n",
-      "    num_steps_sampled: 4044800\n",
-      "    num_steps_trained: 4044800\n",
-      "  iterations_since_restore: 25\n",
+      "        policy_loss: -0.010996688564773649\n",
+      "        total_loss: 8.571913242340088\n",
+      "        vf_explained_var: 0.9842838048934937\n",
+      "        vf_loss: 8.582670211791992\n",
+      "    num_steps_sampled: 2851584\n",
+      "    num_steps_trained: 2851584\n",
+      "  iterations_since_restore: 47\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.09666666666667\n",
-      "    gpu_util_percent0: 0.22766666666666666\n",
+      "    cpu_util_percent: 32.285714285714285\n",
+      "    gpu_util_percent0: 0.09499999999999999\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746666666666668\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4642857142857144\n",
+      "    vram_util_percent0: 0.11634962282715648\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 30378\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15670386391308977\n",
-      "    mean_env_wait_ms: 1.7014434824573494\n",
-      "    mean_inference_ms: 4.66638510128689\n",
-      "    mean_raw_obs_processing_ms: 0.41590574797057145\n",
-      "  time_since_restore: 614.7696187496185\n",
-      "  time_this_iter_s: 24.61661434173584\n",
-      "  time_total_s: 614.7696187496185\n",
+      "    mean_action_processing_ms: 0.12030700443289846\n",
+      "    mean_env_wait_ms: 0.6629518989680405\n",
+      "    mean_inference_ms: 4.605029494850388\n",
+      "    mean_raw_obs_processing_ms: 0.26216238752738485\n",
+      "  time_since_restore: 609.7330024242401\n",
+      "  time_this_iter_s: 12.788973093032837\n",
+      "  time_total_s: 609.7330024242401\n",
       "  timers:\n",
-      "    learn_throughput: 9960.015\n",
-      "    learn_time_ms: 16244.153\n",
-      "    sample_throughput: 19778.628\n",
-      "    sample_time_ms: 8180.143\n",
-      "    update_time_ms: 36.793\n",
-      "  timestamp: 1602167090\n",
+      "    learn_throughput: 7324.169\n",
+      "    learn_time_ms: 8283.806\n",
+      "    sample_throughput: 13614.628\n",
+      "    sample_time_ms: 4456.383\n",
+      "    update_time_ms: 39.685\n",
+      "  timestamp: 1602428261\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4044800\n",
-      "  training_iteration: 25\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2851584\n",
+      "  training_iteration: 47\n",
+      "  trial_id: aa989_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | TERMINATED |       |     25 |           614.77 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
+      "| PPO_jss_env_aa989_00000 | TERMINATED |       |     47 |          609.733 | 2851584 |  242.397 |              294.657 |              118.293 |            811.535 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
+      "2020-10-11 14:57:41,835\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffe9f6a7cf01000000.\n",
+      "2020-10-11 14:57:41,835\tWARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffffd8f83c3801000000.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | TERMINATED |       |     25 |           614.77 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
+      "| PPO_jss_env_aa989_00000 | TERMINATED |       |     47 |          609.733 | 2851584 |  242.397 |              294.657 |              118.293 |            811.535 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 502\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m 2020-10-11 14:57:41,813\tERROR worker.py:372 -- SystemExit was raised from the worker\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m Traceback (most recent call last):\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/function_manager.py\", line 553, in actor_method_executor\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m     return method(actor, *args, **kwargs)\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/actor.py\", line 929, in __ray_terminate__\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m     ray.actor.exit_actor()\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/actor.py\", line 996, in exit_actor\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m     raise exit\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m SystemExit: 0\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m \n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m During handling of the above exception, another exception occurred:\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m \n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m Traceback (most recent call last):\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"python/ray/_raylet.pyx\", line 553, in ray._raylet.task_execution_handler\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"python/ray/_raylet.pyx\", line 440, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"python/ray/includes/libcoreworker.pxi\", line 33, in ray._raylet.ProfileEvent.__exit__\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"/root/miniconda3/lib/python3.8/traceback.py\", line 167, in format_exc\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m     return \"\".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"/root/miniconda3/lib/python3.8/traceback.py\", line 120, in format_exception\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m     return list(TracebackException(\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"/root/miniconda3/lib/python3.8/traceback.py\", line 509, in __init__\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m     self.stack = StackSummary.extract(\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"/root/miniconda3/lib/python3.8/traceback.py\", line 366, in extract\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m     f.line\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"/root/miniconda3/lib/python3.8/traceback.py\", line 288, in line\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m     self._line = linecache.getline(self.filename, self.lineno).strip()\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"/root/miniconda3/lib/python3.8/linecache.py\", line 16, in getline\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m     lines = getlines(filename, module_globals)\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"/root/miniconda3/lib/python3.8/linecache.py\", line 47, in getlines\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m     return updatecache(filename, module_globals)\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"/root/miniconda3/lib/python3.8/linecache.py\", line 136, in updatecache\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m     with tokenize.open(fullname) as fp:\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"/root/miniconda3/lib/python3.8/tokenize.py\", line 392, in open\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m     buffer = _builtin_open(filename, 'rb')\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 369, in sigterm_handler\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m     sys.exit(1)\n",
+      "\u001b[2m\u001b[36m(pid=30329)\u001b[0m SystemExit: 1\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m 2020-10-11 14:57:41,812\tERROR worker.py:372 -- SystemExit was raised from the worker\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m Traceback (most recent call last):\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m   File \"python/ray/_raylet.pyx\", line 553, in ray._raylet.task_execution_handler\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m   File \"python/ray/_raylet.pyx\", line 440, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m   File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m   File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m   File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/function_manager.py\", line 553, in actor_method_executor\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m     return method(actor, *args, **kwargs)\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/actor.py\", line 929, in __ray_terminate__\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m     ray.actor.exit_actor()\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/actor.py\", line 989, in exit_actor\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m     ray.disconnect()\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 1324, in disconnect\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m     ray_actor.ActorClassMethodMetadata.reset_cache()\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/actor.py\", line 185, in reset_cache\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m     cls._cache.clear()\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m   File \"/root/miniconda3/lib/python3.8/site-packages/ray/worker.py\", line 369, in sigterm_handler\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m     sys.exit(1)\n",
+      "\u001b[2m\u001b[36m(pid=30321)\u001b[0m SystemExit: 1\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2895, in get_loc\n",
+      "    return self._engine.get_loc(casted_key)\n",
+      "  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n",
+      "  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n",
+      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1675, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
+      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1683, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
+      "KeyError: 'custom_metrics/time_step_min'\n",
+      "\n",
+      "The above exception was the direct cause of the following exception:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 72, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 57, in train_func\n",
+      "    result = analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').to_dict('index')[0]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 92, in dataframe\n",
+      "    rows = self._retrieve_rows(metric=metric, mode=mode)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 254, in _retrieve_rows\n",
+      "    idx = df[metric].idxmin()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 2902, in __getitem__\n",
+      "    indexer = self.columns.get_loc(key)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2897, in get_loc\n",
+      "    raise KeyError(key) from err\n",
+      "KeyError: 'custom_metrics/time_step_min'\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 30152\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_141421-fpfrymi0/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_141421-fpfrymi0/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3125.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 629\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602167090\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 290.24242\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 235.34277\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1738\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 9\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▄▅▇█\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_144715-l3ysm1iu/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_144715-l3ysm1iu/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/fpfrymi0\u001b[0m\n",
-      "2020-10-08 14:25:03,027 - wandb.wandb_agent - INFO - Cleaning up finished run: fpfrymi0\n",
-      "2020-10-08 14:25:03,372 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:25:03,372 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 16384\n",
-      "2020-10-08 14:25:03,376 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=16384\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlegendary-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/l3ysm1iu\u001b[0m\n",
+      "2020-10-11 14:57:49,754 - wandb.wandb_agent - INFO - Cleaning up finished run: l3ysm1iu\n",
+      "2020-10-11 14:57:50,133 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 14:57:50,133 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tnum_envs_per_worker: 1\n",
+      "\trollout_fragment_length: 1024\n",
+      "2020-10-11 14:57:50,135 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --num_envs_per_worker=1 --rollout_fragment_length=1024\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-11 14:57:55,150 - wandb.wandb_agent - INFO - Running runs: ['17fqd0cs']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmajor-sweep-3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/w8c2p6ff\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_142505-w8c2p6ff\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcrimson-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/8x5lxuul\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/17fqd0cs\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_145751-17fqd0cs\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 14:25:07,555\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:25:08,410 - wandb.wandb_agent - INFO - Running runs: ['w8c2p6ff']\n",
+      "2020-10-11 14:57:55,872\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=33202)\u001b[0m 2020-10-08 14:25:10,570\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=33230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33185)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33185)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33246)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33246)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33192)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33192)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33208)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33208)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33188)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33188)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33095)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33095)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33175)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33175)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33196)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33196)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33186)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33186)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33100)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33098)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33098)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33183)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33183)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33211)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33211)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33180)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33180)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33093)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33093)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33179)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33179)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33193)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33193)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33189)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33189)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33172)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33172)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33194)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33194)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-25-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "\u001b[2m\u001b[36m(pid=79049)\u001b[0m 2020-10-11 14:57:58,580\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=79037)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79037)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79006)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79006)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78986)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78986)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79032)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79032)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79047)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79047)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79081)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79081)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79071)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79071)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79029)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79029)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79079)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79079)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79035)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79035)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79092)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79092)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79043)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79043)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78972)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78972)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79075)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79075)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79056)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79056)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78974)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78974)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79004)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79004)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78965)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78965)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78988)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78988)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78990)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78990)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79053)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79053)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78993)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78993)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79074)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79074)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78985)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78985)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78963)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78963)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78975)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78975)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79057)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79057)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78981)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78981)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79089)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79089)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79087)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79087)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79009)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79009)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79048)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79048)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79082)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79082)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79085)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79085)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79031)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79031)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79011)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79011)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79067)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79067)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78956)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78956)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78958)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78958)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78982)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78982)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79050)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79050)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79076)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79076)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78987)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78987)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79036)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79036)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78971)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78971)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79034)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79034)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78960)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78960)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78957)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78957)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79014)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79014)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78968)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78968)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79055)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79055)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78955)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78955)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79023)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79023)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78973)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78973)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79042)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79042)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78979)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78979)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78967)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78967)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79054)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79054)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79028)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79028)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79083)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79083)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79026)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79026)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79007)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79007)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78966)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78966)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79063)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79063)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78983)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78983)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79046)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79046)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79020)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79020)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78954)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78954)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79030)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79030)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78970)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78970)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79024)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79024)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78961)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78961)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78962)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78962)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=78959)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=78959)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3604.8101265822784\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_14-58-23\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.0759493670886\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 219.83684950773548\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 79\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4670,2503 +4463,2213 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1623204231262207\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0048057976178824905\n",
-      "        model: {}\n",
-      "        policy_loss: -0.00972368239890784\n",
-      "        total_loss: 8.319466400146485\n",
-      "        vf_explained_var: 0.7498777508735657\n",
-      "        vf_loss: 8.328228569030761\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1821814060211182\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005178337823599577\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008954001311212777\n",
+      "        total_loss: 598.7196044921875\n",
+      "        vf_explained_var: 0.23389902710914612\n",
+      "        vf_loss: 598.7276489257813\n",
+      "    num_steps_sampled: 80896\n",
+      "    num_steps_trained: 80896\n",
       "  iterations_since_restore: 1\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 37.63333333333333\n",
-      "    gpu_util_percent0: 0.26266666666666666\n",
+      "    cpu_util_percent: 37.00869565217391\n",
+      "    gpu_util_percent0: 0.28130434782608693\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0003333333333333333\n",
-      "    ram_util_percent: 9.49\n",
-      "    vram_util_percent0: 0.2729856783644911\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.3260869565217397\n",
+      "    vram_util_percent0: 0.08697434654270111\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17678140968259154\n",
-      "    mean_env_wait_ms: 1.6502532711659141\n",
-      "    mean_inference_ms: 5.870735121936333\n",
-      "    mean_raw_obs_processing_ms: 0.4788182656976241\n",
-      "  time_since_restore: 25.622228860855103\n",
-      "  time_this_iter_s: 25.622228860855103\n",
-      "  time_total_s: 25.622228860855103\n",
+      "    mean_action_processing_ms: 0.1405497560091834\n",
+      "    mean_env_wait_ms: 0.6502708059359789\n",
+      "    mean_inference_ms: 5.734528894592265\n",
+      "    mean_raw_obs_processing_ms: 0.3117136883124704\n",
+      "  time_since_restore: 19.361814737319946\n",
+      "  time_this_iter_s: 19.361814737319946\n",
+      "  time_total_s: 19.361814737319946\n",
       "  timers:\n",
-      "    learn_throughput: 10340.312\n",
-      "    learn_time_ms: 15646.724\n",
-      "    sample_throughput: 16338.488\n",
-      "    sample_time_ms: 9902.507\n",
-      "    update_time_ms: 42.975\n",
-      "  timestamp: 1602167142\n",
+      "    learn_throughput: 7390.735\n",
+      "    learn_time_ms: 10945.596\n",
+      "    sample_throughput: 9696.284\n",
+      "    sample_time_ms: 8342.99\n",
+      "    update_time_ms: 38.486\n",
+      "  timestamp: 1602428303\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
+      "  timesteps_total: 80896\n",
       "  training_iteration: 1\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.8/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      1 |          25.6222 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |      1 |          19.3618 | 80896 |  219.837 |              273.444 |              149.354 |            891.076 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-06\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3613.8734177215188\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_14-58-41\n",
       "  done: false\n",
-      "  episode_len_mean: 870.7974683544304\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 226.3724267996418\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 890.2088607594936\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 218.46362357754748\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.138706338405609\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006825200421735645\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01274334719637409\n",
-      "        total_loss: 7.690042400360108\n",
-      "        vf_explained_var: 0.8869457244873047\n",
-      "        vf_loss: 7.702103328704834\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1610076427459717\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005721182934939862\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010106014460325241\n",
+      "        total_loss: 247.57249755859374\n",
+      "        vf_explained_var: 0.652772068977356\n",
+      "        vf_loss: 247.58157653808593\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
       "  iterations_since_restore: 2\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 35.425925925925924\n",
-      "    gpu_util_percent0: 0.3437037037037037\n",
+      "    cpu_util_percent: 34.18571428571429\n",
+      "    gpu_util_percent0: 0.3076190476190476\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.73703703703704\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4666666666666672\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17196632938280343\n",
-      "    mean_env_wait_ms: 1.646491991621751\n",
-      "    mean_inference_ms: 5.588687582318563\n",
-      "    mean_raw_obs_processing_ms: 0.467505042931231\n",
-      "  time_since_restore: 49.39094591140747\n",
-      "  time_this_iter_s: 23.768717050552368\n",
-      "  time_total_s: 49.39094591140747\n",
+      "    mean_action_processing_ms: 0.136365787780534\n",
+      "    mean_env_wait_ms: 0.6471527892022945\n",
+      "    mean_inference_ms: 5.543648386724649\n",
+      "    mean_raw_obs_processing_ms: 0.30285141011200317\n",
+      "  time_since_restore: 37.04883170127869\n",
+      "  time_this_iter_s: 17.68701696395874\n",
+      "  time_total_s: 37.04883170127869\n",
       "  timers:\n",
-      "    learn_throughput: 10452.268\n",
-      "    learn_time_ms: 15479.129\n",
-      "    sample_throughput: 17702.943\n",
-      "    sample_time_ms: 9139.271\n",
-      "    update_time_ms: 38.137\n",
-      "  timestamp: 1602167166\n",
+      "    learn_throughput: 7469.926\n",
+      "    learn_time_ms: 10829.558\n",
+      "    sample_throughput: 10613.329\n",
+      "    sample_time_ms: 7622.113\n",
+      "    update_time_ms: 37.121\n",
+      "  timestamp: 1602428321\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
+      "  timesteps_total: 161792\n",
       "  training_iteration: 2\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 26.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      2 |          49.3909 | 323584 |  226.372 |              278.354 |              115.788 |            870.797 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |      2 |          37.0488 | 161792 |  218.464 |              273.444 |              149.354 |            890.209 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-30\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3614.9113924050635\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_14-58-58\n",
       "  done: false\n",
-      "  episode_len_mean: 866.331223628692\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 226.87126539658163\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 888.590717299578\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 218.30635468610134\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 237\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1217446804046631\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007683717552572489\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014337884564884006\n",
-      "        total_loss: 8.763248443603516\n",
-      "        vf_explained_var: 0.9284197092056274\n",
-      "        vf_loss: 8.77681770324707\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.159032130241394\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0057226565666496755\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01224328400567174\n",
+      "        total_loss: 104.11964721679688\n",
+      "        vf_explained_var: 0.8229959607124329\n",
+      "        vf_loss: 104.13086395263672\n",
+      "    num_steps_sampled: 242688\n",
+      "    num_steps_trained: 242688\n",
       "  iterations_since_restore: 3\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.08620689655172\n",
-      "    gpu_util_percent0: 0.3172413793103448\n",
+      "    cpu_util_percent: 34.3\n",
+      "    gpu_util_percent0: 0.31315789473684214\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16894469760208242\n",
-      "    mean_env_wait_ms: 1.6450424063300917\n",
-      "    mean_inference_ms: 5.427040881695507\n",
-      "    mean_raw_obs_processing_ms: 0.45877313240781425\n",
-      "  time_since_restore: 73.57178139686584\n",
-      "  time_this_iter_s: 24.180835485458374\n",
-      "  time_total_s: 73.57178139686584\n",
+      "    mean_action_processing_ms: 0.13348297467848136\n",
+      "    mean_env_wait_ms: 0.6450977775609045\n",
+      "    mean_inference_ms: 5.3758693242674385\n",
+      "    mean_raw_obs_processing_ms: 0.2962846117850065\n",
+      "  time_since_restore: 53.9220027923584\n",
+      "  time_this_iter_s: 16.873171091079712\n",
+      "  time_total_s: 53.9220027923584\n",
       "  timers:\n",
-      "    learn_throughput: 10452.901\n",
-      "    learn_time_ms: 15478.191\n",
-      "    sample_throughput: 18089.282\n",
-      "    sample_time_ms: 8944.081\n",
-      "    update_time_ms: 56.055\n",
-      "  timestamp: 1602167190\n",
+      "    learn_throughput: 7508.142\n",
+      "    learn_time_ms: 10774.437\n",
+      "    sample_throughput: 11342.181\n",
+      "    sample_time_ms: 7132.314\n",
+      "    update_time_ms: 32.058\n",
+      "  timestamp: 1602428338\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
+      "  timesteps_total: 242688\n",
       "  training_iteration: 3\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 26.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      3 |          73.5718 | 485376 |  226.871 |              278.354 |              115.788 |            866.331 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |      3 |           53.922 | 242688 |  218.306 |              273.444 |               146.02 |            888.591 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-54\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3604.6075949367087\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_14-59-15\n",
       "  done: false\n",
-      "  episode_len_mean: 861.253164556962\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 227.7450294080039\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 886.3354430379746\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 219.86753612070044\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0939712405204773\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.009209706541150808\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015771377924829723\n",
-      "        total_loss: 8.429035234451295\n",
-      "        vf_explained_var: 0.9521434903144836\n",
-      "        vf_loss: 8.443885612487794\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.142055583000183\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006965293735265732\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013879792392253875\n",
+      "        total_loss: 68.49144897460937\n",
+      "        vf_explained_var: 0.8709942698478699\n",
+      "        vf_loss: 68.504052734375\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 4\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 35.03333333333334\n",
-      "    gpu_util_percent0: 0.2777777777777778\n",
+      "    cpu_util_percent: 32.6\n",
+      "    gpu_util_percent0: 0.30350000000000005\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16676384022481172\n",
-      "    mean_env_wait_ms: 1.6466515242102222\n",
-      "    mean_inference_ms: 5.307577815654116\n",
-      "    mean_raw_obs_processing_ms: 0.4522795805237597\n",
-      "  time_since_restore: 97.21736693382263\n",
-      "  time_this_iter_s: 23.645585536956787\n",
-      "  time_total_s: 97.21736693382263\n",
+      "    mean_action_processing_ms: 0.131492585828327\n",
+      "    mean_env_wait_ms: 0.6436242496916351\n",
+      "    mean_inference_ms: 5.253438706090032\n",
+      "    mean_raw_obs_processing_ms: 0.29135991605414235\n",
+      "  time_since_restore: 70.88383412361145\n",
+      "  time_this_iter_s: 16.96183133125305\n",
+      "  time_total_s: 70.88383412361145\n",
       "  timers:\n",
-      "    learn_throughput: 10478.311\n",
-      "    learn_time_ms: 15440.657\n",
-      "    sample_throughput: 18466.869\n",
-      "    sample_time_ms: 8761.204\n",
-      "    update_time_ms: 52.666\n",
-      "  timestamp: 1602167214\n",
+      "    learn_throughput: 7529.185\n",
+      "    learn_time_ms: 10744.323\n",
+      "    sample_throughput: 11702.96\n",
+      "    sample_time_ms: 6912.439\n",
+      "    update_time_ms: 28.741\n",
+      "  timestamp: 1602428355\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
+      "  timesteps_total: 323584\n",
       "  training_iteration: 4\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      4 |          97.2174 | 647168 |  227.745 |              278.354 |              115.788 |            861.253 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |      4 |          70.8838 | 323584 |  219.868 |              273.444 |               146.02 |            886.335 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-27-17\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3599.4151898734176\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_14-59-32\n",
       "  done: false\n",
-      "  episode_len_mean: 849.2613882863341\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 228.4696860141544\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 290\n",
-      "  episodes_total: 922\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 884.0708860759494\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 220.6542641605931\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 395\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0592716097831727\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007743995590135455\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014329827937763185\n",
-      "        total_loss: 12.433664703369141\n",
-      "        vf_explained_var: 0.967904269695282\n",
-      "        vf_loss: 12.447219848632812\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1255623817443847\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006865937076508999\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0142045047134161\n",
+      "        total_loss: 57.66709518432617\n",
+      "        vf_explained_var: 0.8982939720153809\n",
+      "        vf_loss: 57.68003768920899\n",
+      "    num_steps_sampled: 404480\n",
+      "    num_steps_trained: 404480\n",
       "  iterations_since_restore: 5\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.35357142857143\n",
-      "    gpu_util_percent0: 0.2582142857142857\n",
+      "    cpu_util_percent: 31.765000000000008\n",
+      "    gpu_util_percent0: 0.33649999999999997\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16431055835082262\n",
-      "    mean_env_wait_ms: 1.6540874340682217\n",
-      "    mean_inference_ms: 5.1659246506223315\n",
-      "    mean_raw_obs_processing_ms: 0.4451297976580212\n",
-      "  time_since_restore: 120.98013472557068\n",
-      "  time_this_iter_s: 23.762767791748047\n",
-      "  time_total_s: 120.98013472557068\n",
+      "    mean_action_processing_ms: 0.13000907587399763\n",
+      "    mean_env_wait_ms: 0.6429696938711666\n",
+      "    mean_inference_ms: 5.160756409573132\n",
+      "    mean_raw_obs_processing_ms: 0.28765939963701187\n",
+      "  time_since_restore: 87.75734639167786\n",
+      "  time_this_iter_s: 16.873512268066406\n",
+      "  time_total_s: 87.75734639167786\n",
       "  timers:\n",
-      "    learn_throughput: 10471.141\n",
-      "    learn_time_ms: 15451.229\n",
-      "    sample_throughput: 18710.121\n",
-      "    sample_time_ms: 8647.299\n",
-      "    update_time_ms: 46.768\n",
-      "  timestamp: 1602167237\n",
+      "    learn_throughput: 7544.609\n",
+      "    learn_time_ms: 10722.358\n",
+      "    sample_throughput: 11960.587\n",
+      "    sample_time_ms: 6763.548\n",
+      "    update_time_ms: 29.055\n",
+      "  timestamp: 1602428372\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
+      "  timesteps_total: 404480\n",
       "  training_iteration: 5\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 26.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      5 |           120.98 | 808960 |   228.47 |              278.354 |              115.788 |            849.261 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |      5 |          87.7573 | 404480 |  220.654 |              273.444 |               146.02 |            884.071 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-27-41\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3588.4762808349146\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_14-59-48\n",
       "  done: false\n",
-      "  episode_len_mean: 842.2649186256781\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 228.83911447202573\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 184\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 876.9468690702088\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 222.31167462097235\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 132\n",
+      "  episodes_total: 527\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0483574509620666\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007546161720529199\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015934903593733906\n",
-      "        total_loss: 6.211568450927734\n",
-      "        vf_explained_var: 0.979483425617218\n",
-      "        vf_loss: 6.22674880027771\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1013608694076538\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006304158177226782\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016743747983127832\n",
+      "        total_loss: 61.22104263305664\n",
+      "        vf_explained_var: 0.9264847636222839\n",
+      "        vf_loss: 61.23663177490234\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 6\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.42962962962963\n",
-      "    gpu_util_percent0: 0.23518518518518516\n",
+      "    cpu_util_percent: 32.31\n",
+      "    gpu_util_percent0: 0.29600000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.475\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16320835121240662\n",
-      "    mean_env_wait_ms: 1.658072254904595\n",
-      "    mean_inference_ms: 5.101929976377745\n",
-      "    mean_raw_obs_processing_ms: 0.44197622201871506\n",
-      "  time_since_restore: 144.46361637115479\n",
-      "  time_this_iter_s: 23.483481645584106\n",
-      "  time_total_s: 144.46361637115479\n",
+      "    mean_action_processing_ms: 0.12829810238146183\n",
+      "    mean_env_wait_ms: 0.6432681475441565\n",
+      "    mean_inference_ms: 5.050175191309327\n",
+      "    mean_raw_obs_processing_ms: 0.2834020367570414\n",
+      "  time_since_restore: 104.622731924057\n",
+      "  time_this_iter_s: 16.86538553237915\n",
+      "  time_total_s: 104.622731924057\n",
       "  timers:\n",
-      "    learn_throughput: 10482.756\n",
-      "    learn_time_ms: 15434.108\n",
-      "    sample_throughput: 18930.618\n",
-      "    sample_time_ms: 8546.578\n",
-      "    update_time_ms: 45.48\n",
-      "  timestamp: 1602167261\n",
+      "    learn_throughput: 7563.922\n",
+      "    learn_time_ms: 10694.98\n",
+      "    sample_throughput: 12132.549\n",
+      "    sample_time_ms: 6667.684\n",
+      "    update_time_ms: 26.851\n",
+      "  timestamp: 1602428388\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
+      "  timesteps_total: 485376\n",
       "  training_iteration: 6\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      6 |          144.464 | 970752 |  228.839 |              278.354 |              115.788 |            842.265 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |      6 |          104.623 | 485376 |  222.312 |              273.444 |               146.02 |            876.947 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-05\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3579.4794303797466\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_15-00-05\n",
       "  done: false\n",
-      "  episode_len_mean: 837.381329113924\n",
-      "  episode_reward_max: 279.83838383838383\n",
-      "  episode_reward_mean: 228.88543664493022\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 872.9651898734177\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 223.67483378084626\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 105\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0276257395744324\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006892968993633985\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01625481452792883\n",
-      "        total_loss: 5.934515047073364\n",
-      "        vf_explained_var: 0.9834254384040833\n",
-      "        vf_loss: 5.950080394744873\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1148772478103637\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00640232590958476\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01414772029966116\n",
+      "        total_loss: 40.958674621582034\n",
+      "        vf_explained_var: 0.9319775700569153\n",
+      "        vf_loss: 40.97165451049805\n",
+      "    num_steps_sampled: 566272\n",
+      "    num_steps_trained: 566272\n",
       "  iterations_since_restore: 7\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.47777777777778\n",
-      "    gpu_util_percent0: 0.2955555555555555\n",
+      "    cpu_util_percent: 33.463157894736845\n",
+      "    gpu_util_percent0: 0.3436842105263158\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.478947368421052\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16243749898577767\n",
-      "    mean_env_wait_ms: 1.6615503416153818\n",
-      "    mean_inference_ms: 5.056720554339727\n",
-      "    mean_raw_obs_processing_ms: 0.439742077717109\n",
-      "  time_since_restore: 168.09322547912598\n",
-      "  time_this_iter_s: 23.62960910797119\n",
-      "  time_total_s: 168.09322547912598\n",
+      "    mean_action_processing_ms: 0.12731261365806423\n",
+      "    mean_env_wait_ms: 0.6432604682631025\n",
+      "    mean_inference_ms: 4.986517843354875\n",
+      "    mean_raw_obs_processing_ms: 0.28088197454716307\n",
+      "  time_since_restore: 121.37148237228394\n",
+      "  time_this_iter_s: 16.74875044822693\n",
+      "  time_total_s: 121.37148237228394\n",
       "  timers:\n",
-      "    learn_throughput: 10486.247\n",
-      "    learn_time_ms: 15428.971\n",
-      "    sample_throughput: 19063.221\n",
-      "    sample_time_ms: 8487.128\n",
-      "    update_time_ms: 45.241\n",
-      "  timestamp: 1602167285\n",
+      "    learn_throughput: 7575.314\n",
+      "    learn_time_ms: 10678.897\n",
+      "    sample_throughput: 12278.622\n",
+      "    sample_time_ms: 6588.361\n",
+      "    update_time_ms: 25.698\n",
+      "  timestamp: 1602428405\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
+      "  timesteps_total: 566272\n",
       "  training_iteration: 7\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      7 |          168.093 | 1132544 |  228.885 |              279.838 |              115.788 |            837.381 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |      7 |          121.371 | 566272 |  223.675 |              273.444 |               146.02 |            872.965 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-28\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3571.4486638537273\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_15-00-22\n",
       "  done: false\n",
-      "  episode_len_mean: 833.6736990154711\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 229.3878233814942\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 869.395218002813\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 224.891616587819\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 711\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9920619606971741\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0067844231147319075\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01662699868902564\n",
-      "        total_loss: 5.330079460144043\n",
-      "        vf_explained_var: 0.9873720407485962\n",
-      "        vf_loss: 5.346027898788452\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0891266345977784\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006864890549331903\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012392168352380394\n",
+      "        total_loss: 29.909460067749023\n",
+      "        vf_explained_var: 0.9454657435417175\n",
+      "        vf_loss: 29.92058868408203\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 8\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.72222222222223\n",
-      "    gpu_util_percent0: 0.2811111111111111\n",
+      "    cpu_util_percent: 31.905\n",
+      "    gpu_util_percent0: 0.316\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16179048159969586\n",
-      "    mean_env_wait_ms: 1.664834322637065\n",
-      "    mean_inference_ms: 5.017627986563437\n",
-      "    mean_raw_obs_processing_ms: 0.43762471876215703\n",
-      "  time_since_restore: 191.7211263179779\n",
-      "  time_this_iter_s: 23.62790083885193\n",
-      "  time_total_s: 191.7211263179779\n",
+      "    mean_action_processing_ms: 0.12671245780329993\n",
+      "    mean_env_wait_ms: 0.6434006338525907\n",
+      "    mean_inference_ms: 4.94725769618157\n",
+      "    mean_raw_obs_processing_ms: 0.2793458640278308\n",
+      "  time_since_restore: 138.17620182037354\n",
+      "  time_this_iter_s: 16.8047194480896\n",
+      "  time_total_s: 138.17620182037354\n",
       "  timers:\n",
-      "    learn_throughput: 10499.739\n",
-      "    learn_time_ms: 15409.145\n",
-      "    sample_throughput: 19126.146\n",
-      "    sample_time_ms: 8459.205\n",
-      "    update_time_ms: 44.366\n",
-      "  timestamp: 1602167308\n",
+      "    learn_throughput: 7579.728\n",
+      "    learn_time_ms: 10672.678\n",
+      "    sample_throughput: 12388.977\n",
+      "    sample_time_ms: 6529.675\n",
+      "    update_time_ms: 25.023\n",
+      "  timestamp: 1602428422\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
+      "  timesteps_total: 647168\n",
       "  training_iteration: 8\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      8 |          191.721 | 1294336 |  229.388 |              281.606 |              115.788 |            833.674 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |      8 |          138.176 | 647168 |  224.892 |              273.444 |               146.02 |            869.395 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-52\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3564.345569620253\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_15-00-39\n",
       "  done: false\n",
-      "  episode_len_mean: 827.9994246260069\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 229.99320593739455\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 1738\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 866.1582278481013\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 225.96784298683022\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9606243968009949\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005957465758547187\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013455570582300425\n",
-      "        total_loss: 7.494734096527099\n",
-      "        vf_explained_var: 0.9888100624084473\n",
-      "        vf_loss: 7.5075939178466795\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0771050453186035\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006526902969926596\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0148372957482934\n",
+      "        total_loss: 26.008992385864257\n",
+      "        vf_explained_var: 0.9503160715103149\n",
+      "        vf_loss: 26.0226318359375\n",
+      "    num_steps_sampled: 728064\n",
+      "    num_steps_trained: 728064\n",
       "  iterations_since_restore: 9\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.90357142857143\n",
-      "    gpu_util_percent0: 0.26678571428571424\n",
+      "    cpu_util_percent: 32.395\n",
+      "    gpu_util_percent0: 0.3565\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16076244116115793\n",
-      "    mean_env_wait_ms: 1.6704480394177186\n",
-      "    mean_inference_ms: 4.955192966914281\n",
-      "    mean_raw_obs_processing_ms: 0.4343471050403994\n",
-      "  time_since_restore: 215.57324147224426\n",
-      "  time_this_iter_s: 23.852115154266357\n",
-      "  time_total_s: 215.57324147224426\n",
+      "    mean_action_processing_ms: 0.12618623072965274\n",
+      "    mean_env_wait_ms: 0.6435788954968152\n",
+      "    mean_inference_ms: 4.912974030587078\n",
+      "    mean_raw_obs_processing_ms: 0.2779692896540916\n",
+      "  time_since_restore: 155.11791062355042\n",
+      "  time_this_iter_s: 16.94170880317688\n",
+      "  time_total_s: 155.11791062355042\n",
       "  timers:\n",
-      "    learn_throughput: 10506.415\n",
-      "    learn_time_ms: 15399.353\n",
-      "    sample_throughput: 19131.856\n",
-      "    sample_time_ms: 8456.681\n",
-      "    update_time_ms: 41.666\n",
-      "  timestamp: 1602167332\n",
+      "    learn_throughput: 7578.867\n",
+      "    learn_time_ms: 10673.891\n",
+      "    sample_throughput: 12458.636\n",
+      "    sample_time_ms: 6493.167\n",
+      "    update_time_ms: 24.348\n",
+      "  timestamp: 1602428439\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
+      "  timesteps_total: 728064\n",
       "  training_iteration: 9\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      9 |          215.573 | 1456128 |  229.993 |              281.606 |              114.747 |            827.999 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |      9 |          155.118 | 728064 |  225.968 |              273.444 |               146.02 |            866.158 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-29-16\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3557.8855835240274\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_15-00-56\n",
       "  done: false\n",
-      "  episode_len_mean: 826.5395569620254\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.1556546477432\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 862.9096109839817\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 226.94662875898564\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 84\n",
+      "  episodes_total: 874\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9285854279994965\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0062581704463809725\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016021200059913098\n",
-      "        total_loss: 3.8204103231430055\n",
-      "        vf_explained_var: 0.9922056198120117\n",
-      "        vf_loss: 3.835805630683899\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0427801609039307\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006021166313439607\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010975334793329239\n",
+      "        total_loss: 26.823484039306642\n",
+      "        vf_explained_var: 0.9570068120956421\n",
+      "        vf_loss: 26.833358764648438\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 10\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.096296296296295\n",
-      "    gpu_util_percent0: 0.25592592592592595\n",
+      "    cpu_util_percent: 32.36\n",
+      "    gpu_util_percent0: 0.31799999999999995\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4850000000000003\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1603412050605606\n",
-      "    mean_env_wait_ms: 1.6728638400028686\n",
-      "    mean_inference_ms: 4.929926052491426\n",
-      "    mean_raw_obs_processing_ms: 0.4330192737930434\n",
-      "  time_since_restore: 238.919837474823\n",
-      "  time_this_iter_s: 23.346596002578735\n",
-      "  time_total_s: 238.919837474823\n",
+      "    mean_action_processing_ms: 0.1257158946165379\n",
+      "    mean_env_wait_ms: 0.6439133970724744\n",
+      "    mean_inference_ms: 4.881427813012746\n",
+      "    mean_raw_obs_processing_ms: 0.2766901551134662\n",
+      "  time_since_restore: 172.2000482082367\n",
+      "  time_this_iter_s: 17.08213758468628\n",
+      "  time_total_s: 172.2000482082367\n",
       "  timers:\n",
-      "    learn_throughput: 10519.707\n",
-      "    learn_time_ms: 15379.897\n",
-      "    sample_throughput: 19222.536\n",
-      "    sample_time_ms: 8416.788\n",
-      "    update_time_ms: 40.812\n",
-      "  timestamp: 1602167356\n",
+      "    learn_throughput: 7565.115\n",
+      "    learn_time_ms: 10693.295\n",
+      "    sample_throughput: 12526.945\n",
+      "    sample_time_ms: 6457.76\n",
+      "    update_time_ms: 26.007\n",
+      "  timestamp: 1602428456\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
+      "  timesteps_total: 808960\n",
       "  training_iteration: 10\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     10 |           238.92 | 1617920 |  230.156 |              281.606 |              114.747 |             826.54 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     10 |            172.2 | 808960 |  226.947 |              273.444 |               146.02 |             862.91 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-29-39\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3546.17738791423\n",
+      "    time_step_min: 3229\n",
+      "  date: 2020-10-11_15-01-13\n",
       "  done: false\n",
-      "  episode_len_mean: 825.4615384615385\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.21514069615333\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 856.958089668616\n",
+      "  episode_reward_max: 276.77777777777794\n",
+      "  episode_reward_mean: 228.72059779077313\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 152\n",
+      "  episodes_total: 1026\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9235042989253998\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005789411393925548\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014859883906319737\n",
-      "        total_loss: 4.004831600189209\n",
-      "        vf_explained_var: 0.9919689893722534\n",
-      "        vf_loss: 4.019112539291382\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.047643208503723\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0061458229087293145\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012535271141678095\n",
+      "        total_loss: 28.427783584594728\n",
+      "        vf_explained_var: 0.9625579118728638\n",
+      "        vf_loss: 28.439194107055663\n",
+      "    num_steps_sampled: 889856\n",
+      "    num_steps_trained: 889856\n",
       "  iterations_since_restore: 11\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.4\n",
-      "    gpu_util_percent0: 0.3125925925925926\n",
+      "    cpu_util_percent: 32.095\n",
+      "    gpu_util_percent0: 0.34249999999999997\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.475\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15996985034496003\n",
-      "    mean_env_wait_ms: 1.675007114196491\n",
-      "    mean_inference_ms: 4.907016710777437\n",
-      "    mean_raw_obs_processing_ms: 0.4317794077781022\n",
-      "  time_since_restore: 262.4391770362854\n",
-      "  time_this_iter_s: 23.519339561462402\n",
-      "  time_total_s: 262.4391770362854\n",
+      "    mean_action_processing_ms: 0.1250004727198809\n",
+      "    mean_env_wait_ms: 0.6445938363621434\n",
+      "    mean_inference_ms: 4.833793420266109\n",
+      "    mean_raw_obs_processing_ms: 0.2748012933950252\n",
+      "  time_since_restore: 189.14513874053955\n",
+      "  time_this_iter_s: 16.945090532302856\n",
+      "  time_total_s: 189.14513874053955\n",
       "  timers:\n",
-      "    learn_throughput: 10544.089\n",
-      "    learn_time_ms: 15344.332\n",
-      "    sample_throughput: 19638.715\n",
-      "    sample_time_ms: 8238.421\n",
-      "    update_time_ms: 40.485\n",
-      "  timestamp: 1602167379\n",
+      "    learn_throughput: 7584.813\n",
+      "    learn_time_ms: 10665.524\n",
+      "    sample_throughput: 12965.305\n",
+      "    sample_time_ms: 6239.421\n",
+      "    update_time_ms: 24.27\n",
+      "  timestamp: 1602428473\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
+      "  timesteps_total: 889856\n",
       "  training_iteration: 11\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     11 |          262.439 | 1779712 |  230.215 |              281.606 |              114.747 |            825.462 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     11 |          189.145 | 889856 |  228.721 |              276.778 |               146.02 |            856.958 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-03\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3537.3589511754067\n",
+      "    time_step_min: 3229\n",
+      "  date: 2020-10-11_15-01-30\n",
       "  done: false\n",
-      "  episode_len_mean: 824.152428057554\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.18242224402292\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 170\n",
-      "  episodes_total: 2224\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 853.8372513562387\n",
+      "  episode_reward_max: 276.77777777777794\n",
+      "  episode_reward_mean: 230.0567245693827\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 80\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8818272411823272\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005413110228255391\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013095138547942042\n",
-      "        total_loss: 5.083396100997925\n",
-      "        vf_explained_var: 0.9921062588691711\n",
-      "        vf_loss: 5.0959498405456545\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.029042935371399\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006281163450330496\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015307414811104536\n",
+      "        total_loss: 15.060502815246583\n",
+      "        vf_explained_var: 0.9696897268295288\n",
+      "        vf_loss: 15.074656867980957\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 12\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.042857142857144\n",
-      "    gpu_util_percent0: 0.1942857142857143\n",
+      "    cpu_util_percent: 33.14736842105263\n",
+      "    gpu_util_percent0: 0.3373684210526316\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757142857142858\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15960744702974256\n",
-      "    mean_env_wait_ms: 1.677271579492208\n",
-      "    mean_inference_ms: 4.884761150099492\n",
-      "    mean_raw_obs_processing_ms: 0.4305594741365648\n",
-      "  time_since_restore: 286.0365300178528\n",
-      "  time_this_iter_s: 23.597352981567383\n",
-      "  time_total_s: 286.0365300178528\n",
+      "    mean_action_processing_ms: 0.12468306089991366\n",
+      "    mean_env_wait_ms: 0.6449567343788762\n",
+      "    mean_inference_ms: 4.812627363701398\n",
+      "    mean_raw_obs_processing_ms: 0.273944758139881\n",
+      "  time_since_restore: 206.12778520584106\n",
+      "  time_this_iter_s: 16.982646465301514\n",
+      "  time_total_s: 206.12778520584106\n",
       "  timers:\n",
-      "    learn_throughput: 10540.17\n",
-      "    learn_time_ms: 15350.038\n",
-      "    sample_throughput: 19693.201\n",
-      "    sample_time_ms: 8215.627\n",
-      "    update_time_ms: 39.264\n",
-      "  timestamp: 1602167403\n",
+      "    learn_throughput: 7578.509\n",
+      "    learn_time_ms: 10674.395\n",
+      "    sample_throughput: 13133.471\n",
+      "    sample_time_ms: 6159.53\n",
+      "    update_time_ms: 24.381\n",
+      "  timestamp: 1602428490\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
+      "  timesteps_total: 970752\n",
       "  training_iteration: 12\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     12 |          286.037 | 1941504 |  230.182 |              281.606 |              99.1212 |            824.152 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     12 |          206.128 | 970752 |  230.057 |              276.778 |               146.02 |            853.837 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-27\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3530.604219409283\n",
+      "    time_step_min: 3225\n",
+      "  date: 2020-10-11_15-01-47\n",
       "  done: false\n",
-      "  episode_len_mean: 822.2670094936709\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.69313387034907\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 304\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 851.1873417721519\n",
+      "  episode_reward_max: 277.38383838383817\n",
+      "  episode_reward_mean: 231.0801687763712\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1185\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8522311568260192\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005159769672900438\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012773643853142858\n",
-      "        total_loss: 5.1331462383270265\n",
-      "        vf_explained_var: 0.9925912618637085\n",
-      "        vf_loss: 5.145403909683227\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.020499587059021\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0058583361096680164\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014010852668434381\n",
+      "        total_loss: 17.26035079956055\n",
+      "        vf_explained_var: 0.9643712043762207\n",
+      "        vf_loss: 17.273291778564452\n",
+      "    num_steps_sampled: 1051648\n",
+      "    num_steps_trained: 1051648\n",
       "  iterations_since_restore: 13\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.01481481481482\n",
-      "    gpu_util_percent0: 0.30111111111111116\n",
+      "    cpu_util_percent: 31.305\n",
+      "    gpu_util_percent0: 0.29900000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15905681990758594\n",
-      "    mean_env_wait_ms: 1.68066117965344\n",
-      "    mean_inference_ms: 4.850479242048183\n",
-      "    mean_raw_obs_processing_ms: 0.4287066632526924\n",
-      "  time_since_restore: 309.50186347961426\n",
-      "  time_this_iter_s: 23.465333461761475\n",
-      "  time_total_s: 309.50186347961426\n",
+      "    mean_action_processing_ms: 0.12439936516116261\n",
+      "    mean_env_wait_ms: 0.6453060533097584\n",
+      "    mean_inference_ms: 4.793489559966399\n",
+      "    mean_raw_obs_processing_ms: 0.2731737658194734\n",
+      "  time_since_restore: 222.88168025016785\n",
+      "  time_this_iter_s: 16.753895044326782\n",
+      "  time_total_s: 222.88168025016785\n",
       "  timers:\n",
-      "    learn_throughput: 10553.501\n",
-      "    learn_time_ms: 15330.648\n",
-      "    sample_throughput: 19829.166\n",
-      "    sample_time_ms: 8159.294\n",
-      "    update_time_ms: 40.29\n",
-      "  timestamp: 1602167427\n",
+      "    learn_throughput: 7573.566\n",
+      "    learn_time_ms: 10681.362\n",
+      "    sample_throughput: 13175.11\n",
+      "    sample_time_ms: 6140.063\n",
+      "    update_time_ms: 24.318\n",
+      "  timestamp: 1602428507\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
+      "  timesteps_total: 1051648\n",
       "  training_iteration: 13\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     13 |          309.502 | 2103296 |  230.693 |              281.606 |              99.1212 |            822.267 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     13 |          222.882 | 1051648 |   231.08 |              277.384 |               146.02 |            851.187 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-50\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3522.7099296325255\n",
+      "    time_step_min: 3184\n",
+      "  date: 2020-10-11_15-02-04\n",
       "  done: false\n",
-      "  episode_len_mean: 821.4538346984364\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.94512511563886\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 848.0969507427678\n",
+      "  episode_reward_max: 283.59595959595947\n",
+      "  episode_reward_mean: 232.27627328800114\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 94\n",
+      "  episodes_total: 1279\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8369874477386474\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005370886158198118\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01467731585726142\n",
-      "        total_loss: 3.154995489120483\n",
-      "        vf_explained_var: 0.9942510724067688\n",
-      "        vf_loss: 3.1691357612609865\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.988058340549469\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006182871200144291\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014513058867305518\n",
+      "        total_loss: 22.752033996582032\n",
+      "        vf_explained_var: 0.9629007577896118\n",
+      "        vf_loss: 22.76541061401367\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 14\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.181481481481484\n",
-      "    gpu_util_percent0: 0.3040740740740741\n",
+      "    cpu_util_percent: 31.820000000000004\n",
+      "    gpu_util_percent0: 0.3165\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.766666666666667\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1588082507195649\n",
-      "    mean_env_wait_ms: 1.6822641931487865\n",
-      "    mean_inference_ms: 4.835116455543884\n",
-      "    mean_raw_obs_processing_ms: 0.42786989591003743\n",
-      "  time_since_restore: 332.9755485057831\n",
-      "  time_this_iter_s: 23.473685026168823\n",
-      "  time_total_s: 332.9755485057831\n",
+      "    mean_action_processing_ms: 0.12410530343173547\n",
+      "    mean_env_wait_ms: 0.6458437721239955\n",
+      "    mean_inference_ms: 4.772863207242403\n",
+      "    mean_raw_obs_processing_ms: 0.27235669150720343\n",
+      "  time_since_restore: 240.00171875953674\n",
+      "  time_this_iter_s: 17.120038509368896\n",
+      "  time_total_s: 240.00171875953674\n",
       "  timers:\n",
-      "    learn_throughput: 10555.883\n",
-      "    learn_time_ms: 15327.187\n",
-      "    sample_throughput: 19878.044\n",
-      "    sample_time_ms: 8139.232\n",
-      "    update_time_ms: 45.711\n",
-      "  timestamp: 1602167450\n",
+      "    learn_throughput: 7563.78\n",
+      "    learn_time_ms: 10695.181\n",
+      "    sample_throughput: 13172.637\n",
+      "    sample_time_ms: 6141.215\n",
+      "    update_time_ms: 24.555\n",
+      "  timestamp: 1602428524\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
+      "  timesteps_total: 1132544\n",
       "  training_iteration: 14\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     14 |          332.976 | 2265088 |  230.945 |              281.606 |              99.1212 |            821.454 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     14 |          240.002 | 1132544 |  232.276 |              283.596 |               146.02 |            848.097 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-31-14\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3513.834739803094\n",
+      "    time_step_min: 3184\n",
+      "  date: 2020-10-11_15-02-22\n",
       "  done: false\n",
-      "  episode_len_mean: 820.854781997187\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.2064917813863\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 843.6962025316456\n",
+      "  episode_reward_max: 283.59595959595947\n",
+      "  episode_reward_mean: 233.62099901973312\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 143\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.827689278125763\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005339382635429502\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014263017289340495\n",
-      "        total_loss: 3.00002179145813\n",
-      "        vf_explained_var: 0.9941463470458984\n",
-      "        vf_loss: 3.0137508869171143\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9878270983695984\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005273265577852726\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01443924605846405\n",
+      "        total_loss: 19.540371704101563\n",
+      "        vf_explained_var: 0.9709212183952332\n",
+      "        vf_loss: 19.55385627746582\n",
+      "    num_steps_sampled: 1213440\n",
+      "    num_steps_trained: 1213440\n",
       "  iterations_since_restore: 15\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.57037037037037\n",
-      "    gpu_util_percent0: 0.2274074074074074\n",
+      "    cpu_util_percent: 32.02500000000001\n",
+      "    gpu_util_percent0: 0.33049999999999996\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.77037037037037\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4799999999999995\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15857855076630387\n",
-      "    mean_env_wait_ms: 1.6837618809370547\n",
-      "    mean_inference_ms: 4.820936656490715\n",
-      "    mean_raw_obs_processing_ms: 0.4270767088680792\n",
-      "  time_since_restore: 356.605441570282\n",
-      "  time_this_iter_s: 23.6298930644989\n",
-      "  time_total_s: 356.605441570282\n",
+      "    mean_action_processing_ms: 0.12368752424523184\n",
+      "    mean_env_wait_ms: 0.6465292187640248\n",
+      "    mean_inference_ms: 4.745004298337707\n",
+      "    mean_raw_obs_processing_ms: 0.2712266339697401\n",
+      "  time_since_restore: 256.9493980407715\n",
+      "  time_this_iter_s: 16.94767928123474\n",
+      "  time_total_s: 256.9493980407715\n",
       "  timers:\n",
-      "    learn_throughput: 10553.654\n",
-      "    learn_time_ms: 15330.425\n",
-      "    sample_throughput: 19924.68\n",
-      "    sample_time_ms: 8120.181\n",
-      "    update_time_ms: 47.653\n",
-      "  timestamp: 1602167474\n",
+      "    learn_throughput: 7564.837\n",
+      "    learn_time_ms: 10693.687\n",
+      "    sample_throughput: 13155.529\n",
+      "    sample_time_ms: 6149.202\n",
+      "    update_time_ms: 25.398\n",
+      "  timestamp: 1602428542\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
+      "  timesteps_total: 1213440\n",
       "  training_iteration: 15\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     15 |          356.605 | 2426880 |  231.206 |              281.606 |              99.1212 |            820.855 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     15 |          256.949 | 1213440 |  233.621 |              283.596 |               146.02 |            843.696 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-31-38\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3507.775483011326\n",
+      "    time_step_min: 3184\n",
+      "  date: 2020-10-11_15-02-38\n",
       "  done: false\n",
-      "  episode_len_mean: 820.0182767624021\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.22214310203864\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 220\n",
-      "  episodes_total: 3064\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 841.0646235842771\n",
+      "  episode_reward_max: 283.59595959595947\n",
+      "  episode_reward_mean: 234.53906823060714\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1501\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7918125212192535\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004892151476815343\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012084704916924238\n",
-      "        total_loss: 4.1488186597824095\n",
-      "        vf_explained_var: 0.9942665100097656\n",
-      "        vf_loss: 4.160414218902588\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.97277330160141\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005540623422712087\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01531378725776449\n",
+      "        total_loss: 12.622322082519531\n",
+      "        vf_explained_var: 0.9739503860473633\n",
+      "        vf_loss: 12.636624717712403\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
       "  iterations_since_restore: 16\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.81481481481482\n",
-      "    gpu_util_percent0: 0.3077777777777778\n",
+      "    cpu_util_percent: 32.76842105263158\n",
+      "    gpu_util_percent0: 0.3163157894736843\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74814814814815\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.158297804116007\n",
-      "    mean_env_wait_ms: 1.6859562656031242\n",
-      "    mean_inference_ms: 4.803618536248515\n",
-      "    mean_raw_obs_processing_ms: 0.42616514556223817\n",
-      "  time_since_restore: 380.0873718261719\n",
-      "  time_this_iter_s: 23.481930255889893\n",
-      "  time_total_s: 380.0873718261719\n",
+      "    mean_action_processing_ms: 0.12348587446834983\n",
+      "    mean_env_wait_ms: 0.6469145712639862\n",
+      "    mean_inference_ms: 4.731359925325055\n",
+      "    mean_raw_obs_processing_ms: 0.27067393672678736\n",
+      "  time_since_restore: 273.7271740436554\n",
+      "  time_this_iter_s: 16.77777600288391\n",
+      "  time_total_s: 273.7271740436554\n",
       "  timers:\n",
-      "    learn_throughput: 10556.149\n",
-      "    learn_time_ms: 15326.802\n",
-      "    sample_throughput: 19915.022\n",
-      "    sample_time_ms: 8124.119\n",
-      "    update_time_ms: 46.174\n",
-      "  timestamp: 1602167498\n",
+      "    learn_throughput: 7561.237\n",
+      "    learn_time_ms: 10698.778\n",
+      "    sample_throughput: 13174.224\n",
+      "    sample_time_ms: 6140.476\n",
+      "    update_time_ms: 26.374\n",
+      "  timestamp: 1602428558\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
+      "  timesteps_total: 1294336\n",
       "  training_iteration: 16\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     16 |          380.087 | 2588672 |  231.222 |              281.606 |              99.1212 |            820.018 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     16 |          273.727 | 1294336 |  234.539 |              283.596 |               146.02 |            841.065 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-01\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3502.0474383301707\n",
+      "    time_step_min: 3167\n",
+      "  date: 2020-10-11_15-02-55\n",
       "  done: false\n",
-      "  episode_len_mean: 819.2076552139844\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.34207049396923\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 254\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 838.7457305502846\n",
+      "  episode_reward_max: 286.1717171717169\n",
+      "  episode_reward_mean: 235.40695378835792\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 80\n",
+      "  episodes_total: 1581\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.05\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7639730334281921\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004952558875083923\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011812644638121128\n",
-      "        total_loss: 3.641219711303711\n",
-      "        vf_explained_var: 0.9940530061721802\n",
-      "        vf_loss: 3.6527847766876222\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9531836867332458\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005672357883304358\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013997910264879464\n",
+      "        total_loss: 14.515528297424316\n",
+      "        vf_explained_var: 0.9702242016792297\n",
+      "        vf_loss: 14.528486824035644\n",
+      "    num_steps_sampled: 1375232\n",
+      "    num_steps_trained: 1375232\n",
       "  iterations_since_restore: 17\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.58928571428571\n",
-      "    gpu_util_percent0: 0.33428571428571435\n",
+      "    cpu_util_percent: 31.085000000000008\n",
+      "    gpu_util_percent0: 0.346\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1579861428053209\n",
-      "    mean_env_wait_ms: 1.6878268274425987\n",
-      "    mean_inference_ms: 4.784786851610141\n",
-      "    mean_raw_obs_processing_ms: 0.4251258149287427\n",
-      "  time_since_restore: 403.5224757194519\n",
-      "  time_this_iter_s: 23.43510389328003\n",
-      "  time_total_s: 403.5224757194519\n",
+      "    mean_action_processing_ms: 0.12329679443462903\n",
+      "    mean_env_wait_ms: 0.6473200822086033\n",
+      "    mean_inference_ms: 4.7185145686739975\n",
+      "    mean_raw_obs_processing_ms: 0.27014612389586146\n",
+      "  time_since_restore: 290.4690568447113\n",
+      "  time_this_iter_s: 16.741882801055908\n",
+      "  time_total_s: 290.4690568447113\n",
       "  timers:\n",
-      "    learn_throughput: 10564.477\n",
-      "    learn_time_ms: 15314.719\n",
-      "    sample_throughput: 19933.192\n",
-      "    sample_time_ms: 8116.713\n",
-      "    update_time_ms: 45.777\n",
-      "  timestamp: 1602167521\n",
+      "    learn_throughput: 7556.782\n",
+      "    learn_time_ms: 10705.086\n",
+      "    sample_throughput: 13191.474\n",
+      "    sample_time_ms: 6132.446\n",
+      "    update_time_ms: 26.165\n",
+      "  timestamp: 1602428575\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
+      "  timesteps_total: 1375232\n",
       "  training_iteration: 17\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     17 |          403.522 | 2750464 |  231.342 |              281.606 |              99.1212 |            819.208 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     17 |          290.469 | 1375232 |  235.407 |              286.172 |               146.02 |            838.746 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-25\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3492.5957200694043\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_15-03-12\n",
       "  done: false\n",
-      "  episode_len_mean: 818.5304948216341\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.56991956387816\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 834.5801041064199\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 236.83903231271648\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 148\n",
+      "  episodes_total: 1729\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7660917460918426\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005422895355150103\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.926102340221405\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005256259627640247\n",
       "        model: {}\n",
-      "        policy_loss: -0.013137935660779476\n",
-      "        total_loss: 2.9323360919952393\n",
-      "        vf_explained_var: 0.9942866563796997\n",
-      "        vf_loss: 2.94533851146698\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
+      "        policy_loss: -0.011589129082858562\n",
+      "        total_loss: 17.027903366088868\n",
+      "        vf_explained_var: 0.976334273815155\n",
+      "        vf_loss: 17.03853416442871\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
       "  iterations_since_restore: 18\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.25925925925925\n",
-      "    gpu_util_percent0: 0.36148148148148146\n",
+      "    cpu_util_percent: 32.45263157894736\n",
+      "    gpu_util_percent0: 0.3294736842105263\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.759259259259261\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15781721284272957\n",
-      "    mean_env_wait_ms: 1.6890502862525536\n",
-      "    mean_inference_ms: 4.774409463690571\n",
-      "    mean_raw_obs_processing_ms: 0.4245721837690542\n",
-      "  time_since_restore: 426.88156366348267\n",
-      "  time_this_iter_s: 23.35908794403076\n",
-      "  time_total_s: 426.88156366348267\n",
+      "    mean_action_processing_ms: 0.12297569960283086\n",
+      "    mean_env_wait_ms: 0.6481164637801422\n",
+      "    mean_inference_ms: 4.697031733472803\n",
+      "    mean_raw_obs_processing_ms: 0.26926794617915933\n",
+      "  time_since_restore: 307.1953341960907\n",
+      "  time_this_iter_s: 16.726277351379395\n",
+      "  time_total_s: 307.1953341960907\n",
       "  timers:\n",
-      "    learn_throughput: 10562.111\n",
-      "    learn_time_ms: 15318.149\n",
-      "    sample_throughput: 20027.117\n",
-      "    sample_time_ms: 8078.647\n",
-      "    update_time_ms: 51.49\n",
-      "  timestamp: 1602167545\n",
+      "    learn_throughput: 7552.699\n",
+      "    learn_time_ms: 10710.874\n",
+      "    sample_throughput: 13221.798\n",
+      "    sample_time_ms: 6118.381\n",
+      "    update_time_ms: 26.134\n",
+      "  timestamp: 1602428592\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
+      "  timesteps_total: 1456128\n",
       "  training_iteration: 18\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     18 |          426.882 | 2912256 |   231.57 |              281.606 |              99.1212 |             818.53 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     18 |          307.195 | 1456128 |  236.839 |              288.899 |               146.02 |             834.58 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-49\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3488.034672537149\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_15-03-29\n",
       "  done: false\n",
-      "  episode_len_mean: 817.8346629986245\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.78994900865604\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 159\n",
-      "  episodes_total: 3635\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 832.3307649972483\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 237.53010012063393\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 88\n",
+      "  episodes_total: 1817\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.761504179239273\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00561123825609684\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9310240507125854\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005109604261815548\n",
       "        model: {}\n",
-      "        policy_loss: -0.01371184946037829\n",
-      "        total_loss: 2.586661458015442\n",
-      "        vf_explained_var: 0.9948149919509888\n",
-      "        vf_loss: 2.6002331018447875\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
+      "        policy_loss: -0.01098379292525351\n",
+      "        total_loss: 14.388118743896484\n",
+      "        vf_explained_var: 0.9739601016044617\n",
+      "        vf_loss: 14.39817409515381\n",
+      "    num_steps_sampled: 1537024\n",
+      "    num_steps_trained: 1537024\n",
       "  iterations_since_restore: 19\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.98518518518519\n",
-      "    gpu_util_percent0: 0.25\n",
+      "    cpu_util_percent: 31.140000000000004\n",
+      "    gpu_util_percent0: 0.3485\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1576552038626758\n",
-      "    mean_env_wait_ms: 1.6902745430630273\n",
-      "    mean_inference_ms: 4.764639495963006\n",
-      "    mean_raw_obs_processing_ms: 0.42404147010851506\n",
-      "  time_since_restore: 450.4647214412689\n",
-      "  time_this_iter_s: 23.583157777786255\n",
-      "  time_total_s: 450.4647214412689\n",
+      "    mean_action_processing_ms: 0.12280228009136415\n",
+      "    mean_env_wait_ms: 0.6485211065686625\n",
+      "    mean_inference_ms: 4.685172010692531\n",
+      "    mean_raw_obs_processing_ms: 0.26877865575122734\n",
+      "  time_since_restore: 323.9889533519745\n",
+      "  time_this_iter_s: 16.79361915588379\n",
+      "  time_total_s: 323.9889533519745\n",
       "  timers:\n",
-      "    learn_throughput: 10558.952\n",
-      "    learn_time_ms: 15322.733\n",
-      "    sample_throughput: 20107.322\n",
-      "    sample_time_ms: 8046.422\n",
-      "    update_time_ms: 53.421\n",
-      "  timestamp: 1602167569\n",
+      "    learn_throughput: 7558.797\n",
+      "    learn_time_ms: 10702.233\n",
+      "    sample_throughput: 13249.245\n",
+      "    sample_time_ms: 6105.707\n",
+      "    update_time_ms: 26.106\n",
+      "  timestamp: 1602428609\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
+      "  timesteps_total: 1537024\n",
       "  training_iteration: 19\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     19 |          450.465 | 3074048 |   231.79 |              281.606 |              99.1212 |            817.835 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     19 |          323.989 | 1537024 |   237.53 |              288.899 |               146.02 |            832.331 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-33-12\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3484.7273206751056\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_15-03-46\n",
       "  done: false\n",
-      "  episode_len_mean: 816.6687881873727\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.22543664753442\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 293\n",
-      "  episodes_total: 3928\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 830.3449367088608\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 238.03121403912542\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7176933705806732\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004935431573539972\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9225889205932617\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005407916381955147\n",
       "        model: {}\n",
-      "        policy_loss: -0.011507348460145294\n",
-      "        total_loss: 3.7333247661590576\n",
-      "        vf_explained_var: 0.9947683215141296\n",
-      "        vf_loss: 3.744708704948425\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
+      "        policy_loss: -0.014131060149520636\n",
+      "        total_loss: 14.700571441650391\n",
+      "        vf_explained_var: 0.9705582857131958\n",
+      "        vf_loss: 14.713712692260742\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
       "  iterations_since_restore: 20\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.92962962962963\n",
-      "    gpu_util_percent0: 0.22925925925925927\n",
+      "    cpu_util_percent: 32.6\n",
+      "    gpu_util_percent0: 0.35157894736842105\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15738510281829127\n",
-      "    mean_env_wait_ms: 1.6923950386450304\n",
-      "    mean_inference_ms: 4.748233050103123\n",
-      "    mean_raw_obs_processing_ms: 0.4231474863161252\n",
-      "  time_since_restore: 473.9994788169861\n",
-      "  time_this_iter_s: 23.534757375717163\n",
-      "  time_total_s: 473.9994788169861\n",
+      "    mean_action_processing_ms: 0.12265549039934973\n",
+      "    mean_env_wait_ms: 0.6488958537198457\n",
+      "    mean_inference_ms: 4.67537146231669\n",
+      "    mean_raw_obs_processing_ms: 0.2683676603373263\n",
+      "  time_since_restore: 340.80086636543274\n",
+      "  time_this_iter_s: 16.811913013458252\n",
+      "  time_total_s: 340.80086636543274\n",
       "  timers:\n",
-      "    learn_throughput: 10546.772\n",
-      "    learn_time_ms: 15340.429\n",
-      "    sample_throughput: 20112.723\n",
-      "    sample_time_ms: 8044.261\n",
-      "    update_time_ms: 53.96\n",
-      "  timestamp: 1602167592\n",
+      "    learn_throughput: 7570.044\n",
+      "    learn_time_ms: 10686.331\n",
+      "    sample_throughput: 13271.987\n",
+      "    sample_time_ms: 6095.244\n",
+      "    update_time_ms: 24.189\n",
+      "  timestamp: 1602428626\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
+      "  timesteps_total: 1617920\n",
       "  training_iteration: 20\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     20 |          473.999 | 3235840 |  232.225 |              281.606 |              99.1212 |            816.669 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     20 |          340.801 | 1617920 |  238.031 |              288.899 |               146.02 |            830.345 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-33-36\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3479.526524541398\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_15-04-03\n",
       "  done: false\n",
-      "  episode_len_mean: 815.9362220058423\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.68833171048362\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 827.4918195339613\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 238.81921345332347\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 121\n",
+      "  episodes_total: 2017\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6961194634437561\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0054001738782972096\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8949668288230896\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00522464383393526\n",
       "        model: {}\n",
-      "        policy_loss: -0.013575149234384298\n",
-      "        total_loss: 2.1967584609985353\n",
-      "        vf_explained_var: 0.9954622387886047\n",
-      "        vf_loss: 2.210266089439392\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
+      "        policy_loss: -0.015539329266175628\n",
+      "        total_loss: 16.214202308654784\n",
+      "        vf_explained_var: 0.9754984974861145\n",
+      "        vf_loss: 16.228786277770997\n",
+      "    num_steps_sampled: 1698816\n",
+      "    num_steps_trained: 1698816\n",
       "  iterations_since_restore: 21\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.440740740740736\n",
-      "    gpu_util_percent0: 0.29666666666666663\n",
+      "    cpu_util_percent: 31.51\n",
+      "    gpu_util_percent0: 0.34750000000000003\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15722895249997093\n",
-      "    mean_env_wait_ms: 1.6936030533075188\n",
-      "    mean_inference_ms: 4.738907510439971\n",
-      "    mean_raw_obs_processing_ms: 0.42262820408828605\n",
-      "  time_since_restore: 497.52709674835205\n",
-      "  time_this_iter_s: 23.527617931365967\n",
-      "  time_total_s: 497.52709674835205\n",
+      "    mean_action_processing_ms: 0.12244846300265959\n",
+      "    mean_env_wait_ms: 0.6495053775860202\n",
+      "    mean_inference_ms: 4.661203272043386\n",
+      "    mean_raw_obs_processing_ms: 0.2677822534401562\n",
+      "  time_since_restore: 357.5641474723816\n",
+      "  time_this_iter_s: 16.763281106948853\n",
+      "  time_total_s: 357.5641474723816\n",
       "  timers:\n",
-      "    learn_throughput: 10537.753\n",
-      "    learn_time_ms: 15353.558\n",
-      "    sample_throughput: 20139.989\n",
-      "    sample_time_ms: 8033.371\n",
-      "    update_time_ms: 52.995\n",
-      "  timestamp: 1602167616\n",
+      "    learn_throughput: 7567.063\n",
+      "    learn_time_ms: 10690.541\n",
+      "    sample_throughput: 13311.187\n",
+      "    sample_time_ms: 6077.294\n",
+      "    update_time_ms: 25.046\n",
+      "  timestamp: 1602428643\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
+      "  timesteps_total: 1698816\n",
       "  training_iteration: 21\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     21 |          497.527 | 3397632 |  232.688 |              281.606 |              99.1212 |            815.936 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     21 |          357.564 | 1698816 |  238.819 |              288.899 |               146.02 |            827.492 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-00\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3474.1439287388653\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_15-04-19\n",
       "  done: false\n",
-      "  episode_len_mean: 815.2585560243788\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.9339172313856\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4266\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 825.413033286451\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 239.63475827188907\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 116\n",
+      "  episodes_total: 2133\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7063014328479766\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005521039292216301\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8959186911582947\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00528133912011981\n",
       "        model: {}\n",
-      "        policy_loss: -0.013345666276291013\n",
-      "        total_loss: 2.40686240196228\n",
-      "        vf_explained_var: 0.994661808013916\n",
-      "        vf_loss: 2.4201390743255615\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
+      "        policy_loss: -0.011150027438998223\n",
+      "        total_loss: 11.039695358276367\n",
+      "        vf_explained_var: 0.9806930422782898\n",
+      "        vf_loss: 11.04987850189209\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
       "  iterations_since_restore: 22\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.3\n",
-      "    gpu_util_percent0: 0.3596428571428571\n",
+      "    cpu_util_percent: 32.978947368421046\n",
+      "    gpu_util_percent0: 0.35105263157894734\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.760714285714286\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4842105263157896\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15710538677505165\n",
-      "    mean_env_wait_ms: 1.694637493002915\n",
-      "    mean_inference_ms: 4.731284261187251\n",
-      "    mean_raw_obs_processing_ms: 0.42220494507105216\n",
-      "  time_since_restore: 521.2907056808472\n",
-      "  time_this_iter_s: 23.763608932495117\n",
-      "  time_total_s: 521.2907056808472\n",
+      "    mean_action_processing_ms: 0.12226120558461344\n",
+      "    mean_env_wait_ms: 0.6500578173986041\n",
+      "    mean_inference_ms: 4.649194209681777\n",
+      "    mean_raw_obs_processing_ms: 0.2672738214303179\n",
+      "  time_since_restore: 374.14853858947754\n",
+      "  time_this_iter_s: 16.584391117095947\n",
+      "  time_total_s: 374.14853858947754\n",
       "  timers:\n",
-      "    learn_throughput: 10529.291\n",
-      "    learn_time_ms: 15365.897\n",
-      "    sample_throughput: 20152.527\n",
-      "    sample_time_ms: 8028.373\n",
-      "    update_time_ms: 60.563\n",
-      "  timestamp: 1602167640\n",
+      "    learn_throughput: 7584.128\n",
+      "    learn_time_ms: 10666.487\n",
+      "    sample_throughput: 13343.395\n",
+      "    sample_time_ms: 6062.625\n",
+      "    update_time_ms: 23.786\n",
+      "  timestamp: 1602428659\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
+      "  timesteps_total: 1779712\n",
       "  training_iteration: 22\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     22 |          521.291 | 3559424 |  232.934 |              281.606 |              99.1212 |            815.259 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     22 |          374.149 | 1779712 |  239.635 |              288.899 |               146.02 |            825.413 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-24\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3471.4570524412297\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_15-04-36\n",
       "  done: false\n",
-      "  episode_len_mean: 814.5122444394518\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.18438711990723\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 185\n",
-      "  episodes_total: 4451\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 824.0126582278481\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 240.0418607412278\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.687007212638855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005151082994416356\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8983033895492554\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005707137286663055\n",
       "        model: {}\n",
-      "        policy_loss: -0.0136242700740695\n",
-      "        total_loss: 2.3987212419509887\n",
-      "        vf_explained_var: 0.9956458210945129\n",
-      "        vf_loss: 2.412281060218811\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
+      "        policy_loss: -0.011461784783750772\n",
+      "        total_loss: 10.742603302001953\n",
+      "        vf_explained_var: 0.9777244329452515\n",
+      "        vf_loss: 10.753013420104981\n",
+      "    num_steps_sampled: 1860608\n",
+      "    num_steps_trained: 1860608\n",
       "  iterations_since_restore: 23\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.87777777777778\n",
-      "    gpu_util_percent0: 0.32259259259259254\n",
+      "    cpu_util_percent: 32.78947368421052\n",
+      "    gpu_util_percent0: 0.35052631578947374\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15697868978775206\n",
-      "    mean_env_wait_ms: 1.6959996633636125\n",
-      "    mean_inference_ms: 4.723299684373984\n",
-      "    mean_raw_obs_processing_ms: 0.42177767922029563\n",
-      "  time_since_restore: 544.7509255409241\n",
-      "  time_this_iter_s: 23.460219860076904\n",
-      "  time_total_s: 544.7509255409241\n",
+      "    mean_action_processing_ms: 0.12214379206448586\n",
+      "    mean_env_wait_ms: 0.6504145672652913\n",
+      "    mean_inference_ms: 4.641409733081465\n",
+      "    mean_raw_obs_processing_ms: 0.2669458875142305\n",
+      "  time_since_restore: 390.91758847236633\n",
+      "  time_this_iter_s: 16.769049882888794\n",
+      "  time_total_s: 390.91758847236633\n",
       "  timers:\n",
-      "    learn_throughput: 10523.637\n",
-      "    learn_time_ms: 15374.152\n",
-      "    sample_throughput: 20153.695\n",
-      "    sample_time_ms: 8027.908\n",
-      "    update_time_ms: 54.413\n",
-      "  timestamp: 1602167664\n",
+      "    learn_throughput: 7581.401\n",
+      "    learn_time_ms: 10670.323\n",
+      "    sample_throughput: 13349.552\n",
+      "    sample_time_ms: 6059.829\n",
+      "    update_time_ms: 23.955\n",
+      "  timestamp: 1602428676\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
+      "  timesteps_total: 1860608\n",
       "  training_iteration: 23\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     23 |          544.751 | 3721216 |  233.184 |              281.606 |              99.1212 |            814.512 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     23 |          390.918 | 1860608 |  240.042 |              288.899 |               146.02 |            824.013 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-48\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3468.180911062907\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_15-04-53\n",
       "  done: false\n",
-      "  episode_len_mean: 813.3535864978903\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.57533989685885\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 289\n",
-      "  episodes_total: 4740\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 822.7310195227766\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 240.53824579854947\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 93\n",
+      "  episodes_total: 2305\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6324166178703308\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0048749387264251706\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8726944923400879\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005827944166958332\n",
       "        model: {}\n",
-      "        policy_loss: -0.011797640426084399\n",
-      "        total_loss: 2.6533204078674317\n",
-      "        vf_explained_var: 0.9955232739448547\n",
-      "        vf_loss: 2.66505708694458\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
+      "        policy_loss: -0.012724796333350242\n",
+      "        total_loss: 12.167643547058105\n",
+      "        vf_explained_var: 0.9788719415664673\n",
+      "        vf_loss: 12.179289817810059\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
       "  iterations_since_restore: 24\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.074074074074076\n",
-      "    gpu_util_percent0: 0.3251851851851852\n",
+      "    cpu_util_percent: 32.015\n",
+      "    gpu_util_percent0: 0.3365\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74814814814815\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15677630383088909\n",
-      "    mean_env_wait_ms: 1.6975983446472827\n",
-      "    mean_inference_ms: 4.710750302441915\n",
-      "    mean_raw_obs_processing_ms: 0.421060709542158\n",
-      "  time_since_restore: 568.4359018802643\n",
-      "  time_this_iter_s: 23.68497633934021\n",
-      "  time_total_s: 568.4359018802643\n",
+      "    mean_action_processing_ms: 0.12201712317018855\n",
+      "    mean_env_wait_ms: 0.6508549566801675\n",
+      "    mean_inference_ms: 4.632800196509853\n",
+      "    mean_raw_obs_processing_ms: 0.26659025294640726\n",
+      "  time_since_restore: 407.82813453674316\n",
+      "  time_this_iter_s: 16.91054606437683\n",
+      "  time_total_s: 407.82813453674316\n",
       "  timers:\n",
-      "    learn_throughput: 10517.772\n",
-      "    learn_time_ms: 15382.726\n",
-      "    sample_throughput: 20124.264\n",
-      "    sample_time_ms: 8039.648\n",
-      "    update_time_ms: 48.571\n",
-      "  timestamp: 1602167688\n",
+      "    learn_throughput: 7580.439\n",
+      "    learn_time_ms: 10671.677\n",
+      "    sample_throughput: 13399.299\n",
+      "    sample_time_ms: 6037.331\n",
+      "    update_time_ms: 23.73\n",
+      "  timestamp: 1602428693\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
+      "  timesteps_total: 1941504\n",
       "  training_iteration: 24\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     24 |          568.436 | 3883008 |  233.575 |              281.606 |              99.1212 |            813.354 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     24 |          407.828 | 1941504 |  240.538 |              288.899 |               146.02 |            822.731 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-35-11\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3462.297794117647\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_15-05-10\n",
       "  done: false\n",
-      "  episode_len_mean: 812.6929358922009\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.80383252698485\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4898\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 820.6352124183006\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 241.42962715389186\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 143\n",
+      "  episodes_total: 2448\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.00625\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6476718962192536\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004980697343125939\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8506251096725463\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.004865732230246067\n",
       "        model: {}\n",
-      "        policy_loss: -0.012937380420044064\n",
-      "        total_loss: 2.2160698890686037\n",
-      "        vf_explained_var: 0.9949172735214233\n",
-      "        vf_loss: 2.2289761781692503\n",
-      "    num_steps_sampled: 4044800\n",
-      "    num_steps_trained: 4044800\n",
+      "        policy_loss: -0.011699284473434091\n",
+      "        total_loss: 13.54094352722168\n",
+      "        vf_explained_var: 0.9798793792724609\n",
+      "        vf_loss: 13.551755332946778\n",
+      "    num_steps_sampled: 2022400\n",
+      "    num_steps_trained: 2022400\n",
       "  iterations_since_restore: 25\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.93703703703704\n",
-      "    gpu_util_percent0: 0.2511111111111111\n",
+      "    cpu_util_percent: 30.76000000000001\n",
+      "    gpu_util_percent0: 0.28049999999999997\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4799999999999995\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15667803602924033\n",
-      "    mean_env_wait_ms: 1.6985389146300989\n",
-      "    mean_inference_ms: 4.704622565044838\n",
-      "    mean_raw_obs_processing_ms: 0.420720785257639\n",
-      "  time_since_restore: 592.1190402507782\n",
-      "  time_this_iter_s: 23.683138370513916\n",
-      "  time_total_s: 592.1190402507782\n",
+      "    mean_action_processing_ms: 0.1218280208816506\n",
+      "    mean_env_wait_ms: 0.651444924363909\n",
+      "    mean_inference_ms: 4.620390322632076\n",
+      "    mean_raw_obs_processing_ms: 0.2660637639309074\n",
+      "  time_since_restore: 424.82299304008484\n",
+      "  time_this_iter_s: 16.994858503341675\n",
+      "  time_total_s: 424.82299304008484\n",
       "  timers:\n",
-      "    learn_throughput: 10525.475\n",
-      "    learn_time_ms: 15371.468\n",
-      "    sample_throughput: 20083.377\n",
-      "    sample_time_ms: 8056.016\n",
-      "    update_time_ms: 47.817\n",
-      "  timestamp: 1602167711\n",
+      "    learn_throughput: 7564.308\n",
+      "    learn_time_ms: 10694.435\n",
+      "    sample_throughput: 13439.475\n",
+      "    sample_time_ms: 6019.283\n",
+      "    update_time_ms: 23.251\n",
+      "  timestamp: 1602428710\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4044800\n",
+      "  timesteps_total: 2022400\n",
       "  training_iteration: 25\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     25 |          592.119 | 4044800 |  233.804 |              281.606 |              99.1212 |            812.693 |\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     25 |          424.823 | 2022400 |   241.43 |              288.899 |               146.02 |            820.635 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-35-35\n",
-      "  done: true\n",
-      "  episode_len_mean: 812.0104784499803\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 234.07366667864886\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 160\n",
-      "  episodes_total: 5058\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3460.0423259493673\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_15-05-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 819.539161392405\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 241.7713647551464\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 80\n",
+      "  episodes_total: 2528\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.003125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6387091696262359\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00521918865852058\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8542515873908997\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005588684789836406\n",
       "        model: {}\n",
-      "        policy_loss: -0.013382896583061665\n",
-      "        total_loss: 2.0056067228317263\n",
-      "        vf_explained_var: 0.9955011606216431\n",
-      "        vf_loss: 2.0189733505249023\n",
-      "    num_steps_sampled: 4206592\n",
-      "    num_steps_trained: 4206592\n",
+      "        policy_loss: -0.013171911868266762\n",
+      "        total_loss: 15.62488899230957\n",
+      "        vf_explained_var: 0.9691354632377625\n",
+      "        vf_loss: 15.637587738037109\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
       "  iterations_since_restore: 26\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.729629629629635\n",
-      "    gpu_util_percent0: 0.267037037037037\n",
+      "    cpu_util_percent: 33.52631578947369\n",
+      "    gpu_util_percent0: 0.3205263157894737\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.766666666666667\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15658306876779257\n",
-      "    mean_env_wait_ms: 1.6995085455679213\n",
-      "    mean_inference_ms: 4.6987769399539845\n",
-      "    mean_raw_obs_processing_ms: 0.42039589930108456\n",
-      "  time_since_restore: 615.6618909835815\n",
-      "  time_this_iter_s: 23.542850732803345\n",
-      "  time_total_s: 615.6618909835815\n",
+      "    mean_action_processing_ms: 0.12173182767832617\n",
+      "    mean_env_wait_ms: 0.6517732236838806\n",
+      "    mean_inference_ms: 4.613996682870115\n",
+      "    mean_raw_obs_processing_ms: 0.26579729603070834\n",
+      "  time_since_restore: 441.42351174354553\n",
+      "  time_this_iter_s: 16.600518703460693\n",
+      "  time_total_s: 441.42351174354553\n",
       "  timers:\n",
-      "    learn_throughput: 10524.21\n",
-      "    learn_time_ms: 15373.315\n",
-      "    sample_throughput: 20076.608\n",
-      "    sample_time_ms: 8058.732\n",
-      "    update_time_ms: 48.59\n",
-      "  timestamp: 1602167735\n",
+      "    learn_throughput: 7565.413\n",
+      "    learn_time_ms: 10692.873\n",
+      "    sample_throughput: 13476.302\n",
+      "    sample_time_ms: 6002.834\n",
+      "    update_time_ms: 23.495\n",
+      "  timestamp: 1602428727\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4206592\n",
+      "  timesteps_total: 2103296\n",
       "  training_iteration: 26\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 32990\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_142505-w8c2p6ff/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_142505-w8c2p6ff/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3204.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 630\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602167735\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 279.83838\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 228.88544\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1264\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▄▅▇█\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmajor-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/w8c2p6ff\u001b[0m\n",
-      "2020-10-08 14:35:46,970 - wandb.wandb_agent - INFO - Cleaning up finished run: w8c2p6ff\n",
-      "2020-10-08 14:35:47,283 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:35:47,283 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 32768\n",
-      "2020-10-08 14:35:47,287 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=32768\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvibrant-sweep-4\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/y6ys1sgz\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_143549-y6ys1sgz\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-08 14:35:51,552\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:35:52,322 - wandb.wandb_agent - INFO - Running runs: ['y6ys1sgz']\n",
-      "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     26 |          441.424 | 2103296 |  241.771 |              288.899 |               146.02 |            819.539 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=62403)\u001b[0m 2020-10-08 14:35:54,588\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=62386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62376)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62376)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62383)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62383)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62371)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62371)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62368)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62368)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62342)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62342)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62365)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62365)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62267)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62267)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62280)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62280)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62286)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62286)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62356)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62356)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62406)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62406)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62276)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62276)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62375)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62375)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62287)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62287)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62336)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62336)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62264)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62264)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62281)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62281)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62333)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62333)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62341)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62341)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62339)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62339)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62289)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62289)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62288)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62288)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62334)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62334)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62377)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62377)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62270)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62270)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62331)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62331)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62344)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62344)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62284)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62284)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62262)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62262)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62328)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62328)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62338)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62338)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-36-25\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3456.8169984686065\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_15-05-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 818.4391271056661\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 242.26005073707984\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 84\n",
+      "  episodes_total: 2612\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1634249687194824\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0036954283714294434\n",
-      "        model: {}\n",
-      "        policy_loss: -0.006869117938913405\n",
-      "        total_loss: 9.30032901763916\n",
-      "        vf_explained_var: 0.7174946069717407\n",
-      "        vf_loss: 9.306459045410156\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8317709803581238\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00648640925064683\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016052717715501784\n",
+      "        total_loss: 10.588752174377442\n",
+      "        vf_explained_var: 0.9785087704658508\n",
+      "        vf_loss: 10.60423927307129\n",
+      "    num_steps_sampled: 2184192\n",
+      "    num_steps_trained: 2184192\n",
+      "  iterations_since_restore: 27\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 39.282758620689656\n",
-      "    gpu_util_percent0: 0.27758620689655167\n",
+      "    cpu_util_percent: 31.810000000000002\n",
+      "    gpu_util_percent0: 0.318\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0003448275862068966\n",
-      "    ram_util_percent: 9.486206896551723\n",
-      "    vram_util_percent0: 0.30692086721480194\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1757240295410156\n",
-      "    mean_env_wait_ms: 1.64632514878238\n",
-      "    mean_inference_ms: 5.702464303031089\n",
-      "    mean_raw_obs_processing_ms: 0.4785182454697177\n",
-      "  time_since_restore: 24.381270170211792\n",
-      "  time_this_iter_s: 24.381270170211792\n",
-      "  time_total_s: 24.381270170211792\n",
+      "    mean_action_processing_ms: 0.12163409969565207\n",
+      "    mean_env_wait_ms: 0.6521124443046049\n",
+      "    mean_inference_ms: 4.6076088059101075\n",
+      "    mean_raw_obs_processing_ms: 0.2655282922306935\n",
+      "  time_since_restore: 458.18903517723083\n",
+      "  time_this_iter_s: 16.765523433685303\n",
+      "  time_total_s: 458.18903517723083\n",
       "  timers:\n",
-      "    learn_throughput: 10955.585\n",
-      "    learn_time_ms: 14767.992\n",
-      "    sample_throughput: 16976.731\n",
-      "    sample_time_ms: 9530.221\n",
-      "    update_time_ms: 49.441\n",
-      "  timestamp: 1602167785\n",
+      "    learn_throughput: 7569.025\n",
+      "    learn_time_ms: 10687.771\n",
+      "    sample_throughput: 13459.131\n",
+      "    sample_time_ms: 6010.492\n",
+      "    update_time_ms: 23.601\n",
+      "  timestamp: 1602428744\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 2184192\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.7/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      1 |          24.3813 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     27 |          458.189 | 2184192 |   242.26 |              288.899 |               146.02 |            818.439 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-36-48\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3452.055938975663\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_15-06-01\n",
       "  done: false\n",
-      "  episode_len_mean: 867.5569620253165\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 226.67721518987318\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 816.755539411551\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 242.98142338752584\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 141\n",
+      "  episodes_total: 2753\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -7174,83 +6677,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1362101554870605\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006970350444316864\n",
-      "        model: {}\n",
-      "        policy_loss: -0.009705625101923942\n",
-      "        total_loss: 10.32210750579834\n",
-      "        vf_explained_var: 0.8451136350631714\n",
-      "        vf_loss: 10.331116104125977\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8073569655418396\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007314516603946686\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012918723002076148\n",
+      "        total_loss: 14.855539894104004\n",
+      "        vf_explained_var: 0.9783770442008972\n",
+      "        vf_loss: 14.867807388305664\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 28\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.548148148148144\n",
-      "    gpu_util_percent0: 0.2866666666666667\n",
+      "    cpu_util_percent: 32.61052631578947\n",
+      "    gpu_util_percent0: 0.34789473684210526\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.733333333333334\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17100616576939356\n",
-      "    mean_env_wait_ms: 1.647485749663841\n",
-      "    mean_inference_ms: 5.449976105277291\n",
-      "    mean_raw_obs_processing_ms: 0.4667153357279003\n",
-      "  time_since_restore: 47.252567291259766\n",
-      "  time_this_iter_s: 22.871297121047974\n",
-      "  time_total_s: 47.252567291259766\n",
+      "    mean_action_processing_ms: 0.121486994856473\n",
+      "    mean_env_wait_ms: 0.652656269670233\n",
+      "    mean_inference_ms: 4.597419578814093\n",
+      "    mean_raw_obs_processing_ms: 0.2650989345344607\n",
+      "  time_since_restore: 474.9974591732025\n",
+      "  time_this_iter_s: 16.80842399597168\n",
+      "  time_total_s: 474.9974591732025\n",
       "  timers:\n",
-      "    learn_throughput: 11041.238\n",
-      "    learn_time_ms: 14653.429\n",
-      "    sample_throughput: 18199.954\n",
-      "    sample_time_ms: 8889.693\n",
-      "    update_time_ms: 42.206\n",
-      "  timestamp: 1602167808\n",
+      "    learn_throughput: 7570.675\n",
+      "    learn_time_ms: 10685.441\n",
+      "    sample_throughput: 13437.573\n",
+      "    sample_time_ms: 6020.135\n",
+      "    update_time_ms: 23.905\n",
+      "  timestamp: 1602428761\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      2 |          47.2526 | 323584 |  226.677 |              287.616 |              115.788 |            867.557 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     28 |          474.997 | 2265088 |  242.981 |              294.657 |               146.02 |            816.756 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-11\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3449.462728551336\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_15-06-17\n",
       "  done: false\n",
-      "  episode_len_mean: 859.824894514768\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.24830584324238\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 815.731364275668\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 243.3743340578784\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 91\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -7258,83 +6759,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.12405526638031\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006674189120531082\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010977230872958899\n",
-      "        total_loss: 12.676021194458007\n",
-      "        vf_explained_var: 0.8899718523025513\n",
-      "        vf_loss: 12.686330986022949\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8145095586776734\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005709170270711184\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011662486474961042\n",
+      "        total_loss: 12.014441299438477\n",
+      "        vf_explained_var: 0.9769560098648071\n",
+      "        vf_loss: 12.025614356994629\n",
+      "    num_steps_sampled: 2345984\n",
+      "    num_steps_trained: 2345984\n",
+      "  iterations_since_restore: 29\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.05555555555555\n",
-      "    gpu_util_percent0: 0.2644444444444444\n",
+      "    cpu_util_percent: 31.90500000000001\n",
+      "    gpu_util_percent0: 0.352\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16808367664964877\n",
-      "    mean_env_wait_ms: 1.6489405832417077\n",
-      "    mean_inference_ms: 5.307994845910706\n",
-      "    mean_raw_obs_processing_ms: 0.45738673020424264\n",
-      "  time_since_restore: 70.47958087921143\n",
-      "  time_this_iter_s: 23.22701358795166\n",
-      "  time_total_s: 70.47958087921143\n",
+      "    mean_action_processing_ms: 0.12139221106336566\n",
+      "    mean_env_wait_ms: 0.6529852958216937\n",
+      "    mean_inference_ms: 4.591341456669196\n",
+      "    mean_raw_obs_processing_ms: 0.2648428504848152\n",
+      "  time_since_restore: 491.6463711261749\n",
+      "  time_this_iter_s: 16.648911952972412\n",
+      "  time_total_s: 491.6463711261749\n",
       "  timers:\n",
-      "    learn_throughput: 11042.229\n",
-      "    learn_time_ms: 14652.115\n",
-      "    sample_throughput: 18479.026\n",
-      "    sample_time_ms: 8755.44\n",
-      "    update_time_ms: 41.454\n",
-      "  timestamp: 1602167831\n",
+      "    learn_throughput: 7568.49\n",
+      "    learn_time_ms: 10688.526\n",
+      "    sample_throughput: 13464.931\n",
+      "    sample_time_ms: 6007.903\n",
+      "    update_time_ms: 23.866\n",
+      "  timestamp: 1602428777\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 2345984\n",
+      "  training_iteration: 29\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      3 |          70.4796 | 485376 |  228.248 |              287.616 |              115.788 |            859.825 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     29 |          491.646 | 2345984 |  243.374 |              294.657 |               146.02 |            815.731 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-34\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3446.7897435897435\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_15-06-34\n",
       "  done: false\n",
-      "  episode_len_mean: 853.2689873417721\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.76543920214786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 814.8417094017094\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 243.7793317793318\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 81\n",
+      "  episodes_total: 2925\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -7342,83 +6841,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0947366952896118\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005848201550543308\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01150441262871027\n",
-      "        total_loss: 13.476828002929688\n",
-      "        vf_explained_var: 0.9183750152587891\n",
-      "        vf_loss: 13.487747383117675\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8143168568611145\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006050251703709364\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014920068671926856\n",
+      "        total_loss: 10.06276626586914\n",
+      "        vf_explained_var: 0.9785787463188171\n",
+      "        vf_loss: 10.07716236114502\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 30\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 35.855555555555554\n",
-      "    gpu_util_percent0: 0.27814814814814814\n",
+      "    cpu_util_percent: 33.18947368421053\n",
+      "    gpu_util_percent0: 0.32473684210526316\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.744444444444445\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16618084056987167\n",
-      "    mean_env_wait_ms: 1.652121993019246\n",
-      "    mean_inference_ms: 5.206010003773685\n",
-      "    mean_raw_obs_processing_ms: 0.45115332512960615\n",
-      "  time_since_restore: 93.41903614997864\n",
-      "  time_this_iter_s: 22.939455270767212\n",
-      "  time_total_s: 93.41903614997864\n",
+      "    mean_action_processing_ms: 0.12131394765638424\n",
+      "    mean_env_wait_ms: 0.6532775137196953\n",
+      "    mean_inference_ms: 4.58615184577209\n",
+      "    mean_raw_obs_processing_ms: 0.26462242488560034\n",
+      "  time_since_restore: 508.3601791858673\n",
+      "  time_this_iter_s: 16.713808059692383\n",
+      "  time_total_s: 508.3601791858673\n",
       "  timers:\n",
-      "    learn_throughput: 11054.503\n",
-      "    learn_time_ms: 14635.845\n",
-      "    sample_throughput: 18733.219\n",
-      "    sample_time_ms: 8636.637\n",
-      "    update_time_ms: 36.312\n",
-      "  timestamp: 1602167854\n",
+      "    learn_throughput: 7570.724\n",
+      "    learn_time_ms: 10685.372\n",
+      "    sample_throughput: 13479.185\n",
+      "    sample_time_ms: 6001.55\n",
+      "    update_time_ms: 23.677\n",
+      "  timestamp: 1602428794\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 30\n",
+      "  trial_id: 25e0a_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      4 |           93.419 | 647168 |  228.765 |              287.616 |              115.788 |            853.269 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     30 |           508.36 | 2426880 |  243.779 |              294.657 |               146.02 |            814.842 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-57\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3443.8039408866994\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_15-06-52\n",
       "  done: false\n",
-      "  episode_len_mean: 842.2431289640592\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.57511691972567\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 314\n",
-      "  episodes_total: 946\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 813.6032840722496\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 244.2317261282779\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 120\n",
+      "  episodes_total: 3045\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -7426,74 +6923,5016 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0704583883285523\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006159011553972959\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01097527714446187\n",
-      "        total_loss: 18.48041114807129\n",
-      "        vf_explained_var: 0.9505600929260254\n",
-      "        vf_loss: 18.490771102905274\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7847271919250488\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006011144630610943\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0123886376619339\n",
+      "        total_loss: 13.336679077148437\n",
+      "        vf_explained_var: 0.9797344207763672\n",
+      "        vf_loss: 13.348544883728028\n",
+      "    num_steps_sampled: 2507776\n",
+      "    num_steps_trained: 2507776\n",
+      "  iterations_since_restore: 31\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.67142857142857\n",
-      "    gpu_util_percent0: 0.34750000000000003\n",
+      "    cpu_util_percent: 31.325\n",
+      "    gpu_util_percent0: 0.326\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.739285714285716\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 79049\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1637216679032345\n",
-      "    mean_env_wait_ms: 1.6595417244788717\n",
-      "    mean_inference_ms: 5.075327722233796\n",
-      "    mean_raw_obs_processing_ms: 0.443719930951552\n",
-      "  time_since_restore: 116.6165714263916\n",
-      "  time_this_iter_s: 23.197535276412964\n",
-      "  time_total_s: 116.6165714263916\n",
+      "    mean_action_processing_ms: 0.12120461289636575\n",
+      "    mean_env_wait_ms: 0.6537134773825316\n",
+      "    mean_inference_ms: 4.578829606903599\n",
+      "    mean_raw_obs_processing_ms: 0.26431758902828895\n",
+      "  time_since_restore: 525.2894396781921\n",
+      "  time_this_iter_s: 16.92926049232483\n",
+      "  time_total_s: 525.2894396781921\n",
       "  timers:\n",
-      "    learn_throughput: 11077.95\n",
-      "    learn_time_ms: 14604.868\n",
-      "    sample_throughput: 18764.263\n",
-      "    sample_time_ms: 8622.347\n",
-      "    update_time_ms: 48.444\n",
-      "  timestamp: 1602167877\n",
+      "    learn_throughput: 7559.066\n",
+      "    learn_time_ms: 10701.852\n",
+      "    sample_throughput: 13477.547\n",
+      "    sample_time_ms: 6002.279\n",
+      "    update_time_ms: 22.455\n",
+      "  timestamp: 1602428812\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2507776\n",
+      "  training_iteration: 31\n",
+      "  trial_id: 25e0a_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     31 |          525.289 | 2507776 |  244.232 |              294.657 |               146.02 |            813.603 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3441.074050632911\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_15-07-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 812.5060126582279\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 244.64534586370036\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 115\n",
+      "  episodes_total: 3160\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7759140849113464\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005504181887954473\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011239721812307835\n",
+      "        total_loss: 11.656171417236328\n",
+      "        vf_explained_var: 0.9791274070739746\n",
+      "        vf_loss: 11.666938591003419\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 32\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.285000000000004\n",
+      "    gpu_util_percent0: 0.3175\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79049\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12110333400562719\n",
+      "    mean_env_wait_ms: 0.6540812881827459\n",
+      "    mean_inference_ms: 4.57217500758545\n",
+      "    mean_raw_obs_processing_ms: 0.2640325453469295\n",
+      "  time_since_restore: 542.2914707660675\n",
+      "  time_this_iter_s: 17.002031087875366\n",
+      "  time_total_s: 542.2914707660675\n",
+      "  timers:\n",
+      "    learn_throughput: 7540.968\n",
+      "    learn_time_ms: 10727.535\n",
+      "    sample_throughput: 13444.222\n",
+      "    sample_time_ms: 6017.157\n",
+      "    update_time_ms: 23.317\n",
+      "  timestamp: 1602428829\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 32\n",
+      "  trial_id: 25e0a_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     32 |          542.291 | 2588672 |  244.645 |              294.657 |               146.02 |            812.506 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3439.0583333333334\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_15-07-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 811.7601851851852\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 244.95075757575762\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 80\n",
+      "  episodes_total: 3240\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7811835169792175\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006416494492441416\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012559976987540722\n",
+      "        total_loss: 8.990324211120605\n",
+      "        vf_explained_var: 0.9806587100028992\n",
+      "        vf_loss: 9.002320289611816\n",
+      "    num_steps_sampled: 2669568\n",
+      "    num_steps_trained: 2669568\n",
+      "  iterations_since_restore: 33\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.37894736842105\n",
+      "    gpu_util_percent0: 0.2831578947368421\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79049\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12103828068124152\n",
+      "    mean_env_wait_ms: 0.6543448696043557\n",
+      "    mean_inference_ms: 4.567834982455508\n",
+      "    mean_raw_obs_processing_ms: 0.2638492420763033\n",
+      "  time_since_restore: 558.9726655483246\n",
+      "  time_this_iter_s: 16.68119478225708\n",
+      "  time_total_s: 558.9726655483246\n",
+      "  timers:\n",
+      "    learn_throughput: 7553.285\n",
+      "    learn_time_ms: 10710.042\n",
+      "    sample_throughput: 13425.57\n",
+      "    sample_time_ms: 6025.517\n",
+      "    update_time_ms: 23.002\n",
+      "  timestamp: 1602428845\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2669568\n",
+      "  training_iteration: 33\n",
+      "  trial_id: 25e0a_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     33 |          558.973 | 2669568 |  244.951 |              294.657 |               146.02 |             811.76 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3436.664176874813\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_15-07-42\n",
+      "  done: false\n",
+      "  episode_len_mean: 810.7051090528831\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 245.3135085543213\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 107\n",
+      "  episodes_total: 3347\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7612020254135132\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005618926044553519\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014426779658242595\n",
+      "        total_loss: 10.50188980102539\n",
+      "        vf_explained_var: 0.9819744229316711\n",
+      "        vf_loss: 10.515831184387206\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 34\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.050000000000004\n",
+      "    gpu_util_percent0: 0.3135\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79049\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12095196212371193\n",
+      "    mean_env_wait_ms: 0.6546898335950064\n",
+      "    mean_inference_ms: 4.562119786136694\n",
+      "    mean_raw_obs_processing_ms: 0.2636064951710148\n",
+      "  time_since_restore: 575.9109237194061\n",
+      "  time_this_iter_s: 16.938258171081543\n",
+      "  time_total_s: 575.9109237194061\n",
+      "  timers:\n",
+      "    learn_throughput: 7548.387\n",
+      "    learn_time_ms: 10716.991\n",
+      "    sample_throughput: 13440.954\n",
+      "    sample_time_ms: 6018.62\n",
+      "    update_time_ms: 25.267\n",
+      "  timestamp: 1602428862\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 34\n",
+      "  trial_id: 25e0a_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     34 |          575.911 | 2750464 |  245.314 |              294.657 |               146.02 |            810.705 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3433.486323063634\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_15-08-00\n",
+      "  done: false\n",
+      "  episode_len_mean: 809.8491217967176\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 245.79500155601514\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 126\n",
+      "  episodes_total: 3473\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.755747628211975\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00591852879151702\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012422900833189487\n",
+      "        total_loss: 9.482335662841797\n",
+      "        vf_explained_var: 0.9842199087142944\n",
+      "        vf_loss: 9.494241714477539\n",
+      "    num_steps_sampled: 2831360\n",
+      "    num_steps_trained: 2831360\n",
+      "  iterations_since_restore: 35\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.169999999999998\n",
+      "    gpu_util_percent0: 0.313\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79049\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12085747040716455\n",
+      "    mean_env_wait_ms: 0.6550729696743465\n",
+      "    mean_inference_ms: 4.555915738902905\n",
+      "    mean_raw_obs_processing_ms: 0.26334772572820075\n",
+      "  time_since_restore: 592.8397195339203\n",
+      "  time_this_iter_s: 16.92879581451416\n",
+      "  time_total_s: 592.8397195339203\n",
+      "  timers:\n",
+      "    learn_throughput: 7550.241\n",
+      "    learn_time_ms: 10714.361\n",
+      "    sample_throughput: 13452.948\n",
+      "    sample_time_ms: 6013.254\n",
+      "    update_time_ms: 25.59\n",
+      "  timestamp: 1602428880\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2831360\n",
+      "  training_iteration: 35\n",
+      "  trial_id: 25e0a_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | RUNNING  | 172.17.0.4:79049 |     35 |           592.84 | 2831360 |  245.795 |              294.657 |               146.02 |            809.849 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_25e0a_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3432.0928270042195\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_15-08-17\n",
+      "  done: true\n",
+      "  episode_len_mean: 809.4239099859353\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 246.00613732259308\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 82\n",
+      "  episodes_total: 3555\n",
+      "  experiment_id: 53c1d7d85d994ed59577abcd9844eca4\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.762268352508545\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005749249923974275\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014044645662215772\n",
+      "        total_loss: 8.698633766174316\n",
+      "        vf_explained_var: 0.9826677441596985\n",
+      "        vf_loss: 8.712179946899415\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 36\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.48947368421053\n",
+      "    gpu_util_percent0: 0.3121052631578947\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79049\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12080047013051126\n",
+      "    mean_env_wait_ms: 0.6553066919371578\n",
+      "    mean_inference_ms: 4.552032024188442\n",
+      "    mean_raw_obs_processing_ms: 0.263186835860797\n",
+      "  time_since_restore: 609.7753958702087\n",
+      "  time_this_iter_s: 16.935676336288452\n",
+      "  time_total_s: 609.7753958702087\n",
+      "  timers:\n",
+      "    learn_throughput: 7537.787\n",
+      "    learn_time_ms: 10732.062\n",
+      "    sample_throughput: 13421.011\n",
+      "    sample_time_ms: 6027.564\n",
+      "    update_time_ms: 26.437\n",
+      "  timestamp: 1602428897\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 36\n",
+      "  trial_id: 25e0a_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | TERMINATED |       |     36 |          609.775 | 2912256 |  246.006 |              294.657 |               146.02 |            809.424 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_25e0a_00000 | TERMINATED |       |     36 |          609.775 | 2912256 |  246.006 |              294.657 |               146.02 |            809.424 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 78836\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_145751-17fqd0cs/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_145751-17fqd0cs/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3111\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 625\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602428897\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4092\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3452.05594\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 294.65657\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 146.0202\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 242.98142\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 2753\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 28\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▃▄▅▆▇█\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mcrimson-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/17fqd0cs\u001b[0m\n",
+      "2020-10-11 15:08:26,064 - wandb.wandb_agent - INFO - Cleaning up finished run: 17fqd0cs\n",
+      "2020-10-11 15:08:26,388 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 15:08:26,388 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tnum_envs_per_worker: 2\n",
+      "\trollout_fragment_length: 768\n",
+      "2020-10-11 15:08:26,390 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --num_envs_per_worker=2 --rollout_fragment_length=768\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-11 15:08:31,408 - wandb.wandb_agent - INFO - Running runs: ['7u9y5atf']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdark-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/8x5lxuul\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/7u9y5atf\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_150828-7u9y5atf\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-11 15:08:32,080\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=35160)\u001b[0m 2020-10-11 15:08:34,925\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=35061)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35061)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35046)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35046)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35075)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35075)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35055)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35055)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35156)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35156)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35064)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35064)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35053)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35053)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35058)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35058)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35136)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35136)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35059)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35059)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35044)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35044)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35070)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35070)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35073)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35073)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35133)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35133)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35151)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35151)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35138)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35138)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35066)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35066)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35048)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35048)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35047)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35047)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35054)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35054)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35057)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35057)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35067)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35067)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35139)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35139)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35051)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35051)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35179)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35179)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35137)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35137)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35110)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35110)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35052)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35052)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35065)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35065)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35049)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35049)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35129)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35129)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35078)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35078)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35144)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35144)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35132)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35132)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35080)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35080)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35146)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35146)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35117)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35117)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35119)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35119)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35164)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35164)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35062)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35062)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35063)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35063)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35131)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35131)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35060)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35060)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35076)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35076)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35074)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35074)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35079)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35079)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=35125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=35125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics: {}\n",
+      "  date: 2020-10-11_15-09-03\n",
+      "  done: false\n",
+      "  episode_len_mean: .nan\n",
+      "  episode_reward_max: .nan\n",
+      "  episode_reward_mean: .nan\n",
+      "  episode_reward_min: .nan\n",
+      "  episodes_this_iter: 0\n",
+      "  episodes_total: 0\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.19709346975599\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006012780392276389\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012594069770005132\n",
+      "        total_loss: 531.4765886579241\n",
+      "        vf_explained_var: -0.1959501951932907\n",
+      "        vf_loss: 531.4880981445312\n",
+      "    num_steps_sampled: 121344\n",
+      "    num_steps_trained: 121344\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 26.41071428571428\n",
+      "    gpu_util_percent0: 0.42\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.439285714285714\n",
+      "    vram_util_percent0: 0.09704586984022866\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf: {}\n",
+      "  time_since_restore: 23.542519092559814\n",
+      "  time_this_iter_s: 23.542519092559814\n",
+      "  time_total_s: 23.542519092559814\n",
+      "  timers:\n",
+      "    learn_throughput: 7302.868\n",
+      "    learn_time_ms: 16615.938\n",
+      "    sample_throughput: 17642.292\n",
+      "    sample_time_ms: 6878.018\n",
+      "    update_time_ms: 23.09\n",
+      "  timestamp: 1602428943\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 121344\n",
+      "  training_iteration: 1\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      1 |          23.5425 | 121344 |      nan |                  nan |                  nan |                nan |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4112\n",
+      "    time_step_mean: 3628.184\n",
+      "    time_step_min: 3295\n",
+      "  date: 2020-10-11_15-09-26\n",
+      "  done: false\n",
+      "  episode_len_mean: 892.0759493670886\n",
+      "  episode_reward_max: 266.7777777777774\n",
+      "  episode_reward_mean: 216.28679197033605\n",
+      "  episode_reward_min: 142.98989898989888\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.1605888264519828\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005510005168616772\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010740843401955706\n",
+      "        total_loss: 457.9469953264509\n",
+      "        vf_explained_var: 0.5077921152114868\n",
+      "        vf_loss: 457.95674787248885\n",
+      "    num_steps_sampled: 242688\n",
+      "    num_steps_trained: 242688\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.27692307692308\n",
+      "    gpu_util_percent0: 0.28423076923076923\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5807692307692305\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16446233676361774\n",
+      "    mean_env_wait_ms: 1.162943500295647\n",
+      "    mean_inference_ms: 5.557823582499349\n",
+      "    mean_raw_obs_processing_ms: 0.43066957193408895\n",
+      "  time_since_restore: 46.10712456703186\n",
+      "  time_this_iter_s: 22.564605474472046\n",
+      "  time_total_s: 46.10712456703186\n",
+      "  timers:\n",
+      "    learn_throughput: 7354.362\n",
+      "    learn_time_ms: 16499.596\n",
+      "    sample_throughput: 18711.931\n",
+      "    sample_time_ms: 6484.846\n",
+      "    update_time_ms: 31.635\n",
+      "  timestamp: 1602428966\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 242688\n",
+      "  training_iteration: 2\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.0/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      2 |          46.1071 | 242688 |  216.287 |              266.778 |               142.99 |            892.076 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4151\n",
+      "    time_step_mean: 3613.0989399293285\n",
+      "    time_step_min: 3295\n",
+      "  date: 2020-10-11_15-09-48\n",
+      "  done: false\n",
+      "  episode_len_mean: 885.8417721518987\n",
+      "  episode_reward_max: 266.7777777777774\n",
+      "  episode_reward_mean: 219.05146400715998\n",
+      "  episode_reward_min: 137.08080808080805\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.1425047261374337\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006121054757386446\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010844438403312649\n",
+      "        total_loss: 173.54720851353235\n",
+      "        vf_explained_var: 0.7992362380027771\n",
+      "        vf_loss: 173.55693926130022\n",
+      "    num_steps_sampled: 364032\n",
+      "    num_steps_trained: 364032\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.200000000000006\n",
+      "    gpu_util_percent0: 0.2938461538461538\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.657692307692308\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16196955022568685\n",
+      "    mean_env_wait_ms: 1.1660414931875447\n",
+      "    mean_inference_ms: 5.382874079182883\n",
+      "    mean_raw_obs_processing_ms: 0.42491766998890496\n",
+      "  time_since_restore: 67.96861171722412\n",
+      "  time_this_iter_s: 21.86148715019226\n",
+      "  time_total_s: 67.96861171722412\n",
+      "  timers:\n",
+      "    learn_throughput: 7379.502\n",
+      "    learn_time_ms: 16443.386\n",
+      "    sample_throughput: 19767.194\n",
+      "    sample_time_ms: 6138.656\n",
+      "    update_time_ms: 32.948\n",
+      "  timestamp: 1602428988\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 364032\n",
+      "  training_iteration: 3\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      3 |          67.9686 | 364032 |  219.051 |              266.778 |              137.081 |            885.842 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4151\n",
+      "    time_step_mean: 3602.736961451247\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-11_15-10-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 879.8206751054852\n",
+      "  episode_reward_max: 278.89898989898967\n",
+      "  episode_reward_mean: 220.72548267484962\n",
+      "  episode_reward_min: 137.08080808080805\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.125728794506618\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.00639094106320824\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01306218234822154\n",
+      "        total_loss: 96.90472303118024\n",
+      "        vf_explained_var: 0.8719539642333984\n",
+      "        vf_loss: 96.91662052699498\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.504\n",
+      "    gpu_util_percent0: 0.3436\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.6200000000000006\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16011317296980337\n",
+      "    mean_env_wait_ms: 1.1691356112762634\n",
+      "    mean_inference_ms: 5.252999245913915\n",
+      "    mean_raw_obs_processing_ms: 0.42028241781166387\n",
+      "  time_since_restore: 89.6299831867218\n",
+      "  time_this_iter_s: 21.66137146949768\n",
+      "  time_total_s: 89.6299831867218\n",
+      "  timers:\n",
+      "    learn_throughput: 7389.29\n",
+      "    learn_time_ms: 16421.605\n",
+      "    sample_throughput: 20514.598\n",
+      "    sample_time_ms: 5915.007\n",
+      "    update_time_ms: 29.479\n",
+      "  timestamp: 1602429009\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 4\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      4 |            89.63 | 485376 |  220.725 |              278.899 |              137.081 |            879.821 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3605.1502504173623\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-11_15-10-31\n",
+      "  done: false\n",
+      "  episode_len_mean: 875.7405063291139\n",
+      "  episode_reward_max: 278.89898989898967\n",
+      "  episode_reward_mean: 220.5459979542256\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.1141637904303414\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006669476495257446\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012190746708906122\n",
+      "        total_loss: 72.5603757585798\n",
+      "        vf_explained_var: 0.9030656814575195\n",
+      "        vf_loss: 72.57134246826172\n",
+      "    num_steps_sampled: 606720\n",
+      "    num_steps_trained: 606720\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.73076923076923\n",
+      "    gpu_util_percent0: 0.2607692307692307\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.619230769230769\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1586679213940069\n",
+      "    mean_env_wait_ms: 1.1718046862564908\n",
+      "    mean_inference_ms: 5.153834685027547\n",
+      "    mean_raw_obs_processing_ms: 0.4165729405901832\n",
+      "  time_since_restore: 111.46106910705566\n",
+      "  time_this_iter_s: 21.831085920333862\n",
+      "  time_total_s: 111.46106910705566\n",
+      "  timers:\n",
+      "    learn_throughput: 7385.802\n",
+      "    learn_time_ms: 16429.36\n",
+      "    sample_throughput: 21004.437\n",
+      "    sample_time_ms: 5777.065\n",
+      "    update_time_ms: 31.101\n",
+      "  timestamp: 1602429031\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 606720\n",
+      "  training_iteration: 5\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      5 |          111.461 | 606720 |  220.546 |              278.899 |              115.717 |            875.741 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3598.815059445178\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-11_15-10-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 870.0126582278481\n",
+      "  episode_reward_max: 283.4444444444445\n",
+      "  episode_reward_mean: 221.5198184375398\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.1031875269753593\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.0058455463232738635\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013633016629942827\n",
+      "        total_loss: 56.65061024257115\n",
+      "        vf_explained_var: 0.9194228053092957\n",
+      "        vf_loss: 56.66318348475865\n",
+      "    num_steps_sampled: 728064\n",
+      "    num_steps_trained: 728064\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.671999999999997\n",
+      "    gpu_util_percent0: 0.41\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.676\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1575500456508179\n",
+      "    mean_env_wait_ms: 1.1743433825778726\n",
+      "    mean_inference_ms: 5.076129067985898\n",
+      "    mean_raw_obs_processing_ms: 0.41371068930947436\n",
+      "  time_since_restore: 133.44550371170044\n",
+      "  time_this_iter_s: 21.984434604644775\n",
+      "  time_total_s: 133.44550371170044\n",
+      "  timers:\n",
+      "    learn_throughput: 7381.676\n",
+      "    learn_time_ms: 16438.543\n",
+      "    sample_throughput: 21215.982\n",
+      "    sample_time_ms: 5719.462\n",
+      "    update_time_ms: 29.754\n",
+      "  timestamp: 1602429053\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 728064\n",
+      "  training_iteration: 6\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      6 |          133.446 | 728064 |   221.52 |              283.444 |              115.717 |            870.013 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3588.261202185792\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-11_15-11-15\n",
+      "  done: false\n",
+      "  episode_len_mean: 864.6424050632911\n",
+      "  episode_reward_max: 283.4444444444445\n",
+      "  episode_reward_mean: 223.08851169927104\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 948\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.0879003490720476\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006762735878250429\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013632669695653021\n",
+      "        total_loss: 37.261954171316965\n",
+      "        vf_explained_var: 0.944100022315979\n",
+      "        vf_loss: 37.274344308035715\n",
+      "    num_steps_sampled: 849408\n",
+      "    num_steps_trained: 849408\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.33076923076923\n",
+      "    gpu_util_percent0: 0.35000000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.676923076923077\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15664822309319318\n",
+      "    mean_env_wait_ms: 1.1764875590147201\n",
+      "    mean_inference_ms: 5.0132356283014055\n",
+      "    mean_raw_obs_processing_ms: 0.4113315160451748\n",
+      "  time_since_restore: 155.2493019104004\n",
+      "  time_this_iter_s: 21.80379819869995\n",
+      "  time_total_s: 155.2493019104004\n",
+      "  timers:\n",
+      "    learn_throughput: 7379.547\n",
+      "    learn_time_ms: 16443.286\n",
+      "    sample_throughput: 21469.831\n",
+      "    sample_time_ms: 5651.838\n",
+      "    update_time_ms: 30.593\n",
+      "  timestamp: 1602429075\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 849408\n",
+      "  training_iteration: 7\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      7 |          155.249 | 849408 |  223.089 |              283.444 |              115.717 |            864.642 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3578.4057835820895\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-11-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 861.3013574660633\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 224.4733762969056\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 157\n",
+      "  episodes_total: 1105\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.0726469244275774\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.0064350370583789685\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01426797326920288\n",
+      "        total_loss: 36.13643755231585\n",
+      "        vf_explained_var: 0.9460744857788086\n",
+      "        vf_loss: 36.14952414376395\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.708000000000002\n",
+      "    gpu_util_percent0: 0.44480000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.6800000000000006\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15592918975116088\n",
+      "    mean_env_wait_ms: 1.1785108080781528\n",
+      "    mean_inference_ms: 4.961603268618143\n",
+      "    mean_raw_obs_processing_ms: 0.40945494346936523\n",
+      "  time_since_restore: 176.9723105430603\n",
+      "  time_this_iter_s: 21.723008632659912\n",
+      "  time_total_s: 176.9723105430603\n",
+      "  timers:\n",
+      "    learn_throughput: 7387.429\n",
+      "    learn_time_ms: 16425.742\n",
+      "    sample_throughput: 21629.303\n",
+      "    sample_time_ms: 5610.167\n",
+      "    update_time_ms: 31.296\n",
+      "  timestamp: 1602429097\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 8\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.9/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      8 |          176.972 | 970752 |  224.473 |              287.232 |              115.717 |            861.301 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3568.161316872428\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-11-59\n",
+      "  done: false\n",
+      "  episode_len_mean: 858.0144230769231\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 226.13347416472402\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 143\n",
+      "  episodes_total: 1248\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.0612812382834298\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.0064252400770783424\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013670566009490617\n",
+      "        total_loss: 24.85169301714216\n",
+      "        vf_explained_var: 0.9604588150978088\n",
+      "        vf_loss: 24.864185333251953\n",
+      "    num_steps_sampled: 1092096\n",
+      "    num_steps_trained: 1092096\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.88\n",
+      "    gpu_util_percent0: 0.3204\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.716\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1553689882252152\n",
+      "    mean_env_wait_ms: 1.1800334051653998\n",
+      "    mean_inference_ms: 4.921496393253225\n",
+      "    mean_raw_obs_processing_ms: 0.4079070973587893\n",
+      "  time_since_restore: 198.8754620552063\n",
+      "  time_this_iter_s: 21.903151512145996\n",
+      "  time_total_s: 198.8754620552063\n",
+      "  timers:\n",
+      "    learn_throughput: 7391.084\n",
+      "    learn_time_ms: 16417.619\n",
+      "    sample_throughput: 21685.324\n",
+      "    sample_time_ms: 5595.674\n",
+      "    update_time_ms: 30.585\n",
+      "  timestamp: 1602429119\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1092096\n",
+      "  training_iteration: 9\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |      9 |          198.875 | 1092096 |  226.133 |              287.232 |              115.717 |            858.014 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3562.0239752513535\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-12-21\n",
+      "  done: false\n",
+      "  episode_len_mean: 856.1025641025641\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 226.98391151332316\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 78\n",
+      "  episodes_total: 1326\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.0382741349084037\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006699717004916498\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015758267204676355\n",
+      "        total_loss: 19.22611209324428\n",
+      "        vf_explained_var: 0.9653859734535217\n",
+      "        vf_loss: 19.240634645734513\n",
+      "    num_steps_sampled: 1213440\n",
+      "    num_steps_trained: 1213440\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.94\n",
+      "    gpu_util_percent0: 0.43320000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.6800000000000006\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15507451673504405\n",
+      "    mean_env_wait_ms: 1.1807877501396284\n",
+      "    mean_inference_ms: 4.901231582618228\n",
+      "    mean_raw_obs_processing_ms: 0.40704194233638713\n",
+      "  time_since_restore: 220.57692289352417\n",
+      "  time_this_iter_s: 21.70146083831787\n",
+      "  time_total_s: 220.57692289352417\n",
+      "  timers:\n",
+      "    learn_throughput: 7396.911\n",
+      "    learn_time_ms: 16404.686\n",
+      "    sample_throughput: 21782.603\n",
+      "    sample_time_ms: 5570.684\n",
+      "    update_time_ms: 30.062\n",
+      "  timestamp: 1602429141\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1213440\n",
+      "  training_iteration: 10\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.4/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     10 |          220.577 | 1213440 |  226.984 |              287.232 |              115.717 |            856.103 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3552.330719885959\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-12-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 853.9428969359332\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 228.58804620016306\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 110\n",
+      "  episodes_total: 1436\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.0348200968333654\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006286287746791329\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014631494147969144\n",
+      "        total_loss: 14.363759994506836\n",
+      "        vf_explained_var: 0.968192994594574\n",
+      "        vf_loss: 14.377237319946289\n",
+      "    num_steps_sampled: 1334784\n",
+      "    num_steps_trained: 1334784\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.97307692307693\n",
+      "    gpu_util_percent0: 0.3607692307692308\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.6615384615384623\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15474405851865955\n",
+      "    mean_env_wait_ms: 1.182007279150758\n",
+      "    mean_inference_ms: 4.875525574892237\n",
+      "    mean_raw_obs_processing_ms: 0.4059855497358534\n",
+      "  time_since_restore: 242.30754470825195\n",
+      "  time_this_iter_s: 21.730621814727783\n",
+      "  time_total_s: 242.30754470825195\n",
+      "  timers:\n",
+      "    learn_throughput: 7405.477\n",
+      "    learn_time_ms: 16385.71\n",
+      "    sample_throughput: 22442.098\n",
+      "    sample_time_ms: 5406.981\n",
+      "    update_time_ms: 29.414\n",
+      "  timestamp: 1602429163\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1334784\n",
+      "  training_iteration: 11\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     11 |          242.308 | 1334784 |  228.588 |              287.232 |              115.717 |            853.943 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3540.557493540052\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-13-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 850.8380771663504\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 230.23243823433563\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 145\n",
+      "  episodes_total: 1581\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.0262405020850045\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005980719346553087\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014333377592265606\n",
+      "        total_loss: 13.499579974583217\n",
+      "        vf_explained_var: 0.9717524647712708\n",
+      "        vf_loss: 13.51282024383545\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.668000000000003\n",
+      "    gpu_util_percent0: 0.39159999999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.6600000000000006\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15429620617145812\n",
+      "    mean_env_wait_ms: 1.1833319060761593\n",
+      "    mean_inference_ms: 4.843988008368151\n",
+      "    mean_raw_obs_processing_ms: 0.40454396907496637\n",
+      "  time_since_restore: 263.8103744983673\n",
+      "  time_this_iter_s: 21.502829790115356\n",
+      "  time_total_s: 263.8103744983673\n",
+      "  timers:\n",
+      "    learn_throughput: 7408.141\n",
+      "    learn_time_ms: 16379.818\n",
+      "    sample_throughput: 22856.872\n",
+      "    sample_time_ms: 5308.863\n",
+      "    update_time_ms: 27.555\n",
+      "  timestamp: 1602429184\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 12\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     12 |           263.81 | 1456128 |  230.232 |              287.232 |              115.717 |            850.838 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3530.9941348973607\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-13-26\n",
+      "  done: false\n",
+      "  episode_len_mean: 847.584004602992\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 231.74273227092547\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 157\n",
+      "  episodes_total: 1738\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.0086423328944616\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006141403956072671\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014106190563844783\n",
+      "        total_loss: 13.797930717468262\n",
+      "        vf_explained_var: 0.9745455980300903\n",
+      "        vf_loss: 13.810909271240234\n",
+      "    num_steps_sampled: 1577472\n",
+      "    num_steps_trained: 1577472\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.456\n",
+      "    gpu_util_percent0: 0.29279999999999995\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.6600000000000006\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15386821835674025\n",
+      "    mean_env_wait_ms: 1.1847743693546156\n",
+      "    mean_inference_ms: 4.813818277470295\n",
+      "    mean_raw_obs_processing_ms: 0.4032167996556026\n",
+      "  time_since_restore: 285.65070486068726\n",
+      "  time_this_iter_s: 21.840330362319946\n",
+      "  time_total_s: 285.65070486068726\n",
+      "  timers:\n",
+      "    learn_throughput: 7414.726\n",
+      "    learn_time_ms: 16365.271\n",
+      "    sample_throughput: 22797.837\n",
+      "    sample_time_ms: 5322.61\n",
+      "    update_time_ms: 25.914\n",
+      "  timestamp: 1602429206\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1577472\n",
+      "  training_iteration: 13\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     13 |          285.651 | 1577472 |  231.743 |              287.232 |              115.717 |            847.584 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3521.369833601718\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-13-48\n",
+      "  done: false\n",
+      "  episode_len_mean: 844.5965189873418\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 233.0428014320418\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.9857570443834577\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006410458457789251\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013821696629747748\n",
+      "        total_loss: 15.916649545942034\n",
+      "        vf_explained_var: 0.9734243154525757\n",
+      "        vf_loss: 15.92928763798305\n",
+      "    num_steps_sampled: 1698816\n",
+      "    num_steps_trained: 1698816\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.988000000000003\n",
+      "    gpu_util_percent0: 0.37560000000000004\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.6600000000000006\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15349101006112637\n",
+      "    mean_env_wait_ms: 1.1861817431817772\n",
+      "    mean_inference_ms: 4.7871644737859835\n",
+      "    mean_raw_obs_processing_ms: 0.40207297784463586\n",
+      "  time_since_restore: 307.2017602920532\n",
+      "  time_this_iter_s: 21.551055431365967\n",
+      "  time_total_s: 307.2017602920532\n",
+      "  timers:\n",
+      "    learn_throughput: 7423.694\n",
+      "    learn_time_ms: 16345.5\n",
+      "    sample_throughput: 22760.201\n",
+      "    sample_time_ms: 5331.412\n",
+      "    update_time_ms: 25.526\n",
+      "  timestamp: 1602429228\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1698816\n",
+      "  training_iteration: 14\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     14 |          307.202 | 1698816 |  233.043 |              287.232 |              115.717 |            844.597 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3513.2290945076693\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-14-10\n",
+      "  done: false\n",
+      "  episode_len_mean: 842.1966893865628\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 234.1798166671583\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2054\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.9603591901915414\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005421308800578117\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013045819792231279\n",
+      "        total_loss: 15.805892671857562\n",
+      "        vf_explained_var: 0.9750902056694031\n",
+      "        vf_loss: 15.817950112479073\n",
+      "    num_steps_sampled: 1820160\n",
+      "    num_steps_trained: 1820160\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.016\n",
+      "    gpu_util_percent0: 0.2904\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.6600000000000006\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15315197911764228\n",
+      "    mean_env_wait_ms: 1.1875165970511823\n",
+      "    mean_inference_ms: 4.76345541623027\n",
+      "    mean_raw_obs_processing_ms: 0.4010729771882032\n",
+      "  time_since_restore: 328.93989777565\n",
+      "  time_this_iter_s: 21.7381374835968\n",
+      "  time_total_s: 328.93989777565\n",
+      "  timers:\n",
+      "    learn_throughput: 7436.89\n",
+      "    learn_time_ms: 16316.498\n",
+      "    sample_throughput: 22649.632\n",
+      "    sample_time_ms: 5357.438\n",
+      "    update_time_ms: 25.23\n",
+      "  timestamp: 1602429250\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1820160\n",
+      "  training_iteration: 15\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     15 |           328.94 | 1820160 |   234.18 |              287.232 |              115.717 |            842.197 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3504.793483249197\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-14-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 839.8942133815551\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 235.41078506584824\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.9449490819658551\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005445404909551144\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011962981628520148\n",
+      "        total_loss: 16.383984565734863\n",
+      "        vf_explained_var: 0.9741386771202087\n",
+      "        vf_loss: 16.39495345524379\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.316\n",
+      "    gpu_util_percent0: 0.2984\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.664\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1528484315543595\n",
+      "    mean_env_wait_ms: 1.1887911368071282\n",
+      "    mean_inference_ms: 4.74218131957616\n",
+      "    mean_raw_obs_processing_ms: 0.40017344519996434\n",
+      "  time_since_restore: 350.6772770881653\n",
+      "  time_this_iter_s: 21.73737931251526\n",
+      "  time_total_s: 350.6772770881653\n",
+      "  timers:\n",
+      "    learn_throughput: 7450.254\n",
+      "    learn_time_ms: 16287.23\n",
+      "    sample_throughput: 22630.488\n",
+      "    sample_time_ms: 5361.97\n",
+      "    update_time_ms: 24.494\n",
+      "  timestamp: 1602429272\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 16\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     16 |          350.677 | 1941504 |  235.411 |              287.232 |              115.717 |            839.894 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3497.7826272999573\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-14-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 838.1071729957806\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 236.4022503516173\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2370\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.9374308075223651\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.00559737127540367\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013294356209891183\n",
+      "        total_loss: 15.215373992919922\n",
+      "        vf_explained_var: 0.9764556884765625\n",
+      "        vf_loss: 15.227642059326172\n",
+      "    num_steps_sampled: 2062848\n",
+      "    num_steps_trained: 2062848\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.4\n",
+      "    gpu_util_percent0: 0.324\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.664\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15257724502817518\n",
+      "    mean_env_wait_ms: 1.1899996811690225\n",
+      "    mean_inference_ms: 4.722984159887902\n",
+      "    mean_raw_obs_processing_ms: 0.3993836746575927\n",
+      "  time_since_restore: 372.45178604125977\n",
+      "  time_this_iter_s: 21.774508953094482\n",
+      "  time_total_s: 372.45178604125977\n",
+      "  timers:\n",
+      "    learn_throughput: 7461.078\n",
+      "    learn_time_ms: 16263.601\n",
+      "    sample_throughput: 22537.187\n",
+      "    sample_time_ms: 5384.168\n",
+      "    update_time_ms: 23.077\n",
+      "  timestamp: 1602429293\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2062848\n",
+      "  training_iteration: 17\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     17 |          372.452 | 2062848 |  236.402 |              287.232 |              115.717 |            838.107 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3491.910621242485\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-15-15\n",
+      "  done: false\n",
+      "  episode_len_mean: 836.8564082278481\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 237.2802111302901\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2528\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.9169140458106995\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005850059778562614\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013017413771844335\n",
+      "        total_loss: 16.00598362513951\n",
+      "        vf_explained_var: 0.9751184582710266\n",
+      "        vf_loss: 16.017922810145787\n",
+      "    num_steps_sampled: 2184192\n",
+      "    num_steps_trained: 2184192\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.24\n",
+      "    gpu_util_percent0: 0.39039999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.668\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15233482988803507\n",
+      "    mean_env_wait_ms: 1.191126424984892\n",
+      "    mean_inference_ms: 4.705623686958995\n",
+      "    mean_raw_obs_processing_ms: 0.39866854001910007\n",
+      "  time_since_restore: 393.76717138290405\n",
+      "  time_this_iter_s: 21.315385341644287\n",
+      "  time_total_s: 393.76717138290405\n",
+      "  timers:\n",
+      "    learn_throughput: 7475.193\n",
+      "    learn_time_ms: 16232.892\n",
+      "    sample_throughput: 22566.407\n",
+      "    sample_time_ms: 5377.196\n",
+      "    update_time_ms: 21.214\n",
+      "  timestamp: 1602429315\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2184192\n",
+      "  training_iteration: 18\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     18 |          393.767 | 2184192 |   237.28 |              287.232 |              115.717 |            836.856 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3486.705616283453\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-15-36\n",
+      "  done: false\n",
+      "  episode_len_mean: 835.8983618763962\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 238.1144505366395\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8977000202451434\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005370115794773612\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011884738267066755\n",
+      "        total_loss: 14.289475440979004\n",
+      "        vf_explained_var: 0.977433979511261\n",
+      "        vf_loss: 14.300375665937151\n",
+      "    num_steps_sampled: 2305536\n",
+      "    num_steps_trained: 2305536\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.535999999999998\n",
+      "    gpu_util_percent0: 0.41440000000000005\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.668\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15211533498846555\n",
+      "    mean_env_wait_ms: 1.1921504369177447\n",
+      "    mean_inference_ms: 4.6898987667105825\n",
+      "    mean_raw_obs_processing_ms: 0.39802764639523003\n",
+      "  time_since_restore: 415.3786497116089\n",
+      "  time_this_iter_s: 21.611478328704834\n",
+      "  time_total_s: 415.3786497116089\n",
+      "  timers:\n",
+      "    learn_throughput: 7486.311\n",
+      "    learn_time_ms: 16208.785\n",
+      "    sample_throughput: 22589.843\n",
+      "    sample_time_ms: 5371.618\n",
+      "    update_time_ms: 20.898\n",
+      "  timestamp: 1602429336\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2305536\n",
+      "  training_iteration: 19\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     19 |          415.379 | 2305536 |  238.114 |              287.232 |              115.717 |            835.898 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3481.1924581999288\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-15-58\n",
+      "  done: false\n",
+      "  episode_len_mean: 834.8027426160338\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 238.9297297873246\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.882460491997855\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005906718250896249\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01405173699770655\n",
+      "        total_loss: 12.80661950792585\n",
+      "        vf_explained_var: 0.9789648652076721\n",
+      "        vf_loss: 12.819578034537178\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.484615384615385\n",
+      "    gpu_util_percent0: 0.36038461538461536\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.673076923076923\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1519120577690361\n",
+      "    mean_env_wait_ms: 1.1930926752877107\n",
+      "    mean_inference_ms: 4.675480897578167\n",
+      "    mean_raw_obs_processing_ms: 0.3974390370694435\n",
+      "  time_since_restore: 436.8603720664978\n",
+      "  time_this_iter_s: 21.481722354888916\n",
+      "  time_total_s: 436.8603720664978\n",
+      "  timers:\n",
+      "    learn_throughput: 7498.562\n",
+      "    learn_time_ms: 16182.302\n",
+      "    sample_throughput: 22600.883\n",
+      "    sample_time_ms: 5368.994\n",
+      "    update_time_ms: 20.624\n",
+      "  timestamp: 1602429358\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 20\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     20 |           436.86 | 2426880 |   238.93 |              287.232 |              115.717 |            834.803 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3476.7905018524757\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-16-20\n",
+      "  done: false\n",
+      "  episode_len_mean: 833.8247834776815\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 239.44811876257563\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3002\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8673635806356158\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.00530183847461428\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013066353276371956\n",
+      "        total_loss: 12.449682371956962\n",
+      "        vf_explained_var: 0.9802118539810181\n",
+      "        vf_loss: 12.46177509852818\n",
+      "    num_steps_sampled: 2548224\n",
+      "    num_steps_trained: 2548224\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.432000000000006\n",
+      "    gpu_util_percent0: 0.3924\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.6800000000000006\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15172860233482208\n",
+      "    mean_env_wait_ms: 1.1939782753839872\n",
+      "    mean_inference_ms: 4.6623335323887884\n",
+      "    mean_raw_obs_processing_ms: 0.39690189844466195\n",
+      "  time_since_restore: 458.4210512638092\n",
+      "  time_this_iter_s: 21.5606791973114\n",
+      "  time_total_s: 458.4210512638092\n",
+      "  timers:\n",
+      "    learn_throughput: 7518.615\n",
+      "    learn_time_ms: 16139.143\n",
+      "    sample_throughput: 22508.453\n",
+      "    sample_time_ms: 5391.041\n",
+      "    update_time_ms: 22.393\n",
+      "  timestamp: 1602429380\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2548224\n",
+      "  training_iteration: 21\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     21 |          458.421 | 2548224 |  239.448 |              287.232 |              115.717 |            833.825 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3473.221618164375\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-16-42\n",
+      "  done: false\n",
+      "  episode_len_mean: 832.7841772151899\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 240.0985487789284\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3160\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8546512126922607\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005708524624684027\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012896726040967874\n",
+      "        total_loss: 13.318900789533343\n",
+      "        vf_explained_var: 0.9785168766975403\n",
+      "        vf_loss: 13.330741064889091\n",
+      "    num_steps_sampled: 2669568\n",
+      "    num_steps_trained: 2669568\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.732000000000003\n",
+      "    gpu_util_percent0: 0.3812\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.676\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1515593391654816\n",
+      "    mean_env_wait_ms: 1.1948021353136944\n",
+      "    mean_inference_ms: 4.6502269982439834\n",
+      "    mean_raw_obs_processing_ms: 0.3964146444561648\n",
+      "  time_since_restore: 480.10277342796326\n",
+      "  time_this_iter_s: 21.681722164154053\n",
+      "  time_total_s: 480.10277342796326\n",
+      "  timers:\n",
+      "    learn_throughput: 7527.616\n",
+      "    learn_time_ms: 16119.844\n",
+      "    sample_throughput: 22356.062\n",
+      "    sample_time_ms: 5427.79\n",
+      "    update_time_ms: 22.418\n",
+      "  timestamp: 1602429402\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2669568\n",
+      "  training_iteration: 22\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     22 |          480.103 | 2669568 |  240.099 |              287.232 |              115.717 |            832.784 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3468.681887366819\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-17-03\n",
+      "  done: false\n",
+      "  episode_len_mean: 831.6208559373116\n",
+      "  episode_reward_max: 287.232323232323\n",
+      "  episode_reward_mean: 240.76306464281137\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3318\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8429547377995082\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005444437265396118\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013345049694180489\n",
+      "        total_loss: 12.22777053288051\n",
+      "        vf_explained_var: 0.979284405708313\n",
+      "        vf_loss: 12.240111078534808\n",
+      "    num_steps_sampled: 2790912\n",
+      "    num_steps_trained: 2790912\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.77692307692308\n",
+      "    gpu_util_percent0: 0.35500000000000004\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.673076923076923\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.151402365872835\n",
+      "    mean_env_wait_ms: 1.195593929805584\n",
+      "    mean_inference_ms: 4.639032297927149\n",
+      "    mean_raw_obs_processing_ms: 0.39596820923444437\n",
+      "  time_since_restore: 501.7664008140564\n",
+      "  time_this_iter_s: 21.66362738609314\n",
+      "  time_total_s: 501.7664008140564\n",
+      "  timers:\n",
+      "    learn_throughput: 7523.043\n",
+      "    learn_time_ms: 16129.642\n",
+      "    sample_throughput: 22470.793\n",
+      "    sample_time_ms: 5400.077\n",
+      "    update_time_ms: 22.47\n",
+      "  timestamp: 1602429423\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2790912\n",
+      "  training_iteration: 23\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     23 |          501.766 | 2790912 |  240.763 |              287.232 |              115.717 |            831.621 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3465.0403952339434\n",
+      "    time_step_min: 3160\n",
+      "  date: 2020-10-11_15-17-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 830.4363845710996\n",
+      "  episode_reward_max: 290.5656565656564\n",
+      "  episode_reward_mean: 241.39702726749348\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 156\n",
+      "  episodes_total: 3474\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8283182467733111\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005241083912551403\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012423754736248935\n",
+      "        total_loss: 11.81918443952288\n",
+      "        vf_explained_var: 0.9798650741577148\n",
+      "        vf_loss: 11.830643245152064\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.39230769230769\n",
+      "    gpu_util_percent0: 0.35923076923076913\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.673076923076923\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15126197705114475\n",
+      "    mean_env_wait_ms: 1.1963604561138745\n",
+      "    mean_inference_ms: 4.628844870479084\n",
+      "    mean_raw_obs_processing_ms: 0.395573502939486\n",
+      "  time_since_restore: 523.427011013031\n",
+      "  time_this_iter_s: 21.66061019897461\n",
+      "  time_total_s: 523.427011013031\n",
+      "  timers:\n",
+      "    learn_throughput: 7522.297\n",
+      "    learn_time_ms: 16131.242\n",
+      "    sample_throughput: 22463.458\n",
+      "    sample_time_ms: 5401.84\n",
+      "    update_time_ms: 22.776\n",
+      "  timestamp: 1602429445\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 24\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     24 |          523.427 | 2912256 |  241.397 |              290.566 |              115.717 |            830.436 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3460.9023372287147\n",
+      "    time_step_min: 3153\n",
+      "  date: 2020-10-11_15-17-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 829.4948993658671\n",
+      "  episode_reward_max: 290.5656565656564\n",
+      "  episode_reward_mean: 241.90840581163147\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 153\n",
+      "  episodes_total: 3627\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8223013026373727\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005043058589633022\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01201772882736155\n",
+      "        total_loss: 13.969212940761022\n",
+      "        vf_explained_var: 0.9765128493309021\n",
+      "        vf_loss: 13.98030458177839\n",
+      "    num_steps_sampled: 3033600\n",
+      "    num_steps_trained: 3033600\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.528000000000002\n",
+      "    gpu_util_percent0: 0.376\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.676\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1511289350629235\n",
+      "    mean_env_wait_ms: 1.1970657157663167\n",
+      "    mean_inference_ms: 4.619344182754572\n",
+      "    mean_raw_obs_processing_ms: 0.3951966731956858\n",
+      "  time_since_restore: 544.9810814857483\n",
+      "  time_this_iter_s: 21.554070472717285\n",
+      "  time_total_s: 544.9810814857483\n",
+      "  timers:\n",
+      "    learn_throughput: 7529.301\n",
+      "    learn_time_ms: 16116.237\n",
+      "    sample_throughput: 22475.002\n",
+      "    sample_time_ms: 5399.065\n",
+      "    update_time_ms: 21.135\n",
+      "  timestamp: 1602429467\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3033600\n",
+      "  training_iteration: 25\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     25 |          544.981 | 3033600 |  241.908 |              290.566 |              115.717 |            829.495 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3457.9705960973\n",
+      "    time_step_min: 3153\n",
+      "  date: 2020-10-11_15-18-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 828.4104398516163\n",
+      "  episode_reward_max: 290.5656565656564\n",
+      "  episode_reward_mean: 242.37127234186048\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 147\n",
+      "  episodes_total: 3774\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8078862173216683\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005040723165231091\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011561505563024963\n",
+      "        total_loss: 11.968094280787877\n",
+      "        vf_explained_var: 0.9794151186943054\n",
+      "        vf_loss: 11.978727749415807\n",
+      "    num_steps_sampled: 3154944\n",
+      "    num_steps_trained: 3154944\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.244\n",
+      "    gpu_util_percent0: 0.39640000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.676\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15101266406896607\n",
+      "    mean_env_wait_ms: 1.1977560560323717\n",
+      "    mean_inference_ms: 4.610893338816044\n",
+      "    mean_raw_obs_processing_ms: 0.3948661709355843\n",
+      "  time_since_restore: 566.7003345489502\n",
+      "  time_this_iter_s: 21.719253063201904\n",
+      "  time_total_s: 566.7003345489502\n",
+      "  timers:\n",
+      "    learn_throughput: 7531.457\n",
+      "    learn_time_ms: 16111.625\n",
+      "    sample_throughput: 22464.259\n",
+      "    sample_time_ms: 5401.647\n",
+      "    update_time_ms: 21.315\n",
+      "  timestamp: 1602429489\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3154944\n",
+      "  training_iteration: 26\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     26 |            566.7 | 3154944 |  242.371 |              290.566 |              115.717 |             828.41 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3454.131240349974\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-11_15-18-31\n",
+      "  done: false\n",
+      "  episode_len_mean: 827.2209747384537\n",
+      "  episode_reward_max: 290.5656565656564\n",
+      "  episode_reward_mean: 242.9242127836156\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 145\n",
+      "  episodes_total: 3919\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.7926655837467739\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005787588655948639\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013243382131414754\n",
+      "        total_loss: 10.253864560808454\n",
+      "        vf_explained_var: 0.9815097451210022\n",
+      "        vf_loss: 10.266029494149345\n",
+      "    num_steps_sampled: 3276288\n",
+      "    num_steps_trained: 3276288\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.54615384615385\n",
+      "    gpu_util_percent0: 0.42153846153846164\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.676923076923077\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15090275323815575\n",
+      "    mean_env_wait_ms: 1.198396149093764\n",
+      "    mean_inference_ms: 4.602908536633501\n",
+      "    mean_raw_obs_processing_ms: 0.39454760886513374\n",
+      "  time_since_restore: 588.3199353218079\n",
+      "  time_this_iter_s: 21.619600772857666\n",
+      "  time_total_s: 588.3199353218079\n",
+      "  timers:\n",
+      "    learn_throughput: 7530.042\n",
+      "    learn_time_ms: 16114.651\n",
+      "    sample_throughput: 22550.089\n",
+      "    sample_time_ms: 5381.087\n",
+      "    update_time_ms: 20.923\n",
+      "  timestamp: 1602429511\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3276288\n",
+      "  training_iteration: 27\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | RUNNING  | 172.17.0.4:35160 |     27 |           588.32 | 3276288 |  242.924 |              290.566 |              115.717 |            827.221 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_a1235_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4292\n",
+      "    time_step_mean: 3450.2483822797412\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-11_15-18-52\n",
+      "  done: true\n",
+      "  episode_len_mean: 826.2327820291287\n",
+      "  episode_reward_max: 290.5656565656564\n",
+      "  episode_reward_mean: 243.47436597522983\n",
+      "  episode_reward_min: 115.7171717171713\n",
+      "  episodes_this_iter: 132\n",
+      "  episodes_total: 4051\n",
+      "  experiment_id: 8ba568863b9d4127940cc9b3b8e9449c\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.780083451952253\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005220116049583469\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014391705651567983\n",
+      "        total_loss: 7.889552388872419\n",
+      "        vf_explained_var: 0.9851317405700684\n",
+      "        vf_loss: 7.90297760282244\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.296\n",
+      "    gpu_util_percent0: 0.3863999999999999\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.676\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 35160\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.150802969938926\n",
+      "    mean_env_wait_ms: 1.198978183822521\n",
+      "    mean_inference_ms: 4.596044766607328\n",
+      "    mean_raw_obs_processing_ms: 0.39428733205890293\n",
+      "  time_since_restore: 609.900298833847\n",
+      "  time_this_iter_s: 21.580363512039185\n",
+      "  time_total_s: 609.900298833847\n",
+      "  timers:\n",
+      "    learn_throughput: 7518.391\n",
+      "    learn_time_ms: 16139.623\n",
+      "    sample_throughput: 22544.979\n",
+      "    sample_time_ms: 5382.307\n",
+      "    update_time_ms: 21.19\n",
+      "  timestamp: 1602429532\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 28\n",
+      "  trial_id: a1235_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | TERMINATED |       |     28 |            609.9 | 3397632 |  243.474 |              290.566 |              115.717 |            826.233 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_a1235_00000 | TERMINATED |       |     28 |            609.9 | 3397632 |  243.474 |              290.566 |              115.717 |            826.233 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2895, in get_loc\n",
+      "    return self._engine.get_loc(casted_key)\n",
+      "  File \"pandas/_libs/index.pyx\", line 70, in pandas._libs.index.IndexEngine.get_loc\n",
+      "  File \"pandas/_libs/index.pyx\", line 101, in pandas._libs.index.IndexEngine.get_loc\n",
+      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1675, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
+      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 1683, in pandas._libs.hashtable.PyObjectHashTable.get_item\n",
+      "KeyError: 'custom_metrics/time_step_min'\n",
+      "\n",
+      "The above exception was the direct cause of the following exception:\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 72, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 57, in train_func\n",
+      "    result = analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').to_dict('index')[0]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 92, in dataframe\n",
+      "    rows = self._retrieve_rows(metric=metric, mode=mode)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 254, in _retrieve_rows\n",
+      "    idx = df[metric].idxmin()\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 2902, in __getitem__\n",
+      "    indexer = self.columns.get_loc(key)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 2897, in get_loc\n",
+      "    raise KeyError(key) from err\n",
+      "KeyError: 'custom_metrics/time_step_min'\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 34938\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_150828-7u9y5atf/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_150828-7u9y5atf/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdark-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/7u9y5atf\u001b[0m\n",
+      "2020-10-11 15:19:01,913 - wandb.wandb_agent - INFO - Cleaning up finished run: 7u9y5atf\n",
+      "2020-10-11 15:19:02,216 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 15:19:02,216 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tnum_envs_per_worker: 2\n",
+      "\trollout_fragment_length: 1024\n",
+      "2020-10-11 15:19:02,218 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --num_envs_per_worker=2 --rollout_fragment_length=1024\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mamber-sweep-4\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/8x5lxuul\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ddo9b1ba\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_151903-ddo9b1ba\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-11 15:19:07,234 - wandb.wandb_agent - INFO - Running runs: ['ddo9b1ba']\n",
+      "2020-10-11 15:19:07,625\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=65857)\u001b[0m 2020-10-11 15:19:10,369\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=65898)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65898)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65891)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65891)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65887)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65887)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65864)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65864)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65869)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65869)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65896)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65896)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65885)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65885)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65867)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65867)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65882)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65882)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65893)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65893)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65840)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65840)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65900)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65900)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65771)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65771)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65836)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65836)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65838)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65838)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65798)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65798)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65773)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65773)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65772)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65772)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65763)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65763)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65842)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65842)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65797)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65797)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65761)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65761)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65841)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65841)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65781)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65781)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65793)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65793)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65788)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65788)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65759)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65759)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65843)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65843)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65792)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65792)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65768)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65768)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65779)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65779)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65776)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65776)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65795)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65795)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65863)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65863)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65778)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65778)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65851)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65851)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65855)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65855)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65839)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65839)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65823)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65823)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65783)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65783)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=65822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=65822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4054\n",
+      "    time_step_mean: 3615.0923076923077\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-11_15-19-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.1139240506329\n",
+      "  episode_reward_max: 258.59595959595964\n",
+      "  episode_reward_mean: 216.07678046285614\n",
+      "  episode_reward_min: 145.7171717171716\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1843508349524603\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.004721578572773271\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00988805560498602\n",
+      "        total_loss: 509.25912136501734\n",
+      "        vf_explained_var: 0.5215201377868652\n",
+      "        vf_loss: 509.2681816948785\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 25.719444444444445\n",
+      "    gpu_util_percent0: 0.34666666666666673\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5888888888888895\n",
+      "    vram_util_percent0: 0.09758208520097665\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16456120541965052\n",
+      "    mean_env_wait_ms: 1.1688175419297766\n",
+      "    mean_inference_ms: 5.193630932804685\n",
+      "    mean_raw_obs_processing_ms: 0.42884296383081894\n",
+      "  time_since_restore: 30.783287525177002\n",
+      "  time_this_iter_s: 30.783287525177002\n",
+      "  time_total_s: 30.783287525177002\n",
+      "  timers:\n",
+      "    learn_throughput: 7254.476\n",
+      "    learn_time_ms: 22302.369\n",
+      "    sample_throughput: 19224.824\n",
+      "    sample_time_ms: 8415.786\n",
+      "    update_time_ms: 33.256\n",
+      "  timestamp: 1602429586\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 1\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      1 |          30.7833 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4187\n",
+      "    time_step_mean: 3618.434027777778\n",
+      "    time_step_min: 3345\n",
+      "  date: 2020-10-11_15-20-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 889.7056962025316\n",
+      "  episode_reward_max: 259.20202020201975\n",
+      "  episode_reward_mean: 217.59145249968014\n",
+      "  episode_reward_min: 131.62626262626236\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1520691580242581\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008920241250760026\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011849463710354434\n",
+      "        total_loss: 136.11983066134982\n",
+      "        vf_explained_var: 0.7991345524787903\n",
+      "        vf_loss: 136.13090345594617\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.855882352941176\n",
+      "    gpu_util_percent0: 0.3320588235294118\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.761764705882353\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.16161816766198941\n",
+      "    mean_env_wait_ms: 1.169883329663526\n",
+      "    mean_inference_ms: 5.108560094604808\n",
+      "    mean_raw_obs_processing_ms: 0.4238600081063736\n",
+      "  time_since_restore: 60.439977407455444\n",
+      "  time_this_iter_s: 29.656689882278442\n",
+      "  time_total_s: 60.439977407455444\n",
+      "  timers:\n",
+      "    learn_throughput: 7328.983\n",
+      "    learn_time_ms: 22075.642\n",
+      "    sample_throughput: 20049.63\n",
+      "    sample_time_ms: 8069.575\n",
+      "    update_time_ms: 35.988\n",
+      "  timestamp: 1602429616\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 2\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      2 |            60.44 | 323584 |  217.591 |              259.202 |              131.626 |            889.706 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4219\n",
+      "    time_step_mean: 3615.634529147982\n",
+      "    time_step_min: 3345\n",
+      "  date: 2020-10-11_15-20-45\n",
+      "  done: false\n",
+      "  episode_len_mean: 887.3122362869199\n",
+      "  episode_reward_max: 266.929292929293\n",
+      "  episode_reward_mean: 217.47238204833118\n",
+      "  episode_reward_min: 126.77777777777789\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1390231847763062\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.009641255355543561\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013636472686711285\n",
+      "        total_loss: 66.86244625515408\n",
+      "        vf_explained_var: 0.8877179026603699\n",
+      "        vf_loss: 66.87523227267795\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.97941176470588\n",
+      "    gpu_util_percent0: 0.3370588235294118\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7764705882352945\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1595873958810886\n",
+      "    mean_env_wait_ms: 1.1713297641295495\n",
+      "    mean_inference_ms: 5.010924163714069\n",
+      "    mean_raw_obs_processing_ms: 0.41869709445317627\n",
+      "  time_since_restore: 89.61038947105408\n",
+      "  time_this_iter_s: 29.170412063598633\n",
+      "  time_total_s: 89.61038947105408\n",
+      "  timers:\n",
+      "    learn_throughput: 7366.34\n",
+      "    learn_time_ms: 21963.689\n",
+      "    sample_throughput: 20670.18\n",
+      "    sample_time_ms: 7827.314\n",
+      "    update_time_ms: 36.589\n",
+      "  timestamp: 1602429645\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 3\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.0/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      3 |          89.6104 | 485376 |  217.472 |              266.929 |              126.778 |            887.312 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4219\n",
+      "    time_step_mean: 3610.9387417218545\n",
+      "    time_step_min: 3280\n",
+      "  date: 2020-10-11_15-21-14\n",
+      "  done: false\n",
+      "  episode_len_mean: 882.4398734177215\n",
+      "  episode_reward_max: 269.050505050505\n",
+      "  episode_reward_mean: 218.5214007160208\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1255579259660509\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00822751068820556\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014474232939796315\n",
+      "        total_loss: 55.75923114352756\n",
+      "        vf_explained_var: 0.9051828384399414\n",
+      "        vf_loss: 55.77299499511719\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.644117647058824\n",
+      "    gpu_util_percent0: 0.3864705882352942\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7764705882352945\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1581072968672028\n",
+      "    mean_env_wait_ms: 1.173243947815016\n",
+      "    mean_inference_ms: 4.933548653646772\n",
+      "    mean_raw_obs_processing_ms: 0.41465706793439805\n",
+      "  time_since_restore: 118.89508557319641\n",
+      "  time_this_iter_s: 29.284696102142334\n",
+      "  time_total_s: 118.89508557319641\n",
+      "  timers:\n",
+      "    learn_throughput: 7359.442\n",
+      "    learn_time_ms: 21984.274\n",
+      "    sample_throughput: 21123.54\n",
+      "    sample_time_ms: 7659.322\n",
+      "    update_time_ms: 36.04\n",
+      "  timestamp: 1602429674\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      4 |          118.895 | 647168 |  218.521 |              269.051 |              119.202 |             882.44 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4219\n",
+      "    time_step_mean: 3602.5643044619424\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_15-21-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 876.9202531645569\n",
+      "  episode_reward_max: 275.8686868686872\n",
+      "  episode_reward_mean: 219.68801943485468\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0947299003601074\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008854356697864003\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01442181184473965\n",
+      "        total_loss: 41.541700998942055\n",
+      "        vf_explained_var: 0.932768702507019\n",
+      "        vf_loss: 41.5553470187717\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.435294117647057\n",
+      "    gpu_util_percent0: 0.3161764705882353\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7735294117647062\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15701984706993521\n",
+      "    mean_env_wait_ms: 1.175463461146301\n",
+      "    mean_inference_ms: 4.87283679887187\n",
+      "    mean_raw_obs_processing_ms: 0.41124197946070606\n",
+      "  time_since_restore: 148.34783554077148\n",
+      "  time_this_iter_s: 29.452749967575073\n",
+      "  time_total_s: 148.34783554077148\n",
+      "  timers:\n",
+      "    learn_throughput: 7353.467\n",
+      "    learn_time_ms: 22002.139\n",
+      "    sample_throughput: 21362.296\n",
+      "    sample_time_ms: 7573.718\n",
+      "    update_time_ms: 35.704\n",
+      "  timestamp: 1602429704\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: 915d0_00000\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      5 |          148.348 | 808960 |  219.688 |              275.869 |              119.202 |             876.92 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3587.8841121495325\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_15-22-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 867.9408014571949\n",
+      "  episode_reward_max: 275.8686868686872\n",
+      "  episode_reward_mean: 221.79695865761423\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 308\n",
+      "  episodes_total: 1098\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0886027548048232\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007741722743958235\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012663001556777291\n",
+      "        total_loss: 46.83814027574327\n",
+      "        vf_explained_var: 0.9481419324874878\n",
+      "        vf_loss: 46.85013749864366\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.66470588235294\n",
+      "    gpu_util_percent0: 0.33617647058823535\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.761764705882353\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15550204764237266\n",
+      "    mean_env_wait_ms: 1.1802493365620226\n",
+      "    mean_inference_ms: 4.790761944738492\n",
+      "    mean_raw_obs_processing_ms: 0.40703604829577444\n",
+      "  time_since_restore: 177.72296500205994\n",
+      "  time_this_iter_s: 29.375129461288452\n",
+      "  time_total_s: 177.72296500205994\n",
+      "  timers:\n",
+      "    learn_throughput: 7353.221\n",
+      "    learn_time_ms: 22002.876\n",
+      "    sample_throughput: 21535.233\n",
+      "    sample_time_ms: 7512.898\n",
+      "    update_time_ms: 35.895\n",
+      "  timestamp: 1602429733\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      6 |          177.723 | 970752 |  221.797 |              275.869 |              119.202 |            867.941 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3581.128640776699\n",
+      "    time_step_min: 3233\n",
+      "  date: 2020-10-11_15-22-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 863.0419303797469\n",
+      "  episode_reward_max: 278.44444444444446\n",
+      "  episode_reward_mean: 223.4365330520392\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 166\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0738010009129841\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00765216676518321\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013023157115336895\n",
+      "        total_loss: 22.13796827528212\n",
+      "        vf_explained_var: 0.9615828394889832\n",
+      "        vf_loss: 22.150333616468643\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.26969696969697\n",
+      "    gpu_util_percent0: 0.3409090909090909\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.781818181818182\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1549404218308153\n",
+      "    mean_env_wait_ms: 1.182370029417135\n",
+      "    mean_inference_ms: 4.75812694195196\n",
+      "    mean_raw_obs_processing_ms: 0.4053290215921129\n",
+      "  time_since_restore: 206.7824604511261\n",
+      "  time_this_iter_s: 29.059495449066162\n",
+      "  time_total_s: 206.7824604511261\n",
+      "  timers:\n",
+      "    learn_throughput: 7359.145\n",
+      "    learn_time_ms: 21985.163\n",
+      "    sample_throughput: 21709.437\n",
+      "    sample_time_ms: 7452.611\n",
+      "    update_time_ms: 36.345\n",
+      "  timestamp: 1602429763\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      7 |          206.782 | 1132544 |  223.437 |              278.444 |              119.202 |            863.042 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3572.0466284074605\n",
+      "    time_step_min: 3233\n",
+      "  date: 2020-10-11_15-23-12\n",
+      "  done: false\n",
+      "  episode_len_mean: 859.0126582278481\n",
+      "  episode_reward_max: 278.44444444444446\n",
+      "  episode_reward_mean: 224.67052380343503\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0556381013658311\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00822339134497775\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014104325013856093\n",
+      "        total_loss: 21.331751505533855\n",
+      "        vf_explained_var: 0.9627946019172668\n",
+      "        vf_loss: 21.34513897365994\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.385294117647057\n",
+      "    gpu_util_percent0: 0.35529411764705876\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7764705882352945\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15446333710769417\n",
+      "    mean_env_wait_ms: 1.1841968341830276\n",
+      "    mean_inference_ms: 4.731311657999268\n",
+      "    mean_raw_obs_processing_ms: 0.4039583724826134\n",
+      "  time_since_restore: 236.22041082382202\n",
+      "  time_this_iter_s: 29.437950372695923\n",
+      "  time_total_s: 236.22041082382202\n",
+      "  timers:\n",
+      "    learn_throughput: 7362.57\n",
+      "    learn_time_ms: 21974.935\n",
+      "    sample_throughput: 21711.898\n",
+      "    sample_time_ms: 7451.767\n",
+      "    update_time_ms: 36.734\n",
+      "  timestamp: 1602429792\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      8 |           236.22 | 1294336 |  224.671 |              278.444 |              119.202 |            859.013 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3562.9194587628867\n",
+      "    time_step_min: 3217\n",
+      "  date: 2020-10-11_15-23-41\n",
+      "  done: false\n",
+      "  episode_len_mean: 855.1715189873418\n",
+      "  episode_reward_max: 278.59595959595987\n",
+      "  episode_reward_mean: 225.94051272215813\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0263097021314833\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008362756990310218\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014461110244155861\n",
+      "        total_loss: 18.91820780436198\n",
+      "        vf_explained_var: 0.9667680263519287\n",
+      "        vf_loss: 18.931934992472332\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.258823529411767\n",
+      "    gpu_util_percent0: 0.3485294117647059\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7735294117647062\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15404355226013447\n",
+      "    mean_env_wait_ms: 1.1859455812362794\n",
+      "    mean_inference_ms: 4.707736199052138\n",
+      "    mean_raw_obs_processing_ms: 0.4026928459348835\n",
+      "  time_since_restore: 265.2343361377716\n",
+      "  time_this_iter_s: 29.013925313949585\n",
+      "  time_total_s: 265.2343361377716\n",
+      "  timers:\n",
+      "    learn_throughput: 7365.516\n",
+      "    learn_time_ms: 21966.146\n",
+      "    sample_throughput: 21844.175\n",
+      "    sample_time_ms: 7406.643\n",
+      "    update_time_ms: 35.04\n",
+      "  timestamp: 1602429821\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |      9 |          265.234 | 1456128 |  225.941 |              278.596 |              119.202 |            855.172 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3549.151024811219\n",
+      "    time_step_min: 3217\n",
+      "  date: 2020-10-11_15-24-10\n",
+      "  done: false\n",
+      "  episode_len_mean: 848.3198724760892\n",
+      "  episode_reward_max: 278.59595959595987\n",
+      "  episode_reward_mean: 228.1208847239664\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 302\n",
+      "  episodes_total: 1882\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9993236263593038\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007044322685235077\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012485993327572942\n",
+      "        total_loss: 29.24024200439453\n",
+      "        vf_explained_var: 0.9663772583007812\n",
+      "        vf_loss: 29.252121183607315\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.0\n",
+      "    gpu_util_percent0: 0.35000000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.770588235294117\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15336961968425208\n",
+      "    mean_env_wait_ms: 1.189351411446074\n",
+      "    mean_inference_ms: 4.670526206343917\n",
+      "    mean_raw_obs_processing_ms: 0.4008527112604744\n",
+      "  time_since_restore: 294.3171832561493\n",
+      "  time_this_iter_s: 29.082847118377686\n",
+      "  time_total_s: 294.3171832561493\n",
+      "  timers:\n",
+      "    learn_throughput: 7365.132\n",
+      "    learn_time_ms: 21967.291\n",
+      "    sample_throughput: 21962.183\n",
+      "    sample_time_ms: 7366.845\n",
+      "    update_time_ms: 36.172\n",
+      "  timestamp: 1602429850\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     10 |          294.317 | 1617920 |  228.121 |              278.596 |              119.202 |             848.32 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3540.383514313919\n",
+      "    time_step_min: 3194\n",
+      "  date: 2020-10-11_15-24-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 845.0628042843233\n",
+      "  episode_reward_max: 282.0808080808081\n",
+      "  episode_reward_mean: 229.41741661994814\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 172\n",
+      "  episodes_total: 2054\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9859415888786316\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006805953466229969\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013446049040390385\n",
+      "        total_loss: 17.021724277072483\n",
+      "        vf_explained_var: 0.9711102247238159\n",
+      "        vf_loss: 17.0345884958903\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.384848484848483\n",
+      "    gpu_util_percent0: 0.3778787878787879\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.784848484848485\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1530649231494302\n",
+      "    mean_env_wait_ms: 1.1910014023910334\n",
+      "    mean_inference_ms: 4.652815302256331\n",
+      "    mean_raw_obs_processing_ms: 0.3999651508223004\n",
+      "  time_since_restore: 323.0978810787201\n",
+      "  time_this_iter_s: 28.7806978225708\n",
+      "  time_total_s: 323.0978810787201\n",
+      "  timers:\n",
+      "    learn_throughput: 7388.022\n",
+      "    learn_time_ms: 21899.23\n",
+      "    sample_throughput: 22369.159\n",
+      "    sample_time_ms: 7232.815\n",
+      "    update_time_ms: 36.15\n",
+      "  timestamp: 1602429879\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     11 |          323.098 | 1779712 |  229.417 |              282.081 |              119.202 |            845.063 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3534.3695054945056\n",
+      "    time_step_min: 3194\n",
+      "  date: 2020-10-11_15-25-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 842.0660036166365\n",
+      "  episode_reward_max: 282.0808080808081\n",
+      "  episode_reward_mean: 230.48243282736942\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9706595540046692\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006862661490837733\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01380531924466292\n",
+      "        total_loss: 14.500430425008139\n",
+      "        vf_explained_var: 0.9731002449989319\n",
+      "        vf_loss: 14.513646549648708\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.955882352941178\n",
+      "    gpu_util_percent0: 0.3208823529411765\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7823529411764705\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15280917733305144\n",
+      "    mean_env_wait_ms: 1.1924356879286742\n",
+      "    mean_inference_ms: 4.638104602450027\n",
+      "    mean_raw_obs_processing_ms: 0.3992163874407778\n",
+      "  time_since_restore: 352.18300914764404\n",
+      "  time_this_iter_s: 29.08512806892395\n",
+      "  time_total_s: 352.18300914764404\n",
+      "  timers:\n",
+      "    learn_throughput: 7390.357\n",
+      "    learn_time_ms: 21892.312\n",
+      "    sample_throughput: 22528.85\n",
+      "    sample_time_ms: 7181.547\n",
+      "    update_time_ms: 35.898\n",
+      "  timestamp: 1602429908\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     12 |          352.183 | 1941504 |  230.482 |              282.081 |              119.202 |            842.066 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3527.7171331636982\n",
+      "    time_step_min: 3194\n",
+      "  date: 2020-10-11_15-25-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 839.0037720033529\n",
+      "  episode_reward_max: 282.0808080808081\n",
+      "  episode_reward_mean: 231.58327194831799\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 174\n",
+      "  episodes_total: 2386\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9348431163363986\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0074637361491719885\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0140232573935969\n",
+      "        total_loss: 14.015959527757433\n",
+      "        vf_explained_var: 0.9776356816291809\n",
+      "        vf_loss: 14.029329829745823\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.527272727272727\n",
+      "    gpu_util_percent0: 0.36090909090909096\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.76969696969697\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15253892630491492\n",
+      "    mean_env_wait_ms: 1.1940210509052362\n",
+      "    mean_inference_ms: 4.623096785385588\n",
+      "    mean_raw_obs_processing_ms: 0.39841018082699414\n",
+      "  time_since_restore: 381.02371287345886\n",
+      "  time_this_iter_s: 28.84070372581482\n",
+      "  time_total_s: 381.02371287345886\n",
+      "  timers:\n",
+      "    learn_throughput: 7395.168\n",
+      "    learn_time_ms: 21878.068\n",
+      "    sample_throughput: 22586.16\n",
+      "    sample_time_ms: 7163.325\n",
+      "    update_time_ms: 34.045\n",
+      "  timestamp: 1602429937\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     13 |          381.024 | 2103296 |  231.583 |              282.081 |              119.202 |            839.004 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3516.135867519759\n",
+      "    time_step_min: 3193\n",
+      "  date: 2020-10-11_15-26-06\n",
+      "  done: false\n",
+      "  episode_len_mean: 834.3154562383613\n",
+      "  episode_reward_max: 286.17171717171715\n",
+      "  episode_reward_mean: 233.5126685852942\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 299\n",
+      "  episodes_total: 2685\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9252206219567193\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006078497661898534\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01180143483603994\n",
+      "        total_loss: 17.539153416951496\n",
+      "        vf_explained_var: 0.9762699604034424\n",
+      "        vf_loss: 17.5504396226671\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.326470588235292\n",
+      "    gpu_util_percent0: 0.35058823529411764\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.770588235294118\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1521706762239558\n",
+      "    mean_env_wait_ms: 1.1965162552179502\n",
+      "    mean_inference_ms: 4.601095490431229\n",
+      "    mean_raw_obs_processing_ms: 0.3972797722917041\n",
+      "  time_since_restore: 410.0753722190857\n",
+      "  time_this_iter_s: 29.05165934562683\n",
+      "  time_total_s: 410.0753722190857\n",
+      "  timers:\n",
+      "    learn_throughput: 7399.833\n",
+      "    learn_time_ms: 21864.276\n",
+      "    sample_throughput: 22616.992\n",
+      "    sample_time_ms: 7153.56\n",
+      "    update_time_ms: 33.942\n",
+      "  timestamp: 1602429966\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     14 |          410.075 | 2265088 |  233.513 |              286.172 |              119.202 |            834.315 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3509.3366477272725\n",
+      "    time_step_min: 3183\n",
+      "  date: 2020-10-11_15-26-35\n",
+      "  done: false\n",
+      "  episode_len_mean: 831.9680028129395\n",
+      "  episode_reward_max: 286.17171717171715\n",
+      "  episode_reward_mean: 234.53616332097343\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 159\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9084723525577121\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0066332718253963524\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013506995410554938\n",
+      "        total_loss: 11.586083518134224\n",
+      "        vf_explained_var: 0.9771859645843506\n",
+      "        vf_loss: 11.599017884996202\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.027272727272727\n",
+      "    gpu_util_percent0: 0.39333333333333337\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7818181818181817\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15199983061906228\n",
+      "    mean_env_wait_ms: 1.1977310835234722\n",
+      "    mean_inference_ms: 4.590799177793186\n",
+      "    mean_raw_obs_processing_ms: 0.3967386029773961\n",
+      "  time_since_restore: 439.0162863731384\n",
+      "  time_this_iter_s: 28.940914154052734\n",
+      "  time_total_s: 439.0162863731384\n",
+      "  timers:\n",
+      "    learn_throughput: 7408.097\n",
+      "    learn_time_ms: 21839.886\n",
+      "    sample_throughput: 22679.859\n",
+      "    sample_time_ms: 7133.73\n",
+      "    update_time_ms: 32.755\n",
+      "  timestamp: 1602429995\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     15 |          439.016 | 2426880 |  234.536 |              286.172 |              119.202 |            831.968 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3502.817417619368\n",
+      "    time_step_min: 3183\n",
+      "  date: 2020-10-11_15-27-05\n",
+      "  done: false\n",
+      "  episode_len_mean: 829.9267155229846\n",
+      "  episode_reward_max: 287.0808080808082\n",
+      "  episode_reward_mean: 235.3969306657514\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3002\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8938175174925063\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006722591403457854\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014099026991364857\n",
+      "        total_loss: 11.053231239318848\n",
+      "        vf_explained_var: 0.9781302213668823\n",
+      "        vf_loss: 11.06674755944146\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.494117647058818\n",
+      "    gpu_util_percent0: 0.2885294117647059\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7911764705882356\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15183763086038113\n",
+      "    mean_env_wait_ms: 1.198890494877079\n",
+      "    mean_inference_ms: 4.58125844432332\n",
+      "    mean_raw_obs_processing_ms: 0.3962246267416918\n",
+      "  time_since_restore: 468.0653805732727\n",
+      "  time_this_iter_s: 29.049094200134277\n",
+      "  time_total_s: 468.0653805732727\n",
+      "  timers:\n",
+      "    learn_throughput: 7412.462\n",
+      "    learn_time_ms: 21827.025\n",
+      "    sample_throughput: 22719.248\n",
+      "    sample_time_ms: 7121.362\n",
+      "    update_time_ms: 32.132\n",
+      "  timestamp: 1602430025\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: 1be98_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      5 |          116.617 | 808960 |  228.575 |              287.616 |              115.788 |            842.243 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     16 |          468.065 | 2588672 |  235.397 |              287.081 |              119.202 |            829.927 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3492.750997850783\n",
+      "    time_step_min: 3183\n",
+      "  date: 2020-10-11_15-27-34\n",
+      "  done: false\n",
+      "  episode_len_mean: 826.7564687975647\n",
+      "  episode_reward_max: 287.0808080808082\n",
+      "  episode_reward_mean: 236.85245145519113\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 283\n",
+      "  episodes_total: 3285\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8706453177664015\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006674821436819103\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0120168204108874\n",
+      "        total_loss: 15.801198323567709\n",
+      "        vf_explained_var: 0.9784578680992126\n",
+      "        vf_loss: 15.812634997897678\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.008823529411767\n",
+      "    gpu_util_percent0: 0.34441176470588236\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.764705882352941\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1515732315284015\n",
+      "    mean_env_wait_ms: 1.2008966098221894\n",
+      "    mean_inference_ms: 4.565916896703251\n",
+      "    mean_raw_obs_processing_ms: 0.39541875143280103\n",
+      "  time_since_restore: 497.09780168533325\n",
+      "  time_this_iter_s: 29.032421112060547\n",
+      "  time_total_s: 497.09780168533325\n",
+      "  timers:\n",
+      "    learn_throughput: 7419.719\n",
+      "    learn_time_ms: 21805.677\n",
+      "    sample_throughput: 22685.067\n",
+      "    sample_time_ms: 7132.093\n",
+      "    update_time_ms: 32.003\n",
+      "  timestamp: 1602430054\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     17 |          497.098 | 2750464 |  236.852 |              287.081 |              119.202 |            826.756 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3486.8764501160094\n",
+      "    time_step_min: 3183\n",
+      "  date: 2020-10-11_15-28-03\n",
+      "  done: false\n",
+      "  episode_len_mean: 824.9016110471807\n",
+      "  episode_reward_max: 287.0808080808082\n",
+      "  episode_reward_mean: 237.82521997884479\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 191\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8568403522173563\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006638096076332861\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012599811336258426\n",
+      "        total_loss: 11.889694531758627\n",
+      "        vf_explained_var: 0.9782626032829285\n",
+      "        vf_loss: 11.901715914408365\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.569696969696967\n",
+      "    gpu_util_percent0: 0.43909090909090903\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7818181818181817\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1514188696067548\n",
+      "    mean_env_wait_ms: 1.202118269845257\n",
+      "    mean_inference_ms: 4.556750849396632\n",
+      "    mean_raw_obs_processing_ms: 0.39495096638506755\n",
+      "  time_since_restore: 525.8596270084381\n",
+      "  time_this_iter_s: 28.76182532310486\n",
+      "  time_total_s: 525.8596270084381\n",
+      "  timers:\n",
+      "    learn_throughput: 7434.198\n",
+      "    learn_time_ms: 21763.208\n",
+      "    sample_throughput: 22767.002\n",
+      "    sample_time_ms: 7106.425\n",
+      "    update_time_ms: 31.623\n",
+      "  timestamp: 1602430083\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     18 |           525.86 | 2912256 |  237.825 |              287.081 |              119.202 |            824.902 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3481.9750415973376\n",
+      "    time_step_min: 3183\n",
+      "  date: 2020-10-11_15-28-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 823.6560264171711\n",
+      "  episode_reward_max: 287.0808080808082\n",
+      "  episode_reward_mean: 238.62281038230398\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3634\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8560408817397224\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00649417657405138\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014412520097620372\n",
+      "        total_loss: 9.365952597724068\n",
+      "        vf_explained_var: 0.9802858829498291\n",
+      "        vf_loss: 9.379801114400228\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.221212121212123\n",
+      "    gpu_util_percent0: 0.32878787878787885\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.784848484848485\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15130027023513612\n",
+      "    mean_env_wait_ms: 1.20305092969869\n",
+      "    mean_inference_ms: 4.549724630292726\n",
+      "    mean_raw_obs_processing_ms: 0.39457568970198686\n",
+      "  time_since_restore: 554.8013496398926\n",
+      "  time_this_iter_s: 28.941722631454468\n",
+      "  time_total_s: 554.8013496398926\n",
+      "  timers:\n",
+      "    learn_throughput: 7439.245\n",
+      "    learn_time_ms: 21748.443\n",
+      "    sample_throughput: 22750.103\n",
+      "    sample_time_ms: 7111.704\n",
+      "    update_time_ms: 33.645\n",
+      "  timestamp: 1602430112\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     19 |          554.801 | 3074048 |  238.623 |              287.081 |              119.202 |            823.656 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3475.8040451799316\n",
+      "    time_step_min: 3157\n",
+      "  date: 2020-10-11_15-29-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 821.9382007822686\n",
+      "  episode_reward_max: 287.6868686868686\n",
+      "  episode_reward_mean: 239.55439663914234\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 201\n",
+      "  episodes_total: 3835\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8144117461310493\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006672416244530016\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013254672651075654\n",
+      "        total_loss: 11.530830277336968\n",
+      "        vf_explained_var: 0.9809316992759705\n",
+      "        vf_loss: 11.543498675028482\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.841176470588234\n",
+      "    gpu_util_percent0: 0.32264705882352945\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7735294117647062\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15115897495826155\n",
+      "    mean_env_wait_ms: 1.2042481161848355\n",
+      "    mean_inference_ms: 4.541267252470054\n",
+      "    mean_raw_obs_processing_ms: 0.39412942712694293\n",
+      "  time_since_restore: 583.5348660945892\n",
+      "  time_this_iter_s: 28.733516454696655\n",
+      "  time_total_s: 583.5348660945892\n",
+      "  timers:\n",
+      "    learn_throughput: 7454.506\n",
+      "    learn_time_ms: 21703.919\n",
+      "    sample_throughput: 22722.886\n",
+      "    sample_time_ms: 7120.222\n",
+      "    update_time_ms: 33.668\n",
+      "  timestamp: 1602430141\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | RUNNING  | 172.17.0.4:65857 |     20 |          583.535 | 3235840 |  239.554 |              287.687 |              119.202 |            821.938 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
       "\n",
-      "\n"
+      "Result for PPO_jss_env_1be98_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4229\n",
+      "    time_step_mean: 3467.278009316009\n",
+      "    time_step_min: 3157\n",
+      "  date: 2020-10-11_15-29-30\n",
+      "  done: true\n",
+      "  episode_len_mean: 819.8220112003896\n",
+      "  episode_reward_max: 287.6868686868686\n",
+      "  episode_reward_mean: 240.7451357991898\n",
+      "  episode_reward_min: 119.20202020201985\n",
+      "  episodes_this_iter: 272\n",
+      "  episodes_total: 4107\n",
+      "  experiment_id: 90bce87df92943afaf0f4551ae7003ad\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8046955797407362\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006084833345893357\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01188867363250918\n",
+      "        total_loss: 10.848699569702148\n",
+      "        vf_explained_var: 0.9828770160675049\n",
+      "        vf_loss: 10.860060373942057\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.684848484848487\n",
+      "    gpu_util_percent0: 0.44393939393939397\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7727272727272734\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 65857\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15098582425107557\n",
+      "    mean_env_wait_ms: 1.2057127682094804\n",
+      "    mean_inference_ms: 4.531110743744905\n",
+      "    mean_raw_obs_processing_ms: 0.39359864507090275\n",
+      "  time_since_restore: 612.7916913032532\n",
+      "  time_this_iter_s: 29.25682520866394\n",
+      "  time_total_s: 612.7916913032532\n",
+      "  timers:\n",
+      "    learn_throughput: 7442.898\n",
+      "    learn_time_ms: 21737.768\n",
+      "    sample_throughput: 22678.856\n",
+      "    sample_time_ms: 7134.046\n",
+      "    update_time_ms: 32.66\n",
+      "  timestamp: 1602430170\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 1be98_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | TERMINATED |       |     21 |          612.792 | 3397632 |  240.745 |              287.687 |              119.202 |            819.822 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_1be98_00000 | TERMINATED |       |     21 |          612.792 | 3397632 |  240.745 |              287.687 |              119.202 |            819.822 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 65651\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_151903-ddo9b1ba/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_151903-ddo9b1ba/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3157\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 626\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602430170\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4229\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3475.80405\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 287.68687\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 119.20202\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 239.5544\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3835\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 20\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▃▄▅▆▇█\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁▁▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ▁\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mamber-sweep-4\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/ddo9b1ba\u001b[0m\n",
+      "2020-10-11 15:29:37,846 - wandb.wandb_agent - INFO - Cleaning up finished run: ddo9b1ba\n",
+      "2020-10-11 15:29:38,182 - wandb.wandb_agent - INFO - Agent received command: exit\n",
+      "2020-10-11 15:29:38,182 - wandb.wandb_agent - INFO - Received exit command. Killing runs and quitting.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent rfs7la4y"
+    "!wandb agent 8x5lxuul"
    ]
   },
   {
diff --git a/JSS/.ipynb_checkpoints/default_config-checkpoint.py b/JSS/.ipynb_checkpoints/default_config-checkpoint.py
index c91ecc1..5149870 100644
--- a/JSS/.ipynb_checkpoints/default_config-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/default_config-checkpoint.py
@@ -12,7 +12,7 @@ default_config = {
     'num_envs_per_worker': 2,
     'rollout_fragment_length': 1024,
     'num_workers': mp.cpu_count() - 1,
-    'sgd_minibatch_size': 16112,
+    'sgd_minibatch_size': 18384,
     'evaluation_interval': None,
     'metrics_smoothing_episodes': 100000,
     'layer_size': 1024,
@@ -30,7 +30,7 @@ default_config = {
     "lr_schedule": None,
     "vf_share_layers": False,
     "vf_loss_coeff": 1.0,
-    "entropy_coeff": 0.0,
+    "entropy_coeff": 1e-4,
     "entropy_coeff_schedule": None,
     "grad_clip": None,
     "batch_mode": "truncate_episodes",
diff --git a/JSS/.ipynb_checkpoints/train-checkpoint.py b/JSS/.ipynb_checkpoints/train-checkpoint.py
index 568cc37..74405ef 100644
--- a/JSS/.ipynb_checkpoints/train-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/train-checkpoint.py
@@ -54,7 +54,7 @@ def train_func():
     }
 
     analysis = tune.run(PPOTrainer, config=config, stop=stop, name="ppo-jss")
-    result = analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').to_dict('index')[0]
+    result = analysis.dataframe().to_dict('index')[0]
     wandb.log({'time_step_min': result['custom_metrics/time_step_min']})
     if result['custom_metrics/time_step_max'] != float('inf'):
         wandb.log({'time_step_max': result['custom_metrics/time_step_max']})
diff --git a/JSS/Untitled.ipynb b/JSS/Untitled.ipynb
index 73bfae9..3c62b7c 100644
--- a/JSS/Untitled.ipynb
+++ b/JSS/Untitled.ipynb
@@ -29,13 +29,29 @@
     "from ray.tune.integration.wandb import WandbLogger\n",
     "\n",
     "from JSS.env_wrapper import BestActionsWrapper\n",
-    "\n",
+    "2\n",
     "from JSS.models import FCMaskedActionsModel\n",
     "\n",
     "pio.orca.config.use_xvfb = True\n",
     "import wandb\n",
     "\n",
-    "\n",
+    "'''\n",
+    "            'lr': {\n",
+    "                'values': [5e-5, 1e-5]\n",
+    "            },\n",
+    "            'lambda': {\n",
+    "                'values': [0.90, 0.95, 1.0]\n",
+    "            },\n",
+    "            'clip_param': {\n",
+    "                'values': [0.2, 0.3, 0.4]\n",
+    "            },\n",
+    "            'num_sgd_iter': {\n",
+    "                'values': [30, 35, 40]\n",
+    "            },\n",
+    "            'entropy_coeff': {\n",
+    "                'values': [0.0, 1e-4]\n",
+    "            }\n",
+    "'''\n",
     "\n",
     "if __name__ == \"__main__\":\n",
     "    print(\"I have detected {} CPUs here, so I'm going to create {} actors\".format(mp.cpu_count(), mp.cpu_count() - 1))\n",
@@ -49,60 +65,29 @@
     "        },\n",
     "        'parameters': {\n",
     "            'num_envs_per_worker': {\n",
-    "                'values': [4, 6, 8]\n",
-    "            },\n",
-    "            'sgd_minibatch_size': {\n",
-    "                'values': [2**13, 2**13 + 2**12, 2**14, 2**14 + 2**13]\n",
-    "            },\n",
-    "            'lr': {\n",
-    "                'values': [5e-5, 1e-5]\n",
-    "            },\n",
-    "            'lambda': {\n",
-    "                'values': [0.90, 0.95, 1.0]\n",
-    "            },\n",
-    "            'clip_param': {\n",
-    "                'values': [0.2, 0.3, 0.4]\n",
+    "                'values': [1, 2]\n",
     "            },\n",
-    "            'num_sgd_iter': {\n",
-    "                'values': [30, 40]\n",
+    "            'rollout_fragment_length': {\n",
+    "                'values': [768, 1024]\n",
     "            },\n",
+    "            'sgd_minibatch_size': {\n",
+    "                'values': [12384, 18384]\n",
+    "            }\n",
     "        }\n",
     "    }"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": 9,
    "metadata": {},
    "outputs": [
     {
-     "ename": "CommError",
-     "evalue": "Variable \"entityName\" has invalid value null.\nExpected type \"String!\", found null.",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 response = self.gql(\n\u001b[0m\u001b[1;32m   1397\u001b[0m                     \u001b[0mmutation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# Only print resolved attempts once every minute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;31mException\u001b[0m: {'message': 'Variable \"entityName\" has invalid value null.\\nExpected type \"String!\", found null.', 'locations': [{'line': 1, 'column': 70}]}",
-      "\nDuring handling of the above exception, another exception occurred:\n",
-      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
-      "\u001b[0;32m<ipython-input-10-25143ac4787e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RLLIB_SWEEP_2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/wandb_controller.py\u001b[0m in \u001b[0;36msweep\u001b[0;34m(sweep, entity, project)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0mwandb_sdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb_login\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_silent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInternalApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Create sweep with ID:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0msweep_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sweep_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/internal.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCommError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Whoa, you found a bug.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCommError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0msweep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"upsertSweep\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sweep\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, scheduler, obj_id, project, entity)\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmutation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmutation_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_old\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 response = self.gql(\n\u001b[0m\u001b[1;32m   1397\u001b[0m                     \u001b[0mmutation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                     variable_values={\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/old/retry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# Only print resolved attempts once every minute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_print\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminutes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/internal/internal_api.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m\"\"\"Wrapper around execute that logs in cases of failure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/gql/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
-      "\u001b[0;31mCommError\u001b[0m: Variable \"entityName\" has invalid value null.\nExpected type \"String!\", found null."
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Create sweep with ID: gd9q4pbz\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/gd9q4pbz\n"
      ]
     }
    ],
@@ -120,213 +105,207 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent 🕵️\n",
-      "2020-10-08 14:03:50,854 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:03:51,189 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 4096\n",
-      "2020-10-08 14:03:51,192 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=4096\n",
+      "2020-10-11 15:54:06,229 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-11 15:54:06,541 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 15:54:06,541 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tnum_envs_per_worker: 1\n",
+      "\trollout_fragment_length: 768\n",
+      "\tsgd_minibatch_size: 12384\n",
+      "2020-10-11 15:54:06,544 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --num_envs_per_worker=1 --rollout_fragment_length=768 --sgd_minibatch_size=12384\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-08 14:03:56,246 - wandb.wandb_agent - INFO - Running runs: ['5nvugt1y']\n",
+      "2020-10-11 15:54:11,561 - wandb.wandb_agent - INFO - Running runs: ['7luza44j']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-1\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_140356-5nvugt1y\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msunny-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/gd9q4pbz\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/7luza44j\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_155408-7luza44j\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 14:03:58,257\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8271\u001b[39m\u001b[22m\n",
+      "2020-10-11 15:54:12,150\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 77.4/754.6 GiB\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=57899)\u001b[0m 2020-10-08 14:04:01,486\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57857)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57863)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57881)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57855)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57843)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57768)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57780)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57777)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57871)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57756)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57771)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57836)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57824)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57837)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57845)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57772)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57889)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57839)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57770)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57754)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57776)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57763)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57761)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=57858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-04-38\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "\u001b[2m\u001b[36m(pid=10986)\u001b[0m 2020-10-11 15:54:14,974\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=10906)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10906)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10956)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11004)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11004)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10981)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10981)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10963)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10963)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11007)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11007)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10967)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10967)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10914)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10914)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10989)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10989)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11009)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11009)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10992)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10992)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10998)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10998)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10907)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10907)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10975)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10975)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10970)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10970)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10923)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10923)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11005)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11005)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10990)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10990)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10916)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10916)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11011)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11011)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10968)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10968)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10899)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10899)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10966)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10966)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10903)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10903)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10954)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10954)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10972)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10972)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10980)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10980)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10979)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10979)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11013)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11013)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10901)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10901)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10997)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10997)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10977)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10977)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10900)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10900)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11001)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11001)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10960)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10960)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10891)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10891)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10915)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10915)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10962)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10962)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10945)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10945)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10982)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10982)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10949)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10949)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10999)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10999)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10951)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10951)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10978)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10978)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10994)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10994)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10944)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10944)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10892)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10892)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10905)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10905)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11012)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11012)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11014)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11014)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10983)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10983)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10973)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10973)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10961)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10961)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10911)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10911)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10976)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10976)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10895)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10895)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10924)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10924)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10913)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10913)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10958)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10958)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10988)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10988)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10898)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10898)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10940)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10940)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=11003)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=11003)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10920)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10920)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10971)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10971)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10969)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10969)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10893)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10893)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10908)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10908)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10974)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10974)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10909)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10909)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10985)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10985)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10896)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10896)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10912)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10912)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10890)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10890)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10921)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10921)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10910)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10910)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=10917)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=10917)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
+      "  custom_metrics: {}\n",
+      "  date: 2020-10-11_15-54-35\n",
+      "  done: false\n",
+      "  episode_len_mean: .nan\n",
+      "  episode_reward_max: .nan\n",
+      "  episode_reward_mean: .nan\n",
+      "  episode_reward_min: .nan\n",
+      "  episodes_this_iter: 0\n",
+      "  episodes_total: 0\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -334,83 +313,77 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1603952676057816\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006529558636248112\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01697929573711008\n",
-      "        total_loss: 6.624263763427734\n",
-      "        vf_explained_var: 0.8197423815727234\n",
-      "        vf_loss: 6.639937055110932\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.193138313293457\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007721627131104469\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014717266522347927\n",
+      "        total_loss: 550.752490234375\n",
+      "        vf_explained_var: -0.5167572498321533\n",
+      "        vf_loss: 550.7658081054688\n",
+      "    num_steps_sampled: 60672\n",
+      "    num_steps_trained: 60672\n",
       "  iterations_since_restore: 1\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.00833333333333\n",
-      "    gpu_util_percent0: 0.3225\n",
+      "    cpu_util_percent: 34.62777777777778\n",
+      "    gpu_util_percent0: 0.25\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0002777777777777778\n",
-      "    ram_util_percent: 10.413888888888891\n",
-      "    vram_util_percent0: 0.27462328267920266\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.3277777777777775\n",
+      "    vram_util_percent0: 0.07845012936846325\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.18350994266746734\n",
-      "    mean_env_wait_ms: 1.6865222444501913\n",
-      "    mean_inference_ms: 5.985971555624452\n",
-      "    mean_raw_obs_processing_ms: 0.49480385234157925\n",
-      "  time_since_restore: 30.92910385131836\n",
-      "  time_this_iter_s: 30.92910385131836\n",
-      "  time_total_s: 30.92910385131836\n",
+      "  sampler_perf: {}\n",
+      "  time_since_restore: 15.325592994689941\n",
+      "  time_this_iter_s: 15.325592994689941\n",
+      "  time_total_s: 15.325592994689941\n",
       "  timers:\n",
-      "    learn_throughput: 7789.468\n",
-      "    learn_time_ms: 20770.611\n",
-      "    sample_throughput: 16046.653\n",
-      "    sample_time_ms: 10082.601\n",
-      "    update_time_ms: 36.409\n",
-      "  timestamp: 1602165878\n",
+      "    learn_throughput: 6811.854\n",
+      "    learn_time_ms: 8906.826\n",
+      "    sample_throughput: 9538.184\n",
+      "    sample_time_ms: 6360.959\n",
+      "    update_time_ms: 35.621\n",
+      "  timestamp: 1602431675\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
+      "  timesteps_total: 60672\n",
       "  training_iteration: 1\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.8/754.6 GiB\n",
+      "Memory usage on this node: 25.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      1 |          30.9291 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |      1 |          15.3256 | 60672 |      nan |                  nan |                  nan |                nan |\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-05-08\n",
+      "    time_step_max: 3929\n",
+      "    time_step_mean: 3605.2025316455697\n",
+      "    time_step_min: 3274\n",
+      "  date: 2020-10-11_15-54-50\n",
       "  done: false\n",
-      "  episode_len_mean: 869.3417721518987\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.90004475131036\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 886.6582278481013\n",
+      "  episode_reward_max: 269.9595959595958\n",
+      "  episode_reward_mean: 219.77739419511545\n",
+      "  episode_reward_min: 170.71717171717202\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 79\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -418,83 +391,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1352683365345002\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007792104431428015\n",
-      "        model: {}\n",
-      "        policy_loss: -0.020531148964073508\n",
-      "        total_loss: 5.638339829444885\n",
-      "        vf_explained_var: 0.9249752759933472\n",
-      "        vf_loss: 5.657312452793121\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1673843383789062\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006144535727798939\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013755168556235731\n",
+      "        total_loss: 535.4020385742188\n",
+      "        vf_explained_var: 0.31667008996009827\n",
+      "        vf_loss: 535.4146850585937\n",
+      "    num_steps_sampled: 121344\n",
+      "    num_steps_trained: 121344\n",
       "  iterations_since_restore: 2\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.90294117647059\n",
-      "    gpu_util_percent0: 0.26941176470588235\n",
+      "    cpu_util_percent: 32.725\n",
+      "    gpu_util_percent0: 0.27125\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.747058823529413\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.4\n",
+      "    vram_util_percent0: 0.09732699245654312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17676173480204843\n",
-      "    mean_env_wait_ms: 1.6752662514608032\n",
-      "    mean_inference_ms: 5.6785297305935405\n",
-      "    mean_raw_obs_processing_ms: 0.4787812236414886\n",
-      "  time_since_restore: 59.91080617904663\n",
-      "  time_this_iter_s: 28.98170232772827\n",
-      "  time_total_s: 59.91080617904663\n",
+      "    mean_action_processing_ms: 0.1335579653699614\n",
+      "    mean_env_wait_ms: 0.6396630418185466\n",
+      "    mean_inference_ms: 5.461916608139601\n",
+      "    mean_raw_obs_processing_ms: 0.29134479201721725\n",
+      "  time_since_restore: 29.482505321502686\n",
+      "  time_this_iter_s: 14.156912326812744\n",
+      "  time_total_s: 29.482505321502686\n",
       "  timers:\n",
-      "    learn_throughput: 7835.536\n",
-      "    learn_time_ms: 20648.493\n",
-      "    sample_throughput: 17536.73\n",
-      "    sample_time_ms: 9225.893\n",
-      "    update_time_ms: 38.294\n",
-      "  timestamp: 1602165908\n",
+      "    learn_throughput: 6897.036\n",
+      "    learn_time_ms: 8796.822\n",
+      "    sample_throughput: 10311.754\n",
+      "    sample_time_ms: 5883.771\n",
+      "    update_time_ms: 30.512\n",
+      "  timestamp: 1602431690\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
+      "  timesteps_total: 121344\n",
       "  training_iteration: 2\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      2 |          59.9108 | 323584 |    224.9 |              273.131 |              115.788 |            869.342 |\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |      2 |          29.4825 | 121344 |  219.777 |               269.96 |              170.717 |            886.658 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_14-05-37\n",
+      "    time_step_max: 3967\n",
+      "    time_step_mean: 3626.0632911392404\n",
+      "    time_step_min: 3274\n",
+      "  date: 2020-10-11_15-55-03\n",
       "  done: false\n",
-      "  episode_len_mean: 864.6983122362869\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.52218386395583\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 882.9303797468355\n",
+      "  episode_reward_max: 269.9595959595958\n",
+      "  episode_reward_mean: 216.61667305971088\n",
+      "  episode_reward_min: 164.95959595959556\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -502,83 +473,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1208289206027984\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008471710339654237\n",
-      "        model: {}\n",
-      "        policy_loss: -0.024524397612549365\n",
-      "        total_loss: 4.379646378755569\n",
-      "        vf_explained_var: 0.9663649797439575\n",
-      "        vf_loss: 4.4024763882160185\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1481393575668335\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006490523274987936\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015036692284047604\n",
+      "        total_loss: 317.61456909179685\n",
+      "        vf_explained_var: 0.6613558530807495\n",
+      "        vf_loss: 317.6284118652344\n",
+      "    num_steps_sampled: 182016\n",
+      "    num_steps_trained: 182016\n",
       "  iterations_since_restore: 3\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.057142857142864\n",
-      "    gpu_util_percent0: 0.2717142857142857\n",
+      "    cpu_util_percent: 33.61333333333334\n",
+      "    gpu_util_percent0: 0.214\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762857142857143\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17253118731808845\n",
-      "    mean_env_wait_ms: 1.669123154241675\n",
-      "    mean_inference_ms: 5.508714332828136\n",
-      "    mean_raw_obs_processing_ms: 0.46803146600593976\n",
-      "  time_since_restore: 89.00577521324158\n",
-      "  time_this_iter_s: 29.094969034194946\n",
-      "  time_total_s: 89.00577521324158\n",
+      "    mean_action_processing_ms: 0.13096906242211057\n",
+      "    mean_env_wait_ms: 0.6401871641256086\n",
+      "    mean_inference_ms: 5.325638128384396\n",
+      "    mean_raw_obs_processing_ms: 0.2857010919150765\n",
+      "  time_since_restore: 43.16357231140137\n",
+      "  time_this_iter_s: 13.681066989898682\n",
+      "  time_total_s: 43.16357231140137\n",
       "  timers:\n",
-      "    learn_throughput: 7852.583\n",
-      "    learn_time_ms: 20603.665\n",
-      "    sample_throughput: 18018.223\n",
-      "    sample_time_ms: 8979.354\n",
-      "    update_time_ms: 41.291\n",
-      "  timestamp: 1602165937\n",
+      "    learn_throughput: 6910.861\n",
+      "    learn_time_ms: 8779.224\n",
+      "    sample_throughput: 10936.073\n",
+      "    sample_time_ms: 5547.878\n",
+      "    update_time_ms: 26.906\n",
+      "  timestamp: 1602431703\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
+      "  timesteps_total: 182016\n",
       "  training_iteration: 3\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 25.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      3 |          89.0058 | 485376 |  225.522 |                  279 |              115.788 |            864.698 |\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |      3 |          43.1636 | 182016 |  216.617 |               269.96 |               164.96 |             882.93 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3247.0\n",
-      "  date: 2020-10-08_14-06-05\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3631.721518987342\n",
+      "    time_step_min: 3274\n",
+      "  date: 2020-10-11_15-55-17\n",
       "  done: false\n",
-      "  episode_len_mean: 860.242088607595\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 225.50586561820717\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 877.1476793248945\n",
+      "  episode_reward_max: 269.9595959595958\n",
+      "  episode_reward_mean: 215.75936580999857\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 237\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -586,83 +555,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0932798445224763\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.009407231188379227\n",
-      "        model: {}\n",
-      "        policy_loss: -0.026628604688448833\n",
-      "        total_loss: 4.111228054761886\n",
-      "        vf_explained_var: 0.9783345460891724\n",
-      "        vf_loss: 4.135975193977356\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.133927011489868\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006118734646588564\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015129859372973443\n",
+      "        total_loss: 199.39960327148438\n",
+      "        vf_explained_var: 0.7791659235954285\n",
+      "        vf_loss: 199.41362609863282\n",
+      "    num_steps_sampled: 242688\n",
+      "    num_steps_trained: 242688\n",
       "  iterations_since_restore: 4\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.938235294117646\n",
-      "    gpu_util_percent0: 0.24941176470588236\n",
+      "    cpu_util_percent: 30.575\n",
+      "    gpu_util_percent0: 0.32375\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.761764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.4\n",
+      "    vram_util_percent0: 0.09732699245654312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16972262222291365\n",
-      "    mean_env_wait_ms: 1.6663911084469907\n",
-      "    mean_inference_ms: 5.381286213374226\n",
-      "    mean_raw_obs_processing_ms: 0.46035908038467466\n",
-      "  time_since_restore: 117.6076283454895\n",
-      "  time_this_iter_s: 28.601853132247925\n",
-      "  time_total_s: 117.6076283454895\n",
+      "    mean_action_processing_ms: 0.12929822493889637\n",
+      "    mean_env_wait_ms: 0.6416855568072275\n",
+      "    mean_inference_ms: 5.215910171762147\n",
+      "    mean_raw_obs_processing_ms: 0.2820417254294907\n",
+      "  time_since_restore: 56.6672842502594\n",
+      "  time_this_iter_s: 13.503711938858032\n",
+      "  time_total_s: 56.6672842502594\n",
       "  timers:\n",
-      "    learn_throughput: 7898.804\n",
-      "    learn_time_ms: 20483.102\n",
-      "    sample_throughput: 18320.006\n",
-      "    sample_time_ms: 8831.438\n",
-      "    update_time_ms: 41.53\n",
-      "  timestamp: 1602165965\n",
+      "    learn_throughput: 6928.737\n",
+      "    learn_time_ms: 8756.574\n",
+      "    sample_throughput: 11348.28\n",
+      "    sample_time_ms: 5346.361\n",
+      "    update_time_ms: 29.016\n",
+      "  timestamp: 1602431717\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
+      "  timesteps_total: 242688\n",
       "  training_iteration: 4\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      4 |          117.608 | 647168 |  225.506 |                  279 |              115.788 |            860.242 |\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |      4 |          56.6673 | 242688 |  215.759 |               269.96 |               116.02 |            877.148 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_14-06-34\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3621.4493670886077\n",
+      "    time_step_min: 3274\n",
+      "  date: 2020-10-11_15-55-30\n",
       "  done: false\n",
-      "  episode_len_mean: 853.6054421768707\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 226.6438076914266\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 250\n",
-      "  episodes_total: 882\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 871.5411392405064\n",
+      "  episode_reward_max: 269.9595959595958\n",
+      "  episode_reward_mean: 217.31575246132192\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -670,83 +637,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0601136475801467\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008663335489109159\n",
-      "        model: {}\n",
-      "        policy_loss: -0.029689956549555065\n",
-      "        total_loss: 5.979247343540192\n",
-      "        vf_explained_var: 0.9847942590713501\n",
-      "        vf_loss: 6.007204520702362\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1258406400680543\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006548813544213772\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01587002072483301\n",
+      "        total_loss: 101.75677337646485\n",
+      "        vf_explained_var: 0.8550761342048645\n",
+      "        vf_loss: 101.77144622802734\n",
+      "    num_steps_sampled: 303360\n",
+      "    num_steps_trained: 303360\n",
       "  iterations_since_restore: 5\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.05\n",
-      "    gpu_util_percent0: 0.27676470588235297\n",
+      "    cpu_util_percent: 30.74666666666667\n",
+      "    gpu_util_percent0: 0.3306666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1668569945682094\n",
-      "    mean_env_wait_ms: 1.6661518036410352\n",
-      "    mean_inference_ms: 5.245339771382172\n",
-      "    mean_raw_obs_processing_ms: 0.45204585691645865\n",
-      "  time_since_restore: 146.34429287910461\n",
-      "  time_this_iter_s: 28.736664533615112\n",
-      "  time_total_s: 146.34429287910461\n",
+      "    mean_action_processing_ms: 0.1280293362903634\n",
+      "    mean_env_wait_ms: 0.6430775167613013\n",
+      "    mean_inference_ms: 5.129046763534478\n",
+      "    mean_raw_obs_processing_ms: 0.27937883325702817\n",
+      "  time_since_restore: 70.24723482131958\n",
+      "  time_this_iter_s: 13.57995057106018\n",
+      "  time_total_s: 70.24723482131958\n",
       "  timers:\n",
-      "    learn_throughput: 7912.652\n",
-      "    learn_time_ms: 20447.253\n",
-      "    sample_throughput: 18556.235\n",
-      "    sample_time_ms: 8719.01\n",
-      "    update_time_ms: 53.489\n",
-      "  timestamp: 1602165994\n",
+      "    learn_throughput: 6925.054\n",
+      "    learn_time_ms: 8761.231\n",
+      "    sample_throughput: 11611.382\n",
+      "    sample_time_ms: 5225.218\n",
+      "    update_time_ms: 28.584\n",
+      "  timestamp: 1602431730\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
+      "  timesteps_total: 303360\n",
       "  training_iteration: 5\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      5 |          146.344 | 808960 |  226.644 |                  279 |              115.788 |            853.605 |\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |      5 |          70.2472 | 303360 |  217.316 |               269.96 |               116.02 |            871.541 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3235.0\n",
-      "  date: 2020-10-08_14-07-03\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3609.5620253164557\n",
+      "    time_step_min: 3226\n",
+      "  date: 2020-10-11_15-55-44\n",
       "  done: false\n",
-      "  episode_len_mean: 847.8264014466546\n",
-      "  episode_reward_max: 278.99999999999983\n",
-      "  episode_reward_mean: 227.10596927685518\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 224\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 867.2329113924051\n",
+      "  episode_reward_max: 277.23232323232315\n",
+      "  episode_reward_mean: 219.1168648510419\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 395\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -754,83 +719,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0766338467597962\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008614842919632793\n",
-      "        model: {}\n",
-      "        policy_loss: -0.030333096848335118\n",
-      "        total_loss: 4.108908116817474\n",
-      "        vf_explained_var: 0.987047553062439\n",
-      "        vf_loss: 4.137518179416657\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.112362313270569\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00727074546739459\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01704823523759842\n",
+      "        total_loss: 71.98140106201171\n",
+      "        vf_explained_var: 0.8918706774711609\n",
+      "        vf_loss: 71.99710693359376\n",
+      "    num_steps_sampled: 364032\n",
+      "    num_steps_trained: 364032\n",
       "  iterations_since_restore: 6\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.087878787878783\n",
-      "    gpu_util_percent0: 0.2751515151515152\n",
+      "    cpu_util_percent: 30.481250000000003\n",
+      "    gpu_util_percent0: 0.31375\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751515151515152\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.4\n",
+      "    vram_util_percent0: 0.09732699245654312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16521363319543925\n",
-      "    mean_env_wait_ms: 1.6677695579501226\n",
-      "    mean_inference_ms: 5.160918708210536\n",
-      "    mean_raw_obs_processing_ms: 0.4472775860567577\n",
-      "  time_since_restore: 174.83844447135925\n",
-      "  time_this_iter_s: 28.49415159225464\n",
-      "  time_total_s: 174.83844447135925\n",
+      "    mean_action_processing_ms: 0.12705942527607186\n",
+      "    mean_env_wait_ms: 0.6442925509912155\n",
+      "    mean_inference_ms: 5.058719438900431\n",
+      "    mean_raw_obs_processing_ms: 0.27730945071524615\n",
+      "  time_since_restore: 83.75674295425415\n",
+      "  time_this_iter_s: 13.50950813293457\n",
+      "  time_total_s: 83.75674295425415\n",
       "  timers:\n",
-      "    learn_throughput: 7937.482\n",
-      "    learn_time_ms: 20383.289\n",
-      "    sample_throughput: 18693.433\n",
-      "    sample_time_ms: 8655.018\n",
-      "    update_time_ms: 51.581\n",
-      "  timestamp: 1602166023\n",
+      "    learn_throughput: 6924.139\n",
+      "    learn_time_ms: 8762.389\n",
+      "    sample_throughput: 11814.723\n",
+      "    sample_time_ms: 5135.288\n",
+      "    update_time_ms: 27.799\n",
+      "  timestamp: 1602431744\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
+      "  timesteps_total: 364032\n",
       "  training_iteration: 6\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      6 |          174.838 | 970752 |  227.106 |                  279 |              115.788 |            847.826 |\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |      6 |          83.7567 | 364032 |  219.117 |              277.232 |               116.02 |            867.233 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-07-31\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3593.96835443038\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-55-57\n",
       "  done: false\n",
-      "  episode_len_mean: 844.1083860759494\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.6303302007414\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 862.3860759493671\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 221.47954225802314\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -838,83 +801,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0495809823274613\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008355090976692736\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03242016874719411\n",
-      "        total_loss: 3.189230865240097\n",
-      "        vf_explained_var: 0.9909769296646118\n",
-      "        vf_loss: 3.2199800491333006\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0965974807739258\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006363364960998296\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01626312769949436\n",
+      "        total_loss: 60.179150390625\n",
+      "        vf_explained_var: 0.905462920665741\n",
+      "        vf_loss: 60.19425048828125\n",
+      "    num_steps_sampled: 424704\n",
+      "    num_steps_trained: 424704\n",
       "  iterations_since_restore: 7\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.423529411764708\n",
-      "    gpu_util_percent0: 0.25617647058823534\n",
+      "    cpu_util_percent: 31.640000000000004\n",
+      "    gpu_util_percent0: 0.23333333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.406666666666666\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16428938352115002\n",
-      "    mean_env_wait_ms: 1.6688146539398103\n",
-      "    mean_inference_ms: 5.1135213379920055\n",
-      "    mean_raw_obs_processing_ms: 0.4445629925416077\n",
-      "  time_since_restore: 203.33799719810486\n",
-      "  time_this_iter_s: 28.499552726745605\n",
-      "  time_total_s: 203.33799719810486\n",
+      "    mean_action_processing_ms: 0.12626278519887724\n",
+      "    mean_env_wait_ms: 0.6453433568672141\n",
+      "    mean_inference_ms: 5.000835188725645\n",
+      "    mean_raw_obs_processing_ms: 0.2756329424921561\n",
+      "  time_since_restore: 97.15614581108093\n",
+      "  time_this_iter_s: 13.399402856826782\n",
+      "  time_total_s: 97.15614581108093\n",
       "  timers:\n",
-      "    learn_throughput: 7953.152\n",
-      "    learn_time_ms: 20343.13\n",
-      "    sample_throughput: 18800.381\n",
-      "    sample_time_ms: 8605.783\n",
-      "    update_time_ms: 48.851\n",
-      "  timestamp: 1602166051\n",
+      "    learn_throughput: 6924.229\n",
+      "    learn_time_ms: 8762.275\n",
+      "    sample_throughput: 12004.493\n",
+      "    sample_time_ms: 5054.108\n",
+      "    update_time_ms: 28.865\n",
+      "  timestamp: 1602431757\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
+      "  timesteps_total: 424704\n",
       "  training_iteration: 7\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      7 |          203.338 | 1132544 |   227.63 |              282.485 |              115.788 |            844.108 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |      7 |          97.1561 | 424704 |   221.48 |              283.141 |               116.02 |            862.386 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-00\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3587.43115942029\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-56-11\n",
       "  done: false\n",
-      "  episode_len_mean: 840.8741209563995\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 227.87909332424087\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 857.5561594202899\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 222.47002635046098\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 78\n",
+      "  episodes_total: 552\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -922,83 +883,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0188148379325868\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008204545732587576\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03408731806557626\n",
-      "        total_loss: 3.0473277091979982\n",
-      "        vf_explained_var: 0.9921058416366577\n",
-      "        vf_loss: 3.079774135351181\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0854148864746094\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006640845071524381\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017912944313138723\n",
+      "        total_loss: 57.62085189819336\n",
+      "        vf_explained_var: 0.9167647361755371\n",
+      "        vf_loss: 57.637541961669925\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 8\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.724242424242426\n",
-      "    gpu_util_percent0: 0.2678787878787879\n",
+      "    cpu_util_percent: 30.30625\n",
+      "    gpu_util_percent0: 0.273125\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.763636363636364\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.4\n",
+      "    vram_util_percent0: 0.09732699245654312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16348854866217513\n",
-      "    mean_env_wait_ms: 1.6700574598453726\n",
-      "    mean_inference_ms: 5.072164794599845\n",
-      "    mean_raw_obs_processing_ms: 0.44213624402114293\n",
-      "  time_since_restore: 231.6390438079834\n",
-      "  time_this_iter_s: 28.30104660987854\n",
-      "  time_total_s: 231.6390438079834\n",
+      "    mean_action_processing_ms: 0.12561918815334655\n",
+      "    mean_env_wait_ms: 0.6463205594611693\n",
+      "    mean_inference_ms: 4.95316471179105\n",
+      "    mean_raw_obs_processing_ms: 0.27431672518997435\n",
+      "  time_since_restore: 110.58362245559692\n",
+      "  time_this_iter_s: 13.427476644515991\n",
+      "  time_total_s: 110.58362245559692\n",
       "  timers:\n",
-      "    learn_throughput: 7959.464\n",
-      "    learn_time_ms: 20326.997\n",
-      "    sample_throughput: 18968.066\n",
-      "    sample_time_ms: 8529.705\n",
-      "    update_time_ms: 47.225\n",
-      "  timestamp: 1602166080\n",
+      "    learn_throughput: 6923.851\n",
+      "    learn_time_ms: 8762.753\n",
+      "    sample_throughput: 12139.372\n",
+      "    sample_time_ms: 4997.952\n",
+      "    update_time_ms: 27.628\n",
+      "  timestamp: 1602431771\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
+      "  timesteps_total: 485376\n",
       "  training_iteration: 8\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      8 |          231.639 | 1294336 |  227.879 |              282.485 |              115.788 |            840.874 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |      8 |          110.584 | 485376 |   222.47 |              283.141 |               116.02 |            857.556 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-28\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3579.633914421553\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-56-24\n",
       "  done: false\n",
-      "  episode_len_mean: 835.0944055944055\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.1691507146051\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 1716\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 853.2773375594295\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 223.65142710784536\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 631\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1006,83 +965,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9918270707130432\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007521937682759017\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03050975254736841\n",
-      "        total_loss: 5.504689037799835\n",
-      "        vf_explained_var: 0.9918516874313354\n",
-      "        vf_loss: 5.53369448184967\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0685611724853517\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006435621529817581\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017283295653760432\n",
+      "        total_loss: 42.61400680541992\n",
+      "        vf_explained_var: 0.9355558156967163\n",
+      "        vf_loss: 42.63011016845703\n",
+      "    num_steps_sampled: 546048\n",
+      "    num_steps_trained: 546048\n",
       "  iterations_since_restore: 9\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.59705882352941\n",
-      "    gpu_util_percent0: 0.25941176470588234\n",
+      "    cpu_util_percent: 31.56666666666667\n",
+      "    gpu_util_percent0: 0.282\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.413333333333333\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.162284443845516\n",
-      "    mean_env_wait_ms: 1.6727489665801578\n",
-      "    mean_inference_ms: 5.009821132584934\n",
-      "    mean_raw_obs_processing_ms: 0.4384857629606629\n",
-      "  time_since_restore: 259.97689414024353\n",
-      "  time_this_iter_s: 28.337850332260132\n",
-      "  time_total_s: 259.97689414024353\n",
+      "    mean_action_processing_ms: 0.12506485263094025\n",
+      "    mean_env_wait_ms: 0.6472223465212444\n",
+      "    mean_inference_ms: 4.911849955044988\n",
+      "    mean_raw_obs_processing_ms: 0.27313970445811725\n",
+      "  time_since_restore: 123.83380699157715\n",
+      "  time_this_iter_s: 13.250184535980225\n",
+      "  time_total_s: 123.83380699157715\n",
       "  timers:\n",
-      "    learn_throughput: 7968.61\n",
-      "    learn_time_ms: 20303.667\n",
-      "    sample_throughput: 19067.411\n",
-      "    sample_time_ms: 8485.263\n",
-      "    update_time_ms: 45.663\n",
-      "  timestamp: 1602166108\n",
+      "    learn_throughput: 6928.914\n",
+      "    learn_time_ms: 8756.351\n",
+      "    sample_throughput: 12277.675\n",
+      "    sample_time_ms: 4941.652\n",
+      "    update_time_ms: 26.462\n",
+      "  timestamp: 1602431784\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
+      "  timesteps_total: 546048\n",
       "  training_iteration: 9\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |      9 |          259.977 | 1456128 |  228.169 |              282.485 |              115.788 |            835.094 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |      9 |          123.834 | 546048 |  223.651 |              283.141 |               116.02 |            853.277 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-08-57\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3572.5885714285714\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-56-38\n",
       "  done: false\n",
-      "  episode_len_mean: 832.079641350211\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 228.59731279035063\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 848.9885714285714\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 224.71890331890322\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 69\n",
+      "  episodes_total: 700\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1090,83 +1047,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9763310596346855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007896899722982197\n",
-      "        model: {}\n",
-      "        policy_loss: -0.033220290520694105\n",
-      "        total_loss: 2.953149896860123\n",
-      "        vf_explained_var: 0.993627667427063\n",
-      "        vf_loss: 2.98479083776474\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0564856290817262\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0069581371732056144\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017678908724337816\n",
+      "        total_loss: 35.82207412719727\n",
+      "        vf_explained_var: 0.9436900019645691\n",
+      "        vf_loss: 35.83846588134766\n",
+      "    num_steps_sampled: 606720\n",
+      "    num_steps_trained: 606720\n",
       "  iterations_since_restore: 10\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.339393939393936\n",
-      "    gpu_util_percent0: 0.29575757575757583\n",
+      "    cpu_util_percent: 29.625\n",
+      "    gpu_util_percent0: 0.29874999999999996\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.41875\n",
+      "    vram_util_percent0: 0.09732699245654312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16170883141459513\n",
-      "    mean_env_wait_ms: 1.6746347609608598\n",
-      "    mean_inference_ms: 4.978956771385591\n",
-      "    mean_raw_obs_processing_ms: 0.43667186446988804\n",
-      "  time_since_restore: 288.5126984119415\n",
-      "  time_this_iter_s: 28.535804271697998\n",
-      "  time_total_s: 288.5126984119415\n",
+      "    mean_action_processing_ms: 0.12465399711658876\n",
+      "    mean_env_wait_ms: 0.648056121056164\n",
+      "    mean_inference_ms: 4.879984642120459\n",
+      "    mean_raw_obs_processing_ms: 0.27227299804019345\n",
+      "  time_since_restore: 137.2602949142456\n",
+      "  time_this_iter_s: 13.426487922668457\n",
+      "  time_total_s: 137.2602949142456\n",
       "  timers:\n",
-      "    learn_throughput: 7972.454\n",
-      "    learn_time_ms: 20293.877\n",
-      "    sample_throughput: 19124.35\n",
-      "    sample_time_ms: 8460.0\n",
-      "    update_time_ms: 44.735\n",
-      "  timestamp: 1602166137\n",
+      "    learn_throughput: 6929.944\n",
+      "    learn_time_ms: 8755.05\n",
+      "    sample_throughput: 12378.447\n",
+      "    sample_time_ms: 4901.423\n",
+      "    update_time_ms: 34.448\n",
+      "  timestamp: 1602431798\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
+      "  timesteps_total: 606720\n",
       "  training_iteration: 10\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     10 |          288.513 | 1617920 |  228.597 |              282.485 |              115.788 |             832.08 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     10 |           137.26 | 606720 |  224.719 |              283.141 |               116.02 |            848.989 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-09-25\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3569.1739707835327\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-56-51\n",
       "  done: false\n",
-      "  episode_len_mean: 830.1703992210321\n",
-      "  episode_reward_max: 282.4848484848477\n",
-      "  episode_reward_mean: 229.0675253017024\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 846.2270916334661\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 225.236267053\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 53\n",
+      "  episodes_total: 753\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1174,83 +1129,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9670185938477516\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007682974718045443\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03496774770319462\n",
-      "        total_loss: 2.589013671875\n",
-      "        vf_explained_var: 0.9946534037590027\n",
-      "        vf_loss: 2.622444784641266\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0427685260772706\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006341448985040188\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016971242520958184\n",
+      "        total_loss: 35.50624237060547\n",
+      "        vf_explained_var: 0.9447349309921265\n",
+      "        vf_loss: 35.52204895019531\n",
+      "    num_steps_sampled: 667392\n",
+      "    num_steps_trained: 667392\n",
       "  iterations_since_restore: 11\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.45151515151515\n",
-      "    gpu_util_percent0: 0.2739393939393939\n",
+      "    cpu_util_percent: 30.833333333333332\n",
+      "    gpu_util_percent0: 0.26266666666666666\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.763636363636364\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.4133333333333327\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16125382205207386\n",
-      "    mean_env_wait_ms: 1.6761243985903949\n",
-      "    mean_inference_ms: 4.954596343237678\n",
-      "    mean_raw_obs_processing_ms: 0.4352361222242559\n",
-      "  time_since_restore: 316.5878527164459\n",
-      "  time_this_iter_s: 28.075154304504395\n",
-      "  time_total_s: 316.5878527164459\n",
+      "    mean_action_processing_ms: 0.12433623200377432\n",
+      "    mean_env_wait_ms: 0.6486852836553401\n",
+      "    mean_inference_ms: 4.8575339590357\n",
+      "    mean_raw_obs_processing_ms: 0.27152519320797486\n",
+      "  time_since_restore: 150.54876828193665\n",
+      "  time_this_iter_s: 13.28847336769104\n",
+      "  time_total_s: 150.54876828193665\n",
       "  timers:\n",
-      "    learn_throughput: 8000.406\n",
-      "    learn_time_ms: 20222.974\n",
-      "    sample_throughput: 19629.04\n",
-      "    sample_time_ms: 8242.482\n",
-      "    update_time_ms: 45.435\n",
-      "  timestamp: 1602166165\n",
+      "    learn_throughput: 6945.642\n",
+      "    learn_time_ms: 8735.262\n",
+      "    sample_throughput: 12860.23\n",
+      "    sample_time_ms: 4717.801\n",
+      "    update_time_ms: 32.912\n",
+      "  timestamp: 1602431811\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
+      "  timesteps_total: 667392\n",
       "  training_iteration: 11\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     11 |          316.588 | 1779712 |  229.068 |              282.485 |              115.788 |             830.17 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     11 |          150.549 | 667392 |  225.236 |              283.141 |               116.02 |            846.227 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-09-54\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3563.3507462686566\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-57-04\n",
       "  done: false\n",
-      "  episode_len_mean: 828.50904159132\n",
-      "  episode_reward_max: 287.9191919191919\n",
-      "  episode_reward_mean: 229.5476966774434\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 844.0559701492538\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 226.11857379767818\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 51\n",
+      "  episodes_total: 804\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1258,83 +1211,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.940390695631504\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007805287896189839\n",
-      "        model: {}\n",
-      "        policy_loss: -0.035866627853829415\n",
-      "        total_loss: 2.6927455008029937\n",
-      "        vf_explained_var: 0.9949959516525269\n",
-      "        vf_loss: 2.7270510613918306\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0320799827575684\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006349154934287071\n",
+      "        model: {}\n",
+      "        policy_loss: -0.018102188082411885\n",
+      "        total_loss: 23.2988582611084\n",
+      "        vf_explained_var: 0.9564861059188843\n",
+      "        vf_loss: 23.315794372558592\n",
+      "    num_steps_sampled: 728064\n",
+      "    num_steps_trained: 728064\n",
       "  iterations_since_restore: 12\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.993939393939392\n",
-      "    gpu_util_percent0: 0.26969696969696966\n",
+      "    cpu_util_percent: 32.28666666666667\n",
+      "    gpu_util_percent0: 0.3973333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757575757575758\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.406666666666666\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16085250209822033\n",
-      "    mean_env_wait_ms: 1.6775510346401423\n",
-      "    mean_inference_ms: 4.932401985457557\n",
-      "    mean_raw_obs_processing_ms: 0.4338907507677086\n",
-      "  time_since_restore: 345.2145109176636\n",
-      "  time_this_iter_s: 28.62665820121765\n",
-      "  time_total_s: 345.2145109176636\n",
+      "    mean_action_processing_ms: 0.12406581800779055\n",
+      "    mean_env_wait_ms: 0.6492691546624914\n",
+      "    mean_inference_ms: 4.837351513112054\n",
+      "    mean_raw_obs_processing_ms: 0.27095958437703355\n",
+      "  time_since_restore: 163.72990822792053\n",
+      "  time_this_iter_s: 13.181139945983887\n",
+      "  time_total_s: 163.72990822792053\n",
       "  timers:\n",
-      "    learn_throughput: 8013.686\n",
-      "    learn_time_ms: 20189.46\n",
-      "    sample_throughput: 19635.364\n",
-      "    sample_time_ms: 8239.827\n",
-      "    update_time_ms: 45.402\n",
-      "  timestamp: 1602166194\n",
+      "    learn_throughput: 6951.133\n",
+      "    learn_time_ms: 8728.361\n",
+      "    sample_throughput: 13110.742\n",
+      "    sample_time_ms: 4627.656\n",
+      "    update_time_ms: 32.559\n",
+      "  timestamp: 1602431824\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
+      "  timesteps_total: 728064\n",
       "  training_iteration: 12\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     12 |          345.215 | 1941504 |  229.548 |              287.919 |              115.788 |            828.509 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     12 |           163.73 | 728064 |  226.119 |              283.141 |               116.02 |            844.056 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-10-22\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3557.2402745995423\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-57-18\n",
       "  done: false\n",
-      "  episode_len_mean: 825.9173259493671\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 230.737545550441\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 841.3981693363844\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 227.04440283845307\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 70\n",
+      "  episodes_total: 874\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1342,83 +1293,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9119029730558396\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007374470541253686\n",
-      "        model: {}\n",
-      "        policy_loss: -0.031025875953491776\n",
-      "        total_loss: 3.626113736629486\n",
-      "        vf_explained_var: 0.9953392744064331\n",
-      "        vf_loss: 3.655664700269699\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.033131980895996\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006343710143119097\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017480041179805995\n",
+      "        total_loss: 19.233250427246094\n",
+      "        vf_explained_var: 0.9637705087661743\n",
+      "        vf_loss: 19.249564743041994\n",
+      "    num_steps_sampled: 788736\n",
+      "    num_steps_trained: 788736\n",
       "  iterations_since_restore: 13\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.370588235294115\n",
-      "    gpu_util_percent0: 0.2747058823529412\n",
+      "    cpu_util_percent: 30.746666666666673\n",
+      "    gpu_util_percent0: 0.28\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.75294117647059\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.4066666666666663\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16017287678084888\n",
-      "    mean_env_wait_ms: 1.6802277086992836\n",
-      "    mean_inference_ms: 4.89439148640374\n",
-      "    mean_raw_obs_processing_ms: 0.4316389620412026\n",
-      "  time_since_restore: 373.45997977256775\n",
-      "  time_this_iter_s: 28.245468854904175\n",
-      "  time_total_s: 373.45997977256775\n",
+      "    mean_action_processing_ms: 0.12373696501888903\n",
+      "    mean_env_wait_ms: 0.6498939859770279\n",
+      "    mean_inference_ms: 4.812738635870073\n",
+      "    mean_raw_obs_processing_ms: 0.2701312535684045\n",
+      "  time_since_restore: 177.0780427455902\n",
+      "  time_this_iter_s: 13.348134517669678\n",
+      "  time_total_s: 177.0780427455902\n",
       "  timers:\n",
-      "    learn_throughput: 8026.419\n",
-      "    learn_time_ms: 20157.433\n",
-      "    sample_throughput: 19763.446\n",
-      "    sample_time_ms: 8186.427\n",
-      "    update_time_ms: 44.475\n",
-      "  timestamp: 1602166222\n",
+      "    learn_throughput: 6946.551\n",
+      "    learn_time_ms: 8734.118\n",
+      "    sample_throughput: 13222.879\n",
+      "    sample_time_ms: 4588.411\n",
+      "    update_time_ms: 33.566\n",
+      "  timestamp: 1602431838\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
+      "  timesteps_total: 788736\n",
       "  training_iteration: 13\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     13 |           373.46 | 2103296 |  230.738 |               289.98 |              115.788 |            825.917 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     13 |          177.078 | 788736 |  227.044 |              283.141 |               116.02 |            841.398 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-10-50\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3549.9789029535864\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-57-31\n",
       "  done: false\n",
-      "  episode_len_mean: 824.9274013402829\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.18682355949656\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 838.9367088607595\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 228.1446106635979\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 74\n",
+      "  episodes_total: 948\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1426,83 +1375,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8989204004406929\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0074366391287185255\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03388760575326159\n",
-      "        total_loss: 2.3619153201580048\n",
-      "        vf_explained_var: 0.9957093000411987\n",
-      "        vf_loss: 2.394315606355667\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0167401790618897\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007002000138163567\n",
+      "        model: {}\n",
+      "        policy_loss: -0.018312944937497376\n",
+      "        total_loss: 17.715657043457032\n",
+      "        vf_explained_var: 0.9672698974609375\n",
+      "        vf_loss: 17.732671356201173\n",
+      "    num_steps_sampled: 849408\n",
+      "    num_steps_trained: 849408\n",
       "  iterations_since_restore: 14\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.312121212121212\n",
-      "    gpu_util_percent0: 0.26151515151515153\n",
+      "    cpu_util_percent: 28.625\n",
+      "    gpu_util_percent0: 0.27875\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.772727272727275\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.4\n",
+      "    vram_util_percent0: 0.09732699245654312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15988462752258317\n",
-      "    mean_env_wait_ms: 1.6814425515145586\n",
-      "    mean_inference_ms: 4.878041025826835\n",
-      "    mean_raw_obs_processing_ms: 0.430664812314108\n",
-      "  time_since_restore: 401.80727195739746\n",
-      "  time_this_iter_s: 28.347292184829712\n",
-      "  time_total_s: 401.80727195739746\n",
+      "    mean_action_processing_ms: 0.12342031345688508\n",
+      "    mean_env_wait_ms: 0.6505408949897603\n",
+      "    mean_inference_ms: 4.789156144582933\n",
+      "    mean_raw_obs_processing_ms: 0.2693535752713011\n",
+      "  time_since_restore: 190.60786366462708\n",
+      "  time_this_iter_s: 13.529820919036865\n",
+      "  time_total_s: 190.60786366462708\n",
       "  timers:\n",
-      "    learn_throughput: 8023.866\n",
-      "    learn_time_ms: 20163.846\n",
-      "    sample_throughput: 19841.783\n",
-      "    sample_time_ms: 8154.106\n",
-      "    update_time_ms: 44.12\n",
-      "  timestamp: 1602166250\n",
+      "    learn_throughput: 6937.619\n",
+      "    learn_time_ms: 8745.363\n",
+      "    sample_throughput: 13251.943\n",
+      "    sample_time_ms: 4578.347\n",
+      "    update_time_ms: 35.259\n",
+      "  timestamp: 1602431851\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
+      "  timesteps_total: 849408\n",
       "  training_iteration: 14\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     14 |          401.807 | 2265088 |  231.187 |               289.98 |              115.788 |            824.927 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     14 |          190.608 | 849408 |  228.145 |              283.141 |               116.02 |            838.937 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-11-19\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3543.60564751704\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-57-45\n",
       "  done: false\n",
-      "  episode_len_mean: 824.0777074542897\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 231.63322749293204\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 836.4985394352483\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 229.11025542671103\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1027\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1510,83 +1457,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.895898899435997\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007697970513254404\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03602396983187646\n",
-      "        total_loss: 1.9372931450605393\n",
-      "        vf_explained_var: 0.9962417483329773\n",
-      "        vf_loss: 1.9717775255441665\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9943946719169616\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007912519946694374\n",
+      "        model: {}\n",
+      "        policy_loss: -0.018420965038239957\n",
+      "        total_loss: 17.297443771362303\n",
+      "        vf_explained_var: 0.9709770083427429\n",
+      "        vf_loss: 17.314381790161132\n",
+      "    num_steps_sampled: 910080\n",
+      "    num_steps_trained: 910080\n",
       "  iterations_since_restore: 15\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.59705882352941\n",
-      "    gpu_util_percent0: 0.27\n",
+      "    cpu_util_percent: 32.22\n",
+      "    gpu_util_percent0: 0.2553333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.761764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.4066666666666663\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15962256586295442\n",
-      "    mean_env_wait_ms: 1.6825632050368664\n",
-      "    mean_inference_ms: 4.862887505621167\n",
-      "    mean_raw_obs_processing_ms: 0.42975456496408376\n",
-      "  time_since_restore: 430.180118560791\n",
-      "  time_this_iter_s: 28.372846603393555\n",
-      "  time_total_s: 430.180118560791\n",
+      "    mean_action_processing_ms: 0.12311990239994437\n",
+      "    mean_env_wait_ms: 0.6512540754970045\n",
+      "    mean_inference_ms: 4.766607307829725\n",
+      "    mean_raw_obs_processing_ms: 0.26859772667314763\n",
+      "  time_since_restore: 203.8491177558899\n",
+      "  time_this_iter_s: 13.241254091262817\n",
+      "  time_total_s: 203.8491177558899\n",
       "  timers:\n",
-      "    learn_throughput: 8029.244\n",
-      "    learn_time_ms: 20150.342\n",
-      "    sample_throughput: 19898.49\n",
-      "    sample_time_ms: 8130.868\n",
-      "    update_time_ms: 37.742\n",
-      "  timestamp: 1602166279\n",
+      "    learn_throughput: 6948.253\n",
+      "    learn_time_ms: 8731.979\n",
+      "    sample_throughput: 13314.017\n",
+      "    sample_time_ms: 4557.002\n",
+      "    update_time_ms: 36.008\n",
+      "  timestamp: 1602431865\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
+      "  timesteps_total: 910080\n",
       "  training_iteration: 15\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     15 |           430.18 | 2426880 |  231.633 |               289.98 |              115.788 |            824.078 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     15 |          203.849 | 910080 |   229.11 |              283.141 |               116.02 |            836.499 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-11-48\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3535.533453887884\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-57-58\n",
       "  done: false\n",
-      "  episode_len_mean: 822.9910447761195\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 232.33685444829712\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 171\n",
-      "  episodes_total: 3015\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 834.1925858951175\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 230.33331506749218\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1594,83 +1539,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8683042243123055\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007607861259020865\n",
-      "        model: {}\n",
-      "        policy_loss: -0.036039730068296194\n",
-      "        total_loss: 2.116857588291168\n",
-      "        vf_explained_var: 0.9965157508850098\n",
-      "        vf_loss: 2.1513757526874544\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9890294790267944\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0057542574591934684\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016859600320458412\n",
+      "        total_loss: 22.078242111206055\n",
+      "        vf_explained_var: 0.9638479948043823\n",
+      "        vf_loss: 22.09404945373535\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 16\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 31.03030303030303\n",
-      "    gpu_util_percent0: 0.28878787878787876\n",
+      "    cpu_util_percent: 31.439999999999998\n",
+      "    gpu_util_percent0: 0.24866666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76060606060606\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.406666666666666\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15936424957771478\n",
-      "    mean_env_wait_ms: 1.6837075606485503\n",
-      "    mean_inference_ms: 4.8476482100837615\n",
-      "    mean_raw_obs_processing_ms: 0.4288385279340961\n",
-      "  time_since_restore: 458.61421608924866\n",
-      "  time_this_iter_s: 28.43409752845764\n",
-      "  time_total_s: 458.61421608924866\n",
+      "    mean_action_processing_ms: 0.12284977928720761\n",
+      "    mean_env_wait_ms: 0.6519194255420189\n",
+      "    mean_inference_ms: 4.746385724624431\n",
+      "    mean_raw_obs_processing_ms: 0.2679060922505163\n",
+      "  time_since_restore: 217.11126279830933\n",
+      "  time_this_iter_s: 13.262145042419434\n",
+      "  time_total_s: 217.11126279830933\n",
       "  timers:\n",
-      "    learn_throughput: 8025.775\n",
-      "    learn_time_ms: 20159.051\n",
-      "    sample_throughput: 19933.741\n",
-      "    sample_time_ms: 8116.489\n",
-      "    update_time_ms: 36.891\n",
-      "  timestamp: 1602166308\n",
+      "    learn_throughput: 6952.965\n",
+      "    learn_time_ms: 8726.062\n",
+      "    sample_throughput: 13370.649\n",
+      "    sample_time_ms: 4537.7\n",
+      "    update_time_ms: 35.577\n",
+      "  timestamp: 1602431878\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
+      "  timesteps_total: 970752\n",
       "  training_iteration: 16\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     16 |          458.614 | 2588672 |  232.337 |               289.98 |              115.788 |            822.991 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     16 |          217.111 | 970752 |  230.333 |              283.141 |               116.02 |            834.193 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-12-16\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3527.42194092827\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-58-11\n",
       "  done: false\n",
-      "  episode_len_mean: 821.0216998191681\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.1551683197252\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 303\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 832.0430379746836\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 231.56233218258527\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1185\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1678,83 +1621,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8348902150988579\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00740289380773902\n",
-      "        model: {}\n",
-      "        policy_loss: -0.029998348827939482\n",
-      "        total_loss: 2.5100847482681274\n",
-      "        vf_explained_var: 0.9960853457450867\n",
-      "        vf_loss: 2.538602519035339\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9727253675460815\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006370769906789064\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01666537211276591\n",
+      "        total_loss: 16.41226272583008\n",
+      "        vf_explained_var: 0.971873939037323\n",
+      "        vf_loss: 16.42775077819824\n",
+      "    num_steps_sampled: 1031424\n",
+      "    num_steps_trained: 1031424\n",
       "  iterations_since_restore: 17\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.170588235294122\n",
-      "    gpu_util_percent0: 0.22911764705882354\n",
+      "    cpu_util_percent: 31.580000000000002\n",
+      "    gpu_util_percent0: 0.24333333333333335\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.75294117647059\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.4133333333333327\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1589481712029165\n",
-      "    mean_env_wait_ms: 1.6856610626461734\n",
-      "    mean_inference_ms: 4.823647348850542\n",
-      "    mean_raw_obs_processing_ms: 0.4273782452417025\n",
-      "  time_since_restore: 486.7920489311218\n",
-      "  time_this_iter_s: 28.17783284187317\n",
-      "  time_total_s: 486.7920489311218\n",
+      "    mean_action_processing_ms: 0.12260554522131402\n",
+      "    mean_env_wait_ms: 0.6525447829778301\n",
+      "    mean_inference_ms: 4.728098652422307\n",
+      "    mean_raw_obs_processing_ms: 0.26727086732837113\n",
+      "  time_since_restore: 230.35052013397217\n",
+      "  time_this_iter_s: 13.239257335662842\n",
+      "  time_total_s: 230.35052013397217\n",
       "  timers:\n",
-      "    learn_throughput: 8025.414\n",
-      "    learn_time_ms: 20159.958\n",
-      "    sample_throughput: 20020.205\n",
-      "    sample_time_ms: 8081.436\n",
-      "    update_time_ms: 37.784\n",
-      "  timestamp: 1602166336\n",
+      "    learn_throughput: 6956.359\n",
+      "    learn_time_ms: 8721.804\n",
+      "    sample_throughput: 13401.743\n",
+      "    sample_time_ms: 4527.172\n",
+      "    update_time_ms: 33.824\n",
+      "  timestamp: 1602431891\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
+      "  timesteps_total: 1031424\n",
       "  training_iteration: 17\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     17 |          486.792 | 2750464 |  233.155 |               289.98 |              115.788 |            821.022 |\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     17 |          230.351 | 1031424 |  231.562 |              283.141 |               116.02 |            832.043 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-12-44\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3521.1756329113923\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-58-25\n",
       "  done: false\n",
-      "  episode_len_mean: 820.0376869965478\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 233.58232206995146\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 830.375\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 232.50874248817277\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1762,83 +1703,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8338133722543717\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007797137019224465\n",
-      "        model: {}\n",
-      "        policy_loss: -0.0366627115290612\n",
-      "        total_loss: 1.7475906014442444\n",
-      "        vf_explained_var: 0.9965535998344421\n",
-      "        vf_loss: 1.7826938778162003\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9600818872451782\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006693596951663494\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017358003184199333\n",
+      "        total_loss: 18.817015075683592\n",
+      "        vf_explained_var: 0.9695835113525391\n",
+      "        vf_loss: 18.833131790161133\n",
+      "    num_steps_sampled: 1092096\n",
+      "    num_steps_trained: 1092096\n",
       "  iterations_since_restore: 18\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.263636363636362\n",
-      "    gpu_util_percent0: 0.2739393939393939\n",
+      "    cpu_util_percent: 28.900000000000002\n",
+      "    gpu_util_percent0: 0.31125\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.4124999999999996\n",
+      "    vram_util_percent0: 0.09732699245654312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15875079551526766\n",
-      "    mean_env_wait_ms: 1.6865974079727117\n",
-      "    mean_inference_ms: 4.812393081904589\n",
-      "    mean_raw_obs_processing_ms: 0.42669712128025067\n",
-      "  time_since_restore: 515.002126455307\n",
-      "  time_this_iter_s: 28.21007752418518\n",
-      "  time_total_s: 515.002126455307\n",
+      "    mean_action_processing_ms: 0.12238541135239141\n",
+      "    mean_env_wait_ms: 0.6531369692901041\n",
+      "    mean_inference_ms: 4.711528553519437\n",
+      "    mean_raw_obs_processing_ms: 0.2666955382496055\n",
+      "  time_since_restore: 243.7254707813263\n",
+      "  time_this_iter_s: 13.374950647354126\n",
+      "  time_total_s: 243.7254707813263\n",
       "  timers:\n",
-      "    learn_throughput: 8034.771\n",
-      "    learn_time_ms: 20136.48\n",
-      "    sample_throughput: 19987.012\n",
-      "    sample_time_ms: 8094.857\n",
-      "    update_time_ms: 37.274\n",
-      "  timestamp: 1602166364\n",
+      "    learn_throughput: 6960.665\n",
+      "    learn_time_ms: 8716.408\n",
+      "    sample_throughput: 13406.891\n",
+      "    sample_time_ms: 4525.434\n",
+      "    update_time_ms: 35.896\n",
+      "  timestamp: 1602431905\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
+      "  timesteps_total: 1092096\n",
       "  training_iteration: 18\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     18 |          515.002 | 2912256 |  233.582 |               289.98 |              115.788 |            820.038 |\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     18 |          243.725 | 1092096 |  232.509 |              283.141 |               116.02 |            830.375 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-13-13\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3516.3827252419956\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-58-38\n",
       "  done: false\n",
-      "  episode_len_mean: 819.1164006604292\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.0312925623877\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 829.0067014147431\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 233.23494061989956\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1343\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1846,83 +1785,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8341425269842148\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007575143571011722\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03457739797886461\n",
-      "        total_loss: 1.834545186161995\n",
-      "        vf_explained_var: 0.9961616396903992\n",
-      "        vf_loss: 1.8676075398921967\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9440988779067994\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007389881648123264\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01705184131860733\n",
+      "        total_loss: 15.939278411865235\n",
+      "        vf_explained_var: 0.9752111434936523\n",
+      "        vf_loss: 15.954946899414063\n",
+      "    num_steps_sampled: 1152768\n",
+      "    num_steps_trained: 1152768\n",
       "  iterations_since_restore: 19\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.017647058823528\n",
-      "    gpu_util_percent0: 0.2832352941176471\n",
+      "    cpu_util_percent: 31.26\n",
+      "    gpu_util_percent0: 0.25133333333333335\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.76764705882353\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.4066666666666663\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15856558726293105\n",
-      "    mean_env_wait_ms: 1.6874969155605837\n",
-      "    mean_inference_ms: 4.801814859500953\n",
-      "    mean_raw_obs_processing_ms: 0.42604884838564067\n",
-      "  time_since_restore: 543.3891928195953\n",
-      "  time_this_iter_s: 28.38706636428833\n",
-      "  time_total_s: 543.3891928195953\n",
+      "    mean_action_processing_ms: 0.1221860119313473\n",
+      "    mean_env_wait_ms: 0.6536970250442272\n",
+      "    mean_inference_ms: 4.696402876530246\n",
+      "    mean_raw_obs_processing_ms: 0.2661655553941498\n",
+      "  time_since_restore: 257.01133251190186\n",
+      "  time_this_iter_s: 13.285861730575562\n",
+      "  time_total_s: 257.01133251190186\n",
       "  timers:\n",
-      "    learn_throughput: 8037.512\n",
-      "    learn_time_ms: 20129.612\n",
-      "    sample_throughput: 19971.836\n",
-      "    sample_time_ms: 8101.008\n",
-      "    update_time_ms: 41.201\n",
-      "  timestamp: 1602166393\n",
+      "    learn_throughput: 6968.979\n",
+      "    learn_time_ms: 8706.01\n",
+      "    sample_throughput: 13371.633\n",
+      "    sample_time_ms: 4537.366\n",
+      "    update_time_ms: 37.907\n",
+      "  timestamp: 1602431918\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
+      "  timesteps_total: 1152768\n",
       "  training_iteration: 19\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     19 |          543.389 | 3074048 |  234.031 |               289.98 |              115.788 |            819.116 |\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     19 |          257.011 | 1152768 |  233.235 |              283.141 |               116.02 |            829.007 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-13-42\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3510.7897327707456\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-58-52\n",
       "  done: false\n",
-      "  episode_len_mean: 817.554763117677\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 234.8146184205786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 292\n",
-      "  episodes_total: 3926\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "  episode_len_mean: 828.0991561181435\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 234.08236372160414\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1930,83 +1867,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7916461393237114\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007353159273043275\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03166137257358059\n",
-      "        total_loss: 2.4200849175453185\n",
-      "        vf_explained_var: 0.9965318441390991\n",
-      "        vf_loss: 2.450275695323944\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9336613178253174\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006462276726961136\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017750857584178447\n",
+      "        total_loss: 12.616872406005859\n",
+      "        vf_explained_var: 0.9794406890869141\n",
+      "        vf_loss: 12.63342456817627\n",
+      "    num_steps_sampled: 1213440\n",
+      "    num_steps_trained: 1213440\n",
       "  iterations_since_restore: 20\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.500000000000007\n",
-      "    gpu_util_percent0: 0.2582352941176471\n",
+      "    cpu_util_percent: 31.500000000000007\n",
+      "    gpu_util_percent0: 0.36666666666666664\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755882352941178\n",
-      "    vram_util_percent0: 0.257051492292555\n",
+      "    ram_util_percent: 3.4066666666666663\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15824728170515573\n",
-      "    mean_env_wait_ms: 1.689080359464987\n",
-      "    mean_inference_ms: 4.783977737237845\n",
-      "    mean_raw_obs_processing_ms: 0.4249789923662631\n",
-      "  time_since_restore: 572.0331726074219\n",
-      "  time_this_iter_s: 28.643979787826538\n",
-      "  time_total_s: 572.0331726074219\n",
+      "    mean_action_processing_ms: 0.12200509085547602\n",
+      "    mean_env_wait_ms: 0.6542092230193569\n",
+      "    mean_inference_ms: 4.682519514645896\n",
+      "    mean_raw_obs_processing_ms: 0.26567865937886914\n",
+      "  time_since_restore: 270.40074610710144\n",
+      "  time_this_iter_s: 13.389413595199585\n",
+      "  time_total_s: 270.40074610710144\n",
       "  timers:\n",
-      "    learn_throughput: 8035.517\n",
-      "    learn_time_ms: 20134.61\n",
-      "    sample_throughput: 19976.949\n",
-      "    sample_time_ms: 8098.935\n",
-      "    update_time_ms: 46.558\n",
-      "  timestamp: 1602166422\n",
+      "    learn_throughput: 6973.737\n",
+      "    learn_time_ms: 8700.07\n",
+      "    sample_throughput: 13345.344\n",
+      "    sample_time_ms: 4546.305\n",
+      "    update_time_ms: 30.911\n",
+      "  timestamp: 1602431932\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
+      "  timesteps_total: 1213440\n",
       "  training_iteration: 20\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | RUNNING  | 172.17.0.4:57899 |     20 |          572.033 | 3235840 |  234.815 |               289.98 |              115.788 |            817.555 |\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     20 |          270.401 | 1213440 |  234.082 |              283.141 |               116.02 |            828.099 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_1cfe6_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3176.0\n",
-      "  date: 2020-10-08_14-14-10\n",
-      "  done: true\n",
-      "  episode_len_mean: 816.6701557935735\n",
-      "  episode_reward_max: 289.9797979797982\n",
-      "  episode_reward_mean: 235.22827594346575\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 182\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 7cb4762c55e847bf887d254490157add\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3505.7934710193204\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-59-05\n",
+      "  done: false\n",
+      "  episode_len_mean: 827.3597601598934\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 234.83937307788065\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1501\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2014,2655 +1949,2300 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7638061985373497\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007330618624109775\n",
-      "        model: {}\n",
-      "        policy_loss: -0.03147139406064525\n",
-      "        total_loss: 1.8828283458948136\n",
-      "        vf_explained_var: 0.9963488578796387\n",
-      "        vf_loss: 1.912833634018898\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9111692786216736\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007237232103943825\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016399275790899993\n",
+      "        total_loss: 14.045680236816406\n",
+      "        vf_explained_var: 0.9778404235839844\n",
+      "        vf_loss: 14.060722923278808\n",
+      "    num_steps_sampled: 1274112\n",
+      "    num_steps_trained: 1274112\n",
       "  iterations_since_restore: 21\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 30.76060606060606\n",
-      "    gpu_util_percent0: 0.25030303030303036\n",
+      "    cpu_util_percent: 29.075000000000003\n",
+      "    gpu_util_percent0: 0.305625\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.769696969696971\n",
-      "    vram_util_percent0: 0.2570514922925549\n",
+      "    ram_util_percent: 3.4\n",
+      "    vram_util_percent0: 0.09732699245654312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 57899\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15806698356889384\n",
-      "    mean_env_wait_ms: 1.6900183481280247\n",
-      "    mean_inference_ms: 4.773945395364269\n",
-      "    mean_raw_obs_processing_ms: 0.42436064467246504\n",
-      "  time_since_restore: 600.5207903385162\n",
-      "  time_this_iter_s: 28.48761773109436\n",
-      "  time_total_s: 600.5207903385162\n",
+      "    mean_action_processing_ms: 0.12183713496784085\n",
+      "    mean_env_wait_ms: 0.6546777091680613\n",
+      "    mean_inference_ms: 4.669743037173543\n",
+      "    mean_raw_obs_processing_ms: 0.2652312054653271\n",
+      "  time_since_restore: 283.9569752216339\n",
+      "  time_this_iter_s: 13.55622911453247\n",
+      "  time_total_s: 283.9569752216339\n",
       "  timers:\n",
-      "    learn_throughput: 8034.641\n",
-      "    learn_time_ms: 20136.804\n",
-      "    sample_throughput: 19881.19\n",
-      "    sample_time_ms: 8137.943\n",
-      "    update_time_ms: 46.415\n",
-      "  timestamp: 1602166450\n",
+      "    learn_throughput: 6962.288\n",
+      "    learn_time_ms: 8714.376\n",
+      "    sample_throughput: 13314.663\n",
+      "    sample_time_ms: 4556.781\n",
+      "    update_time_ms: 32.387\n",
+      "  timestamp: 1602431945\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
+      "  timesteps_total: 1274112\n",
       "  training_iteration: 21\n",
-      "  trial_id: 1cfe6_00000\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | TERMINATED |       |     21 |          600.521 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/493.41 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_1cfe6_00000 | TERMINATED |       |     21 |          600.521 | 3397632 |  235.228 |               289.98 |              115.788 |             816.67 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     21 |          283.957 | 1274112 |  234.839 |              283.141 |               116.02 |             827.36 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 57594\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_140356-5nvugt1y/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_140356-5nvugt1y/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3176.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 614\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602166450\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 282.48485\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 227.63033\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1264\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▄▅▇█\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/5nvugt1y\u001b[0m\n",
-      "2020-10-08 14:14:19,138 - wandb.wandb_agent - INFO - Cleaning up finished run: 5nvugt1y\n",
-      "2020-10-08 14:14:19,448 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:14:19,448 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 8192\n",
-      "2020-10-08 14:14:19,452 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=8192\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/fpfrymi0\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_141421-fpfrymi0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 14:14:23,731\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:14:24,486 - wandb.wandb_agent - INFO - Running runs: ['fpfrymi0']\n",
-      "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=756)\u001b[0m 2020-10-08 14:14:26,675\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=710)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=710)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=734)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=734)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=742)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=742)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=711)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=696)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=696)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=731)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=731)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=679)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=679)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=725)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=725)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=718)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=718)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=697)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=697)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=723)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=723)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=687)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=687)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=707)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=707)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=703)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=703)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=699)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=699)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=730)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=730)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=684)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=684)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=700)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=700)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=612)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=612)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=650)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=650)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=689)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=689)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=733)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=733)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=691)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=691)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=615)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=615)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=649)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=649)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=686)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=686)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=712)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=712)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=646)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=646)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=629)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=629)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=702)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=702)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=638)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=638)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=688)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=688)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=608)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=608)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=606)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=606)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=620)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=620)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=690)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=690)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=698)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=698)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=678)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=678)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=692)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=692)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=683)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=683)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=727)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=727)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=626)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=626)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=609)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=609)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=695)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=695)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=720)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=720)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=680)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=680)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=641)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=641)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=682)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=682)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=607)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=607)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=715)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=715)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=623)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=623)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=622)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=622)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=705)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=705)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=624)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=624)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=611)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=611)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=685)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=685)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=621)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=621)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-14-58\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3500.7069620253164\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-59-19\n",
+      "  done: false\n",
+      "  episode_len_mean: 826.9227848101266\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 235.61005625879037\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1611746549606323\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005718740075826645\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8991423726081849\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005821902584284544\n",
       "        model: {}\n",
-      "        policy_loss: -0.013096390827558934\n",
-      "        total_loss: 7.403090405464172\n",
-      "        vf_explained_var: 0.7892305254936218\n",
-      "        vf_loss: 7.415043115615845\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
+      "        policy_loss: -0.01675959237618372\n",
+      "        total_loss: 11.816276931762696\n",
+      "        vf_explained_var: 0.9811431169509888\n",
+      "        vf_loss: 11.83196144104004\n",
+      "    num_steps_sampled: 1334784\n",
+      "    num_steps_trained: 1334784\n",
+      "  iterations_since_restore: 22\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 37.735483870967734\n",
-      "    gpu_util_percent0: 0.051935483870967754\n",
-      "    gpu_util_percent1: 0.0003225806451612903\n",
-      "    gpu_util_percent2: 0.0003225806451612903\n",
-      "    ram_util_percent: 9.529032258064516\n",
-      "    vram_util_percent0: 0.25613104243591234\n",
+      "    cpu_util_percent: 31.193333333333335\n",
+      "    gpu_util_percent0: 0.24600000000000005\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.413333333333333\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17423707785964127\n",
-      "    mean_env_wait_ms: 1.645963223637825\n",
-      "    mean_inference_ms: 5.692081848902995\n",
-      "    mean_raw_obs_processing_ms: 0.4677243687628816\n",
-      "  time_since_restore: 26.03303360939026\n",
-      "  time_this_iter_s: 26.03303360939026\n",
-      "  time_total_s: 26.03303360939026\n",
+      "    mean_action_processing_ms: 0.121681789485281\n",
+      "    mean_env_wait_ms: 0.6550983362033309\n",
+      "    mean_inference_ms: 4.657925233192698\n",
+      "    mean_raw_obs_processing_ms: 0.2648172095844593\n",
+      "  time_since_restore: 297.25005173683167\n",
+      "  time_this_iter_s: 13.293076515197754\n",
+      "  time_total_s: 297.25005173683167\n",
       "  timers:\n",
-      "    learn_throughput: 9842.911\n",
-      "    learn_time_ms: 16437.413\n",
-      "    sample_throughput: 17001.439\n",
-      "    sample_time_ms: 9516.371\n",
-      "    update_time_ms: 39.605\n",
-      "  timestamp: 1602166498\n",
+      "    learn_throughput: 6958.474\n",
+      "    learn_time_ms: 8719.153\n",
+      "    sample_throughput: 13299.556\n",
+      "    sample_time_ms: 4561.957\n",
+      "    update_time_ms: 33.32\n",
+      "  timestamp: 1602431959\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1334784\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.7/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      1 |           26.033 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     22 |           297.25 | 1334784 |   235.61 |              283.141 |               116.02 |            826.923 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_14-15-23\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3496.0596745027124\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-59-32\n",
       "  done: false\n",
-      "  episode_len_mean: 873.4715189873418\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 227.3690384861269\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 826.6172393007836\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 236.3141907319122\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1659\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.132627922296524\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006706285546533764\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8894487977027893\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00622055558487773\n",
       "        model: {}\n",
-      "        policy_loss: -0.016248987091239543\n",
-      "        total_loss: 5.631959009170532\n",
-      "        vf_explained_var: 0.9176143407821655\n",
-      "        vf_loss: 5.646866726875305\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
+      "        policy_loss: -0.016685663908720016\n",
+      "        total_loss: 12.154040336608887\n",
+      "        vf_explained_var: 0.9802371859550476\n",
+      "        vf_loss: 12.169570541381836\n",
+      "    num_steps_sampled: 1395456\n",
+      "    num_steps_trained: 1395456\n",
+      "  iterations_since_restore: 23\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.220689655172414\n",
-      "    gpu_util_percent0: 0.019655172413793106\n",
+      "    cpu_util_percent: 30.74000000000001\n",
+      "    gpu_util_percent0: 0.28800000000000003\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74137931034483\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4199999999999995\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17038163777984144\n",
-      "    mean_env_wait_ms: 1.6424572254451888\n",
-      "    mean_inference_ms: 5.447572680731352\n",
-      "    mean_raw_obs_processing_ms: 0.4584056950467155\n",
-      "  time_since_restore: 50.949177742004395\n",
-      "  time_this_iter_s: 24.916144132614136\n",
-      "  time_total_s: 50.949177742004395\n",
+      "    mean_action_processing_ms: 0.12153697127540337\n",
+      "    mean_env_wait_ms: 0.655473859315079\n",
+      "    mean_inference_ms: 4.646941960611419\n",
+      "    mean_raw_obs_processing_ms: 0.2644309640735632\n",
+      "  time_since_restore: 310.55483388900757\n",
+      "  time_this_iter_s: 13.304782152175903\n",
+      "  time_total_s: 310.55483388900757\n",
       "  timers:\n",
-      "    learn_throughput: 9861.266\n",
-      "    learn_time_ms: 16406.818\n",
-      "    sample_throughput: 18024.658\n",
-      "    sample_time_ms: 8976.148\n",
-      "    update_time_ms: 38.131\n",
-      "  timestamp: 1602166523\n",
+      "    learn_throughput: 6960.758\n",
+      "    learn_time_ms: 8716.292\n",
+      "    sample_throughput: 13305.845\n",
+      "    sample_time_ms: 4559.801\n",
+      "    update_time_ms: 33.628\n",
+      "  timestamp: 1602431972\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1395456\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      2 |          50.9492 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     23 |          310.555 | 1395456 |  236.314 |              283.141 |               116.02 |            826.617 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3265.0\n",
-      "  date: 2020-10-08_14-15-48\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3493.070195627158\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-59-45\n",
       "  done: false\n",
-      "  episode_len_mean: 867.8713080168776\n",
-      "  episode_reward_max: 274.85858585858557\n",
-      "  episode_reward_mean: 228.246196138601\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 826.337169159954\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 236.7671420766932\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1738\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1271256804466248\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007389193354174495\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8807594299316406\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005982859991490841\n",
       "        model: {}\n",
-      "        policy_loss: -0.018508310522884132\n",
-      "        total_loss: 6.457739639282226\n",
-      "        vf_explained_var: 0.9464155435562134\n",
-      "        vf_loss: 6.4747700691223145\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
+      "        policy_loss: -0.016763895750045776\n",
+      "        total_loss: 12.645524978637695\n",
+      "        vf_explained_var: 0.9802120923995972\n",
+      "        vf_loss: 12.661180877685547\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 24\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.61379310344827\n",
-      "    gpu_util_percent0: 0.21344827586206902\n",
+      "    cpu_util_percent: 30.819999999999997\n",
+      "    gpu_util_percent0: 0.2433333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4133333333333327\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16769761323536675\n",
-      "    mean_env_wait_ms: 1.6416986329657957\n",
-      "    mean_inference_ms: 5.306852272749373\n",
-      "    mean_raw_obs_processing_ms: 0.4500760030355006\n",
-      "  time_since_restore: 75.78218650817871\n",
-      "  time_this_iter_s: 24.833008766174316\n",
-      "  time_total_s: 75.78218650817871\n",
+      "    mean_action_processing_ms: 0.1214031377499436\n",
+      "    mean_env_wait_ms: 0.6558162618321063\n",
+      "    mean_inference_ms: 4.636744336810363\n",
+      "    mean_raw_obs_processing_ms: 0.2640767432812346\n",
+      "  time_since_restore: 323.7830502986908\n",
+      "  time_this_iter_s: 13.228216409683228\n",
+      "  time_total_s: 323.7830502986908\n",
       "  timers:\n",
-      "    learn_throughput: 9901.992\n",
-      "    learn_time_ms: 16339.339\n",
-      "    sample_throughput: 18316.884\n",
-      "    sample_time_ms: 8832.943\n",
-      "    update_time_ms: 36.895\n",
-      "  timestamp: 1602166548\n",
+      "    learn_throughput: 6970.567\n",
+      "    learn_time_ms: 8704.027\n",
+      "    sample_throughput: 13350.301\n",
+      "    sample_time_ms: 4544.617\n",
+      "    update_time_ms: 29.989\n",
+      "  timestamp: 1602431985\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 24\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      3 |          75.7822 | 485376 |  228.246 |              274.859 |              115.788 |            867.871 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     24 |          323.783 | 1456128 |  236.767 |              283.141 |               116.02 |            826.337 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3230.0\n",
-      "  date: 2020-10-08_14-16-13\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3489.458998348927\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_15-59-59\n",
       "  done: false\n",
-      "  episode_len_mean: 862.3544303797469\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 230.3964326812426\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 826.1761144744083\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 237.31429317945543\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1817\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0996861219406129\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.008276985818520188\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8732481479644776\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00523865120485425\n",
       "        model: {}\n",
-      "        policy_loss: -0.020328705292195083\n",
-      "        total_loss: 5.005046558380127\n",
-      "        vf_explained_var: 0.9697187542915344\n",
-      "        vf_loss: 5.023719763755798\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
+      "        policy_loss: -0.015956384362652898\n",
+      "        total_loss: 13.58818016052246\n",
+      "        vf_explained_var: 0.9780164957046509\n",
+      "        vf_loss: 13.603175735473632\n",
+      "    num_steps_sampled: 1516800\n",
+      "    num_steps_trained: 1516800\n",
+      "  iterations_since_restore: 25\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.723333333333336\n",
-      "    gpu_util_percent0: 0.4343333333333333\n",
+      "    cpu_util_percent: 29.926666666666662\n",
+      "    gpu_util_percent0: 0.336\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.413333333333333\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1657578301907817\n",
-      "    mean_env_wait_ms: 1.6430517247856948\n",
-      "    mean_inference_ms: 5.2018997182402025\n",
-      "    mean_raw_obs_processing_ms: 0.44406851617825566\n",
-      "  time_since_restore: 100.74394655227661\n",
-      "  time_this_iter_s: 24.9617600440979\n",
-      "  time_total_s: 100.74394655227661\n",
+      "    mean_action_processing_ms: 0.12127871828117874\n",
+      "    mean_env_wait_ms: 0.6561269763112696\n",
+      "    mean_inference_ms: 4.627235935246541\n",
+      "    mean_raw_obs_processing_ms: 0.26375211427761996\n",
+      "  time_since_restore: 337.0192449092865\n",
+      "  time_this_iter_s: 13.236194610595703\n",
+      "  time_total_s: 337.0192449092865\n",
       "  timers:\n",
-      "    learn_throughput: 9911.992\n",
-      "    learn_time_ms: 16322.854\n",
-      "    sample_throughput: 18445.327\n",
-      "    sample_time_ms: 8771.436\n",
-      "    update_time_ms: 36.541\n",
-      "  timestamp: 1602166573\n",
+      "    learn_throughput: 6967.733\n",
+      "    learn_time_ms: 8707.566\n",
+      "    sample_throughput: 13360.034\n",
+      "    sample_time_ms: 4541.306\n",
+      "    update_time_ms: 28.564\n",
+      "  timestamp: 1602431999\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1516800\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      4 |          100.744 | 647168 |  230.396 |              278.707 |              115.788 |            862.354 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     25 |          337.019 | 1516800 |  237.314 |              283.141 |               116.02 |            826.176 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3223.0\n",
-      "  date: 2020-10-08_14-16-38\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3486.208443271768\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_16-00-12\n",
       "  done: false\n",
-      "  episode_len_mean: 852.6247216035634\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 231.18069334773102\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 266\n",
-      "  episodes_total: 898\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 825.932981530343\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 237.80680152447957\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 78\n",
+      "  episodes_total: 1895\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0624429881572723\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0077964670956134794\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8687670111656189\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005749080330133438\n",
       "        model: {}\n",
-      "        policy_loss: -0.02084309732308611\n",
-      "        total_loss: 7.683893799781799\n",
-      "        vf_explained_var: 0.9791978597640991\n",
-      "        vf_loss: 7.703177666664123\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
+      "        policy_loss: -0.016765564773231746\n",
+      "        total_loss: 11.381985664367676\n",
+      "        vf_explained_var: 0.9814356565475464\n",
+      "        vf_loss: 11.397688293457032\n",
+      "    num_steps_sampled: 1577472\n",
+      "    num_steps_trained: 1577472\n",
+      "  iterations_since_restore: 26\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.225\n",
-      "    gpu_util_percent0: 0.25178571428571433\n",
+      "    cpu_util_percent: 30.268749999999997\n",
+      "    gpu_util_percent0: 0.33375\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4124999999999996\n",
+      "    vram_util_percent0: 0.09732699245654312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16364555568838862\n",
-      "    mean_env_wait_ms: 1.649353801806338\n",
-      "    mean_inference_ms: 5.083644859595276\n",
-      "    mean_raw_obs_processing_ms: 0.4376329609722663\n",
-      "  time_since_restore: 125.15412139892578\n",
-      "  time_this_iter_s: 24.41017484664917\n",
-      "  time_total_s: 125.15412139892578\n",
+      "    mean_action_processing_ms: 0.12115824527452636\n",
+      "    mean_env_wait_ms: 0.6564064837434892\n",
+      "    mean_inference_ms: 4.618442471884918\n",
+      "    mean_raw_obs_processing_ms: 0.2634490220819825\n",
+      "  time_since_restore: 350.4165382385254\n",
+      "  time_this_iter_s: 13.397293329238892\n",
+      "  time_total_s: 350.4165382385254\n",
       "  timers:\n",
-      "    learn_throughput: 9921.993\n",
-      "    learn_time_ms: 16306.401\n",
-      "    sample_throughput: 18736.645\n",
-      "    sample_time_ms: 8635.057\n",
-      "    update_time_ms: 35.191\n",
-      "  timestamp: 1602166598\n",
+      "    learn_throughput: 6957.032\n",
+      "    learn_time_ms: 8720.961\n",
+      "    sample_throughput: 13364.095\n",
+      "    sample_time_ms: 4539.926\n",
+      "    update_time_ms: 30.258\n",
+      "  timestamp: 1602432012\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1577472\n",
+      "  training_iteration: 26\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      5 |          125.154 | 808960 |  231.181 |              278.707 |              115.788 |            852.625 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     26 |          350.417 | 1577472 |  237.807 |              283.141 |               116.02 |            825.933 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3223.0\n",
-      "  date: 2020-10-08_14-17-02\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3483.598268839104\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_16-00-25\n",
       "  done: false\n",
-      "  episode_len_mean: 846.0479204339964\n",
-      "  episode_reward_max: 278.70707070707056\n",
-      "  episode_reward_mean: 231.96029919447625\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 208\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 825.6252545824847\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 238.2022824991256\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 69\n",
+      "  episodes_total: 1964\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0738083600997925\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007217544643208384\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8563682079315186\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005709396209567785\n",
       "        model: {}\n",
-      "        policy_loss: -0.02225890466943383\n",
-      "        total_loss: 4.545075726509094\n",
-      "        vf_explained_var: 0.9842392206192017\n",
-      "        vf_loss: 4.565891194343567\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
+      "        policy_loss: -0.017698555067181588\n",
+      "        total_loss: 10.851219177246094\n",
+      "        vf_explained_var: 0.9818906784057617\n",
+      "        vf_loss: 10.867861557006837\n",
+      "    num_steps_sampled: 1638144\n",
+      "    num_steps_trained: 1638144\n",
+      "  iterations_since_restore: 27\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.55517241379311\n",
-      "    gpu_util_percent0: 0.4293103448275861\n",
+      "    cpu_util_percent: 30.98666666666666\n",
+      "    gpu_util_percent0: 0.368\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.413333333333333\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16251990142651115\n",
-      "    mean_env_wait_ms: 1.6530343779974206\n",
-      "    mean_inference_ms: 5.018380813854082\n",
-      "    mean_raw_obs_processing_ms: 0.43409996967266995\n",
-      "  time_since_restore: 149.7096438407898\n",
-      "  time_this_iter_s: 24.555522441864014\n",
-      "  time_total_s: 149.7096438407898\n",
+      "    mean_action_processing_ms: 0.12106144903411631\n",
+      "    mean_env_wait_ms: 0.65663010350919\n",
+      "    mean_inference_ms: 4.611047299197732\n",
+      "    mean_raw_obs_processing_ms: 0.2631941726080479\n",
+      "  time_since_restore: 363.66497015953064\n",
+      "  time_this_iter_s: 13.248431921005249\n",
+      "  time_total_s: 363.66497015953064\n",
       "  timers:\n",
-      "    learn_throughput: 9912.286\n",
-      "    learn_time_ms: 16322.371\n",
-      "    sample_throughput: 18942.241\n",
-      "    sample_time_ms: 8541.334\n",
-      "    update_time_ms: 33.368\n",
-      "  timestamp: 1602166622\n",
+      "    learn_throughput: 6962.683\n",
+      "    learn_time_ms: 8713.882\n",
+      "    sample_throughput: 13342.129\n",
+      "    sample_time_ms: 4547.4\n",
+      "    update_time_ms: 30.61\n",
+      "  timestamp: 1602432025\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1638144\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      6 |           149.71 | 970752 |   231.96 |              278.707 |              115.788 |            846.048 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     27 |          363.665 | 1638144 |  238.202 |              283.141 |               116.02 |            825.625 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3170.0\n",
-      "  date: 2020-10-08_14-17-27\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3481.9901429275506\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_16-00-39\n",
       "  done: false\n",
-      "  episode_len_mean: 841.3995253164557\n",
-      "  episode_reward_max: 284.4040404040406\n",
-      "  episode_reward_mean: 232.7926815624599\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 825.3652045342533\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 238.44593794027003\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 65\n",
+      "  episodes_total: 2029\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0473353922367097\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006994991353712976\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8387965321540832\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006011899933218956\n",
       "        model: {}\n",
-      "        policy_loss: -0.022564191045239566\n",
-      "        total_loss: 4.000831997394561\n",
-      "        vf_explained_var: 0.9874190092086792\n",
-      "        vf_loss: 4.021997082233429\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
+      "        policy_loss: -0.01685419175773859\n",
+      "        total_loss: 10.585357475280762\n",
+      "        vf_explained_var: 0.9818204045295715\n",
+      "        vf_loss: 10.601093292236328\n",
+      "    num_steps_sampled: 1698816\n",
+      "    num_steps_trained: 1698816\n",
+      "  iterations_since_restore: 28\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.59655172413793\n",
-      "    gpu_util_percent0: 0.4562068965517241\n",
+      "    cpu_util_percent: 30.373333333333335\n",
+      "    gpu_util_percent0: 0.31666666666666665\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.758620689655174\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4133333333333327\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16183355318977655\n",
-      "    mean_env_wait_ms: 1.656038102133309\n",
-      "    mean_inference_ms: 4.9782716342931606\n",
-      "    mean_raw_obs_processing_ms: 0.4319914234530791\n",
-      "  time_since_restore: 174.1368727684021\n",
-      "  time_this_iter_s: 24.427228927612305\n",
-      "  time_total_s: 174.1368727684021\n",
+      "    mean_action_processing_ms: 0.12098182650706206\n",
+      "    mean_env_wait_ms: 0.656839713845296\n",
+      "    mean_inference_ms: 4.604512070314659\n",
+      "    mean_raw_obs_processing_ms: 0.2629729069126024\n",
+      "  time_since_restore: 377.0492670536041\n",
+      "  time_this_iter_s: 13.384296894073486\n",
+      "  time_total_s: 377.0492670536041\n",
       "  timers:\n",
-      "    learn_throughput: 9918.301\n",
-      "    learn_time_ms: 16312.471\n",
-      "    sample_throughput: 19088.76\n",
-      "    sample_time_ms: 8475.773\n",
-      "    update_time_ms: 33.238\n",
-      "  timestamp: 1602166647\n",
+      "    learn_throughput: 6958.282\n",
+      "    learn_time_ms: 8719.393\n",
+      "    sample_throughput: 13354.543\n",
+      "    sample_time_ms: 4543.173\n",
+      "    update_time_ms: 29.93\n",
+      "  timestamp: 1602432039\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1698816\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      7 |          174.137 | 1132544 |  232.793 |              284.404 |              115.788 |              841.4 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     28 |          377.049 | 1698816 |  238.446 |              283.141 |               116.02 |            825.365 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3170.0\n",
-      "  date: 2020-10-08_14-17-51\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3479.421254188607\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-11_16-00-52\n",
       "  done: false\n",
-      "  episode_len_mean: 837.3713080168776\n",
-      "  episode_reward_max: 284.4040404040406\n",
-      "  episode_reward_mean: 233.61432184006011\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 825.2077549066539\n",
+      "  episode_reward_max: 283.1414141414142\n",
+      "  episode_reward_mean: 238.83516350677664\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 60\n",
+      "  episodes_total: 2089\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.01868434548378\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007189809367991984\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8409842371940612\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006058331951498986\n",
       "        model: {}\n",
-      "        policy_loss: -0.023347471375018358\n",
-      "        total_loss: 3.781139385700226\n",
-      "        vf_explained_var: 0.9891014099121094\n",
-      "        vf_loss: 3.803048861026764\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
+      "        policy_loss: -0.017604468390345573\n",
+      "        total_loss: 8.032962226867676\n",
+      "        vf_explained_var: 0.9850233197212219\n",
+      "        vf_loss: 8.049439334869385\n",
+      "    num_steps_sampled: 1759488\n",
+      "    num_steps_trained: 1759488\n",
+      "  iterations_since_restore: 29\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.625\n",
-      "    gpu_util_percent0: 0.04107142857142857\n",
+      "    cpu_util_percent: 29.226666666666667\n",
+      "    gpu_util_percent0: 0.3433333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.771428571428572\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4133333333333327\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16125876245924115\n",
-      "    mean_env_wait_ms: 1.6590341255429097\n",
-      "    mean_inference_ms: 4.943515953135972\n",
-      "    mean_raw_obs_processing_ms: 0.430128591449942\n",
-      "  time_since_restore: 198.50214219093323\n",
-      "  time_this_iter_s: 24.365269422531128\n",
-      "  time_total_s: 198.50214219093323\n",
+      "    mean_action_processing_ms: 0.12090547620256412\n",
+      "    mean_env_wait_ms: 0.6570354909118539\n",
+      "    mean_inference_ms: 4.5988118399764675\n",
+      "    mean_raw_obs_processing_ms: 0.2627840875420408\n",
+      "  time_since_restore: 390.4477002620697\n",
+      "  time_this_iter_s: 13.398433208465576\n",
+      "  time_total_s: 390.4477002620697\n",
       "  timers:\n",
-      "    learn_throughput: 9923.421\n",
-      "    learn_time_ms: 16304.054\n",
-      "    sample_throughput: 19218.701\n",
-      "    sample_time_ms: 8418.467\n",
-      "    update_time_ms: 34.044\n",
-      "  timestamp: 1602166671\n",
+      "    learn_throughput: 6949.219\n",
+      "    learn_time_ms: 8730.765\n",
+      "    sample_throughput: 13351.476\n",
+      "    sample_time_ms: 4544.217\n",
+      "    update_time_ms: 28.118\n",
+      "  timestamp: 1602432052\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1759488\n",
+      "  training_iteration: 29\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      8 |          198.502 | 1294336 |  233.614 |              284.404 |              115.788 |            837.371 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     29 |          390.448 | 1759488 |  238.835 |              283.141 |               116.02 |            825.208 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-18-15\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3477.6100511865984\n",
+      "    time_step_min: 3169\n",
+      "  date: 2020-10-11_16-01-06\n",
       "  done: false\n",
-      "  episode_len_mean: 829.8141542002302\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 235.34277179156337\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 1738\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 825.1763610981852\n",
+      "  episode_reward_max: 285.86868686868667\n",
+      "  episode_reward_mean: 239.10958820405065\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 60\n",
+      "  episodes_total: 2149\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9904811769723892\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006311689200811088\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8300541996955871\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006526672095060348\n",
       "        model: {}\n",
-      "        policy_loss: -0.020997717510908842\n",
-      "        total_loss: 5.1504497051239015\n",
-      "        vf_explained_var: 0.9909344911575317\n",
-      "        vf_loss: 5.170185089111328\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
+      "        policy_loss: -0.017102842684835196\n",
+      "        total_loss: 9.383557319641113\n",
+      "        vf_explained_var: 0.9828168153762817\n",
+      "        vf_loss: 9.399437713623048\n",
+      "    num_steps_sampled: 1820160\n",
+      "    num_steps_trained: 1820160\n",
+      "  iterations_since_restore: 30\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.78928571428572\n",
-      "    gpu_util_percent0: 0.30821428571428566\n",
+      "    cpu_util_percent: 30.106666666666666\n",
+      "    gpu_util_percent0: 0.26666666666666666\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.750000000000002\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.413333333333333\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.160369309924211\n",
-      "    mean_env_wait_ms: 1.6650071130850876\n",
-      "    mean_inference_ms: 4.888377085687167\n",
-      "    mean_raw_obs_processing_ms: 0.42729617584826485\n",
-      "  time_since_restore: 222.59675359725952\n",
-      "  time_this_iter_s: 24.094611406326294\n",
-      "  time_total_s: 222.59675359725952\n",
+      "    mean_action_processing_ms: 0.12083493613574385\n",
+      "    mean_env_wait_ms: 0.6571775091137801\n",
+      "    mean_inference_ms: 4.593183145199037\n",
+      "    mean_raw_obs_processing_ms: 0.2626079323019862\n",
+      "  time_since_restore: 403.7302429676056\n",
+      "  time_this_iter_s: 13.282542705535889\n",
+      "  time_total_s: 403.7302429676056\n",
       "  timers:\n",
-      "    learn_throughput: 9938.553\n",
-      "    learn_time_ms: 16279.231\n",
-      "    sample_throughput: 19342.706\n",
-      "    sample_time_ms: 8364.497\n",
-      "    update_time_ms: 33.218\n",
-      "  timestamp: 1602166695\n",
+      "    learn_throughput: 6953.349\n",
+      "    learn_time_ms: 8725.58\n",
+      "    sample_throughput: 13362.1\n",
+      "    sample_time_ms: 4540.603\n",
+      "    update_time_ms: 26.462\n",
+      "  timestamp: 1602432066\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1820160\n",
+      "  training_iteration: 30\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |      9 |          222.597 | 1456128 |  235.343 |              290.242 |              115.788 |            829.814 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     30 |           403.73 | 1820160 |   239.11 |              285.869 |               116.02 |            825.176 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-18-40\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3474.5842342342344\n",
+      "    time_step_min: 3169\n",
+      "  date: 2020-10-11_16-01-19\n",
       "  done: false\n",
-      "  episode_len_mean: 826.4541139240506\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 235.7108905510803\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 825.2738738738739\n",
+      "  episode_reward_max: 285.86868686868667\n",
+      "  episode_reward_mean: 239.56804531804525\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 71\n",
+      "  episodes_total: 2220\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9730047971010208\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006372990598902106\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8318358898162842\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005705495923757553\n",
       "        model: {}\n",
-      "        policy_loss: -0.022790615819394587\n",
-      "        total_loss: 3.343014180660248\n",
-      "        vf_explained_var: 0.9915106892585754\n",
-      "        vf_loss: 3.3645302057266235\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
+      "        policy_loss: -0.016056472854688763\n",
+      "        total_loss: 9.408385086059571\n",
+      "        vf_explained_var: 0.9828255772590637\n",
+      "        vf_loss: 9.423383331298828\n",
+      "    num_steps_sampled: 1880832\n",
+      "    num_steps_trained: 1880832\n",
+      "  iterations_since_restore: 31\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.324137931034485\n",
-      "    gpu_util_percent0: 0.2775862068965517\n",
+      "    cpu_util_percent: 31.400000000000002\n",
+      "    gpu_util_percent0: 0.3466666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.406666666666666\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16000657164975352\n",
-      "    mean_env_wait_ms: 1.6678046661692965\n",
-      "    mean_inference_ms: 4.86599024622493\n",
-      "    mean_raw_obs_processing_ms: 0.42614775920547227\n",
-      "  time_since_restore: 246.9238064289093\n",
-      "  time_this_iter_s: 24.32705283164978\n",
-      "  time_total_s: 246.9238064289093\n",
+      "    mean_action_processing_ms: 0.12075211819346843\n",
+      "    mean_env_wait_ms: 0.6573531301258803\n",
+      "    mean_inference_ms: 4.586823952399324\n",
+      "    mean_raw_obs_processing_ms: 0.2623892144532047\n",
+      "  time_since_restore: 416.916544675827\n",
+      "  time_this_iter_s: 13.186301708221436\n",
+      "  time_total_s: 416.916544675827\n",
       "  timers:\n",
-      "    learn_throughput: 9939.106\n",
-      "    learn_time_ms: 16278.326\n",
-      "    sample_throughput: 19435.411\n",
-      "    sample_time_ms: 8324.599\n",
-      "    update_time_ms: 33.566\n",
-      "  timestamp: 1602166720\n",
+      "    learn_throughput: 6971.674\n",
+      "    learn_time_ms: 8702.645\n",
+      "    sample_throughput: 13399.302\n",
+      "    sample_time_ms: 4527.997\n",
+      "    update_time_ms: 24.959\n",
+      "  timestamp: 1602432079\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1880832\n",
+      "  training_iteration: 31\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     10 |          246.924 | 1617920 |  235.711 |              290.242 |              115.788 |            826.454 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     31 |          416.917 | 1880832 |  239.568 |              285.869 |               116.02 |            825.274 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-04\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3471.0850043591977\n",
+      "    time_step_min: 3169\n",
+      "  date: 2020-10-11_16-01-33\n",
       "  done: false\n",
-      "  episode_len_mean: 823.6002921129503\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 236.65748035368276\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 825.2794245858762\n",
+      "  episode_reward_max: 285.86868686868667\n",
+      "  episode_reward_mean: 240.0982316627477\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 74\n",
+      "  episodes_total: 2294\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9577732890844345\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006211055861786008\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8104691743850708\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005790698435157537\n",
       "        model: {}\n",
-      "        policy_loss: -0.022765795403392984\n",
-      "        total_loss: 3.0192813992500307\n",
-      "        vf_explained_var: 0.9923363924026489\n",
-      "        vf_loss: 3.0408049702644346\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
+      "        policy_loss: -0.016167748929001392\n",
+      "        total_loss: 10.063735961914062\n",
+      "        vf_explained_var: 0.982425332069397\n",
+      "        vf_loss: 10.078826713562012\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 32\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.706896551724135\n",
-      "    gpu_util_percent0: 0.43068965517241387\n",
+      "    cpu_util_percent: 29.887500000000003\n",
+      "    gpu_util_percent0: 0.271875\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.40625\n",
+      "    vram_util_percent0: 0.09732699245654312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1596848966715417\n",
-      "    mean_env_wait_ms: 1.6704675074629387\n",
-      "    mean_inference_ms: 4.845793508809106\n",
-      "    mean_raw_obs_processing_ms: 0.42510446710641553\n",
-      "  time_since_restore: 271.42553091049194\n",
-      "  time_this_iter_s: 24.50172448158264\n",
-      "  time_total_s: 271.42553091049194\n",
+      "    mean_action_processing_ms: 0.12066404371282796\n",
+      "    mean_env_wait_ms: 0.657500318704452\n",
+      "    mean_inference_ms: 4.580569539725109\n",
+      "    mean_raw_obs_processing_ms: 0.2621707368723776\n",
+      "  time_since_restore: 430.2910635471344\n",
+      "  time_this_iter_s: 13.374518871307373\n",
+      "  time_total_s: 430.2910635471344\n",
       "  timers:\n",
-      "    learn_throughput: 9946.653\n",
-      "    learn_time_ms: 16265.974\n",
-      "    sample_throughput: 19772.529\n",
-      "    sample_time_ms: 8182.666\n",
-      "    update_time_ms: 32.542\n",
-      "  timestamp: 1602166744\n",
+      "    learn_throughput: 6951.438\n",
+      "    learn_time_ms: 8727.978\n",
+      "    sample_throughput: 13453.933\n",
+      "    sample_time_ms: 4509.611\n",
+      "    update_time_ms: 25.83\n",
+      "  timestamp: 1602432093\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 32\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     11 |          271.426 | 1779712 |  236.657 |              290.242 |              115.788 |              823.6 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     32 |          430.291 | 1941504 |  240.098 |              285.869 |               116.02 |            825.279 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-29\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3468.250105440742\n",
+      "    time_step_min: 3169\n",
+      "  date: 2020-10-11_16-01-46\n",
       "  done: false\n",
-      "  episode_len_mean: 820.2957437472576\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 237.36838769440774\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 225\n",
-      "  episodes_total: 2279\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 825.065795023197\n",
+      "  episode_reward_max: 285.86868686868667\n",
+      "  episode_reward_mean: 240.52776180190762\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 77\n",
+      "  episodes_total: 2371\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9244333893060684\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006004941323772073\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8031792521476746\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005553171876817942\n",
       "        model: {}\n",
-      "        policy_loss: -0.021168453525751828\n",
-      "        total_loss: 4.074023377895355\n",
-      "        vf_explained_var: 0.9932994842529297\n",
-      "        vf_loss: 4.093990921974182\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
+      "        policy_loss: -0.01612788438796997\n",
+      "        total_loss: 8.300242805480957\n",
+      "        vf_explained_var: 0.9860474467277527\n",
+      "        vf_loss: 8.31534023284912\n",
+      "    num_steps_sampled: 2002176\n",
+      "    num_steps_trained: 2002176\n",
+      "  iterations_since_restore: 33\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.251724137931035\n",
-      "    gpu_util_percent0: 0.39206896551724135\n",
+      "    cpu_util_percent: 29.61333333333334\n",
+      "    gpu_util_percent0: 0.264\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.744827586206897\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.406666666666666\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1592619934185692\n",
-      "    mean_env_wait_ms: 1.6739541868498113\n",
-      "    mean_inference_ms: 4.819806265535011\n",
-      "    mean_raw_obs_processing_ms: 0.42372078258183\n",
-      "  time_since_restore: 296.40609192848206\n",
-      "  time_this_iter_s: 24.980561017990112\n",
-      "  time_total_s: 296.40609192848206\n",
+      "    mean_action_processing_ms: 0.12058245855496046\n",
+      "    mean_env_wait_ms: 0.6576537296479603\n",
+      "    mean_inference_ms: 4.574343663239295\n",
+      "    mean_raw_obs_processing_ms: 0.26195669747331446\n",
+      "  time_since_restore: 443.59071135520935\n",
+      "  time_this_iter_s: 13.299647808074951\n",
+      "  time_total_s: 443.59071135520935\n",
       "  timers:\n",
-      "    learn_throughput: 9957.289\n",
-      "    learn_time_ms: 16248.6\n",
-      "    sample_throughput: 19727.515\n",
-      "    sample_time_ms: 8201.337\n",
-      "    update_time_ms: 32.973\n",
-      "  timestamp: 1602166769\n",
+      "    learn_throughput: 6946.573\n",
+      "    learn_time_ms: 8734.091\n",
+      "    sample_throughput: 13475.346\n",
+      "    sample_time_ms: 4502.445\n",
+      "    update_time_ms: 25.53\n",
+      "  timestamp: 1602432106\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2002176\n",
+      "  training_iteration: 33\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     12 |          296.406 | 1941504 |  237.368 |              290.242 |              115.788 |            820.296 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     33 |          443.591 | 2002176 |  240.528 |              285.869 |               116.02 |            825.066 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-19-54\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3465.450204081633\n",
+      "    time_step_min: 3169\n",
+      "  date: 2020-10-11_16-01-59\n",
       "  done: false\n",
-      "  episode_len_mean: 817.5490506329114\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.05452068149842\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 249\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 824.8004081632653\n",
+      "  episode_reward_max: 285.86868686868667\n",
+      "  episode_reward_mean: 240.95198928056067\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 2450\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9116032361984253\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0059999656863510605\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7909312963485717\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005124823935329914\n",
       "        model: {}\n",
-      "        policy_loss: -0.020421561488183214\n",
-      "        total_loss: 3.2677656054496764\n",
-      "        vf_explained_var: 0.9931272268295288\n",
-      "        vf_loss: 3.2869871616363526\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
+      "        policy_loss: -0.01604766147211194\n",
+      "        total_loss: 9.810696792602538\n",
+      "        vf_explained_var: 0.9840415716171265\n",
+      "        vf_loss: 9.825798606872558\n",
+      "    num_steps_sampled: 2062848\n",
+      "    num_steps_trained: 2062848\n",
+      "  iterations_since_restore: 34\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.02857142857143\n",
-      "    gpu_util_percent0: 0.06035714285714285\n",
+      "    cpu_util_percent: 30.77333333333333\n",
+      "    gpu_util_percent0: 0.26866666666666666\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.764285714285716\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4066666666666663\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15888263499780286\n",
-      "    mean_env_wait_ms: 1.677646536061787\n",
-      "    mean_inference_ms: 4.796171409815506\n",
-      "    mean_raw_obs_processing_ms: 0.42253131691795703\n",
-      "  time_since_restore: 320.67564845085144\n",
-      "  time_this_iter_s: 24.269556522369385\n",
-      "  time_total_s: 320.67564845085144\n",
+      "    mean_action_processing_ms: 0.12050173079399744\n",
+      "    mean_env_wait_ms: 0.6578011058508888\n",
+      "    mean_inference_ms: 4.568264627887463\n",
+      "    mean_raw_obs_processing_ms: 0.26174526053956815\n",
+      "  time_since_restore: 456.79246163368225\n",
+      "  time_this_iter_s: 13.2017502784729\n",
+      "  time_total_s: 456.79246163368225\n",
       "  timers:\n",
-      "    learn_throughput: 9954.003\n",
-      "    learn_time_ms: 16253.963\n",
-      "    sample_throughput: 19876.989\n",
-      "    sample_time_ms: 8139.664\n",
-      "    update_time_ms: 31.685\n",
-      "  timestamp: 1602166794\n",
+      "    learn_throughput: 6941.001\n",
+      "    learn_time_ms: 8741.102\n",
+      "    sample_throughput: 13507.081\n",
+      "    sample_time_ms: 4491.866\n",
+      "    update_time_ms: 26.626\n",
+      "  timestamp: 1602432119\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2062848\n",
+      "  training_iteration: 34\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     13 |          320.676 | 2103296 |  238.055 |              290.242 |              115.788 |            817.549 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     34 |          456.792 | 2062848 |  240.952 |              285.869 |               116.02 |              824.8 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-20-18\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3462.2349683544303\n",
+      "    time_step_min: 3169\n",
+      "  date: 2020-10-11_16-02-13\n",
       "  done: false\n",
-      "  episode_len_mean: 816.2442293373045\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.46138225140444\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 824.4497626582279\n",
+      "  episode_reward_max: 285.86868686868667\n",
+      "  episode_reward_mean: 241.4391462089246\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 78\n",
+      "  episodes_total: 2528\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9013321816921234\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006421135948039591\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7874290704727173\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00535367289558053\n",
       "        model: {}\n",
-      "        policy_loss: -0.021805241936817765\n",
-      "        total_loss: 2.9366058349609374\n",
-      "        vf_explained_var: 0.9931826591491699\n",
-      "        vf_loss: 2.9571268558502197\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
+      "        policy_loss: -0.015816283226013184\n",
+      "        total_loss: 8.599153900146485\n",
+      "        vf_explained_var: 0.9853988885879517\n",
+      "        vf_loss: 8.613978385925293\n",
+      "    num_steps_sampled: 2123520\n",
+      "    num_steps_trained: 2123520\n",
+      "  iterations_since_restore: 35\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.642857142857146\n",
-      "    gpu_util_percent0: 0.30678571428571433\n",
+      "    cpu_util_percent: 31.153333333333332\n",
+      "    gpu_util_percent0: 0.3366666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757142857142858\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4066666666666663\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15866013164662812\n",
-      "    mean_env_wait_ms: 1.6796736234314602\n",
-      "    mean_inference_ms: 4.782626736230756\n",
-      "    mean_raw_obs_processing_ms: 0.42183995211689523\n",
-      "  time_since_restore: 344.8741044998169\n",
-      "  time_this_iter_s: 24.198456048965454\n",
-      "  time_total_s: 344.8741044998169\n",
+      "    mean_action_processing_ms: 0.12042366165133124\n",
+      "    mean_env_wait_ms: 0.6579429388606653\n",
+      "    mean_inference_ms: 4.56254680786855\n",
+      "    mean_raw_obs_processing_ms: 0.2615465353064913\n",
+      "  time_since_restore: 470.0361771583557\n",
+      "  time_this_iter_s: 13.243715524673462\n",
+      "  time_total_s: 470.0361771583557\n",
       "  timers:\n",
-      "    learn_throughput: 9964.721\n",
-      "    learn_time_ms: 16236.481\n",
-      "    sample_throughput: 20015.961\n",
-      "    sample_time_ms: 8083.149\n",
-      "    update_time_ms: 29.819\n",
-      "  timestamp: 1602166818\n",
+      "    learn_throughput: 6939.014\n",
+      "    learn_time_ms: 8743.605\n",
+      "    sample_throughput: 13519.013\n",
+      "    sample_time_ms: 4487.902\n",
+      "    update_time_ms: 28.558\n",
+      "  timestamp: 1602432133\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2123520\n",
+      "  training_iteration: 35\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     14 |          344.874 | 2265088 |  238.461 |              290.242 |              115.788 |            816.244 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     35 |          470.036 | 2123520 |  241.439 |              285.869 |               116.02 |             824.45 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-20-43\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3459.7096279248176\n",
+      "    time_step_min: 3169\n",
+      "  date: 2020-10-11_16-02-26\n",
       "  done: false\n",
-      "  episode_len_mean: 814.502106741573\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 238.95662736919752\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 162\n",
-      "  episodes_total: 2848\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 824.2305331799002\n",
+      "  episode_reward_max: 285.86868686868667\n",
+      "  episode_reward_mean: 241.82177354674468\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 2607\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8737345904111862\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005880716699175536\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7673699378967285\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005303710792213678\n",
       "        model: {}\n",
-      "        policy_loss: -0.023541058914270253\n",
-      "        total_loss: 2.77874299287796\n",
-      "        vf_explained_var: 0.9943079948425293\n",
-      "        vf_loss: 2.801107919216156\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
+      "        policy_loss: -0.015531449741683901\n",
+      "        total_loss: 9.45707950592041\n",
+      "        vf_explained_var: 0.9850137829780579\n",
+      "        vf_loss: 9.47162685394287\n",
+      "    num_steps_sampled: 2184192\n",
+      "    num_steps_trained: 2184192\n",
+      "  iterations_since_restore: 36\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.53793103448275\n",
-      "    gpu_util_percent0: 0.09275862068965515\n",
+      "    cpu_util_percent: 31.14666666666667\n",
+      "    gpu_util_percent0: 0.34600000000000003\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.77241379310345\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4066666666666663\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15844943627409838\n",
-      "    mean_env_wait_ms: 1.6816497328437465\n",
-      "    mean_inference_ms: 4.769681731783559\n",
-      "    mean_raw_obs_processing_ms: 0.42115262835775236\n",
-      "  time_since_restore: 369.2295935153961\n",
-      "  time_this_iter_s: 24.355489015579224\n",
-      "  time_total_s: 369.2295935153961\n",
+      "    mean_action_processing_ms: 0.12035006653693807\n",
+      "    mean_env_wait_ms: 0.6580753825207725\n",
+      "    mean_inference_ms: 4.556990252644127\n",
+      "    mean_raw_obs_processing_ms: 0.26135253126859137\n",
+      "  time_since_restore: 483.28974437713623\n",
+      "  time_this_iter_s: 13.253567218780518\n",
+      "  time_total_s: 483.28974437713623\n",
       "  timers:\n",
-      "    learn_throughput: 9970.424\n",
-      "    learn_time_ms: 16227.193\n",
-      "    sample_throughput: 20006.648\n",
-      "    sample_time_ms: 8086.912\n",
-      "    update_time_ms: 28.747\n",
-      "  timestamp: 1602166843\n",
+      "    learn_throughput: 6945.36\n",
+      "    learn_time_ms: 8735.617\n",
+      "    sample_throughput: 13539.679\n",
+      "    sample_time_ms: 4481.051\n",
+      "    update_time_ms: 28.793\n",
+      "  timestamp: 1602432146\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2184192\n",
+      "  training_iteration: 36\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     15 |           369.23 | 2426880 |  238.957 |              290.242 |              115.788 |            814.502 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     36 |           483.29 | 2184192 |  241.822 |              285.869 |               116.02 |            824.231 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-07\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3457.1046165301564\n",
+      "    time_step_min: 3169\n",
+      "  date: 2020-10-11_16-02-39\n",
       "  done: false\n",
-      "  episode_len_mean: 811.5661392405063\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.56847270170044\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 312\n",
-      "  episodes_total: 3160\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 823.8406552494415\n",
+      "  episode_reward_max: 285.86868686868667\n",
+      "  episode_reward_mean: 242.21647224290552\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.836417630314827\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005600748467259109\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7685246229171753\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005332937464118004\n",
       "        model: {}\n",
-      "        policy_loss: -0.019153478858061134\n",
-      "        total_loss: 3.4916038155555724\n",
-      "        vf_explained_var: 0.9944165349006653\n",
-      "        vf_loss: 3.5096370816230773\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
+      "        policy_loss: -0.015074999816715718\n",
+      "        total_loss: 10.110424613952636\n",
+      "        vf_explained_var: 0.9831159710884094\n",
+      "        vf_loss: 10.124510192871094\n",
+      "    num_steps_sampled: 2244864\n",
+      "    num_steps_trained: 2244864\n",
+      "  iterations_since_restore: 37\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.9551724137931\n",
-      "    gpu_util_percent0: 0.43275862068965526\n",
+      "    cpu_util_percent: 28.96875\n",
+      "    gpu_util_percent0: 0.30999999999999994\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4124999999999996\n",
+      "    vram_util_percent0: 0.09732699245654312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15809978406417496\n",
-      "    mean_env_wait_ms: 1.6853761096348427\n",
-      "    mean_inference_ms: 4.748027409045223\n",
-      "    mean_raw_obs_processing_ms: 0.42003623239671906\n",
-      "  time_since_restore: 393.7941789627075\n",
-      "  time_this_iter_s: 24.5645854473114\n",
-      "  time_total_s: 393.7941789627075\n",
+      "    mean_action_processing_ms: 0.12027973471638467\n",
+      "    mean_env_wait_ms: 0.658205448627044\n",
+      "    mean_inference_ms: 4.5516748794788455\n",
+      "    mean_raw_obs_processing_ms: 0.26116646832530793\n",
+      "  time_since_restore: 496.7275276184082\n",
+      "  time_this_iter_s: 13.437783241271973\n",
+      "  time_total_s: 496.7275276184082\n",
       "  timers:\n",
-      "    learn_throughput: 9977.021\n",
-      "    learn_time_ms: 16216.464\n",
-      "    sample_throughput: 19987.267\n",
-      "    sample_time_ms: 8094.753\n",
-      "    update_time_ms: 30.454\n",
-      "  timestamp: 1602166867\n",
+      "    learn_throughput: 6922.742\n",
+      "    learn_time_ms: 8764.158\n",
+      "    sample_throughput: 13575.987\n",
+      "    sample_time_ms: 4469.067\n",
+      "    update_time_ms: 30.271\n",
+      "  timestamp: 1602432159\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2244864\n",
+      "  training_iteration: 37\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     16 |          393.794 | 2588672 |  239.568 |              290.242 |              115.788 |            811.566 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     37 |          496.728 | 2244864 |  242.216 |              285.869 |               116.02 |            823.841 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-32\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3454.723327305606\n",
+      "    time_step_min: 3169\n",
+      "  date: 2020-10-11_16-02-53\n",
       "  done: false\n",
-      "  episode_len_mean: 810.3282097649186\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.7355501975754\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 823.6517179023508\n",
+      "  episode_reward_max: 285.86868686868667\n",
+      "  episode_reward_mean: 242.57727364056467\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 2765\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8335719257593155\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006123062083497643\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7509182333946228\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00532805984839797\n",
       "        model: {}\n",
-      "        policy_loss: -0.020987965818494558\n",
-      "        total_loss: 2.507720983028412\n",
-      "        vf_explained_var: 0.9944343566894531\n",
-      "        vf_loss: 2.5274842858314512\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
+      "        policy_loss: -0.01556666032411158\n",
+      "        total_loss: 8.812029457092285\n",
+      "        vf_explained_var: 0.9855332374572754\n",
+      "        vf_loss: 8.826605606079102\n",
+      "    num_steps_sampled: 2305536\n",
+      "    num_steps_trained: 2305536\n",
+      "  iterations_since_restore: 38\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.18275862068966\n",
-      "    gpu_util_percent0: 0.27655172413793105\n",
+      "    cpu_util_percent: 30.94666666666667\n",
+      "    gpu_util_percent0: 0.2786666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.758620689655173\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4133333333333327\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15794348066077543\n",
-      "    mean_env_wait_ms: 1.687080352601384\n",
-      "    mean_inference_ms: 4.7382363513709365\n",
-      "    mean_raw_obs_processing_ms: 0.41954097731825146\n",
-      "  time_since_restore: 418.4777216911316\n",
-      "  time_this_iter_s: 24.683542728424072\n",
-      "  time_total_s: 418.4777216911316\n",
+      "    mean_action_processing_ms: 0.12021245248126033\n",
+      "    mean_env_wait_ms: 0.6583288256972009\n",
+      "    mean_inference_ms: 4.546589884580029\n",
+      "    mean_raw_obs_processing_ms: 0.26098810296950836\n",
+      "  time_since_restore: 509.97461771965027\n",
+      "  time_this_iter_s: 13.247090101242065\n",
+      "  time_total_s: 509.97461771965027\n",
       "  timers:\n",
-      "    learn_throughput: 9984.096\n",
-      "    learn_time_ms: 16204.972\n",
-      "    sample_throughput: 19915.659\n",
-      "    sample_time_ms: 8123.859\n",
-      "    update_time_ms: 31.876\n",
-      "  timestamp: 1602166892\n",
+      "    learn_throughput: 6925.375\n",
+      "    learn_time_ms: 8760.825\n",
+      "    sample_throughput: 13610.856\n",
+      "    sample_time_ms: 4457.618\n",
+      "    update_time_ms: 30.876\n",
+      "  timestamp: 1602432173\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2305536\n",
+      "  training_iteration: 38\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     17 |          418.478 | 2750464 |  239.736 |              290.242 |              115.788 |            810.328 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     38 |          509.975 | 2305536 |  242.577 |              285.869 |               116.02 |            823.652 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-21-57\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3452.709563994374\n",
+      "    time_step_min: 3169\n",
+      "  date: 2020-10-11_16-03-06\n",
       "  done: false\n",
-      "  episode_len_mean: 809.0097813578826\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 239.89810649649536\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 823.4556962025316\n",
+      "  episode_reward_max: 285.86868686868667\n",
+      "  episode_reward_mean: 242.8823892937816\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.830751609802246\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005981297581456602\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7447753310203552\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0048968297429382805\n",
       "        model: {}\n",
-      "        policy_loss: -0.023448871518485247\n",
-      "        total_loss: 2.440117084980011\n",
-      "        vf_explained_var: 0.994672954082489\n",
-      "        vf_loss: 2.462369680404663\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
+      "        policy_loss: -0.015580352582037448\n",
+      "        total_loss: 9.111823654174804\n",
+      "        vf_explained_var: 0.9850462079048157\n",
+      "        vf_loss: 9.126498985290528\n",
+      "    num_steps_sampled: 2366208\n",
+      "    num_steps_trained: 2366208\n",
+      "  iterations_since_restore: 39\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.78928571428572\n",
-      "    gpu_util_percent0: 0.04142857142857143\n",
+      "    cpu_util_percent: 31.6\n",
+      "    gpu_util_percent0: 0.29933333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.792857142857144\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.413333333333333\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15779369461228313\n",
-      "    mean_env_wait_ms: 1.6887300269221321\n",
-      "    mean_inference_ms: 4.729069241301459\n",
-      "    mean_raw_obs_processing_ms: 0.419066132995007\n",
-      "  time_since_restore: 442.8714327812195\n",
-      "  time_this_iter_s: 24.39371109008789\n",
-      "  time_total_s: 442.8714327812195\n",
+      "    mean_action_processing_ms: 0.12014789314603108\n",
+      "    mean_env_wait_ms: 0.6584441665611782\n",
+      "    mean_inference_ms: 4.541718618823155\n",
+      "    mean_raw_obs_processing_ms: 0.26081771478569926\n",
+      "  time_since_restore: 523.1847684383392\n",
+      "  time_this_iter_s: 13.210150718688965\n",
+      "  time_total_s: 523.1847684383392\n",
       "  timers:\n",
-      "    learn_throughput: 9977.82\n",
-      "    learn_time_ms: 16215.165\n",
-      "    sample_throughput: 19931.133\n",
-      "    sample_time_ms: 8117.551\n",
-      "    update_time_ms: 31.094\n",
-      "  timestamp: 1602166917\n",
+      "    learn_throughput: 6923.937\n",
+      "    learn_time_ms: 8762.645\n",
+      "    sample_throughput: 13672.937\n",
+      "    sample_time_ms: 4437.379\n",
+      "    update_time_ms: 30.636\n",
+      "  timestamp: 1602432186\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2366208\n",
+      "  training_iteration: 39\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     18 |          442.871 | 2912256 |  239.898 |              290.242 |              115.788 |             809.01 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     39 |          523.185 | 2366208 |  242.882 |              285.869 |               116.02 |            823.456 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-22-21\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3450.620595278823\n",
+      "    time_step_min: 3169\n",
+      "  date: 2020-10-11_16-03-20\n",
       "  done: false\n",
-      "  episode_len_mean: 806.8230485232068\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.2267639474917\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 823.1758467328087\n",
+      "  episode_reward_max: 285.86868686868667\n",
+      "  episode_reward_mean: 243.19889970522874\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 2923\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7929262965917587\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005467748525552452\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7417478799819947\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005580193921923637\n",
       "        model: {}\n",
-      "        policy_loss: -0.018968340079300105\n",
-      "        total_loss: 3.431827688217163\n",
-      "        vf_explained_var: 0.9950782060623169\n",
-      "        vf_loss: 3.4497024059295653\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
+      "        policy_loss: -0.014510815404355526\n",
+      "        total_loss: 12.874164962768555\n",
+      "        vf_explained_var: 0.9789665341377258\n",
+      "        vf_loss: 12.88819179534912\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 40\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.99655172413794\n",
-      "    gpu_util_percent0: 0.27379310344827584\n",
+      "    cpu_util_percent: 29.487499999999997\n",
+      "    gpu_util_percent0: 0.291875\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4124999999999996\n",
+      "    vram_util_percent0: 0.09732699245654312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15751807790452294\n",
-      "    mean_env_wait_ms: 1.6918670821992567\n",
-      "    mean_inference_ms: 4.71261405039136\n",
-      "    mean_raw_obs_processing_ms: 0.41822277427376653\n",
-      "  time_since_restore: 467.25490164756775\n",
-      "  time_this_iter_s: 24.383468866348267\n",
-      "  time_total_s: 467.25490164756775\n",
+      "    mean_action_processing_ms: 0.12008566779531311\n",
+      "    mean_env_wait_ms: 0.658553620312004\n",
+      "    mean_inference_ms: 4.537043319707952\n",
+      "    mean_raw_obs_processing_ms: 0.2606554858331845\n",
+      "  time_since_restore: 536.526570558548\n",
+      "  time_this_iter_s: 13.34180212020874\n",
+      "  time_total_s: 536.526570558548\n",
       "  timers:\n",
-      "    learn_throughput: 9975.719\n",
-      "    learn_time_ms: 16218.58\n",
-      "    sample_throughput: 19874.518\n",
-      "    sample_time_ms: 8140.676\n",
-      "    update_time_ms: 32.327\n",
-      "  timestamp: 1602166941\n",
+      "    learn_throughput: 6909.967\n",
+      "    learn_time_ms: 8780.361\n",
+      "    sample_throughput: 13717.06\n",
+      "    sample_time_ms: 4423.105\n",
+      "    update_time_ms: 31.99\n",
+      "  timestamp: 1602432200\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 40\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     19 |          467.255 | 3074048 |  240.227 |              290.242 |              115.788 |            806.823 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     40 |          536.527 | 2426880 |  243.199 |              285.869 |               116.02 |            823.176 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-22-46\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3448.715856095936\n",
+      "    time_step_min: 3169\n",
+      "  date: 2020-10-11_16-03-33\n",
       "  done: false\n",
-      "  episode_len_mean: 805.7225316455696\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.49984400971735\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3950\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 822.8854097268488\n",
+      "  episode_reward_max: 285.86868686868667\n",
+      "  episode_reward_mean: 243.48749655112073\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3002\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7794228792190552\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005526655982248485\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7339844465255737\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006111154239624739\n",
       "        model: {}\n",
-      "        policy_loss: -0.023039081250317395\n",
-      "        total_loss: 2.078591358661652\n",
-      "        vf_explained_var: 0.9953739047050476\n",
-      "        vf_loss: 2.1005250751972198\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
+      "        policy_loss: -0.015608488768339156\n",
+      "        total_loss: 11.980018806457519\n",
+      "        vf_explained_var: 0.9802266359329224\n",
+      "        vf_loss: 11.995088958740235\n",
+      "    num_steps_sampled: 2487552\n",
+      "    num_steps_trained: 2487552\n",
+      "  iterations_since_restore: 41\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.92068965517242\n",
-      "    gpu_util_percent0: 0.4165517241379311\n",
+      "    cpu_util_percent: 31.453333333333333\n",
+      "    gpu_util_percent0: 0.3173333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.413333333333333\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1573904574836841\n",
-      "    mean_env_wait_ms: 1.6933221569620878\n",
-      "    mean_inference_ms: 4.705165325354333\n",
-      "    mean_raw_obs_processing_ms: 0.4178457110788417\n",
-      "  time_since_restore: 491.8251175880432\n",
-      "  time_this_iter_s: 24.570215940475464\n",
-      "  time_total_s: 491.8251175880432\n",
+      "    mean_action_processing_ms: 0.12002562127903713\n",
+      "    mean_env_wait_ms: 0.6586582582973108\n",
+      "    mean_inference_ms: 4.5325578877618105\n",
+      "    mean_raw_obs_processing_ms: 0.2605001259860025\n",
+      "  time_since_restore: 549.8374593257904\n",
+      "  time_this_iter_s: 13.310888767242432\n",
+      "  time_total_s: 549.8374593257904\n",
       "  timers:\n",
-      "    learn_throughput: 9972.19\n",
-      "    learn_time_ms: 16224.319\n",
-      "    sample_throughput: 19829.965\n",
-      "    sample_time_ms: 8158.965\n",
-      "    update_time_ms: 31.231\n",
-      "  timestamp: 1602166966\n",
+      "    learn_throughput: 6898.689\n",
+      "    learn_time_ms: 8794.714\n",
+      "    sample_throughput: 13723.492\n",
+      "    sample_time_ms: 4421.032\n",
+      "    update_time_ms: 31.755\n",
+      "  timestamp: 1602432213\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2487552\n",
+      "  training_iteration: 41\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     20 |          491.825 | 3235840 |    240.5 |              290.242 |              115.788 |            805.723 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     41 |          549.837 | 2487552 |  243.487 |              285.869 |               116.02 |            822.885 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-23-11\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3446.6886363636363\n",
+      "    time_step_min: 3169\n",
+      "  date: 2020-10-11_16-03-46\n",
       "  done: false\n",
-      "  episode_len_mean: 804.7280915287245\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 240.70876486382807\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 822.4435064935064\n",
+      "  episode_reward_max: 285.86868686868667\n",
+      "  episode_reward_mean: 243.7946510560146\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 78\n",
+      "  episodes_total: 3080\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7865538984537125\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005757506913505494\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7262521624565125\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006154146790504455\n",
       "        model: {}\n",
-      "        policy_loss: -0.02310952057596296\n",
-      "        total_loss: 1.973700213432312\n",
-      "        vf_explained_var: 0.9953605532646179\n",
-      "        vf_loss: 1.9956582367420197\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
+      "        policy_loss: -0.015755283087491988\n",
+      "        total_loss: 9.44112319946289\n",
+      "        vf_explained_var: 0.9838287234306335\n",
+      "        vf_loss: 9.456335830688477\n",
+      "    num_steps_sampled: 2548224\n",
+      "    num_steps_trained: 2548224\n",
+      "  iterations_since_restore: 42\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 32.99655172413794\n",
-      "    gpu_util_percent0: 0.4148275862068965\n",
+      "    cpu_util_percent: 31.040000000000003\n",
+      "    gpu_util_percent0: 0.2786666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4066666666666663\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15726970308067142\n",
-      "    mean_env_wait_ms: 1.6947178273814376\n",
-      "    mean_inference_ms: 4.698130026253491\n",
-      "    mean_raw_obs_processing_ms: 0.4174790686263623\n",
-      "  time_since_restore: 516.4608044624329\n",
-      "  time_this_iter_s: 24.63568687438965\n",
-      "  time_total_s: 516.4608044624329\n",
+      "    mean_action_processing_ms: 0.11996818677997442\n",
+      "    mean_env_wait_ms: 0.658761393096635\n",
+      "    mean_inference_ms: 4.528281717882777\n",
+      "    mean_raw_obs_processing_ms: 0.26035232371452727\n",
+      "  time_since_restore: 562.987548828125\n",
+      "  time_this_iter_s: 13.150089502334595\n",
+      "  time_total_s: 562.987548828125\n",
       "  timers:\n",
-      "    learn_throughput: 9977.798\n",
-      "    learn_time_ms: 16215.201\n",
-      "    sample_throughput: 19793.078\n",
-      "    sample_time_ms: 8174.171\n",
-      "    update_time_ms: 32.464\n",
-      "  timestamp: 1602166991\n",
+      "    learn_throughput: 6917.615\n",
+      "    learn_time_ms: 8770.652\n",
+      "    sample_throughput: 13717.044\n",
+      "    sample_time_ms: 4423.11\n",
+      "    update_time_ms: 29.849\n",
+      "  timestamp: 1602432226\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2548224\n",
+      "  training_iteration: 42\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     21 |          516.461 | 3397632 |  240.709 |              290.242 |              115.788 |            804.728 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     42 |          562.988 | 2548224 |  243.795 |              285.869 |               116.02 |            822.444 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-23-36\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3444.746907706946\n",
+      "    time_step_min: 3165\n",
+      "  date: 2020-10-11_16-04-00\n",
       "  done: false\n",
-      "  episode_len_mean: 803.1457812144644\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.09711855879692\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 289\n",
-      "  episodes_total: 4397\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 822.0837297811609\n",
+      "  episode_reward_max: 286.47474747474723\n",
+      "  episode_reward_mean: 244.08885236763436\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 73\n",
+      "  episodes_total: 3153\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.755255714058876\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005404739850200712\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7186455488204956\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006436989177018404\n",
       "        model: {}\n",
-      "        policy_loss: -0.019464567000977696\n",
-      "        total_loss: 3.0453175783157347\n",
-      "        vf_explained_var: 0.9953736066818237\n",
-      "        vf_loss: 3.0637012124061584\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
+      "        policy_loss: -0.016508414037525655\n",
+      "        total_loss: 9.405962371826172\n",
+      "        vf_explained_var: 0.983354926109314\n",
+      "        vf_loss: 9.421898651123048\n",
+      "    num_steps_sampled: 2608896\n",
+      "    num_steps_trained: 2608896\n",
+      "  iterations_since_restore: 43\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.010344827586216\n",
-      "    gpu_util_percent0: 0.25551724137931037\n",
+      "    cpu_util_percent: 29.81875\n",
+      "    gpu_util_percent0: 0.286875\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.748275862068967\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.40625\n",
+      "    vram_util_percent0: 0.09732699245654312\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15706065795015647\n",
-      "    mean_env_wait_ms: 1.6971458462496418\n",
-      "    mean_inference_ms: 4.686353824274288\n",
-      "    mean_raw_obs_processing_ms: 0.41688654879158077\n",
-      "  time_since_restore: 541.0245015621185\n",
-      "  time_this_iter_s: 24.56369709968567\n",
-      "  time_total_s: 541.0245015621185\n",
+      "    mean_action_processing_ms: 0.11991691589410147\n",
+      "    mean_env_wait_ms: 0.6588630418483384\n",
+      "    mean_inference_ms: 4.524409380273655\n",
+      "    mean_raw_obs_processing_ms: 0.26021799573953674\n",
+      "  time_since_restore: 576.3550531864166\n",
+      "  time_this_iter_s: 13.367504358291626\n",
+      "  time_total_s: 576.3550531864166\n",
       "  timers:\n",
-      "    learn_throughput: 9974.186\n",
-      "    learn_time_ms: 16221.074\n",
-      "    sample_throughput: 19914.903\n",
-      "    sample_time_ms: 8124.167\n",
-      "    update_time_ms: 32.124\n",
-      "  timestamp: 1602167016\n",
+      "    learn_throughput: 6922.718\n",
+      "    learn_time_ms: 8764.188\n",
+      "    sample_throughput: 13678.815\n",
+      "    sample_time_ms: 4435.472\n",
+      "    update_time_ms: 30.861\n",
+      "  timestamp: 1602432240\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2608896\n",
+      "  training_iteration: 43\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     22 |          541.025 | 3559424 |  241.097 |              290.242 |              115.788 |            803.146 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     43 |          576.355 | 2608896 |  244.089 |              286.475 |               116.02 |            822.084 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-00\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3442.7816377171216\n",
+      "    time_step_min: 3165\n",
+      "  date: 2020-10-11_16-04-13\n",
       "  done: false\n",
-      "  episode_len_mean: 802.2247926669577\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.27666671075653\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 185\n",
-      "  episodes_total: 4582\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 821.6752481389578\n",
+      "  episode_reward_max: 286.47474747474723\n",
+      "  episode_reward_mean: 244.3866205479108\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 71\n",
+      "  episodes_total: 3224\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7225345104932785\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005478021572344005\n",
-      "        model: {}\n",
-      "        policy_loss: -0.022186438925564288\n",
-      "        total_loss: 1.9642526030540466\n",
-      "        vf_explained_var: 0.9957612752914429\n",
-      "        vf_loss: 1.9853434622287751\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
-      "  iterations_since_restore: 23\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 33.33793103448276\n",
-      "    gpu_util_percent0: 0.43206896551724133\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762068965517242\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1569378381550041\n",
-      "    mean_env_wait_ms: 1.698596232047108\n",
-      "    mean_inference_ms: 4.679417530334113\n",
-      "    mean_raw_obs_processing_ms: 0.4165376750547412\n",
-      "  time_since_restore: 565.687112569809\n",
-      "  time_this_iter_s: 24.66261100769043\n",
-      "  time_total_s: 565.687112569809\n",
-      "  timers:\n",
-      "    learn_throughput: 9968.382\n",
-      "    learn_time_ms: 16230.518\n",
-      "    sample_throughput: 19860.374\n",
-      "    sample_time_ms: 8146.473\n",
-      "    update_time_ms: 32.606\n",
-      "  timestamp: 1602167040\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
-      "  training_iteration: 23\n",
-      "  trial_id: 91b37_00000\n",
-      "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     23 |          565.687 | 3721216 |  241.277 |              290.242 |              115.788 |            802.225 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-25\n",
-      "  done: false\n",
-      "  episode_len_mean: 801.512447257384\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.5184460640156\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4740\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7451686680316925\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005771003756672144\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7102178335189819\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006092663202434778\n",
       "        model: {}\n",
-      "        policy_loss: -0.024150656536221504\n",
-      "        total_loss: 1.7480961799621582\n",
-      "        vf_explained_var: 0.9958817362785339\n",
-      "        vf_loss: 1.7710926413536072\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
+      "        policy_loss: -0.016193848475813864\n",
+      "        total_loss: 7.7973559379577635\n",
+      "        vf_explained_var: 0.9857897758483887\n",
+      "        vf_loss: 7.813011932373047\n",
+      "    num_steps_sampled: 2669568\n",
+      "    num_steps_trained: 2669568\n",
+      "  iterations_since_restore: 44\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.81071428571429\n",
-      "    gpu_util_percent0: 0.16499999999999998\n",
+      "    cpu_util_percent: 31.013333333333335\n",
+      "    gpu_util_percent0: 0.2613333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.782142857142857\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.4133333333333327\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15683784552145583\n",
-      "    mean_env_wait_ms: 1.6997744080868349\n",
-      "    mean_inference_ms: 4.673850092393118\n",
-      "    mean_raw_obs_processing_ms: 0.4162613145590402\n",
-      "  time_since_restore: 590.1530044078827\n",
-      "  time_this_iter_s: 24.46589183807373\n",
-      "  time_total_s: 590.1530044078827\n",
+      "    mean_action_processing_ms: 0.1198664242616846\n",
+      "    mean_env_wait_ms: 0.6589631458590229\n",
+      "    mean_inference_ms: 4.520789945644346\n",
+      "    mean_raw_obs_processing_ms: 0.26009408393208483\n",
+      "  time_since_restore: 589.6252753734589\n",
+      "  time_this_iter_s: 13.270222187042236\n",
+      "  time_total_s: 589.6252753734589\n",
       "  timers:\n",
-      "    learn_throughput: 9968.406\n",
-      "    learn_time_ms: 16230.478\n",
-      "    sample_throughput: 19802.656\n",
-      "    sample_time_ms: 8170.217\n",
-      "    update_time_ms: 35.007\n",
-      "  timestamp: 1602167065\n",
+      "    learn_throughput: 6917.919\n",
+      "    learn_time_ms: 8770.267\n",
+      "    sample_throughput: 13676.552\n",
+      "    sample_time_ms: 4436.206\n",
+      "    update_time_ms: 30.756\n",
+      "  timestamp: 1602432253\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2669568\n",
+      "  training_iteration: 44\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | RUNNING  | 172.17.0.4:756 |     24 |          590.153 | 3883008 |  241.518 |              290.242 |              115.788 |            801.512 |\n",
-      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_0254c_00000 | RUNNING  | 172.17.0.4:10986 |     44 |          589.625 | 2669568 |  244.387 |              286.475 |               116.02 |            821.675 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_91b37_00000:\n",
+      "Result for PPO_jss_env_0254c_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3125.0\n",
-      "  date: 2020-10-08_14-24-50\n",
+      "    time_step_max: 4290\n",
+      "    time_step_mean: 3441.1525629360026\n",
+      "    time_step_min: 3165\n",
+      "  date: 2020-10-11_16-04-27\n",
       "  done: true\n",
-      "  episode_len_mean: 800.4764492753624\n",
-      "  episode_reward_max: 290.2424242424239\n",
-      "  episode_reward_mean: 241.8013874656386\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 228\n",
-      "  episodes_total: 4968\n",
-      "  experiment_id: 0c679985281b4d9b9f0415ba9b338f31\n",
+      "  episode_len_mean: 821.3342432514407\n",
+      "  episode_reward_max: 286.47474747474723\n",
+      "  episode_reward_mean: 244.6334500602016\n",
+      "  episode_reward_min: 116.02020202020218\n",
+      "  episodes_this_iter: 73\n",
+      "  episodes_total: 3297\n",
+      "  experiment_id: 4e4d4af88c6a4e308baad1d66aa25375\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7212436735630036\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00533560358453542\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7077718257904053\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006186609528958798\n",
       "        model: {}\n",
-      "        policy_loss: -0.020342798670753837\n",
-      "        total_loss: 2.63335440158844\n",
-      "        vf_explained_var: 0.9957489967346191\n",
-      "        vf_loss: 2.65263010263443\n",
-      "    num_steps_sampled: 4044800\n",
-      "    num_steps_trained: 4044800\n",
-      "  iterations_since_restore: 25\n",
+      "        policy_loss: -0.015196176012977958\n",
+      "        total_loss: 7.407955741882324\n",
+      "        vf_explained_var: 0.9867888689041138\n",
+      "        vf_loss: 7.422603893280029\n",
+      "    num_steps_sampled: 2730240\n",
+      "    num_steps_trained: 2730240\n",
+      "  iterations_since_restore: 45\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.09666666666667\n",
-      "    gpu_util_percent0: 0.22766666666666666\n",
+      "    cpu_util_percent: 30.193333333333335\n",
+      "    gpu_util_percent0: 0.36866666666666664\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746666666666668\n",
-      "    vram_util_percent0: 0.2682026894063627\n",
+      "    ram_util_percent: 3.413333333333333\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 756\n",
+      "  pid: 10986\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15670386391308977\n",
-      "    mean_env_wait_ms: 1.7014434824573494\n",
-      "    mean_inference_ms: 4.66638510128689\n",
-      "    mean_raw_obs_processing_ms: 0.41590574797057145\n",
-      "  time_since_restore: 614.7696187496185\n",
-      "  time_this_iter_s: 24.61661434173584\n",
-      "  time_total_s: 614.7696187496185\n",
+      "    mean_action_processing_ms: 0.11981876939093743\n",
+      "    mean_env_wait_ms: 0.6590464095428158\n",
+      "    mean_inference_ms: 4.517161100822282\n",
+      "    mean_raw_obs_processing_ms: 0.2599740087722748\n",
+      "  time_since_restore: 602.8806293010712\n",
+      "  time_this_iter_s: 13.255353927612305\n",
+      "  time_total_s: 602.8806293010712\n",
       "  timers:\n",
-      "    learn_throughput: 9960.015\n",
-      "    learn_time_ms: 16244.153\n",
-      "    sample_throughput: 19778.628\n",
-      "    sample_time_ms: 8180.143\n",
-      "    update_time_ms: 36.793\n",
-      "  timestamp: 1602167090\n",
+      "    learn_throughput: 6912.729\n",
+      "    learn_time_ms: 8776.852\n",
+      "    sample_throughput: 13692.621\n",
+      "    sample_time_ms: 4431.0\n",
+      "    update_time_ms: 30.218\n",
+      "  timestamp: 1602432267\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4044800\n",
-      "  training_iteration: 25\n",
-      "  trial_id: 91b37_00000\n",
+      "  timesteps_total: 2730240\n",
+      "  training_iteration: 45\n",
+      "  trial_id: 0254c_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | TERMINATED |       |     25 |           614.77 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
+      "| PPO_jss_env_0254c_00000 | TERMINATED |       |     45 |          602.881 | 2730240 |  244.633 |              286.475 |               116.02 |            821.334 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_91b37_00000 | TERMINATED |       |     25 |           614.77 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |\n",
+      "| PPO_jss_env_0254c_00000 | TERMINATED |       |     45 |          602.881 | 2730240 |  244.633 |              286.475 |               116.02 |            821.334 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 72, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 57, in train_func\n",
+      "    result = analysis.dataframe().to_dict('index')[0]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 89, in dataframe\n",
+      "    metric = self._validate_metric(metric)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 64, in _validate_metric\n",
+      "    raise ValueError(\n",
+      "ValueError: No `metric` has been passed and  `default_metric` has not been set. Please specify the `metric` parameter.\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 502\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 10772\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_141421-fpfrymi0/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_141421-fpfrymi0/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3125.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 629\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602167090\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 290.24242\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 235.34277\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1738\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 9\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▄▅▇█\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_155408-7luza44j/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_155408-7luza44j/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfast-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/fpfrymi0\u001b[0m\n",
-      "2020-10-08 14:25:03,027 - wandb.wandb_agent - INFO - Cleaning up finished run: fpfrymi0\n",
-      "2020-10-08 14:25:03,372 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:25:03,372 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 16384\n",
-      "2020-10-08 14:25:03,376 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=16384\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msunny-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/7luza44j\u001b[0m\n",
+      "2020-10-11 16:04:37,151 - wandb.wandb_agent - INFO - Cleaning up finished run: 7luza44j\n",
+      "2020-10-11 16:04:37,481 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 16:04:37,481 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tnum_envs_per_worker: 1\n",
+      "\trollout_fragment_length: 768\n",
+      "\tsgd_minibatch_size: 18384\n",
+      "2020-10-11 16:04:37,485 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --num_envs_per_worker=1 --rollout_fragment_length=768 --sgd_minibatch_size=18384\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-11 16:04:42,503 - wandb.wandb_agent - INFO - Running runs: ['b76gv5l6']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmajor-sweep-3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/w8c2p6ff\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_142505-w8c2p6ff\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlyric-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/gd9q4pbz\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/b76gv5l6\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_160439-b76gv5l6\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-08 14:25:07,555\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:25:08,410 - wandb.wandb_agent - INFO - Running runs: ['w8c2p6ff']\n",
+      "2020-10-11 16:04:43,236\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=33202)\u001b[0m 2020-10-08 14:25:10,570\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=33230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33121)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33121)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33185)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33185)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33246)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33246)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33124)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33124)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33192)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33192)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33208)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33208)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33188)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33188)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33095)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33095)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33175)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33175)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33196)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33196)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33186)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33186)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33100)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33098)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33098)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33183)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33183)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33211)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33211)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33180)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33180)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33093)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33093)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33179)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33179)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33193)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33193)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33111)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33111)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33130)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33130)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33189)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33189)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33127)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33127)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33172)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33172)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=33194)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=33194)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_11823_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-25-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m F1011 16:04:45.503923 58108 58108 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:42211\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m *** Check failure stack trace: ***\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x7ff16efa56ed  google::LogMessage::Fail()\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x7ff16efa684c  google::LogMessage::SendToLog()\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x7ff16efa53c9  google::LogMessage::Flush()\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x7ff16efa55e1  google::LogMessage::~LogMessage()\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x7ff16ef5c789  ray::RayLog::~RayLog()\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x7ff16eca01ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x7ff16eca02ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x7ff16eca0491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x7ff16eca2801  ray::gcs::ServiceBasedGcsClient::Connect()\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x7ff16ebb17a8  ray::gcs::GlobalStateAccessor::Connect()\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x7ff16eb22a2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1c6198a  method_vectorcall_NOARGS\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1bf1b08  _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1c7c6a2  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1c7da20  method_vectorcall\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1bf2de6  _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1c7cbaf  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1c7d643  _PyFunction_Vectorcall.localalias.353\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1bf2de6  _PyEval_EvalFrameDefault.cold.2792\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1c7c6a2  _PyEval_EvalCodeWithName\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1c7d454  PyEval_EvalCodeEx\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1d0bbbc  PyEval_EvalCode\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1d0bc64  run_eval_code_obj\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1d3dd14  run_mod\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1c06625  PyRun_FileExFlags\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1c06a0a  PyRun_SimpleFileExFlags\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1c078cf  Py_RunMain.cold.2911\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1d40829  Py_BytesMain\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x7ff1702aa840  __libc_start_main\n",
+      "\u001b[2m\u001b[36m(pid=58108)\u001b[0m     @     0x5595b1cd0b33  (unknown)\n",
+      "\u001b[2m\u001b[36m(pid=58131)\u001b[0m 2020-10-11 16:04:46,089\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=58209)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58209)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58232)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58232)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58207)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58207)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58200)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58200)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58206)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58206)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58214)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58214)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58210)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58210)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58224)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58224)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58212)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58212)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58195)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58195)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58168)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58168)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58117)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58117)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58172)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58172)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58171)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58171)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58222)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58222)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58228)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58228)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58175)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58175)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58095)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58095)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58112)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58112)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58126)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58126)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58198)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58198)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58120)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58120)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58105)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58105)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58110)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58110)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58114)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58114)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58234)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58234)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58132)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58132)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58098)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58098)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58186)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58186)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58225)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58225)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58211)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58211)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58159)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58159)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58165)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58165)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58109)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58109)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58208)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58208)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58202)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58202)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58100)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=59506)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=59506)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58191)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58191)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58183)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58183)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58185)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58185)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58164)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58164)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58220)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58220)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=58184)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=58184)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics: {}\n",
+      "  date: 2020-10-11_16-05-06\n",
+      "  done: false\n",
+      "  episode_len_mean: .nan\n",
+      "  episode_reward_max: .nan\n",
+      "  episode_reward_mean: .nan\n",
+      "  episode_reward_min: .nan\n",
+      "  episodes_this_iter: 0\n",
+      "  episodes_total: 0\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4670,2503 +4250,2537 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1623204231262207\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0048057976178824905\n",
-      "        model: {}\n",
-      "        policy_loss: -0.00972368239890784\n",
-      "        total_loss: 8.319466400146485\n",
-      "        vf_explained_var: 0.7498777508735657\n",
-      "        vf_loss: 8.328228569030761\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1914540827274323\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007823126390576363\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015033794334158301\n",
+      "        total_loss: 562.9246368408203\n",
+      "        vf_explained_var: -0.7487409114837646\n",
+      "        vf_loss: 562.938232421875\n",
+      "    num_steps_sampled: 60672\n",
+      "    num_steps_trained: 60672\n",
       "  iterations_since_restore: 1\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 37.63333333333333\n",
-      "    gpu_util_percent0: 0.26266666666666666\n",
+      "    cpu_util_percent: 38.30555555555556\n",
+      "    gpu_util_percent0: 0.28833333333333333\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0003333333333333333\n",
-      "    ram_util_percent: 9.49\n",
-      "    vram_util_percent0: 0.2729856783644911\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.3166666666666664\n",
+      "    vram_util_percent0: 0.08632156262526876\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17678140968259154\n",
-      "    mean_env_wait_ms: 1.6502532711659141\n",
-      "    mean_inference_ms: 5.870735121936333\n",
-      "    mean_raw_obs_processing_ms: 0.4788182656976241\n",
-      "  time_since_restore: 25.622228860855103\n",
-      "  time_this_iter_s: 25.622228860855103\n",
-      "  time_total_s: 25.622228860855103\n",
+      "  sampler_perf: {}\n",
+      "  time_since_restore: 14.397291421890259\n",
+      "  time_this_iter_s: 14.397291421890259\n",
+      "  time_total_s: 14.397291421890259\n",
       "  timers:\n",
-      "    learn_throughput: 10340.312\n",
-      "    learn_time_ms: 15646.724\n",
-      "    sample_throughput: 16338.488\n",
-      "    sample_time_ms: 9902.507\n",
-      "    update_time_ms: 42.975\n",
-      "  timestamp: 1602167142\n",
+      "    learn_throughput: 7415.073\n",
+      "    learn_time_ms: 8182.253\n",
+      "    sample_throughput: 9844.83\n",
+      "    sample_time_ms: 6162.829\n",
+      "    update_time_ms: 25.725\n",
+      "  timestamp: 1602432306\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
+      "  timesteps_total: 60672\n",
       "  training_iteration: 1\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.8/754.6 GiB\n",
+      "Memory usage on this node: 25.4/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      1 |          25.6222 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |      1 |          14.3973 | 60672 |      nan |                  nan |                  nan |                nan |\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-06\n",
+      "    time_step_max: 4058\n",
+      "    time_step_mean: 3611.3670886075947\n",
+      "    time_step_min: 3306\n",
+      "  date: 2020-10-11_16-05-19\n",
       "  done: false\n",
-      "  episode_len_mean: 870.7974683544304\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 226.3724267996418\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 886.0379746835443\n",
+      "  episode_reward_max: 265.11111111111086\n",
+      "  episode_reward_mean: 218.84337041299042\n",
+      "  episode_reward_min: 151.1717171717169\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 79\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.138706338405609\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006825200421735645\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01274334719637409\n",
-      "        total_loss: 7.690042400360108\n",
-      "        vf_explained_var: 0.8869457244873047\n",
-      "        vf_loss: 7.702103328704834\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1658275425434113\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005513080162927508\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010292008926626295\n",
+      "        total_loss: 595.6605682373047\n",
+      "        vf_explained_var: 0.18877363204956055\n",
+      "        vf_loss: 595.6699066162109\n",
+      "    num_steps_sampled: 121344\n",
+      "    num_steps_trained: 121344\n",
       "  iterations_since_restore: 2\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 35.425925925925924\n",
-      "    gpu_util_percent0: 0.3437037037037037\n",
+      "    cpu_util_percent: 39.51875\n",
+      "    gpu_util_percent0: 0.37\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.73703703703704\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17196632938280343\n",
-      "    mean_env_wait_ms: 1.646491991621751\n",
-      "    mean_inference_ms: 5.588687582318563\n",
-      "    mean_raw_obs_processing_ms: 0.467505042931231\n",
-      "  time_since_restore: 49.39094591140747\n",
-      "  time_this_iter_s: 23.768717050552368\n",
-      "  time_total_s: 49.39094591140747\n",
+      "    mean_action_processing_ms: 0.1392562642493361\n",
+      "    mean_env_wait_ms: 0.6516056658962992\n",
+      "    mean_inference_ms: 5.6192679575765245\n",
+      "    mean_raw_obs_processing_ms: 0.3050151187445618\n",
+      "  time_since_restore: 28.144527196884155\n",
+      "  time_this_iter_s: 13.747235774993896\n",
+      "  time_total_s: 28.144527196884155\n",
       "  timers:\n",
-      "    learn_throughput: 10452.268\n",
-      "    learn_time_ms: 15479.129\n",
-      "    sample_throughput: 17702.943\n",
-      "    sample_time_ms: 9139.271\n",
-      "    update_time_ms: 38.137\n",
-      "  timestamp: 1602167166\n",
+      "    learn_throughput: 7525.277\n",
+      "    learn_time_ms: 8062.427\n",
+      "    sample_throughput: 10187.451\n",
+      "    sample_time_ms: 5955.562\n",
+      "    update_time_ms: 21.166\n",
+      "  timestamp: 1602432319\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
+      "  timesteps_total: 121344\n",
       "  training_iteration: 2\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      2 |          49.3909 | 323584 |  226.372 |              278.354 |              115.788 |            870.797 |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |      2 |          28.1445 | 121344 |  218.843 |              265.111 |              151.172 |            886.038 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-30\n",
+      "    time_step_max: 4159\n",
+      "    time_step_mean: 3614.0443037974683\n",
+      "    time_step_min: 3306\n",
+      "  date: 2020-10-11_16-05-33\n",
       "  done: false\n",
-      "  episode_len_mean: 866.331223628692\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 226.87126539658163\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 880.4050632911392\n",
+      "  episode_reward_max: 265.11111111111086\n",
+      "  episode_reward_mean: 218.43773174785815\n",
+      "  episode_reward_min: 135.8686868686869\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1217446804046631\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007683717552572489\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014337884564884006\n",
-      "        total_loss: 8.763248443603516\n",
-      "        vf_explained_var: 0.9284197092056274\n",
-      "        vf_loss: 8.77681770324707\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1451095044612885\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006658109603449702\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009628374013118446\n",
+      "        total_loss: 343.8333053588867\n",
+      "        vf_explained_var: 0.582950234413147\n",
+      "        vf_loss: 343.8417205810547\n",
+      "    num_steps_sampled: 182016\n",
+      "    num_steps_trained: 182016\n",
       "  iterations_since_restore: 3\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.08620689655172\n",
-      "    gpu_util_percent0: 0.3172413793103448\n",
+      "    cpu_util_percent: 36.25\n",
+      "    gpu_util_percent0: 0.37749999999999995\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755172413793105\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16894469760208242\n",
-      "    mean_env_wait_ms: 1.6450424063300917\n",
-      "    mean_inference_ms: 5.427040881695507\n",
-      "    mean_raw_obs_processing_ms: 0.45877313240781425\n",
-      "  time_since_restore: 73.57178139686584\n",
-      "  time_this_iter_s: 24.180835485458374\n",
-      "  time_total_s: 73.57178139686584\n",
+      "    mean_action_processing_ms: 0.1365851144959723\n",
+      "    mean_env_wait_ms: 0.6516483429947283\n",
+      "    mean_inference_ms: 5.518104287901824\n",
+      "    mean_raw_obs_processing_ms: 0.2998649657433892\n",
+      "  time_since_restore: 41.348203897476196\n",
+      "  time_this_iter_s: 13.203676700592041\n",
+      "  time_total_s: 41.348203897476196\n",
       "  timers:\n",
-      "    learn_throughput: 10452.901\n",
-      "    learn_time_ms: 15478.191\n",
-      "    sample_throughput: 18089.282\n",
-      "    sample_time_ms: 8944.081\n",
-      "    update_time_ms: 56.055\n",
-      "  timestamp: 1602167190\n",
+      "    learn_throughput: 7564.887\n",
+      "    learn_time_ms: 8020.212\n",
+      "    sample_throughput: 10632.146\n",
+      "    sample_time_ms: 5706.468\n",
+      "    update_time_ms: 19.192\n",
+      "  timestamp: 1602432333\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
+      "  timesteps_total: 182016\n",
       "  training_iteration: 3\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 25.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      3 |          73.5718 | 485376 |  226.871 |              278.354 |              115.788 |            866.331 |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |      3 |          41.3482 | 182016 |  218.438 |              265.111 |              135.869 |            880.405 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-26-54\n",
+      "    time_step_max: 4213\n",
+      "    time_step_mean: 3624.0\n",
+      "    time_step_min: 3306\n",
+      "  date: 2020-10-11_16-05-45\n",
       "  done: false\n",
-      "  episode_len_mean: 861.253164556962\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 227.7450294080039\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 877.9535864978903\n",
+      "  episode_reward_max: 265.11111111111086\n",
+      "  episode_reward_mean: 216.92929292929279\n",
+      "  episode_reward_min: 127.68686868686834\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 237\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0939712405204773\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.009209706541150808\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015771377924829723\n",
-      "        total_loss: 8.429035234451295\n",
-      "        vf_explained_var: 0.9521434903144836\n",
-      "        vf_loss: 8.443885612487794\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1370092332363129\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0060931689804419875\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015206624171696603\n",
+      "        total_loss: 237.94325637817383\n",
+      "        vf_explained_var: 0.7285435795783997\n",
+      "        vf_loss: 237.95736694335938\n",
+      "    num_steps_sampled: 242688\n",
+      "    num_steps_trained: 242688\n",
       "  iterations_since_restore: 4\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 35.03333333333334\n",
-      "    gpu_util_percent0: 0.2777777777777778\n",
+      "    cpu_util_percent: 32.99375\n",
+      "    gpu_util_percent0: 0.425\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16676384022481172\n",
-      "    mean_env_wait_ms: 1.6466515242102222\n",
-      "    mean_inference_ms: 5.307577815654116\n",
-      "    mean_raw_obs_processing_ms: 0.4522795805237597\n",
-      "  time_since_restore: 97.21736693382263\n",
-      "  time_this_iter_s: 23.645585536956787\n",
-      "  time_total_s: 97.21736693382263\n",
+      "    mean_action_processing_ms: 0.13454040622665203\n",
+      "    mean_env_wait_ms: 0.6515288631657379\n",
+      "    mean_inference_ms: 5.404449168345442\n",
+      "    mean_raw_obs_processing_ms: 0.29550310639496924\n",
+      "  time_since_restore: 54.15542149543762\n",
+      "  time_this_iter_s: 12.807217597961426\n",
+      "  time_total_s: 54.15542149543762\n",
       "  timers:\n",
-      "    learn_throughput: 10478.311\n",
-      "    learn_time_ms: 15440.657\n",
-      "    sample_throughput: 18466.869\n",
-      "    sample_time_ms: 8761.204\n",
-      "    update_time_ms: 52.666\n",
-      "  timestamp: 1602167214\n",
+      "    learn_throughput: 7552.661\n",
+      "    learn_time_ms: 8033.195\n",
+      "    sample_throughput: 11133.455\n",
+      "    sample_time_ms: 5449.521\n",
+      "    update_time_ms: 19.784\n",
+      "  timestamp: 1602432345\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
+      "  timesteps_total: 242688\n",
       "  training_iteration: 4\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      4 |          97.2174 | 647168 |  227.745 |              278.354 |              115.788 |            861.253 |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |      4 |          54.1554 | 242688 |  216.929 |              265.111 |              127.687 |            877.954 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-27-17\n",
+      "    time_step_max: 4220\n",
+      "    time_step_mean: 3626.240506329114\n",
+      "    time_step_min: 3306\n",
+      "  date: 2020-10-11_16-05-58\n",
       "  done: false\n",
-      "  episode_len_mean: 849.2613882863341\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 228.4696860141544\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 290\n",
-      "  episodes_total: 922\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 876.5949367088608\n",
+      "  episode_reward_max: 265.11111111111086\n",
+      "  episode_reward_mean: 216.58982227336645\n",
+      "  episode_reward_min: 126.62626262626257\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0592716097831727\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007743995590135455\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014329827937763185\n",
-      "        total_loss: 12.433664703369141\n",
-      "        vf_explained_var: 0.967904269695282\n",
-      "        vf_loss: 12.447219848632812\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.12206369638443\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006890057120472193\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011395521811209619\n",
+      "        total_loss: 132.92739486694336\n",
+      "        vf_explained_var: 0.8328981995582581\n",
+      "        vf_loss: 132.9375228881836\n",
+      "    num_steps_sampled: 303360\n",
+      "    num_steps_trained: 303360\n",
       "  iterations_since_restore: 5\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.35357142857143\n",
-      "    gpu_util_percent0: 0.2582142857142857\n",
+      "    cpu_util_percent: 34.593333333333334\n",
+      "    gpu_util_percent0: 0.3026666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16431055835082262\n",
-      "    mean_env_wait_ms: 1.6540874340682217\n",
-      "    mean_inference_ms: 5.1659246506223315\n",
-      "    mean_raw_obs_processing_ms: 0.4451297976580212\n",
-      "  time_since_restore: 120.98013472557068\n",
-      "  time_this_iter_s: 23.762767791748047\n",
-      "  time_total_s: 120.98013472557068\n",
+      "    mean_action_processing_ms: 0.1329078870095902\n",
+      "    mean_env_wait_ms: 0.6514872340321675\n",
+      "    mean_inference_ms: 5.307067246094525\n",
+      "    mean_raw_obs_processing_ms: 0.2919517870113773\n",
+      "  time_since_restore: 66.84345602989197\n",
+      "  time_this_iter_s: 12.688034534454346\n",
+      "  time_total_s: 66.84345602989197\n",
       "  timers:\n",
-      "    learn_throughput: 10471.141\n",
-      "    learn_time_ms: 15451.229\n",
-      "    sample_throughput: 18710.121\n",
-      "    sample_time_ms: 8647.299\n",
-      "    update_time_ms: 46.768\n",
-      "  timestamp: 1602167237\n",
+      "    learn_throughput: 7550.811\n",
+      "    learn_time_ms: 8035.164\n",
+      "    sample_throughput: 11496.568\n",
+      "    sample_time_ms: 5277.401\n",
+      "    update_time_ms: 19.59\n",
+      "  timestamp: 1602432358\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
+      "  timesteps_total: 303360\n",
       "  training_iteration: 5\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      5 |           120.98 | 808960 |   228.47 |              278.354 |              115.788 |            849.261 |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |      5 |          66.8435 | 303360 |   216.59 |              265.111 |              126.626 |            876.595 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3217.0\n",
-      "  date: 2020-10-08_14-27-41\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3624.9088607594936\n",
+      "    time_step_min: 3306\n",
+      "  date: 2020-10-11_16-06-11\n",
       "  done: false\n",
-      "  episode_len_mean: 842.2649186256781\n",
-      "  episode_reward_max: 278.3535353535354\n",
-      "  episode_reward_mean: 228.83911447202573\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 184\n",
-      "  episodes_total: 1106\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 873.2886075949367\n",
+      "  episode_reward_max: 265.11111111111086\n",
+      "  episode_reward_mean: 216.7915867536119\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 395\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0483574509620666\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.007546161720529199\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015934903593733906\n",
-      "        total_loss: 6.211568450927734\n",
-      "        vf_explained_var: 0.979483425617218\n",
-      "        vf_loss: 6.22674880027771\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1141673624515533\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006491948966868222\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012061259825713933\n",
+      "        total_loss: 95.29883575439453\n",
+      "        vf_explained_var: 0.8731156587600708\n",
+      "        vf_loss: 95.30970764160156\n",
+      "    num_steps_sampled: 364032\n",
+      "    num_steps_trained: 364032\n",
       "  iterations_since_restore: 6\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.42962962962963\n",
-      "    gpu_util_percent0: 0.23518518518518516\n",
+      "    cpu_util_percent: 32.575\n",
+      "    gpu_util_percent0: 0.270625\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.40625\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16320835121240662\n",
-      "    mean_env_wait_ms: 1.658072254904595\n",
-      "    mean_inference_ms: 5.101929976377745\n",
-      "    mean_raw_obs_processing_ms: 0.44197622201871506\n",
-      "  time_since_restore: 144.46361637115479\n",
-      "  time_this_iter_s: 23.483481645584106\n",
-      "  time_total_s: 144.46361637115479\n",
+      "    mean_action_processing_ms: 0.13158014825376585\n",
+      "    mean_env_wait_ms: 0.6515391207968362\n",
+      "    mean_inference_ms: 5.225820762190736\n",
+      "    mean_raw_obs_processing_ms: 0.2889980741150863\n",
+      "  time_since_restore: 79.62222123146057\n",
+      "  time_this_iter_s: 12.778765201568604\n",
+      "  time_total_s: 79.62222123146057\n",
       "  timers:\n",
-      "    learn_throughput: 10482.756\n",
-      "    learn_time_ms: 15434.108\n",
-      "    sample_throughput: 18930.618\n",
-      "    sample_time_ms: 8546.578\n",
-      "    update_time_ms: 45.48\n",
-      "  timestamp: 1602167261\n",
+      "    learn_throughput: 7542.412\n",
+      "    learn_time_ms: 8044.111\n",
+      "    sample_throughput: 11734.364\n",
+      "    sample_time_ms: 5170.455\n",
+      "    update_time_ms: 19.635\n",
+      "  timestamp: 1602432371\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
+      "  timesteps_total: 364032\n",
       "  training_iteration: 6\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      6 |          144.464 | 970752 |  228.839 |              278.354 |              115.788 |            842.265 |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |      6 |          79.6222 | 364032 |  216.792 |              265.111 |              118.293 |            873.289 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-05\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3619.0021097046415\n",
+      "    time_step_min: 3289\n",
+      "  date: 2020-10-11_16-06-24\n",
       "  done: false\n",
-      "  episode_len_mean: 837.381329113924\n",
-      "  episode_reward_max: 279.83838383838383\n",
-      "  episode_reward_mean: 228.88543664493022\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 868.9451476793249\n",
+      "  episode_reward_max: 267.6868686868684\n",
+      "  episode_reward_mean: 217.68654903465014\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 474\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0276257395744324\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006892968993633985\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01625481452792883\n",
-      "        total_loss: 5.934515047073364\n",
-      "        vf_explained_var: 0.9834254384040833\n",
-      "        vf_loss: 5.950080394744873\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0996873378753662\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007531901705078781\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010992132098181173\n",
+      "        total_loss: 71.36981773376465\n",
+      "        vf_explained_var: 0.8989866375923157\n",
+      "        vf_loss: 71.3794174194336\n",
+      "    num_steps_sampled: 424704\n",
+      "    num_steps_trained: 424704\n",
       "  iterations_since_restore: 7\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.47777777777778\n",
-      "    gpu_util_percent0: 0.2955555555555555\n",
+      "    cpu_util_percent: 34.71333333333333\n",
+      "    gpu_util_percent0: 0.29133333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16243749898577767\n",
-      "    mean_env_wait_ms: 1.6615503416153818\n",
-      "    mean_inference_ms: 5.056720554339727\n",
-      "    mean_raw_obs_processing_ms: 0.439742077717109\n",
-      "  time_since_restore: 168.09322547912598\n",
-      "  time_this_iter_s: 23.62960910797119\n",
-      "  time_total_s: 168.09322547912598\n",
+      "    mean_action_processing_ms: 0.13050844491749886\n",
+      "    mean_env_wait_ms: 0.6516941788425266\n",
+      "    mean_inference_ms: 5.15856307166687\n",
+      "    mean_raw_obs_processing_ms: 0.2865702558167328\n",
+      "  time_since_restore: 92.38265776634216\n",
+      "  time_this_iter_s: 12.760436534881592\n",
+      "  time_total_s: 92.38265776634216\n",
       "  timers:\n",
-      "    learn_throughput: 10486.247\n",
-      "    learn_time_ms: 15428.971\n",
-      "    sample_throughput: 19063.221\n",
-      "    sample_time_ms: 8487.128\n",
-      "    update_time_ms: 45.241\n",
-      "  timestamp: 1602167285\n",
+      "    learn_throughput: 7546.712\n",
+      "    learn_time_ms: 8039.528\n",
+      "    sample_throughput: 11896.524\n",
+      "    sample_time_ms: 5099.977\n",
+      "    update_time_ms: 21.179\n",
+      "  timestamp: 1602432384\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
+      "  timesteps_total: 424704\n",
       "  training_iteration: 7\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      7 |          168.093 | 1132544 |  228.885 |              279.838 |              115.788 |            837.381 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |      7 |          92.3827 | 424704 |  217.687 |              267.687 |              118.293 |            868.945 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-28\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3617.5623869801084\n",
+      "    time_step_min: 3289\n",
+      "  date: 2020-10-11_16-06-37\n",
       "  done: false\n",
-      "  episode_len_mean: 833.6736990154711\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 229.3878233814942\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 863.7233273056058\n",
+      "  episode_reward_max: 267.6868686868684\n",
+      "  episode_reward_mean: 217.9046888413976\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 553\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9920619606971741\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0067844231147319075\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01662699868902564\n",
-      "        total_loss: 5.330079460144043\n",
-      "        vf_explained_var: 0.9873720407485962\n",
-      "        vf_loss: 5.346027898788452\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.080336093902588\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00649541465099901\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014029796118848026\n",
+      "        total_loss: 65.09321212768555\n",
+      "        vf_explained_var: 0.9129441976547241\n",
+      "        vf_loss: 65.10604953765869\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 8\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.72222222222223\n",
-      "    gpu_util_percent0: 0.2811111111111111\n",
+      "    cpu_util_percent: 32.29375\n",
+      "    gpu_util_percent0: 0.275\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4375\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16179048159969586\n",
-      "    mean_env_wait_ms: 1.664834322637065\n",
-      "    mean_inference_ms: 5.017627986563437\n",
-      "    mean_raw_obs_processing_ms: 0.43762471876215703\n",
-      "  time_since_restore: 191.7211263179779\n",
-      "  time_this_iter_s: 23.62790083885193\n",
-      "  time_total_s: 191.7211263179779\n",
+      "    mean_action_processing_ms: 0.12960126640808023\n",
+      "    mean_env_wait_ms: 0.6519909904724125\n",
+      "    mean_inference_ms: 5.101620631871957\n",
+      "    mean_raw_obs_processing_ms: 0.28448811359847365\n",
+      "  time_since_restore: 105.08664917945862\n",
+      "  time_this_iter_s: 12.703991413116455\n",
+      "  time_total_s: 105.08664917945862\n",
       "  timers:\n",
-      "    learn_throughput: 10499.739\n",
-      "    learn_time_ms: 15409.145\n",
-      "    sample_throughput: 19126.146\n",
-      "    sample_time_ms: 8459.205\n",
-      "    update_time_ms: 44.366\n",
-      "  timestamp: 1602167308\n",
+      "    learn_throughput: 7550.184\n",
+      "    learn_time_ms: 8035.831\n",
+      "    sample_throughput: 12037.574\n",
+      "    sample_time_ms: 5040.218\n",
+      "    update_time_ms: 23.219\n",
+      "  timestamp: 1602432397\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
+      "  timesteps_total: 485376\n",
       "  training_iteration: 8\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      8 |          191.721 | 1294336 |  229.388 |              281.606 |              115.788 |            833.674 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |      8 |          105.087 | 485376 |  217.905 |              267.687 |              118.293 |            863.723 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-28-52\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3613.845276872964\n",
+      "    time_step_min: 3289\n",
+      "  date: 2020-10-11_16-06-49\n",
       "  done: false\n",
-      "  episode_len_mean: 827.9994246260069\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 229.99320593739455\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 316\n",
-      "  episodes_total: 1738\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 860.5602605863193\n",
+      "  episode_reward_max: 267.6868686868684\n",
+      "  episode_reward_mean: 218.46788734248003\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 61\n",
+      "  episodes_total: 614\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9606243968009949\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005957465758547187\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013455570582300425\n",
-      "        total_loss: 7.494734096527099\n",
-      "        vf_explained_var: 0.9888100624084473\n",
-      "        vf_loss: 7.5075939178466795\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0620779395103455\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0070233645383268595\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011862239392939955\n",
+      "        total_loss: 53.99057388305664\n",
+      "        vf_explained_var: 0.9240583181381226\n",
+      "        vf_loss: 54.00113868713379\n",
+      "    num_steps_sampled: 546048\n",
+      "    num_steps_trained: 546048\n",
       "  iterations_since_restore: 9\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.90357142857143\n",
-      "    gpu_util_percent0: 0.26678571428571424\n",
+      "    cpu_util_percent: 34.13333333333333\n",
+      "    gpu_util_percent0: 0.4153333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.413333333333333\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16076244116115793\n",
-      "    mean_env_wait_ms: 1.6704480394177186\n",
-      "    mean_inference_ms: 4.955192966914281\n",
-      "    mean_raw_obs_processing_ms: 0.4343471050403994\n",
-      "  time_since_restore: 215.57324147224426\n",
-      "  time_this_iter_s: 23.852115154266357\n",
-      "  time_total_s: 215.57324147224426\n",
+      "    mean_action_processing_ms: 0.12895817569501378\n",
+      "    mean_env_wait_ms: 0.6522547132371642\n",
+      "    mean_inference_ms: 5.062253685921348\n",
+      "    mean_raw_obs_processing_ms: 0.28298767768141286\n",
+      "  time_since_restore: 117.85798716545105\n",
+      "  time_this_iter_s: 12.771337985992432\n",
+      "  time_total_s: 117.85798716545105\n",
       "  timers:\n",
-      "    learn_throughput: 10506.415\n",
-      "    learn_time_ms: 15399.353\n",
-      "    sample_throughput: 19131.856\n",
-      "    sample_time_ms: 8456.681\n",
-      "    update_time_ms: 41.666\n",
-      "  timestamp: 1602167332\n",
+      "    learn_throughput: 7549.945\n",
+      "    learn_time_ms: 8036.085\n",
+      "    sample_throughput: 12134.416\n",
+      "    sample_time_ms: 4999.993\n",
+      "    update_time_ms: 23.094\n",
+      "  timestamp: 1602432409\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
+      "  timesteps_total: 546048\n",
       "  training_iteration: 9\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |      9 |          215.573 | 1456128 |  229.993 |              281.606 |              114.747 |            827.999 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |      9 |          117.858 | 546048 |  218.468 |              267.687 |              118.293 |             860.56 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-29-16\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3611.2753846153846\n",
+      "    time_step_min: 3289\n",
+      "  date: 2020-10-11_16-07-02\n",
       "  done: false\n",
-      "  episode_len_mean: 826.5395569620254\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.1556546477432\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1896\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 859.0492307692308\n",
+      "  episode_reward_max: 267.6868686868684\n",
+      "  episode_reward_mean: 218.85726495726487\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 36\n",
+      "  episodes_total: 650\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9285854279994965\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0062581704463809725\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016021200059913098\n",
-      "        total_loss: 3.8204103231430055\n",
-      "        vf_explained_var: 0.9922056198120117\n",
-      "        vf_loss: 3.835805630683899\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0485284924507141\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006600828724913299\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017158268485218287\n",
+      "        total_loss: 33.94167709350586\n",
+      "        vf_explained_var: 0.9404016137123108\n",
+      "        vf_loss: 33.95761775970459\n",
+      "    num_steps_sampled: 606720\n",
+      "    num_steps_trained: 606720\n",
       "  iterations_since_restore: 10\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.096296296296295\n",
-      "    gpu_util_percent0: 0.25592592592592595\n",
+      "    cpu_util_percent: 32.25625\n",
+      "    gpu_util_percent0: 0.399375\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1603412050605606\n",
-      "    mean_env_wait_ms: 1.6728638400028686\n",
-      "    mean_inference_ms: 4.929926052491426\n",
-      "    mean_raw_obs_processing_ms: 0.4330192737930434\n",
-      "  time_since_restore: 238.919837474823\n",
-      "  time_this_iter_s: 23.346596002578735\n",
-      "  time_total_s: 238.919837474823\n",
+      "    mean_action_processing_ms: 0.12864684415887948\n",
+      "    mean_env_wait_ms: 0.6524636378572293\n",
+      "    mean_inference_ms: 5.041163744895523\n",
+      "    mean_raw_obs_processing_ms: 0.2822528246771891\n",
+      "  time_since_restore: 130.60816597938538\n",
+      "  time_this_iter_s: 12.750178813934326\n",
+      "  time_total_s: 130.60816597938538\n",
       "  timers:\n",
-      "    learn_throughput: 10519.707\n",
-      "    learn_time_ms: 15379.897\n",
-      "    sample_throughput: 19222.536\n",
-      "    sample_time_ms: 8416.788\n",
-      "    update_time_ms: 40.812\n",
-      "  timestamp: 1602167356\n",
+      "    learn_throughput: 7547.873\n",
+      "    learn_time_ms: 8038.291\n",
+      "    sample_throughput: 12229.181\n",
+      "    sample_time_ms: 4961.248\n",
+      "    update_time_ms: 25.366\n",
+      "  timestamp: 1602432422\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
+      "  timesteps_total: 606720\n",
       "  training_iteration: 10\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     10 |           238.92 | 1617920 |  230.156 |              281.606 |              114.747 |             826.54 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     10 |          130.608 | 606720 |  218.857 |              267.687 |              118.293 |            859.049 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-29-39\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3606.5876577840113\n",
+      "    time_step_min: 3289\n",
+      "  date: 2020-10-11_16-07-15\n",
       "  done: false\n",
-      "  episode_len_mean: 825.4615384615385\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.21514069615333\n",
-      "  episode_reward_min: 114.74747474747485\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 856.6143057503506\n",
+      "  episode_reward_max: 267.6868686868684\n",
+      "  episode_reward_mean: 219.56752659838202\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 63\n",
+      "  episodes_total: 713\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.9235042989253998\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005789411393925548\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014859883906319737\n",
-      "        total_loss: 4.004831600189209\n",
-      "        vf_explained_var: 0.9919689893722534\n",
-      "        vf_loss: 4.019112539291382\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0584369599819183\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005829800385981798\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01342546020168811\n",
+      "        total_loss: 33.587894439697266\n",
+      "        vf_explained_var: 0.931602954864502\n",
+      "        vf_loss: 33.60025978088379\n",
+      "    num_steps_sampled: 667392\n",
+      "    num_steps_trained: 667392\n",
       "  iterations_since_restore: 11\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.4\n",
-      "    gpu_util_percent0: 0.3125925925925926\n",
+      "    cpu_util_percent: 34.186666666666675\n",
+      "    gpu_util_percent0: 0.3693333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4199999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15996985034496003\n",
-      "    mean_env_wait_ms: 1.675007114196491\n",
-      "    mean_inference_ms: 4.907016710777437\n",
-      "    mean_raw_obs_processing_ms: 0.4317794077781022\n",
-      "  time_since_restore: 262.4391770362854\n",
-      "  time_this_iter_s: 23.519339561462402\n",
-      "  time_total_s: 262.4391770362854\n",
+      "    mean_action_processing_ms: 0.128078485783574\n",
+      "    mean_env_wait_ms: 0.6526832097580031\n",
+      "    mean_inference_ms: 5.006329609058325\n",
+      "    mean_raw_obs_processing_ms: 0.2808894089431526\n",
+      "  time_since_restore: 143.25520038604736\n",
+      "  time_this_iter_s: 12.647034406661987\n",
+      "  time_total_s: 143.25520038604736\n",
       "  timers:\n",
-      "    learn_throughput: 10544.089\n",
-      "    learn_time_ms: 15344.332\n",
-      "    sample_throughput: 19638.715\n",
-      "    sample_time_ms: 8238.421\n",
-      "    update_time_ms: 40.485\n",
-      "  timestamp: 1602167379\n",
+      "    learn_throughput: 7569.718\n",
+      "    learn_time_ms: 8015.094\n",
+      "    sample_throughput: 12618.947\n",
+      "    sample_time_ms: 4808.008\n",
+      "    update_time_ms: 26.108\n",
+      "  timestamp: 1602432435\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
+      "  timesteps_total: 667392\n",
       "  training_iteration: 11\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     11 |          262.439 | 1779712 |  230.215 |              281.606 |              114.747 |            825.462 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     11 |          143.255 | 667392 |  219.568 |              267.687 |              118.293 |            856.614 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-03\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3600.558227848101\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_16-07-28\n",
       "  done: false\n",
-      "  episode_len_mean: 824.152428057554\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.18242224402292\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 170\n",
-      "  episodes_total: 2224\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 853.659493670886\n",
+      "  episode_reward_max: 275.86868686868684\n",
+      "  episode_reward_mean: 220.48107658867144\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 77\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8818272411823272\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005413110228255391\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013095138547942042\n",
-      "        total_loss: 5.083396100997925\n",
-      "        vf_explained_var: 0.9921062588691711\n",
-      "        vf_loss: 5.0959498405456545\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.044329285621643\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0065484626684337854\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014785136096179485\n",
+      "        total_loss: 35.80673599243164\n",
+      "        vf_explained_var: 0.9390555024147034\n",
+      "        vf_loss: 35.820316314697266\n",
+      "    num_steps_sampled: 728064\n",
+      "    num_steps_trained: 728064\n",
       "  iterations_since_restore: 12\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.042857142857144\n",
-      "    gpu_util_percent0: 0.1942857142857143\n",
+      "    cpu_util_percent: 34.58\n",
+      "    gpu_util_percent0: 0.32933333333333337\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.757142857142858\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4133333333333327\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15960744702974256\n",
-      "    mean_env_wait_ms: 1.677271579492208\n",
-      "    mean_inference_ms: 4.884761150099492\n",
-      "    mean_raw_obs_processing_ms: 0.4305594741365648\n",
-      "  time_since_restore: 286.0365300178528\n",
-      "  time_this_iter_s: 23.597352981567383\n",
-      "  time_total_s: 286.0365300178528\n",
+      "    mean_action_processing_ms: 0.12748298109172757\n",
+      "    mean_env_wait_ms: 0.6530935558457849\n",
+      "    mean_inference_ms: 4.968588687024664\n",
+      "    mean_raw_obs_processing_ms: 0.2794120972899121\n",
+      "  time_since_restore: 155.83940172195435\n",
+      "  time_this_iter_s: 12.584201335906982\n",
+      "  time_total_s: 155.83940172195435\n",
       "  timers:\n",
-      "    learn_throughput: 10540.17\n",
-      "    learn_time_ms: 15350.038\n",
-      "    sample_throughput: 19693.201\n",
-      "    sample_time_ms: 8215.627\n",
-      "    update_time_ms: 39.264\n",
-      "  timestamp: 1602167403\n",
+      "    learn_throughput: 7569.422\n",
+      "    learn_time_ms: 8015.407\n",
+      "    sample_throughput: 12932.198\n",
+      "    sample_time_ms: 4691.546\n",
+      "    update_time_ms: 26.218\n",
+      "  timestamp: 1602432448\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
+      "  timesteps_total: 728064\n",
       "  training_iteration: 12\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     12 |          286.037 | 1941504 |  230.182 |              281.606 |              99.1212 |            824.152 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     12 |          155.839 | 728064 |  220.481 |              275.869 |              118.293 |            853.659 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-27\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3593.910241657077\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_16-07-40\n",
       "  done: false\n",
-      "  episode_len_mean: 822.2670094936709\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.69313387034907\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 304\n",
-      "  episodes_total: 2528\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 850.2543153049482\n",
+      "  episode_reward_max: 275.86868686868684\n",
+      "  episode_reward_mean: 221.48834722367513\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 869\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8522311568260192\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005159769672900438\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012773643853142858\n",
-      "        total_loss: 5.1331462383270265\n",
-      "        vf_explained_var: 0.9925912618637085\n",
-      "        vf_loss: 5.145403909683227\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0323504209518433\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005593539914116263\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007711198413744569\n",
+      "        total_loss: 33.82645511627197\n",
+      "        vf_explained_var: 0.9453220367431641\n",
+      "        vf_loss: 33.83315181732178\n",
+      "    num_steps_sampled: 788736\n",
+      "    num_steps_trained: 788736\n",
       "  iterations_since_restore: 13\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.01481481481482\n",
-      "    gpu_util_percent0: 0.30111111111111116\n",
+      "    cpu_util_percent: 33.75333333333334\n",
+      "    gpu_util_percent0: 0.35799999999999993\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4066666666666663\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15905681990758594\n",
-      "    mean_env_wait_ms: 1.68066117965344\n",
-      "    mean_inference_ms: 4.850479242048183\n",
-      "    mean_raw_obs_processing_ms: 0.4287066632526924\n",
-      "  time_since_restore: 309.50186347961426\n",
-      "  time_this_iter_s: 23.465333461761475\n",
-      "  time_total_s: 309.50186347961426\n",
+      "    mean_action_processing_ms: 0.1269440350269048\n",
+      "    mean_env_wait_ms: 0.6535218584739464\n",
+      "    mean_inference_ms: 4.934719120591657\n",
+      "    mean_raw_obs_processing_ms: 0.2780699107334339\n",
+      "  time_since_restore: 168.4566102027893\n",
+      "  time_this_iter_s: 12.617208480834961\n",
+      "  time_total_s: 168.4566102027893\n",
       "  timers:\n",
-      "    learn_throughput: 10553.501\n",
-      "    learn_time_ms: 15330.648\n",
-      "    sample_throughput: 19829.166\n",
-      "    sample_time_ms: 8159.294\n",
-      "    update_time_ms: 40.29\n",
-      "  timestamp: 1602167427\n",
+      "    learn_throughput: 7570.15\n",
+      "    learn_time_ms: 8014.636\n",
+      "    sample_throughput: 13092.615\n",
+      "    sample_time_ms: 4634.063\n",
+      "    update_time_ms: 26.364\n",
+      "  timestamp: 1602432460\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
+      "  timesteps_total: 788736\n",
       "  training_iteration: 13\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     13 |          309.502 | 2103296 |  230.693 |              281.606 |              99.1212 |            822.267 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     13 |          168.457 | 788736 |  221.488 |              275.869 |              118.293 |            850.254 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-30-50\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3588.6867088607596\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_16-07-53\n",
       "  done: false\n",
-      "  episode_len_mean: 821.4538346984364\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 230.94512511563886\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2686\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 847.3449367088608\n",
+      "  episode_reward_max: 275.86868686868684\n",
+      "  episode_reward_mean: 222.2797915867535\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 948\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.8369874477386474\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005370886158198118\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01467731585726142\n",
-      "        total_loss: 3.154995489120483\n",
-      "        vf_explained_var: 0.9942510724067688\n",
-      "        vf_loss: 3.1691357612609865\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.013579249382019\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0068066451931372285\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014376593055203557\n",
+      "        total_loss: 28.295745849609375\n",
+      "        vf_explained_var: 0.9575772881507874\n",
+      "        vf_loss: 28.308862686157227\n",
+      "    num_steps_sampled: 849408\n",
+      "    num_steps_trained: 849408\n",
       "  iterations_since_restore: 14\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.181481481481484\n",
-      "    gpu_util_percent0: 0.3040740740740741\n",
+      "    cpu_util_percent: 32.5625\n",
+      "    gpu_util_percent0: 0.33999999999999997\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.766666666666667\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.40625\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1588082507195649\n",
-      "    mean_env_wait_ms: 1.6822641931487865\n",
-      "    mean_inference_ms: 4.835116455543884\n",
-      "    mean_raw_obs_processing_ms: 0.42786989591003743\n",
-      "  time_since_restore: 332.9755485057831\n",
-      "  time_this_iter_s: 23.473685026168823\n",
-      "  time_total_s: 332.9755485057831\n",
+      "    mean_action_processing_ms: 0.12647271860099454\n",
+      "    mean_env_wait_ms: 0.6539710230127329\n",
+      "    mean_inference_ms: 4.904906013887914\n",
+      "    mean_raw_obs_processing_ms: 0.2768762836434561\n",
+      "  time_since_restore: 181.10891199111938\n",
+      "  time_this_iter_s: 12.652301788330078\n",
+      "  time_total_s: 181.10891199111938\n",
       "  timers:\n",
-      "    learn_throughput: 10555.883\n",
-      "    learn_time_ms: 15327.187\n",
-      "    sample_throughput: 19878.044\n",
-      "    sample_time_ms: 8139.232\n",
-      "    update_time_ms: 45.711\n",
-      "  timestamp: 1602167450\n",
+      "    learn_throughput: 7582.305\n",
+      "    learn_time_ms: 8001.788\n",
+      "    sample_throughput: 13099.679\n",
+      "    sample_time_ms: 4631.564\n",
+      "    update_time_ms: 25.995\n",
+      "  timestamp: 1602432473\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
+      "  timesteps_total: 849408\n",
       "  training_iteration: 14\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     14 |          332.976 | 2265088 |  230.945 |              281.606 |              99.1212 |            821.454 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     14 |          181.109 | 849408 |   222.28 |              275.869 |              118.293 |            847.345 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-31-14\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3583.4829600778967\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_16-08-06\n",
       "  done: false\n",
-      "  episode_len_mean: 820.854781997187\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.2064917813863\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 844.6426484907497\n",
+      "  episode_reward_max: 275.86868686868684\n",
+      "  episode_reward_mean: 223.06823837203578\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1027\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.827689278125763\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005339382635429502\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014263017289340495\n",
-      "        total_loss: 3.00002179145813\n",
-      "        vf_explained_var: 0.9941463470458984\n",
-      "        vf_loss: 3.0137508869171143\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9933836460113525\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00562152813654393\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011437032371759415\n",
+      "        total_loss: 25.94105339050293\n",
+      "        vf_explained_var: 0.9608175158500671\n",
+      "        vf_loss: 25.951465129852295\n",
+      "    num_steps_sampled: 910080\n",
+      "    num_steps_trained: 910080\n",
       "  iterations_since_restore: 15\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.57037037037037\n",
-      "    gpu_util_percent0: 0.2274074074074074\n",
+      "    cpu_util_percent: 33.85333333333333\n",
+      "    gpu_util_percent0: 0.362\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.77037037037037\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.413333333333333\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15857855076630387\n",
-      "    mean_env_wait_ms: 1.6837618809370547\n",
-      "    mean_inference_ms: 4.820936656490715\n",
-      "    mean_raw_obs_processing_ms: 0.4270767088680792\n",
-      "  time_since_restore: 356.605441570282\n",
-      "  time_this_iter_s: 23.6298930644989\n",
-      "  time_total_s: 356.605441570282\n",
+      "    mean_action_processing_ms: 0.12605533833513857\n",
+      "    mean_env_wait_ms: 0.6544519960553011\n",
+      "    mean_inference_ms: 4.878354055195134\n",
+      "    mean_raw_obs_processing_ms: 0.2758113414277131\n",
+      "  time_since_restore: 193.74963283538818\n",
+      "  time_this_iter_s: 12.640720844268799\n",
+      "  time_total_s: 193.74963283538818\n",
       "  timers:\n",
-      "    learn_throughput: 10553.654\n",
-      "    learn_time_ms: 15330.425\n",
-      "    sample_throughput: 19924.68\n",
-      "    sample_time_ms: 8120.181\n",
-      "    update_time_ms: 47.653\n",
-      "  timestamp: 1602167474\n",
+      "    learn_throughput: 7592.843\n",
+      "    learn_time_ms: 7990.682\n",
+      "    sample_throughput: 13080.301\n",
+      "    sample_time_ms: 4638.425\n",
+      "    update_time_ms: 25.795\n",
+      "  timestamp: 1602432486\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
+      "  timesteps_total: 910080\n",
       "  training_iteration: 15\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     15 |          356.605 | 2426880 |  231.206 |              281.606 |              99.1212 |            820.855 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     15 |           193.75 | 910080 |  223.068 |              275.869 |              118.293 |            844.643 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-31-38\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3577.5723327305604\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_16-08-18\n",
       "  done: false\n",
-      "  episode_len_mean: 820.0182767624021\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.22214310203864\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 220\n",
-      "  episodes_total: 3064\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 841.9891500904159\n",
+      "  episode_reward_max: 275.86868686868684\n",
+      "  episode_reward_mean: 223.963787970117\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7918125212192535\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004892151476815343\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012084704916924238\n",
-      "        total_loss: 4.1488186597824095\n",
-      "        vf_explained_var: 0.9942665100097656\n",
-      "        vf_loss: 4.160414218902588\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9824153780937195\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005990388686768711\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007877310505136847\n",
+      "        total_loss: 21.027120113372803\n",
+      "        vf_explained_var: 0.9672377705574036\n",
+      "        vf_loss: 21.033896446228027\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 16\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.81481481481482\n",
-      "    gpu_util_percent0: 0.3077777777777778\n",
+      "    cpu_util_percent: 34.5\n",
+      "    gpu_util_percent0: 0.31666666666666665\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74814814814815\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.42\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.158297804116007\n",
-      "    mean_env_wait_ms: 1.6859562656031242\n",
-      "    mean_inference_ms: 4.803618536248515\n",
-      "    mean_raw_obs_processing_ms: 0.42616514556223817\n",
-      "  time_since_restore: 380.0873718261719\n",
-      "  time_this_iter_s: 23.481930255889893\n",
-      "  time_total_s: 380.0873718261719\n",
+      "    mean_action_processing_ms: 0.1256833967188158\n",
+      "    mean_env_wait_ms: 0.6549438728683441\n",
+      "    mean_inference_ms: 4.8545523827810815\n",
+      "    mean_raw_obs_processing_ms: 0.27484890394986167\n",
+      "  time_since_restore: 206.33544921875\n",
+      "  time_this_iter_s: 12.585816383361816\n",
+      "  time_total_s: 206.33544921875\n",
       "  timers:\n",
-      "    learn_throughput: 10556.149\n",
-      "    learn_time_ms: 15326.802\n",
-      "    sample_throughput: 19915.022\n",
-      "    sample_time_ms: 8124.119\n",
-      "    update_time_ms: 46.174\n",
-      "  timestamp: 1602167498\n",
+      "    learn_throughput: 7610.998\n",
+      "    learn_time_ms: 7971.623\n",
+      "    sample_throughput: 13079.829\n",
+      "    sample_time_ms: 4638.593\n",
+      "    update_time_ms: 25.306\n",
+      "  timestamp: 1602432498\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
+      "  timesteps_total: 970752\n",
       "  training_iteration: 16\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     16 |          380.087 | 2588672 |  231.222 |              281.606 |              99.1212 |            820.018 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     16 |          206.335 | 970752 |  223.964 |              275.869 |              118.293 |            841.989 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-01\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3572.2556962025315\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_16-08-31\n",
       "  done: false\n",
-      "  episode_len_mean: 819.2076552139844\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.34207049396923\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 254\n",
-      "  episodes_total: 3318\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 839.464135021097\n",
+      "  episode_reward_max: 275.86868686868684\n",
+      "  episode_reward_mean: 224.76933895921235\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1185\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.05\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7639730334281921\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004952558875083923\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011812644638121128\n",
-      "        total_loss: 3.641219711303711\n",
-      "        vf_explained_var: 0.9940530061721802\n",
-      "        vf_loss: 3.6527847766876222\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9703270643949509\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005524565000087023\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01052850013365969\n",
+      "        total_loss: 24.28107976913452\n",
+      "        vf_explained_var: 0.9627320766448975\n",
+      "        vf_loss: 24.290600299835205\n",
+      "    num_steps_sampled: 1031424\n",
+      "    num_steps_trained: 1031424\n",
       "  iterations_since_restore: 17\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.58928571428571\n",
-      "    gpu_util_percent0: 0.33428571428571435\n",
+      "    cpu_util_percent: 34.2\n",
+      "    gpu_util_percent0: 0.3493333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.746428571428572\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1579861428053209\n",
-      "    mean_env_wait_ms: 1.6878268274425987\n",
-      "    mean_inference_ms: 4.784786851610141\n",
-      "    mean_raw_obs_processing_ms: 0.4251258149287427\n",
-      "  time_since_restore: 403.5224757194519\n",
-      "  time_this_iter_s: 23.43510389328003\n",
-      "  time_total_s: 403.5224757194519\n",
+      "    mean_action_processing_ms: 0.12534404550034728\n",
+      "    mean_env_wait_ms: 0.6554369049907028\n",
+      "    mean_inference_ms: 4.83299518786737\n",
+      "    mean_raw_obs_processing_ms: 0.2739734408062774\n",
+      "  time_since_restore: 218.80903387069702\n",
+      "  time_this_iter_s: 12.473584651947021\n",
+      "  time_total_s: 218.80903387069702\n",
       "  timers:\n",
-      "    learn_throughput: 10564.477\n",
-      "    learn_time_ms: 15314.719\n",
-      "    sample_throughput: 19933.192\n",
-      "    sample_time_ms: 8116.713\n",
-      "    update_time_ms: 45.777\n",
-      "  timestamp: 1602167521\n",
+      "    learn_throughput: 7623.048\n",
+      "    learn_time_ms: 7959.021\n",
+      "    sample_throughput: 13121.081\n",
+      "    sample_time_ms: 4624.009\n",
+      "    update_time_ms: 24.086\n",
+      "  timestamp: 1602432511\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
+      "  timesteps_total: 1031424\n",
       "  training_iteration: 17\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     17 |          403.522 | 2750464 |  231.342 |              281.606 |              99.1212 |            819.208 |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     17 |          218.809 | 1031424 |  224.769 |              275.869 |              118.293 |            839.464 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-25\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3566.5245253164558\n",
+      "    time_step_min: 3235\n",
+      "  date: 2020-10-11_16-08-44\n",
       "  done: false\n",
-      "  episode_len_mean: 818.5304948216341\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.56991956387816\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3476\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 837.506329113924\n",
+      "  episode_reward_max: 275.86868686868684\n",
+      "  episode_reward_mean: 225.63769818437535\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7660917460918426\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005422895355150103\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9576845765113831\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006472750450484455\n",
       "        model: {}\n",
-      "        policy_loss: -0.013137935660779476\n",
-      "        total_loss: 2.9323360919952393\n",
-      "        vf_explained_var: 0.9942866563796997\n",
-      "        vf_loss: 2.94533851146698\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
+      "        policy_loss: -0.01621266547590494\n",
+      "        total_loss: 19.243000507354736\n",
+      "        vf_explained_var: 0.9701140522956848\n",
+      "        vf_loss: 19.258015155792236\n",
+      "    num_steps_sampled: 1092096\n",
+      "    num_steps_trained: 1092096\n",
       "  iterations_since_restore: 18\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.25925925925925\n",
-      "    gpu_util_percent0: 0.36148148148148146\n",
+      "    cpu_util_percent: 32.6\n",
+      "    gpu_util_percent0: 0.43062500000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.759259259259261\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15781721284272957\n",
-      "    mean_env_wait_ms: 1.6890502862525536\n",
-      "    mean_inference_ms: 4.774409463690571\n",
-      "    mean_raw_obs_processing_ms: 0.4245721837690542\n",
-      "  time_since_restore: 426.88156366348267\n",
-      "  time_this_iter_s: 23.35908794403076\n",
-      "  time_total_s: 426.88156366348267\n",
+      "    mean_action_processing_ms: 0.12503446974780746\n",
+      "    mean_env_wait_ms: 0.6559195313687357\n",
+      "    mean_inference_ms: 4.81334827821275\n",
+      "    mean_raw_obs_processing_ms: 0.27317726254777247\n",
+      "  time_since_restore: 231.5099401473999\n",
+      "  time_this_iter_s: 12.70090627670288\n",
+      "  time_total_s: 231.5099401473999\n",
       "  timers:\n",
-      "    learn_throughput: 10562.111\n",
-      "    learn_time_ms: 15318.149\n",
-      "    sample_throughput: 20027.117\n",
-      "    sample_time_ms: 8078.647\n",
-      "    update_time_ms: 51.49\n",
-      "  timestamp: 1602167545\n",
+      "    learn_throughput: 7618.755\n",
+      "    learn_time_ms: 7963.506\n",
+      "    sample_throughput: 13133.663\n",
+      "    sample_time_ms: 4619.579\n",
+      "    update_time_ms: 23.877\n",
+      "  timestamp: 1602432524\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
+      "  timesteps_total: 1092096\n",
       "  training_iteration: 18\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     18 |          426.882 | 2912256 |   231.57 |              281.606 |              99.1212 |             818.53 |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     18 |           231.51 | 1092096 |  225.638 |              275.869 |              118.293 |            837.506 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-32-49\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3560.9985107967236\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-11_16-08-56\n",
       "  done: false\n",
-      "  episode_len_mean: 817.8346629986245\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 231.78994900865604\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 159\n",
-      "  episodes_total: 3635\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 835.8816083395384\n",
+      "  episode_reward_max: 280.26262626262593\n",
+      "  episode_reward_mean: 226.47497311160745\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1343\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.761504179239273\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00561123825609684\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9319173842668533\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006037887651473284\n",
       "        model: {}\n",
-      "        policy_loss: -0.01371184946037829\n",
-      "        total_loss: 2.586661458015442\n",
-      "        vf_explained_var: 0.9948149919509888\n",
-      "        vf_loss: 2.6002331018447875\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
+      "        policy_loss: -0.012360059190541506\n",
+      "        total_loss: 18.858981609344482\n",
+      "        vf_explained_var: 0.971014678478241\n",
+      "        vf_loss: 18.87022590637207\n",
+      "    num_steps_sampled: 1152768\n",
+      "    num_steps_trained: 1152768\n",
       "  iterations_since_restore: 19\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.98518518518519\n",
-      "    gpu_util_percent0: 0.25\n",
+      "    cpu_util_percent: 33.406666666666666\n",
+      "    gpu_util_percent0: 0.3486666666666666\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4266666666666663\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1576552038626758\n",
-      "    mean_env_wait_ms: 1.6902745430630273\n",
-      "    mean_inference_ms: 4.764639495963006\n",
-      "    mean_raw_obs_processing_ms: 0.42404147010851506\n",
-      "  time_since_restore: 450.4647214412689\n",
-      "  time_this_iter_s: 23.583157777786255\n",
-      "  time_total_s: 450.4647214412689\n",
+      "    mean_action_processing_ms: 0.12475188650860593\n",
+      "    mean_env_wait_ms: 0.6563772532072604\n",
+      "    mean_inference_ms: 4.795310461019384\n",
+      "    mean_raw_obs_processing_ms: 0.2724444120578135\n",
+      "  time_since_restore: 244.0025041103363\n",
+      "  time_this_iter_s: 12.492563962936401\n",
+      "  time_total_s: 244.0025041103363\n",
       "  timers:\n",
-      "    learn_throughput: 10558.952\n",
-      "    learn_time_ms: 15322.733\n",
-      "    sample_throughput: 20107.322\n",
-      "    sample_time_ms: 8046.422\n",
-      "    update_time_ms: 53.421\n",
-      "  timestamp: 1602167569\n",
+      "    learn_throughput: 7627.655\n",
+      "    learn_time_ms: 7954.214\n",
+      "    sample_throughput: 13187.854\n",
+      "    sample_time_ms: 4600.597\n",
+      "    update_time_ms: 23.622\n",
+      "  timestamp: 1602432536\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
+      "  timesteps_total: 1152768\n",
       "  training_iteration: 19\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     19 |          450.465 | 3074048 |   231.79 |              281.606 |              99.1212 |            817.835 |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     19 |          244.003 | 1152768 |  226.475 |              280.263 |              118.293 |            835.882 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-33-12\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3557.6068917018283\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-11_16-09-09\n",
       "  done: false\n",
-      "  episode_len_mean: 816.6687881873727\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.22543664753442\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 293\n",
-      "  episodes_total: 3928\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 834.2637130801688\n",
+      "  episode_reward_max: 280.26262626262593\n",
+      "  episode_reward_mean: 226.9888547926522\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.025\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7176933705806732\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004935431573539972\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9170082658529282\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005881667952053249\n",
       "        model: {}\n",
-      "        policy_loss: -0.011507348460145294\n",
-      "        total_loss: 3.7333247661590576\n",
-      "        vf_explained_var: 0.9947683215141296\n",
-      "        vf_loss: 3.744708704948425\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
+      "        policy_loss: -0.009232628857716918\n",
+      "        total_loss: 21.077390670776367\n",
+      "        vf_explained_var: 0.9689568877220154\n",
+      "        vf_loss: 21.0855393409729\n",
+      "    num_steps_sampled: 1213440\n",
+      "    num_steps_trained: 1213440\n",
       "  iterations_since_restore: 20\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.92962962962963\n",
-      "    gpu_util_percent0: 0.22925925925925927\n",
+      "    cpu_util_percent: 32.3375\n",
+      "    gpu_util_percent0: 0.2875\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4562500000000003\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15738510281829127\n",
-      "    mean_env_wait_ms: 1.6923950386450304\n",
-      "    mean_inference_ms: 4.748233050103123\n",
-      "    mean_raw_obs_processing_ms: 0.4231474863161252\n",
-      "  time_since_restore: 473.9994788169861\n",
-      "  time_this_iter_s: 23.534757375717163\n",
-      "  time_total_s: 473.9994788169861\n",
+      "    mean_action_processing_ms: 0.12449303757212322\n",
+      "    mean_env_wait_ms: 0.6568240411041691\n",
+      "    mean_inference_ms: 4.778750735788818\n",
+      "    mean_raw_obs_processing_ms: 0.27177693900219413\n",
+      "  time_since_restore: 256.8121967315674\n",
+      "  time_this_iter_s: 12.809692621231079\n",
+      "  time_total_s: 256.8121967315674\n",
       "  timers:\n",
-      "    learn_throughput: 10546.772\n",
-      "    learn_time_ms: 15340.429\n",
-      "    sample_throughput: 20112.723\n",
-      "    sample_time_ms: 8044.261\n",
-      "    update_time_ms: 53.96\n",
-      "  timestamp: 1602167592\n",
+      "    learn_throughput: 7620.269\n",
+      "    learn_time_ms: 7961.924\n",
+      "    sample_throughput: 13189.585\n",
+      "    sample_time_ms: 4599.993\n",
+      "    update_time_ms: 22.14\n",
+      "  timestamp: 1602432549\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
+      "  timesteps_total: 1213440\n",
       "  training_iteration: 20\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     20 |          473.999 | 3235840 |  232.225 |              281.606 |              99.1212 |            816.669 |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     20 |          256.812 | 1213440 |  226.989 |              280.263 |              118.293 |            834.264 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-33-36\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3553.070619586942\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-11_16-09-22\n",
       "  done: false\n",
-      "  episode_len_mean: 815.9362220058423\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.68833171048362\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 180\n",
-      "  episodes_total: 4108\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 832.6069287141905\n",
+      "  episode_reward_max: 280.26262626262593\n",
+      "  episode_reward_mean: 227.67616874945318\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1501\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6961194634437561\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0054001738782972096\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9074065536260605\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005816309945657849\n",
       "        model: {}\n",
-      "        policy_loss: -0.013575149234384298\n",
-      "        total_loss: 2.1967584609985353\n",
-      "        vf_explained_var: 0.9954622387886047\n",
-      "        vf_loss: 2.210266089439392\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
+      "        policy_loss: -0.015069264685735106\n",
+      "        total_loss: 16.58755850791931\n",
+      "        vf_explained_var: 0.9737280011177063\n",
+      "        vf_loss: 16.601556301116943\n",
+      "    num_steps_sampled: 1274112\n",
+      "    num_steps_trained: 1274112\n",
       "  iterations_since_restore: 21\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.440740740740736\n",
-      "    gpu_util_percent0: 0.29666666666666663\n",
+      "    cpu_util_percent: 34.49333333333333\n",
+      "    gpu_util_percent0: 0.32466666666666666\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4199999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15722895249997093\n",
-      "    mean_env_wait_ms: 1.6936030533075188\n",
-      "    mean_inference_ms: 4.738907510439971\n",
-      "    mean_raw_obs_processing_ms: 0.42262820408828605\n",
-      "  time_since_restore: 497.52709674835205\n",
-      "  time_this_iter_s: 23.527617931365967\n",
-      "  time_total_s: 497.52709674835205\n",
+      "    mean_action_processing_ms: 0.12425433273673535\n",
+      "    mean_env_wait_ms: 0.6572579299079598\n",
+      "    mean_inference_ms: 4.763498257013923\n",
+      "    mean_raw_obs_processing_ms: 0.27116589181050743\n",
+      "  time_since_restore: 269.43881154060364\n",
+      "  time_this_iter_s: 12.626614809036255\n",
+      "  time_total_s: 269.43881154060364\n",
       "  timers:\n",
-      "    learn_throughput: 10537.753\n",
-      "    learn_time_ms: 15353.558\n",
-      "    sample_throughput: 20139.989\n",
-      "    sample_time_ms: 8033.371\n",
-      "    update_time_ms: 52.995\n",
-      "  timestamp: 1602167616\n",
+      "    learn_throughput: 7617.989\n",
+      "    learn_time_ms: 7964.306\n",
+      "    sample_throughput: 13199.951\n",
+      "    sample_time_ms: 4596.381\n",
+      "    update_time_ms: 20.586\n",
+      "  timestamp: 1602432562\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
+      "  timesteps_total: 1274112\n",
       "  training_iteration: 21\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     21 |          497.527 | 3397632 |  232.688 |              281.606 |              99.1212 |            815.936 |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     21 |          269.439 | 1274112 |  227.676 |              280.263 |              118.293 |            832.607 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-00\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3546.6664556962023\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-11_16-09-35\n",
       "  done: false\n",
-      "  episode_len_mean: 815.2585560243788\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 232.9339172313856\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4266\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 831.3810126582279\n",
+      "  episode_reward_max: 280.26262626262593\n",
+      "  episode_reward_mean: 228.64649661168644\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.7063014328479766\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005521039292216301\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8895199149847031\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006235960638150573\n",
       "        model: {}\n",
-      "        policy_loss: -0.013345666276291013\n",
-      "        total_loss: 2.40686240196228\n",
-      "        vf_explained_var: 0.994661808013916\n",
-      "        vf_loss: 2.4201390743255615\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
+      "        policy_loss: -0.016274704947136343\n",
+      "        total_loss: 14.437464952468872\n",
+      "        vf_explained_var: 0.9757154583930969\n",
+      "        vf_loss: 14.45258092880249\n",
+      "    num_steps_sampled: 1334784\n",
+      "    num_steps_trained: 1334784\n",
       "  iterations_since_restore: 22\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.3\n",
-      "    gpu_util_percent0: 0.3596428571428571\n",
+      "    cpu_util_percent: 34.239999999999995\n",
+      "    gpu_util_percent0: 0.34933333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.760714285714286\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4266666666666667\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15710538677505165\n",
-      "    mean_env_wait_ms: 1.694637493002915\n",
-      "    mean_inference_ms: 4.731284261187251\n",
-      "    mean_raw_obs_processing_ms: 0.42220494507105216\n",
-      "  time_since_restore: 521.2907056808472\n",
-      "  time_this_iter_s: 23.763608932495117\n",
-      "  time_total_s: 521.2907056808472\n",
+      "    mean_action_processing_ms: 0.12403295090588674\n",
+      "    mean_env_wait_ms: 0.657665481140537\n",
+      "    mean_inference_ms: 4.749378803791054\n",
+      "    mean_raw_obs_processing_ms: 0.27060251674617225\n",
+      "  time_since_restore: 282.1660873889923\n",
+      "  time_this_iter_s: 12.727275848388672\n",
+      "  time_total_s: 282.1660873889923\n",
       "  timers:\n",
-      "    learn_throughput: 10529.291\n",
-      "    learn_time_ms: 15365.897\n",
-      "    sample_throughput: 20152.527\n",
-      "    sample_time_ms: 8028.373\n",
-      "    update_time_ms: 60.563\n",
-      "  timestamp: 1602167640\n",
+      "    learn_throughput: 7613.066\n",
+      "    learn_time_ms: 7969.456\n",
+      "    sample_throughput: 13177.208\n",
+      "    sample_time_ms: 4604.314\n",
+      "    update_time_ms: 21.077\n",
+      "  timestamp: 1602432575\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
+      "  timesteps_total: 1334784\n",
       "  training_iteration: 22\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     22 |          521.291 | 3559424 |  232.934 |              281.606 |              99.1212 |            815.259 |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     22 |          282.166 | 1334784 |  228.646 |              280.263 |              118.293 |            831.381 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-24\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3541.2525617842075\n",
+      "    time_step_min: 3199\n",
+      "  date: 2020-10-11_16-09-47\n",
       "  done: false\n",
-      "  episode_len_mean: 814.5122444394518\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.18438711990723\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 185\n",
-      "  episodes_total: 4451\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 829.9795057263411\n",
+      "  episode_reward_max: 281.3232323232324\n",
+      "  episode_reward_mean: 229.46678356804938\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1659\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.687007212638855\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005151082994416356\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8658313006162643\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005380009184591472\n",
       "        model: {}\n",
-      "        policy_loss: -0.0136242700740695\n",
-      "        total_loss: 2.3987212419509887\n",
-      "        vf_explained_var: 0.9956458210945129\n",
-      "        vf_loss: 2.412281060218811\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
+      "        policy_loss: -0.008646945061627775\n",
+      "        total_loss: 20.08211898803711\n",
+      "        vf_explained_var: 0.9681438207626343\n",
+      "        vf_loss: 20.08977699279785\n",
+      "    num_steps_sampled: 1395456\n",
+      "    num_steps_trained: 1395456\n",
       "  iterations_since_restore: 23\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.87777777777778\n",
-      "    gpu_util_percent0: 0.32259259259259254\n",
+      "    cpu_util_percent: 32.59375\n",
+      "    gpu_util_percent0: 0.391875\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.755555555555556\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.425\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15697868978775206\n",
-      "    mean_env_wait_ms: 1.6959996633636125\n",
-      "    mean_inference_ms: 4.723299684373984\n",
-      "    mean_raw_obs_processing_ms: 0.42177767922029563\n",
-      "  time_since_restore: 544.7509255409241\n",
-      "  time_this_iter_s: 23.460219860076904\n",
-      "  time_total_s: 544.7509255409241\n",
+      "    mean_action_processing_ms: 0.12382703417818555\n",
+      "    mean_env_wait_ms: 0.658056314534902\n",
+      "    mean_inference_ms: 4.736261256209528\n",
+      "    mean_raw_obs_processing_ms: 0.2700851065081186\n",
+      "  time_since_restore: 294.70430302619934\n",
+      "  time_this_iter_s: 12.538215637207031\n",
+      "  time_total_s: 294.70430302619934\n",
       "  timers:\n",
-      "    learn_throughput: 10523.637\n",
-      "    learn_time_ms: 15374.152\n",
-      "    sample_throughput: 20153.695\n",
-      "    sample_time_ms: 8027.908\n",
-      "    update_time_ms: 54.413\n",
-      "  timestamp: 1602167664\n",
+      "    learn_throughput: 7614.448\n",
+      "    learn_time_ms: 7968.01\n",
+      "    sample_throughput: 13196.964\n",
+      "    sample_time_ms: 4597.421\n",
+      "    update_time_ms: 21.077\n",
+      "  timestamp: 1602432587\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
+      "  timesteps_total: 1395456\n",
       "  training_iteration: 23\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     23 |          544.751 | 3721216 |  233.184 |              281.606 |              99.1212 |            814.512 |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     23 |          294.704 | 1395456 |  229.467 |              281.323 |              118.293 |             829.98 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-34-48\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3536.58918296893\n",
+      "    time_step_min: 3199\n",
+      "  date: 2020-10-11_16-10-00\n",
       "  done: false\n",
-      "  episode_len_mean: 813.3535864978903\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.57533989685885\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 289\n",
-      "  episodes_total: 4740\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 829.3107019562716\n",
+      "  episode_reward_max: 281.3232323232324\n",
+      "  episode_reward_mean: 230.1733561158187\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1738\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.0125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6324166178703308\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0048749387264251706\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8665132224559784\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005198416416533291\n",
       "        model: {}\n",
-      "        policy_loss: -0.011797640426084399\n",
-      "        total_loss: 2.6533204078674317\n",
-      "        vf_explained_var: 0.9955232739448547\n",
-      "        vf_loss: 2.66505708694458\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
+      "        policy_loss: -0.011439272901043296\n",
+      "        total_loss: 17.11276149749756\n",
+      "        vf_explained_var: 0.9721271991729736\n",
+      "        vf_loss: 17.12324619293213\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
       "  iterations_since_restore: 24\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.074074074074076\n",
-      "    gpu_util_percent0: 0.3251851851851852\n",
+      "    cpu_util_percent: 34.3\n",
+      "    gpu_util_percent0: 0.34199999999999997\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.74814814814815\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4399999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15677630383088909\n",
-      "    mean_env_wait_ms: 1.6975983446472827\n",
-      "    mean_inference_ms: 4.710750302441915\n",
-      "    mean_raw_obs_processing_ms: 0.421060709542158\n",
-      "  time_since_restore: 568.4359018802643\n",
-      "  time_this_iter_s: 23.68497633934021\n",
-      "  time_total_s: 568.4359018802643\n",
+      "    mean_action_processing_ms: 0.12363491086642305\n",
+      "    mean_env_wait_ms: 0.6584116401779622\n",
+      "    mean_inference_ms: 4.724030151418645\n",
+      "    mean_raw_obs_processing_ms: 0.26960390783354077\n",
+      "  time_since_restore: 307.4050681591034\n",
+      "  time_this_iter_s: 12.700765132904053\n",
+      "  time_total_s: 307.4050681591034\n",
       "  timers:\n",
-      "    learn_throughput: 10517.772\n",
-      "    learn_time_ms: 15382.726\n",
-      "    sample_throughput: 20124.264\n",
-      "    sample_time_ms: 8039.648\n",
-      "    update_time_ms: 48.571\n",
-      "  timestamp: 1602167688\n",
+      "    learn_throughput: 7603.751\n",
+      "    learn_time_ms: 7979.22\n",
+      "    sample_throughput: 13221.046\n",
+      "    sample_time_ms: 4589.047\n",
+      "    update_time_ms: 22.999\n",
+      "  timestamp: 1602432600\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
+      "  timesteps_total: 1456128\n",
       "  training_iteration: 24\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     24 |          568.436 | 3883008 |  233.575 |              281.606 |              99.1212 |            813.354 |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     24 |          307.405 | 1456128 |  230.173 |              281.323 |              118.293 |            829.311 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-35-11\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3531.2894881673087\n",
+      "    time_step_min: 3199\n",
+      "  date: 2020-10-11_16-10-13\n",
       "  done: false\n",
-      "  episode_len_mean: 812.6929358922009\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 233.80383252698485\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4898\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "  episode_len_mean: 828.4171711612548\n",
+      "  episode_reward_max: 281.3232323232324\n",
+      "  episode_reward_mean: 230.9763401766704\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1817\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.00625\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6476718962192536\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.004980697343125939\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8617505133152008\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0055166283855214715\n",
       "        model: {}\n",
-      "        policy_loss: -0.012937380420044064\n",
-      "        total_loss: 2.2160698890686037\n",
-      "        vf_explained_var: 0.9949172735214233\n",
-      "        vf_loss: 2.2289761781692503\n",
-      "    num_steps_sampled: 4044800\n",
-      "    num_steps_trained: 4044800\n",
+      "        policy_loss: -0.012109191156923771\n",
+      "        total_loss: 12.609570026397705\n",
+      "        vf_explained_var: 0.9781627655029297\n",
+      "        vf_loss: 12.620662212371826\n",
+      "    num_steps_sampled: 1516800\n",
+      "    num_steps_trained: 1516800\n",
       "  iterations_since_restore: 25\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.93703703703704\n",
-      "    gpu_util_percent0: 0.2511111111111111\n",
+      "    cpu_util_percent: 34.186666666666675\n",
+      "    gpu_util_percent0: 0.3253333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.762962962962964\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4266666666666667\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15667803602924033\n",
-      "    mean_env_wait_ms: 1.6985389146300989\n",
-      "    mean_inference_ms: 4.704622565044838\n",
-      "    mean_raw_obs_processing_ms: 0.420720785257639\n",
-      "  time_since_restore: 592.1190402507782\n",
-      "  time_this_iter_s: 23.683138370513916\n",
-      "  time_total_s: 592.1190402507782\n",
+      "    mean_action_processing_ms: 0.12345748985022473\n",
+      "    mean_env_wait_ms: 0.6587396184782712\n",
+      "    mean_inference_ms: 4.712634606635987\n",
+      "    mean_raw_obs_processing_ms: 0.2691615888388835\n",
+      "  time_since_restore: 319.9479868412018\n",
+      "  time_this_iter_s: 12.542918682098389\n",
+      "  time_total_s: 319.9479868412018\n",
       "  timers:\n",
-      "    learn_throughput: 10525.475\n",
-      "    learn_time_ms: 15371.468\n",
-      "    sample_throughput: 20083.377\n",
-      "    sample_time_ms: 8056.016\n",
-      "    update_time_ms: 47.817\n",
-      "  timestamp: 1602167711\n",
+      "    learn_throughput: 7608.199\n",
+      "    learn_time_ms: 7974.555\n",
+      "    sample_throughput: 13240.633\n",
+      "    sample_time_ms: 4582.258\n",
+      "    update_time_ms: 24.345\n",
+      "  timestamp: 1602432613\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4044800\n",
+      "  timesteps_total: 1516800\n",
       "  training_iteration: 25\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.4/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | RUNNING  | 172.17.0.4:33202 |     25 |          592.119 | 4044800 |  233.804 |              281.606 |              99.1212 |            812.693 |\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     25 |          319.948 | 1516800 |  230.976 |              281.323 |              118.293 |            828.417 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_11823_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3204.0\n",
-      "  date: 2020-10-08_14-35-35\n",
-      "  done: true\n",
-      "  episode_len_mean: 812.0104784499803\n",
-      "  episode_reward_max: 281.6060606060598\n",
-      "  episode_reward_mean: 234.07366667864886\n",
-      "  episode_reward_min: 99.12121212121178\n",
-      "  episodes_this_iter: 160\n",
-      "  episodes_total: 5058\n",
-      "  experiment_id: 421e23f0dd5440b2b1dad81139e219db\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3525.5443505807816\n",
+      "    time_step_min: 3199\n",
+      "  date: 2020-10-11_16-10-26\n",
+      "  done: false\n",
+      "  episode_len_mean: 827.2967265047519\n",
+      "  episode_reward_max: 281.3232323232324\n",
+      "  episode_reward_mean: 231.84681556856845\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 77\n",
+      "  episodes_total: 1894\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.003125\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 0.6387091696262359\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.00521918865852058\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8505872040987015\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005504266591742635\n",
       "        model: {}\n",
-      "        policy_loss: -0.013382896583061665\n",
-      "        total_loss: 2.0056067228317263\n",
-      "        vf_explained_var: 0.9955011606216431\n",
-      "        vf_loss: 2.0189733505249023\n",
-      "    num_steps_sampled: 4206592\n",
-      "    num_steps_trained: 4206592\n",
+      "        policy_loss: -0.013713978929445148\n",
+      "        total_loss: 14.596449613571167\n",
+      "        vf_explained_var: 0.9737269878387451\n",
+      "        vf_loss: 14.609147310256958\n",
+      "    num_steps_sampled: 1577472\n",
+      "    num_steps_trained: 1577472\n",
       "  iterations_since_restore: 26\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 33.729629629629635\n",
-      "    gpu_util_percent0: 0.267037037037037\n",
+      "    cpu_util_percent: 31.56875\n",
+      "    gpu_util_percent0: 0.348125\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.766666666666667\n",
-      "    vram_util_percent0: 0.29673663496228275\n",
+      "    ram_util_percent: 3.4124999999999996\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 33202\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15658306876779257\n",
-      "    mean_env_wait_ms: 1.6995085455679213\n",
-      "    mean_inference_ms: 4.6987769399539845\n",
-      "    mean_raw_obs_processing_ms: 0.42039589930108456\n",
-      "  time_since_restore: 615.6618909835815\n",
-      "  time_this_iter_s: 23.542850732803345\n",
-      "  time_total_s: 615.6618909835815\n",
+      "    mean_action_processing_ms: 0.12329297195619345\n",
+      "    mean_env_wait_ms: 0.6590516458679436\n",
+      "    mean_inference_ms: 4.702228905867046\n",
+      "    mean_raw_obs_processing_ms: 0.26875659849681693\n",
+      "  time_since_restore: 332.69026041030884\n",
+      "  time_this_iter_s: 12.742273569107056\n",
+      "  time_total_s: 332.69026041030884\n",
       "  timers:\n",
-      "    learn_throughput: 10524.21\n",
-      "    learn_time_ms: 15373.315\n",
-      "    sample_throughput: 20076.608\n",
-      "    sample_time_ms: 8058.732\n",
-      "    update_time_ms: 48.59\n",
-      "  timestamp: 1602167735\n",
+      "    learn_throughput: 7606.745\n",
+      "    learn_time_ms: 7976.079\n",
+      "    sample_throughput: 13222.83\n",
+      "    sample_time_ms: 4588.428\n",
+      "    update_time_ms: 31.364\n",
+      "  timestamp: 1602432626\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 4206592\n",
+      "  timesteps_total: 1577472\n",
       "  training_iteration: 26\n",
-      "  trial_id: '11823_00000'\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     26 |           332.69 | 1577472 |  231.847 |              281.323 |              118.293 |            827.297 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3521.043279022403\n",
+      "    time_step_min: 3199\n",
+      "  date: 2020-10-11_16-10-38\n",
+      "  done: false\n",
+      "  episode_len_mean: 826.1883910386965\n",
+      "  episode_reward_max: 281.3232323232324\n",
+      "  episode_reward_mean: 232.52879610771666\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 70\n",
+      "  episodes_total: 1964\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8386607617139816\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006047990289516747\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015535812475718558\n",
+      "        total_loss: 14.120278358459473\n",
+      "        vf_explained_var: 0.9748682379722595\n",
+      "        vf_loss: 14.134687900543213\n",
+      "    num_steps_sampled: 1638144\n",
+      "    num_steps_trained: 1638144\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.160000000000004\n",
+      "    gpu_util_percent0: 0.3973333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4066666666666663\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12315610587568344\n",
+      "    mean_env_wait_ms: 0.6593429320218321\n",
+      "    mean_inference_ms: 4.693429433131529\n",
+      "    mean_raw_obs_processing_ms: 0.2684223897882011\n",
+      "  time_since_restore: 345.326283454895\n",
+      "  time_this_iter_s: 12.636023044586182\n",
+      "  time_total_s: 345.326283454895\n",
+      "  timers:\n",
+      "    learn_throughput: 7589.995\n",
+      "    learn_time_ms: 7993.681\n",
+      "    sample_throughput: 13232.661\n",
+      "    sample_time_ms: 4585.019\n",
+      "    update_time_ms: 33.304\n",
+      "  timestamp: 1602432638\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1638144\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 73.5/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_11823_00000 | TERMINATED |       |     26 |          615.662 | 4206592 |  234.074 |              281.606 |              99.1212 |             812.01 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     27 |          345.326 | 1638144 |  232.529 |              281.323 |              118.293 |            826.188 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
       "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3516.673720472441\n",
+      "    time_step_min: 3199\n",
+      "  date: 2020-10-11_16-10-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 825.3661417322835\n",
+      "  episode_reward_max: 281.3232323232324\n",
+      "  episode_reward_mean: 233.19085043346854\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 68\n",
+      "  episodes_total: 2032\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8244215697050095\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005533277872018516\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01628575964423362\n",
+      "        total_loss: 14.40134334564209\n",
+      "        vf_explained_var: 0.974392294883728\n",
+      "        vf_loss: 14.41660475730896\n",
+      "    num_steps_sampled: 1698816\n",
+      "    num_steps_trained: 1698816\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.400000000000006\n",
+      "    gpu_util_percent0: 0.286\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12302757695675907\n",
+      "    mean_env_wait_ms: 0.6595993005928896\n",
+      "    mean_inference_ms: 4.685169265257335\n",
+      "    mean_raw_obs_processing_ms: 0.268104203669914\n",
+      "  time_since_restore: 357.9906647205353\n",
+      "  time_this_iter_s: 12.664381265640259\n",
+      "  time_total_s: 357.9906647205353\n",
+      "  timers:\n",
+      "    learn_throughput: 7589.693\n",
+      "    learn_time_ms: 7993.999\n",
+      "    sample_throughput: 13241.299\n",
+      "    sample_time_ms: 4582.028\n",
+      "    update_time_ms: 31.503\n",
+      "  timestamp: 1602432651\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1698816\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     28 |          357.991 | 1698816 |  233.191 |              281.323 |              118.293 |            825.366 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 32990\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201008_142505-w8c2p6ff/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201008_142505-w8c2p6ff/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3204.0\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 630\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602167735\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 279.83838\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 115.78788\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 228.88544\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 1264\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ▁▂▄▅▇█\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ▁▁▁▁▁▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ▁\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mmajor-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/w8c2p6ff\u001b[0m\n",
-      "2020-10-08 14:35:46,970 - wandb.wandb_agent - INFO - Cleaning up finished run: w8c2p6ff\n",
-      "2020-10-08 14:35:47,283 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-08 14:35:47,283 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.2\n",
-      "\tlambda: 0.95\n",
-      "\tlr: 0.0001\n",
-      "\tnum_envs_per_worker: 2\n",
-      "\tnum_sgd_iter: 20\n",
-      "\tsgd_minibatch_size: 32768\n",
-      "2020-10-08 14:35:47,287 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.2 --lambda=0.95 --lr=0.0001 --num_envs_per_worker=2 --num_sgd_iter=20 --sgd_minibatch_size=32768\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvibrant-sweep-4\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/sweeps/rfs7la4y\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP/runs/y6ys1sgz\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201008_143549-y6ys1sgz\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3512.8546927108146\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-11-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 824.6441162458314\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 233.7694910034119\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 67\n",
+      "  episodes_total: 2099\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8053620457649231\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.004583484609611332\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011118872789666057\n",
+      "        total_loss: 10.728185892105103\n",
+      "        vf_explained_var: 0.979694128036499\n",
+      "        vf_loss: 10.738468647003174\n",
+      "    num_steps_sampled: 1759488\n",
+      "    num_steps_trained: 1759488\n",
+      "  iterations_since_restore: 29\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.413333333333334\n",
+      "    gpu_util_percent0: 0.374\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.42\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12289704902758945\n",
+      "    mean_env_wait_ms: 0.6597944890531547\n",
+      "    mean_inference_ms: 4.677136872350052\n",
+      "    mean_raw_obs_processing_ms: 0.26778808417806077\n",
+      "  time_since_restore: 370.6478157043457\n",
+      "  time_this_iter_s: 12.657150983810425\n",
+      "  time_total_s: 370.6478157043457\n",
+      "  timers:\n",
+      "    learn_throughput: 7589.4\n",
+      "    learn_time_ms: 7994.308\n",
+      "    sample_throughput: 13196.913\n",
+      "    sample_time_ms: 4597.439\n",
+      "    update_time_ms: 31.097\n",
+      "  timestamp: 1602432664\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1759488\n",
+      "  training_iteration: 29\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     29 |          370.648 | 1759488 |  233.769 |              294.657 |              118.293 |            824.644 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
       "\n",
-      "2020-10-08 14:35:51,552\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8270\u001b[39m\u001b[22m\n",
-      "2020-10-08 14:35:52,322 - wandb.wandb_agent - INFO - Running runs: ['y6ys1sgz']\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3509.5301982480405\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-11-16\n",
+      "  done: false\n",
+      "  episode_len_mean: 823.8326417704011\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 234.2732022856504\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 70\n",
+      "  episodes_total: 2169\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8010383099317551\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005840748781338334\n",
+      "        model: {}\n",
+      "        policy_loss: -0.00798800599295646\n",
+      "        total_loss: 11.50804591178894\n",
+      "        vf_explained_var: 0.9788138270378113\n",
+      "        vf_loss: 11.515530347824097\n",
+      "    num_steps_sampled: 1820160\n",
+      "    num_steps_trained: 1820160\n",
+      "  iterations_since_restore: 30\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.800000000000004\n",
+      "    gpu_util_percent0: 0.378\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.42\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12277065660850758\n",
+      "    mean_env_wait_ms: 0.6600029964591032\n",
+      "    mean_inference_ms: 4.669321099994522\n",
+      "    mean_raw_obs_processing_ms: 0.2674844545880775\n",
+      "  time_since_restore: 383.0449287891388\n",
+      "  time_this_iter_s: 12.39711308479309\n",
+      "  time_total_s: 383.0449287891388\n",
+      "  timers:\n",
+      "    learn_throughput: 7614.353\n",
+      "    learn_time_ms: 7968.11\n",
+      "    sample_throughput: 13239.191\n",
+      "    sample_time_ms: 4582.757\n",
+      "    update_time_ms: 30.229\n",
+      "  timestamp: 1602432676\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1820160\n",
+      "  training_iteration: 30\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 57.0/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     30 |          383.045 | 1820160 |  234.273 |              294.657 |              118.293 |            823.833 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=62403)\u001b[0m 2020-10-08 14:35:54,588\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=62386)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62386)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62376)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62376)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62393)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62393)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62398)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62398)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62383)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62383)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62395)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62395)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62371)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62371)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62368)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62368)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62388)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62388)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62342)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62342)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62365)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62365)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62267)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62267)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62280)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62280)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62286)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62286)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62363)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62363)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62356)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62356)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62384)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62384)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62406)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62406)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62276)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62276)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62375)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62375)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62411)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62411)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62287)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62287)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62336)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62336)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62264)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62264)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62281)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62281)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62333)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62333)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62341)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62341)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62339)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62339)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62289)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62289)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62288)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62288)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62334)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62334)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62377)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62377)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62270)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62270)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62331)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62331)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62391)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62391)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62344)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62344)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62284)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62284)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62262)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62262)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62328)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62328)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=62338)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=62338)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3279.0\n",
-      "  date: 2020-10-08_14-36-25\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.1708860759494\n",
-      "  episode_reward_max: 273.13131313131294\n",
-      "  episode_reward_mean: 224.28870988364636\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3506.5406976744184\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-11-29\n",
+      "  done: false\n",
+      "  episode_len_mean: 823.0178890876565\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 234.7261569180174\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 67\n",
+      "  episodes_total: 2236\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.2\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1634249687194824\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.0036954283714294434\n",
-      "        model: {}\n",
-      "        policy_loss: -0.006869117938913405\n",
-      "        total_loss: 9.30032901763916\n",
-      "        vf_explained_var: 0.7174946069717407\n",
-      "        vf_loss: 9.306459045410156\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7931597828865051\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00602615880779922\n",
+      "        model: {}\n",
+      "        policy_loss: -0.007323025201912969\n",
+      "        total_loss: 12.5483980178833\n",
+      "        vf_explained_var: 0.9768276810646057\n",
+      "        vf_loss: 12.555197715759277\n",
+      "    num_steps_sampled: 1880832\n",
+      "    num_steps_trained: 1880832\n",
+      "  iterations_since_restore: 31\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 39.282758620689656\n",
-      "    gpu_util_percent0: 0.27758620689655167\n",
+      "    cpu_util_percent: 31.75625\n",
+      "    gpu_util_percent0: 0.323125\n",
       "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0003448275862068966\n",
-      "    ram_util_percent: 9.486206896551723\n",
-      "    vram_util_percent0: 0.30692086721480194\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1757240295410156\n",
-      "    mean_env_wait_ms: 1.64632514878238\n",
-      "    mean_inference_ms: 5.702464303031089\n",
-      "    mean_raw_obs_processing_ms: 0.4785182454697177\n",
-      "  time_since_restore: 24.381270170211792\n",
-      "  time_this_iter_s: 24.381270170211792\n",
-      "  time_total_s: 24.381270170211792\n",
+      "    mean_action_processing_ms: 0.12265725095336075\n",
+      "    mean_env_wait_ms: 0.6602202213072201\n",
+      "    mean_inference_ms: 4.662258018301666\n",
+      "    mean_raw_obs_processing_ms: 0.2672126209689783\n",
+      "  time_since_restore: 395.6041238307953\n",
+      "  time_this_iter_s: 12.559195041656494\n",
+      "  time_total_s: 395.6041238307953\n",
       "  timers:\n",
-      "    learn_throughput: 10955.585\n",
-      "    learn_time_ms: 14767.992\n",
-      "    sample_throughput: 16976.731\n",
-      "    sample_time_ms: 9530.221\n",
-      "    update_time_ms: 49.441\n",
-      "  timestamp: 1602167785\n",
+      "    learn_throughput: 7614.934\n",
+      "    learn_time_ms: 7967.502\n",
+      "    sample_throughput: 13261.629\n",
+      "    sample_time_ms: 4575.004\n",
+      "    update_time_ms: 32.018\n",
+      "  timestamp: 1602432689\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 1880832\n",
+      "  training_iteration: 31\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 72.7/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      1 |          24.3813 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     31 |          395.604 | 1880832 |  234.726 |              294.657 |              118.293 |            823.018 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-36-48\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3503.4176062445795\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-11-42\n",
       "  done: false\n",
-      "  episode_len_mean: 867.5569620253165\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 226.67721518987318\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 822.153512575889\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 235.19935258920518\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 70\n",
+      "  episodes_total: 2306\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -7174,83 +6788,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.1362101554870605\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006970350444316864\n",
-      "        model: {}\n",
-      "        policy_loss: -0.009705625101923942\n",
-      "        total_loss: 10.32210750579834\n",
-      "        vf_explained_var: 0.8451136350631714\n",
-      "        vf_loss: 10.331116104125977\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7887319028377533\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006466412800364196\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011869820766150951\n",
+      "        total_loss: 10.237318277359009\n",
+      "        vf_explained_var: 0.9808382987976074\n",
+      "        vf_loss: 10.248620510101318\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 32\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.548148148148144\n",
-      "    gpu_util_percent0: 0.2866666666666667\n",
+      "    cpu_util_percent: 34.06666666666667\n",
+      "    gpu_util_percent0: 0.39866666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.733333333333334\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 3.4266666666666667\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17100616576939356\n",
-      "    mean_env_wait_ms: 1.647485749663841\n",
-      "    mean_inference_ms: 5.449976105277291\n",
-      "    mean_raw_obs_processing_ms: 0.4667153357279003\n",
-      "  time_since_restore: 47.252567291259766\n",
-      "  time_this_iter_s: 22.871297121047974\n",
-      "  time_total_s: 47.252567291259766\n",
+      "    mean_action_processing_ms: 0.12254758625828596\n",
+      "    mean_env_wait_ms: 0.6604370618429498\n",
+      "    mean_inference_ms: 4.655120295370935\n",
+      "    mean_raw_obs_processing_ms: 0.26694040957559567\n",
+      "  time_since_restore: 408.1169400215149\n",
+      "  time_this_iter_s: 12.512816190719604\n",
+      "  time_total_s: 408.1169400215149\n",
       "  timers:\n",
-      "    learn_throughput: 11041.238\n",
-      "    learn_time_ms: 14653.429\n",
-      "    sample_throughput: 18199.954\n",
-      "    sample_time_ms: 8889.693\n",
-      "    update_time_ms: 42.206\n",
-      "  timestamp: 1602167808\n",
+      "    learn_throughput: 7621.861\n",
+      "    learn_time_ms: 7960.261\n",
+      "    sample_throughput: 13301.639\n",
+      "    sample_time_ms: 4561.243\n",
+      "    update_time_ms: 31.613\n",
+      "  timestamp: 1602432702\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 32\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      2 |          47.2526 | 323584 |  226.677 |              287.616 |              115.788 |            867.557 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     32 |          408.117 | 1941504 |  235.199 |              294.657 |              118.293 |            822.154 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-11\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3499.610012620951\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-11-54\n",
       "  done: false\n",
-      "  episode_len_mean: 859.824894514768\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.24830584324238\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 821.4859066049643\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 235.77626071399737\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 71\n",
+      "  episodes_total: 2377\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -7258,83 +6870,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.12405526638031\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006674189120531082\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010977230872958899\n",
-      "        total_loss: 12.676021194458007\n",
-      "        vf_explained_var: 0.8899718523025513\n",
-      "        vf_loss: 12.686330986022949\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7735395282506943\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006109715439379215\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013684868696145713\n",
+      "        total_loss: 9.02634072303772\n",
+      "        vf_explained_var: 0.9823529720306396\n",
+      "        vf_loss: 9.039491653442383\n",
+      "    num_steps_sampled: 2002176\n",
+      "    num_steps_trained: 2002176\n",
+      "  iterations_since_restore: 33\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 36.05555555555555\n",
-      "    gpu_util_percent0: 0.2644444444444444\n",
+      "    cpu_util_percent: 34.22\n",
+      "    gpu_util_percent0: 0.3446666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.751851851851852\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 3.4199999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16808367664964877\n",
-      "    mean_env_wait_ms: 1.6489405832417077\n",
-      "    mean_inference_ms: 5.307994845910706\n",
-      "    mean_raw_obs_processing_ms: 0.45738673020424264\n",
-      "  time_since_restore: 70.47958087921143\n",
-      "  time_this_iter_s: 23.22701358795166\n",
-      "  time_total_s: 70.47958087921143\n",
+      "    mean_action_processing_ms: 0.12244578065618276\n",
+      "    mean_env_wait_ms: 0.6606534822204309\n",
+      "    mean_inference_ms: 4.648254413795414\n",
+      "    mean_raw_obs_processing_ms: 0.26667231021273746\n",
+      "  time_since_restore: 420.65903425216675\n",
+      "  time_this_iter_s: 12.542094230651855\n",
+      "  time_total_s: 420.65903425216675\n",
       "  timers:\n",
-      "    learn_throughput: 11042.229\n",
-      "    learn_time_ms: 14652.115\n",
-      "    sample_throughput: 18479.026\n",
-      "    sample_time_ms: 8755.44\n",
-      "    update_time_ms: 41.454\n",
-      "  timestamp: 1602167831\n",
+      "    learn_throughput: 7617.632\n",
+      "    learn_time_ms: 7964.679\n",
+      "    sample_throughput: 13314.046\n",
+      "    sample_time_ms: 4556.992\n",
+      "    update_time_ms: 31.635\n",
+      "  timestamp: 1602432714\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 2002176\n",
+      "  training_iteration: 33\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.2/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      3 |          70.4796 | 485376 |  228.248 |              287.616 |              115.788 |            859.825 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     33 |          420.659 | 2002176 |  235.776 |              294.657 |              118.293 |            821.486 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-34\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3495.8756117455137\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-12-07\n",
       "  done: false\n",
-      "  episode_len_mean: 853.2689873417721\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.76543920214786\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 820.7389885807504\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 236.34207902845748\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 75\n",
+      "  episodes_total: 2452\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -7342,83 +6952,81 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0947366952896118\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.005848201550543308\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01150441262871027\n",
-      "        total_loss: 13.476828002929688\n",
-      "        vf_explained_var: 0.9183750152587891\n",
-      "        vf_loss: 13.487747383117675\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7676493227481842\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006269674748182297\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01027127931592986\n",
+      "        total_loss: 10.94404411315918\n",
+      "        vf_explained_var: 0.9788558483123779\n",
+      "        vf_loss: 10.953765153884888\n",
+      "    num_steps_sampled: 2062848\n",
+      "    num_steps_trained: 2062848\n",
+      "  iterations_since_restore: 34\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 35.855555555555554\n",
-      "    gpu_util_percent0: 0.27814814814814814\n",
+      "    cpu_util_percent: 33.666666666666664\n",
+      "    gpu_util_percent0: 0.42000000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.744444444444445\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16618084056987167\n",
-      "    mean_env_wait_ms: 1.652121993019246\n",
-      "    mean_inference_ms: 5.206010003773685\n",
-      "    mean_raw_obs_processing_ms: 0.45115332512960615\n",
-      "  time_since_restore: 93.41903614997864\n",
-      "  time_this_iter_s: 22.939455270767212\n",
-      "  time_total_s: 93.41903614997864\n",
+      "    mean_action_processing_ms: 0.12233866219496542\n",
+      "    mean_env_wait_ms: 0.6608791809583239\n",
+      "    mean_inference_ms: 4.6413449326072955\n",
+      "    mean_raw_obs_processing_ms: 0.2663978147269404\n",
+      "  time_since_restore: 433.28397512435913\n",
+      "  time_this_iter_s: 12.624940872192383\n",
+      "  time_total_s: 433.28397512435913\n",
       "  timers:\n",
-      "    learn_throughput: 11054.503\n",
-      "    learn_time_ms: 14635.845\n",
-      "    sample_throughput: 18733.219\n",
-      "    sample_time_ms: 8636.637\n",
-      "    update_time_ms: 36.312\n",
-      "  timestamp: 1602167854\n",
+      "    learn_throughput: 7615.72\n",
+      "    learn_time_ms: 7966.68\n",
+      "    sample_throughput: 13344.134\n",
+      "    sample_time_ms: 4546.717\n",
+      "    update_time_ms: 31.655\n",
+      "  timestamp: 1602432727\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 2062848\n",
+      "  training_iteration: 34\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      4 |           93.419 | 647168 |  228.765 |              287.616 |              115.788 |            853.269 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     34 |          433.284 | 2062848 |  236.342 |              294.657 |              118.293 |            820.739 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_915d0_00000:\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: .inf\n",
-      "    time_step_mean: .inf\n",
-      "    time_step_min: 3152.0\n",
-      "  date: 2020-10-08_14-37-57\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3492.986956521739\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-12-20\n",
       "  done: false\n",
-      "  episode_len_mean: 842.2431289640592\n",
-      "  episode_reward_max: 287.616161616161\n",
-      "  episode_reward_mean: 228.57511691972567\n",
-      "  episode_reward_min: 115.78787878787875\n",
-      "  episodes_this_iter: 314\n",
-      "  episodes_total: 946\n",
-      "  experiment_id: 9f9d18d1775c479cb62320e4982fbe23\n",
+      "  episode_len_mean: 819.8332015810277\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 236.77975406236274\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 78\n",
+      "  episodes_total: 2530\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -7426,74 +7034,7240 @@
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.1\n",
-      "        cur_lr: 0.0001\n",
-      "        entropy: 1.0704583883285523\n",
-      "        entropy_coeff: 0.0\n",
-      "        kl: 0.006159011553972959\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01097527714446187\n",
-      "        total_loss: 18.48041114807129\n",
-      "        vf_explained_var: 0.9505600929260254\n",
-      "        vf_loss: 18.490771102905274\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7546486258506775\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0058147438103333116\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012304193340241909\n",
+      "        total_loss: 10.538083553314209\n",
+      "        vf_explained_var: 0.980566680431366\n",
+      "        vf_loss: 10.549881935119629\n",
+      "    num_steps_sampled: 2123520\n",
+      "    num_steps_trained: 2123520\n",
+      "  iterations_since_restore: 35\n",
       "  node_ip: 172.17.0.4\n",
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 34.67142857142857\n",
-      "    gpu_util_percent0: 0.34750000000000003\n",
+      "    cpu_util_percent: 31.881249999999998\n",
+      "    gpu_util_percent0: 0.38749999999999996\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 9.739285714285716\n",
-      "    vram_util_percent0: 0.355608396195474\n",
+      "    ram_util_percent: 3.4\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 62403\n",
+      "  pid: 58131\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1637216679032345\n",
-      "    mean_env_wait_ms: 1.6595417244788717\n",
-      "    mean_inference_ms: 5.075327722233796\n",
-      "    mean_raw_obs_processing_ms: 0.443719930951552\n",
-      "  time_since_restore: 116.6165714263916\n",
-      "  time_this_iter_s: 23.197535276412964\n",
-      "  time_total_s: 116.6165714263916\n",
+      "    mean_action_processing_ms: 0.12222794658999028\n",
+      "    mean_env_wait_ms: 0.6610959002225931\n",
+      "    mean_inference_ms: 4.634419702177536\n",
+      "    mean_raw_obs_processing_ms: 0.26611683838637945\n",
+      "  time_since_restore: 445.942663192749\n",
+      "  time_this_iter_s: 12.658688068389893\n",
+      "  time_total_s: 445.942663192749\n",
       "  timers:\n",
-      "    learn_throughput: 11077.95\n",
-      "    learn_time_ms: 14604.868\n",
-      "    sample_throughput: 18764.263\n",
-      "    sample_time_ms: 8622.347\n",
-      "    update_time_ms: 48.444\n",
-      "  timestamp: 1602167877\n",
+      "    learn_throughput: 7606.23\n",
+      "    learn_time_ms: 7976.619\n",
+      "    sample_throughput: 13359.952\n",
+      "    sample_time_ms: 4541.334\n",
+      "    update_time_ms: 37.681\n",
+      "  timestamp: 1602432740\n",
       "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: 915d0_00000\n",
+      "  timesteps_total: 2123520\n",
+      "  training_iteration: 35\n",
+      "  trial_id: 7a7ff_00000\n",
       "  \n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
-      "WARNING:root:NaN or Inf found in input tensor.\n",
       "== Status ==\n",
-      "Memory usage on this node: 73.3/754.6 GiB\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      5 |          116.617 | 808960 |  228.575 |              287.616 |              115.788 |            842.243 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     35 |          445.943 | 2123520 |   236.78 |              294.657 |              118.293 |            819.833 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3488.9290916059795\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-12-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 818.9126101954772\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 237.39458207990214\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 2609\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7400196939706802\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0058068325743079185\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013815922429785132\n",
+      "        total_loss: 10.05512261390686\n",
+      "        vf_explained_var: 0.9806376099586487\n",
+      "        vf_loss: 10.068431377410889\n",
+      "    num_steps_sampled: 2184192\n",
+      "    num_steps_trained: 2184192\n",
+      "  iterations_since_restore: 36\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.053333333333335\n",
+      "    gpu_util_percent0: 0.3686666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4266666666666667\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12212225178823108\n",
+      "    mean_env_wait_ms: 0.6613143142351993\n",
+      "    mean_inference_ms: 4.627720603822091\n",
+      "    mean_raw_obs_processing_ms: 0.265844670572868\n",
+      "  time_since_restore: 458.47173833847046\n",
+      "  time_this_iter_s: 12.529075145721436\n",
+      "  time_total_s: 458.47173833847046\n",
+      "  timers:\n",
+      "    learn_throughput: 7600.836\n",
+      "    learn_time_ms: 7982.28\n",
+      "    sample_throughput: 13421.08\n",
+      "    sample_time_ms: 4520.65\n",
+      "    update_time_ms: 31.579\n",
+      "  timestamp: 1602432752\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2184192\n",
+      "  training_iteration: 36\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     36 |          458.472 | 2184192 |  237.395 |              294.657 |              118.293 |            818.913 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3485.9352678571427\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-12-45\n",
+      "  done: false\n",
+      "  episode_len_mean: 818.0517113095239\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 237.84819173881675\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 2688\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7301702946424484\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005751452641561627\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013575302669778466\n",
+      "        total_loss: 9.521034479141235\n",
+      "        vf_explained_var: 0.982122540473938\n",
+      "        vf_loss: 9.534107208251953\n",
+      "    num_steps_sampled: 2244864\n",
+      "    num_steps_trained: 2244864\n",
+      "  iterations_since_restore: 37\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.106666666666676\n",
+      "    gpu_util_percent0: 0.334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4466666666666663\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.122021320091186\n",
+      "    mean_env_wait_ms: 0.6615287027514779\n",
+      "    mean_inference_ms: 4.621330885247032\n",
+      "    mean_raw_obs_processing_ms: 0.2655831882729574\n",
+      "  time_since_restore: 471.03045630455017\n",
+      "  time_this_iter_s: 12.558717966079712\n",
+      "  time_total_s: 471.03045630455017\n",
+      "  timers:\n",
+      "    learn_throughput: 7604.935\n",
+      "    learn_time_ms: 7977.978\n",
+      "    sample_throughput: 13433.247\n",
+      "    sample_time_ms: 4516.555\n",
+      "    update_time_ms: 31.29\n",
+      "  timestamp: 1602432765\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2244864\n",
+      "  training_iteration: 37\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     37 |           471.03 | 2244864 |  237.848 |              294.657 |              118.293 |            818.052 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3482.712942877802\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-12-58\n",
+      "  done: false\n",
+      "  episode_len_mean: 817.2541576283442\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 238.33642279629268\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 78\n",
+      "  episodes_total: 2766\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7123904228210449\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006374098709784448\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013502237037755549\n",
+      "        total_loss: 11.306285858154297\n",
+      "        vf_explained_var: 0.9792220592498779\n",
+      "        vf_loss: 11.319222211837769\n",
+      "    num_steps_sampled: 2305536\n",
+      "    num_steps_trained: 2305536\n",
+      "  iterations_since_restore: 38\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.31333333333334\n",
+      "    gpu_util_percent0: 0.37133333333333335\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.433333333333333\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12192696639683571\n",
+      "    mean_env_wait_ms: 0.6617340285726273\n",
+      "    mean_inference_ms: 4.615272777054371\n",
+      "    mean_raw_obs_processing_ms: 0.26533222492254516\n",
+      "  time_since_restore: 483.5480728149414\n",
+      "  time_this_iter_s: 12.517616510391235\n",
+      "  time_total_s: 483.5480728149414\n",
+      "  timers:\n",
+      "    learn_throughput: 7616.943\n",
+      "    learn_time_ms: 7965.4\n",
+      "    sample_throughput: 13440.282\n",
+      "    sample_time_ms: 4514.191\n",
+      "    update_time_ms: 31.372\n",
+      "  timestamp: 1602432778\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2305536\n",
+      "  training_iteration: 38\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     38 |          483.548 | 2305536 |  238.336 |              294.657 |              118.293 |            817.254 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3479.0738137082603\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-13-10\n",
+      "  done: false\n",
+      "  episode_len_mean: 816.4987697715289\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 238.887806003799\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 2845\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7063906639814377\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006619708146899939\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008540161070413888\n",
+      "        total_loss: 10.110114336013794\n",
+      "        vf_explained_var: 0.9805809855461121\n",
+      "        vf_loss: 10.118062973022461\n",
+      "    num_steps_sampled: 2366208\n",
+      "    num_steps_trained: 2366208\n",
+      "  iterations_since_restore: 39\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.29375\n",
+      "    gpu_util_percent0: 0.35\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.41875\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12183449138565841\n",
+      "    mean_env_wait_ms: 0.6619379598742459\n",
+      "    mean_inference_ms: 4.609421720491569\n",
+      "    mean_raw_obs_processing_ms: 0.26508944925438577\n",
+      "  time_since_restore: 496.10764169692993\n",
+      "  time_this_iter_s: 12.559568881988525\n",
+      "  time_total_s: 496.10764169692993\n",
+      "  timers:\n",
+      "    learn_throughput: 7616.998\n",
+      "    learn_time_ms: 7965.343\n",
+      "    sample_throughput: 13468.468\n",
+      "    sample_time_ms: 4504.744\n",
+      "    update_time_ms: 31.81\n",
+      "  timestamp: 1602432790\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2366208\n",
+      "  training_iteration: 39\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     39 |          496.108 | 2366208 |  238.888 |              294.657 |              118.293 |            816.499 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3476.669859733151\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-13-23\n",
+      "  done: false\n",
+      "  episode_len_mean: 815.7071501881628\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 239.25204145457312\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 78\n",
+      "  episodes_total: 2923\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6949535459280014\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005586441489867866\n",
+      "        model: {}\n",
+      "        policy_loss: -0.009916623908793554\n",
+      "        total_loss: 12.35196328163147\n",
+      "        vf_explained_var: 0.9776116609573364\n",
+      "        vf_loss: 12.361390352249146\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 40\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.82\n",
+      "    gpu_util_percent0: 0.35133333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4466666666666668\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1217463072325626\n",
+      "    mean_env_wait_ms: 0.662131895610092\n",
+      "    mean_inference_ms: 4.6038412855908755\n",
+      "    mean_raw_obs_processing_ms: 0.2648563846585165\n",
+      "  time_since_restore: 508.76882886886597\n",
+      "  time_this_iter_s: 12.661187171936035\n",
+      "  time_total_s: 508.76882886886597\n",
+      "  timers:\n",
+      "    learn_throughput: 7603.181\n",
+      "    learn_time_ms: 7979.818\n",
+      "    sample_throughput: 13433.358\n",
+      "    sample_time_ms: 4516.518\n",
+      "    update_time_ms: 31.19\n",
+      "  timestamp: 1602432803\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 40\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     40 |          508.769 | 2426880 |  239.252 |              294.657 |              118.293 |            815.707 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3473.2671552298466\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-13-36\n",
+      "  done: false\n",
+      "  episode_len_mean: 814.9037308461026\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 239.76760274295256\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3002\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6896779984235764\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00545170099940151\n",
+      "        model: {}\n",
+      "        policy_loss: -0.006760447518900037\n",
+      "        total_loss: 10.799469709396362\n",
+      "        vf_explained_var: 0.9795577526092529\n",
+      "        vf_loss: 10.805754661560059\n",
+      "    num_steps_sampled: 2487552\n",
+      "    num_steps_trained: 2487552\n",
+      "  iterations_since_restore: 41\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.67333333333333\n",
+      "    gpu_util_percent0: 0.3293333333333333\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12166107279338173\n",
+      "    mean_env_wait_ms: 0.6623265457389281\n",
+      "    mean_inference_ms: 4.598450888389196\n",
+      "    mean_raw_obs_processing_ms: 0.2646293661196949\n",
+      "  time_since_restore: 521.2429101467133\n",
+      "  time_this_iter_s: 12.47408127784729\n",
+      "  time_total_s: 521.2429101467133\n",
+      "  timers:\n",
+      "    learn_throughput: 7607.721\n",
+      "    learn_time_ms: 7975.056\n",
+      "    sample_throughput: 13441.993\n",
+      "    sample_time_ms: 4513.616\n",
+      "    update_time_ms: 30.063\n",
+      "  timestamp: 1602432816\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2487552\n",
+      "  training_iteration: 41\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     41 |          521.243 | 2487552 |  239.768 |              294.657 |              118.293 |            814.904 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3469.998052580331\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-13-48\n",
+      "  done: false\n",
+      "  episode_len_mean: 814.205452775073\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 240.26292132621253\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3081\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6865971684455872\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005908183171413839\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013723642565310001\n",
+      "        total_loss: 10.921100378036499\n",
+      "        vf_explained_var: 0.9789117574691772\n",
+      "        vf_loss: 10.934301376342773\n",
+      "    num_steps_sampled: 2548224\n",
+      "    num_steps_trained: 2548224\n",
+      "  iterations_since_restore: 42\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.446666666666665\n",
+      "    gpu_util_percent0: 0.32599999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.3999999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12157909965570467\n",
+      "    mean_env_wait_ms: 0.6625155357831264\n",
+      "    mean_inference_ms: 4.593272441734872\n",
+      "    mean_raw_obs_processing_ms: 0.2644102576167796\n",
+      "  time_since_restore: 533.6973576545715\n",
+      "  time_this_iter_s: 12.454447507858276\n",
+      "  time_total_s: 533.6973576545715\n",
+      "  timers:\n",
+      "    learn_throughput: 7607.583\n",
+      "    learn_time_ms: 7975.201\n",
+      "    sample_throughput: 13462.367\n",
+      "    sample_time_ms: 4506.786\n",
+      "    update_time_ms: 31.204\n",
+      "  timestamp: 1602432828\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2548224\n",
+      "  training_iteration: 42\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     42 |          533.697 | 2548224 |  240.263 |              294.657 |              118.293 |            814.205 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3466.8977848101267\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-14-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 813.7351265822784\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 240.73265886715257\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3160\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.673320397734642\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005441875662654638\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01596468430943787\n",
+      "        total_loss: 9.379735231399536\n",
+      "        vf_explained_var: 0.9821313619613647\n",
+      "        vf_loss: 9.395222902297974\n",
+      "    num_steps_sampled: 2608896\n",
+      "    num_steps_trained: 2608896\n",
+      "  iterations_since_restore: 43\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.62666666666667\n",
+      "    gpu_util_percent0: 0.33133333333333337\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.42\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12150030433775505\n",
+      "    mean_env_wait_ms: 0.6626975133129722\n",
+      "    mean_inference_ms: 4.588298094915638\n",
+      "    mean_raw_obs_processing_ms: 0.26419929842819045\n",
+      "  time_since_restore: 546.1801235675812\n",
+      "  time_this_iter_s: 12.482765913009644\n",
+      "  time_total_s: 546.1801235675812\n",
+      "  timers:\n",
+      "    learn_throughput: 7620.357\n",
+      "    learn_time_ms: 7961.832\n",
+      "    sample_throughput: 13440.021\n",
+      "    sample_time_ms: 4514.279\n",
+      "    update_time_ms: 31.552\n",
+      "  timestamp: 1602432841\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2608896\n",
+      "  training_iteration: 43\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     43 |           546.18 | 2608896 |  240.733 |              294.657 |              118.293 |            813.735 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3464.2837295461563\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-14-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 813.19851806113\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 241.128727846542\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3239\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6631857454776764\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005600042990408838\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013800082611851394\n",
+      "        total_loss: 8.741819620132446\n",
+      "        vf_explained_var: 0.983812153339386\n",
+      "        vf_loss: 8.755126237869263\n",
+      "    num_steps_sampled: 2669568\n",
+      "    num_steps_trained: 2669568\n",
+      "  iterations_since_restore: 44\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.766666666666666\n",
+      "    gpu_util_percent0: 0.3433333333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4133333333333327\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12142464407322914\n",
+      "    mean_env_wait_ms: 0.6628767611562613\n",
+      "    mean_inference_ms: 4.583519697915844\n",
+      "    mean_raw_obs_processing_ms: 0.2639971100990282\n",
+      "  time_since_restore: 558.4696769714355\n",
+      "  time_this_iter_s: 12.28955340385437\n",
+      "  time_total_s: 558.4696769714355\n",
+      "  timers:\n",
+      "    learn_throughput: 7656.433\n",
+      "    learn_time_ms: 7924.317\n",
+      "    sample_throughput: 13425.228\n",
+      "    sample_time_ms: 4519.253\n",
+      "    update_time_ms: 29.502\n",
+      "  timestamp: 1602432853\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2669568\n",
+      "  training_iteration: 44\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     44 |           558.47 | 2669568 |  241.129 |              294.657 |              118.293 |            813.199 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3461.2525617842075\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-14-26\n",
+      "  done: false\n",
+      "  episode_len_mean: 812.5304400241109\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 241.58799568926156\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3318\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6549868285655975\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.004678940866142511\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012409038899932057\n",
+      "        total_loss: 8.848819255828857\n",
+      "        vf_explained_var: 0.9826209545135498\n",
+      "        vf_loss: 8.860825538635254\n",
+      "    num_steps_sampled: 2730240\n",
+      "    num_steps_trained: 2730240\n",
+      "  iterations_since_restore: 45\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.51333333333334\n",
+      "    gpu_util_percent0: 0.27399999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4199999999999995\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12135184796651013\n",
+      "    mean_env_wait_ms: 0.6630532897122141\n",
+      "    mean_inference_ms: 4.578917370745875\n",
+      "    mean_raw_obs_processing_ms: 0.26380273697363726\n",
+      "  time_since_restore: 570.9770197868347\n",
+      "  time_this_iter_s: 12.50734281539917\n",
+      "  time_total_s: 570.9770197868347\n",
+      "  timers:\n",
+      "    learn_throughput: 7659.718\n",
+      "    learn_time_ms: 7920.918\n",
+      "    sample_throughput: 13438.696\n",
+      "    sample_time_ms: 4514.724\n",
+      "    update_time_ms: 22.245\n",
+      "  timestamp: 1602432866\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2730240\n",
+      "  training_iteration: 45\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     45 |          570.977 | 2730240 |  241.588 |              294.657 |              118.293 |             812.53 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3458.4942596408596\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-14-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 811.9428907859876\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 242.00592025643545\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3397\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6498712301254272\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006043577450327575\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013496566331014037\n",
+      "        total_loss: 10.97796106338501\n",
+      "        vf_explained_var: 0.9792823791503906\n",
+      "        vf_loss: 10.991219997406006\n",
+      "    num_steps_sampled: 2790912\n",
+      "    num_steps_trained: 2790912\n",
+      "  iterations_since_restore: 46\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.27333333333333\n",
+      "    gpu_util_percent0: 0.27466666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.46\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12128185002227779\n",
+      "    mean_env_wait_ms: 0.663225592862293\n",
+      "    mean_inference_ms: 4.574485566206917\n",
+      "    mean_raw_obs_processing_ms: 0.2636157158558468\n",
+      "  time_since_restore: 583.6050810813904\n",
+      "  time_this_iter_s: 12.628061294555664\n",
+      "  time_total_s: 583.6050810813904\n",
+      "  timers:\n",
+      "    learn_throughput: 7649.665\n",
+      "    learn_time_ms: 7931.328\n",
+      "    sample_throughput: 13441.107\n",
+      "    sample_time_ms: 4513.914\n",
+      "    update_time_ms: 22.368\n",
+      "  timestamp: 1602432879\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2790912\n",
+      "  training_iteration: 46\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     46 |          583.605 | 2790912 |  242.006 |              294.657 |              118.293 |            811.943 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3455.911104718067\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-14-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 811.5350978135788\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 242.39730736594953\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6342495381832123\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006048538372851908\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010996688564773649\n",
+      "        total_loss: 8.571913242340088\n",
+      "        vf_explained_var: 0.9842838048934937\n",
+      "        vf_loss: 8.582670211791992\n",
+      "    num_steps_sampled: 2851584\n",
+      "    num_steps_trained: 2851584\n",
+      "  iterations_since_restore: 47\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.9625\n",
+      "    gpu_util_percent0: 0.34750000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.40625\n",
+      "    vram_util_percent0: 0.11634962282715644\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12121440710340929\n",
+      "    mean_env_wait_ms: 0.6633916334880035\n",
+      "    mean_inference_ms: 4.570215206532649\n",
+      "    mean_raw_obs_processing_ms: 0.26343558812156864\n",
+      "  time_since_restore: 596.10276222229\n",
+      "  time_this_iter_s: 12.497681140899658\n",
+      "  time_total_s: 596.10276222229\n",
+      "  timers:\n",
+      "    learn_throughput: 7664.847\n",
+      "    learn_time_ms: 7915.618\n",
+      "    sample_throughput: 13433.163\n",
+      "    sample_time_ms: 4516.583\n",
+      "    update_time_ms: 22.72\n",
+      "  timestamp: 1602432891\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2851584\n",
+      "  training_iteration: 47\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | RUNNING  | 172.17.0.4:58131 |     47 |          596.103 | 2851584 |  242.397 |              294.657 |              118.293 |            811.535 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_7a7ff_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4275\n",
+      "    time_step_mean: 3453.0551336146273\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-15-04\n",
+      "  done: true\n",
+      "  episode_len_mean: 811.0132208157524\n",
+      "  episode_reward_max: 294.6565656565658\n",
+      "  episode_reward_mean: 242.83003026041007\n",
+      "  episode_reward_min: 118.29292929292929\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3555\n",
+      "  experiment_id: 1d171a18a5d54a9daf4bf72942cfbe74\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.05\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.6302320063114166\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005789852002635598\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011886644060723484\n",
+      "        total_loss: 9.188382387161255\n",
+      "        vf_explained_var: 0.9817778468132019\n",
+      "        vf_loss: 9.200042247772217\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 48\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.833333333333336\n",
+      "    gpu_util_percent0: 0.38733333333333336\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4266666666666667\n",
+      "    vram_util_percent0: 0.1163496228271565\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 58131\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12114967799853825\n",
+      "    mean_env_wait_ms: 0.6635533104163663\n",
+      "    mean_inference_ms: 4.566091176760414\n",
+      "    mean_raw_obs_processing_ms: 0.2632612772401684\n",
+      "  time_since_restore: 608.6148672103882\n",
+      "  time_this_iter_s: 12.512104988098145\n",
+      "  time_total_s: 608.6148672103882\n",
+      "  timers:\n",
+      "    learn_throughput: 7660.877\n",
+      "    learn_time_ms: 7919.719\n",
+      "    sample_throughput: 13450.41\n",
+      "    sample_time_ms: 4510.792\n",
+      "    update_time_ms: 23.015\n",
+      "  timestamp: 1602432904\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 48\n",
+      "  trial_id: 7a7ff_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.8/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | TERMINATED |       |     48 |          608.615 | 2912256 |   242.83 |              294.657 |              118.293 |            811.013 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7a7ff_00000 | TERMINATED |       |     48 |          608.615 | 2912256 |   242.83 |              294.657 |              118.293 |            811.013 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 72, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 57, in train_func\n",
+      "    result = analysis.dataframe().to_dict('index')[0]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 89, in dataframe\n",
+      "    metric = self._validate_metric(metric)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 64, in _validate_metric\n",
+      "    raise ValueError(\n",
+      "ValueError: No `metric` has been passed and  `default_metric` has not been set. Please specify the `metric` parameter.\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 57988\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_160439-b76gv5l6/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_160439-b76gv5l6/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mlyric-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/b76gv5l6\u001b[0m\n",
+      "2020-10-11 16:15:13,338 - wandb.wandb_agent - INFO - Cleaning up finished run: b76gv5l6\n",
+      "2020-10-11 16:15:13,650 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 16:15:13,650 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tnum_envs_per_worker: 1\n",
+      "\trollout_fragment_length: 1024\n",
+      "\tsgd_minibatch_size: 12384\n",
+      "2020-10-11 16:15:13,655 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --num_envs_per_worker=1 --rollout_fragment_length=1024 --sgd_minibatch_size=12384\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-11 16:15:18,673 - wandb.wandb_agent - INFO - Running runs: ['55q7t0lv']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdrawn-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/gd9q4pbz\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/55q7t0lv\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_161515-55q7t0lv\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-11 16:15:19,401\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=25709)\u001b[0m 2020-10-11 16:15:22,150\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=25645)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25645)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25664)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25664)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25696)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25696)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25653)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25653)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25684)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25684)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25649)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25649)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25670)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25670)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25691)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25691)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25690)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25690)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25662)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25662)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25675)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25675)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25677)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25677)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25679)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25679)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25676)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25676)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25581)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25581)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25575)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25575)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25651)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25651)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25577)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25577)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25582)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25582)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25588)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25588)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25671)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25671)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25646)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25646)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25595)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25595)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25601)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25601)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25638)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25659)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25659)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25660)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25660)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25589)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25589)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25586)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25586)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25666)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25666)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25702)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25702)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25592)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25592)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25607)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25607)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25706)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25706)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25584)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25584)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25612)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25612)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25597)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25597)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25672)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25672)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25606)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25606)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25708)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25708)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25572)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25572)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25578)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25578)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25590)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25590)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25574)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25574)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25573)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25573)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25678)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25678)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25587)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25587)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25583)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25583)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25665)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25665)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25683)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25683)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25580)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25580)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25644)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25644)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25637)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25593)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25593)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25647)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25647)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25695)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25695)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25661)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25661)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25640)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25640)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25668)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25668)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25701)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25701)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25641)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25641)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25687)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25687)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25704)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25704)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25652)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25652)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25650)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25650)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=25654)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=25654)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3604.8101265822784\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_16-15-48\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.0759493670886\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 219.83684950773548\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 79\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.1817580461502075\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.0056662580796650475\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012262638957638825\n",
+      "        total_loss: 530.9325648716518\n",
+      "        vf_explained_var: 0.42352813482284546\n",
+      "        vf_loss: 530.9438127790179\n",
+      "    num_steps_sampled: 80896\n",
+      "    num_steps_trained: 80896\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 34.49583333333333\n",
+      "    gpu_util_percent0: 0.2104166666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.3333333333333335\n",
+      "    vram_util_percent0: 0.07734776429430414\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14321407295738187\n",
+      "    mean_env_wait_ms: 0.6565433153586462\n",
+      "    mean_inference_ms: 6.003179202737835\n",
+      "    mean_raw_obs_processing_ms: 0.3204385216275127\n",
+      "  time_since_restore: 20.765223741531372\n",
+      "  time_this_iter_s: 20.765223741531372\n",
+      "  time_total_s: 20.765223741531372\n",
+      "  timers:\n",
+      "    learn_throughput: 6704.389\n",
+      "    learn_time_ms: 12066.126\n",
+      "    sample_throughput: 9389.874\n",
+      "    sample_time_ms: 8615.238\n",
+      "    update_time_ms: 46.782\n",
+      "  timestamp: 1602432948\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 80896\n",
+      "  training_iteration: 1\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      1 |          20.7652 | 80896 |  219.837 |              273.444 |              149.354 |            891.076 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3612.772151898734\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_16-16-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 890.5569620253165\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 218.63048203554516\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.1560483149119787\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005446308026356357\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013145096733101777\n",
+      "        total_loss: 172.32416643415178\n",
+      "        vf_explained_var: 0.7585111260414124\n",
+      "        vf_loss: 172.33633422851562\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.58636363636363\n",
+      "    gpu_util_percent0: 0.1886363636363636\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4681818181818187\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.13861688092893748\n",
+      "    mean_env_wait_ms: 0.6527614905773435\n",
+      "    mean_inference_ms: 5.77088424227358\n",
+      "    mean_raw_obs_processing_ms: 0.3094348867722723\n",
+      "  time_since_restore: 39.82163381576538\n",
+      "  time_this_iter_s: 19.05641007423401\n",
+      "  time_total_s: 39.82163381576538\n",
+      "  timers:\n",
+      "    learn_throughput: 6717.507\n",
+      "    learn_time_ms: 12042.562\n",
+      "    sample_throughput: 10382.684\n",
+      "    sample_time_ms: 7791.435\n",
+      "    update_time_ms: 37.14\n",
+      "  timestamp: 1602432967\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 2\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      2 |          39.8216 | 161792 |   218.63 |              273.444 |              149.354 |            890.557 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3609.4388185654007\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_16-16-25\n",
+      "  done: false\n",
+      "  episode_len_mean: 887.1223628691984\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 219.13553254059562\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 237\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.1498419557298933\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006340766059500831\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014920676459691353\n",
+      "        total_loss: 76.00567081996373\n",
+      "        vf_explained_var: 0.866301953792572\n",
+      "        vf_loss: 76.01943751743862\n",
+      "    num_steps_sampled: 242688\n",
+      "    num_steps_trained: 242688\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.46190476190476\n",
+      "    gpu_util_percent0: 0.33380952380952383\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.13545802809359248\n",
+      "    mean_env_wait_ms: 0.6503085829247192\n",
+      "    mean_inference_ms: 5.572566056238619\n",
+      "    mean_raw_obs_processing_ms: 0.3015824022104329\n",
+      "  time_since_restore: 58.027791023254395\n",
+      "  time_this_iter_s: 18.206157207489014\n",
+      "  time_total_s: 58.027791023254395\n",
+      "  timers:\n",
+      "    learn_throughput: 6747.04\n",
+      "    learn_time_ms: 11989.851\n",
+      "    sample_throughput: 11112.788\n",
+      "    sample_time_ms: 7279.541\n",
+      "    update_time_ms: 35.88\n",
+      "  timestamp: 1602432985\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 242688\n",
+      "  training_iteration: 3\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      3 |          58.0278 | 242688 |  219.136 |              273.444 |              149.354 |            887.122 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3612.3860759493673\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-11_16-16-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 884.8006329113924\n",
+      "  episode_reward_max: 275.7171717171716\n",
+      "  episode_reward_mean: 218.68897839150986\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.1339221341269357\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006889853426920516\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016060244691159044\n",
+      "        total_loss: 57.26039069039481\n",
+      "        vf_explained_var: 0.9008350372314453\n",
+      "        vf_loss: 57.275186266217915\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.157142857142865\n",
+      "    gpu_util_percent0: 0.3380952380952381\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1331958726813208\n",
+      "    mean_env_wait_ms: 0.6487802760465601\n",
+      "    mean_inference_ms: 5.425174772283316\n",
+      "    mean_raw_obs_processing_ms: 0.29582564215470597\n",
+      "  time_since_restore: 76.0679042339325\n",
+      "  time_this_iter_s: 18.0401132106781\n",
+      "  time_total_s: 76.0679042339325\n",
+      "  timers:\n",
+      "    learn_throughput: 6777.158\n",
+      "    learn_time_ms: 11936.566\n",
+      "    sample_throughput: 11536.285\n",
+      "    sample_time_ms: 7012.31\n",
+      "    update_time_ms: 31.516\n",
+      "  timestamp: 1602433003\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 4\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      4 |          76.0679 | 323584 |  218.689 |              275.717 |              149.354 |            884.801 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3607.460759493671\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-11_16-17-01\n",
+      "  done: false\n",
+      "  episode_len_mean: 882.3113924050633\n",
+      "  episode_reward_max: 275.7171717171716\n",
+      "  episode_reward_mean: 219.43523846055473\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 395\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.1165154491152083\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.0067611168404775\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016354712857199565\n",
+      "        total_loss: 47.563328879220144\n",
+      "        vf_explained_var: 0.917331337928772\n",
+      "        vf_loss: 47.57844488961356\n",
+      "    num_steps_sampled: 404480\n",
+      "    num_steps_trained: 404480\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.02380952380953\n",
+      "    gpu_util_percent0: 0.34476190476190477\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1314880972380966\n",
+      "    mean_env_wait_ms: 0.647942514465797\n",
+      "    mean_inference_ms: 5.310229644984075\n",
+      "    mean_raw_obs_processing_ms: 0.29130235731107407\n",
+      "  time_since_restore: 93.97231364250183\n",
+      "  time_this_iter_s: 17.904409408569336\n",
+      "  time_total_s: 93.97231364250183\n",
+      "  timers:\n",
+      "    learn_throughput: 6782.867\n",
+      "    learn_time_ms: 11926.519\n",
+      "    sample_throughput: 11904.351\n",
+      "    sample_time_ms: 6795.499\n",
+      "    update_time_ms: 34.942\n",
+      "  timestamp: 1602433021\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 404480\n",
+      "  training_iteration: 5\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      5 |          93.9723 | 404480 |  219.435 |              275.717 |              149.354 |            882.311 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3606.8284600389866\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-11_16-17-19\n",
+      "  done: false\n",
+      "  episode_len_mean: 877.4658869395712\n",
+      "  episode_reward_max: 275.7171717171716\n",
+      "  episode_reward_mean: 219.53104140823424\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 118\n",
+      "  episodes_total: 513\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.092801911490304\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.0062296149720038685\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016466571666699435\n",
+      "        total_loss: 56.3185304914202\n",
+      "        vf_explained_var: 0.9366416335105896\n",
+      "        vf_loss: 56.333861759730745\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.05500000000001\n",
+      "    gpu_util_percent0: 0.382\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.475\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12959529747481283\n",
+      "    mean_env_wait_ms: 0.6477971817067627\n",
+      "    mean_inference_ms: 5.182745401972663\n",
+      "    mean_raw_obs_processing_ms: 0.286488595152834\n",
+      "  time_since_restore: 111.8152723312378\n",
+      "  time_this_iter_s: 17.842958688735962\n",
+      "  time_total_s: 111.8152723312378\n",
+      "  timers:\n",
+      "    learn_throughput: 6796.691\n",
+      "    learn_time_ms: 11902.262\n",
+      "    sample_throughput: 12148.614\n",
+      "    sample_time_ms: 6658.867\n",
+      "    update_time_ms: 35.202\n",
+      "  timestamp: 1602433039\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 6\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      6 |          111.815 | 485376 |  219.531 |              275.717 |              149.354 |            877.466 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3600.9762658227846\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-11_16-17-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 872.1598101265823\n",
+      "  episode_reward_max: 275.7171717171716\n",
+      "  episode_reward_mean: 220.4177375015981\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 119\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.1184720993041992\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006490583797650678\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01627908361011318\n",
+      "        total_loss: 31.425927298409597\n",
+      "        vf_explained_var: 0.9506322145462036\n",
+      "        vf_loss: 31.44101824079241\n",
+      "    num_steps_sampled: 566272\n",
+      "    num_steps_trained: 566272\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.423809523809524\n",
+      "    gpu_util_percent0: 0.24952380952380956\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4809523809523806\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12828566444803613\n",
+      "    mean_env_wait_ms: 0.6478166533336334\n",
+      "    mean_inference_ms: 5.0918193072553635\n",
+      "    mean_raw_obs_processing_ms: 0.2829554308475049\n",
+      "  time_since_restore: 129.9019570350647\n",
+      "  time_this_iter_s: 18.086684703826904\n",
+      "  time_total_s: 129.9019570350647\n",
+      "  timers:\n",
+      "    learn_throughput: 6795.729\n",
+      "    learn_time_ms: 11903.948\n",
+      "    sample_throughput: 12297.469\n",
+      "    sample_time_ms: 6578.264\n",
+      "    update_time_ms: 35.836\n",
+      "  timestamp: 1602433057\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 566272\n",
+      "  training_iteration: 7\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      7 |          129.902 | 566272 |  220.418 |              275.717 |              149.354 |             872.16 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3596.4275668073137\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-11_16-17-55\n",
+      "  done: false\n",
+      "  episode_len_mean: 868.098452883263\n",
+      "  episode_reward_max: 275.7171717171716\n",
+      "  episode_reward_mean: 221.10693432212403\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 711\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.10015412739345\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006557688050504241\n",
+      "        model: {}\n",
+      "        policy_loss: -0.018214247721646513\n",
+      "        total_loss: 23.04970223563058\n",
+      "        vf_explained_var: 0.9621651768684387\n",
+      "        vf_loss: 23.066714423043386\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.91428571428571\n",
+      "    gpu_util_percent0: 0.27666666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1275760484783097\n",
+      "    mean_env_wait_ms: 0.6478968142099572\n",
+      "    mean_inference_ms: 5.042569339222437\n",
+      "    mean_raw_obs_processing_ms: 0.2810865791155001\n",
+      "  time_since_restore: 147.80396723747253\n",
+      "  time_this_iter_s: 17.902010202407837\n",
+      "  time_total_s: 147.80396723747253\n",
+      "  timers:\n",
+      "    learn_throughput: 6801.445\n",
+      "    learn_time_ms: 11893.944\n",
+      "    sample_throughput: 12433.85\n",
+      "    sample_time_ms: 6506.11\n",
+      "    update_time_ms: 36.165\n",
+      "  timestamp: 1602433075\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 8\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      8 |          147.804 | 647168 |  221.107 |              275.717 |              149.354 |            868.098 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3591.618987341772\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-11_16-18-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 863.7075949367089\n",
+      "  episode_reward_max: 275.7171717171716\n",
+      "  episode_reward_mean: 221.83550696841823\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.0786409548350744\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006580007595143148\n",
+      "        model: {}\n",
+      "        policy_loss: -0.018403502513787577\n",
+      "        total_loss: 22.735295704432897\n",
+      "        vf_explained_var: 0.9610903859138489\n",
+      "        vf_loss: 22.752492087227957\n",
+      "    num_steps_sampled: 728064\n",
+      "    num_steps_trained: 728064\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.928571428571427\n",
+      "    gpu_util_percent0: 0.26142857142857145\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12695482879374936\n",
+      "    mean_env_wait_ms: 0.6480843407701399\n",
+      "    mean_inference_ms: 4.999428668526167\n",
+      "    mean_raw_obs_processing_ms: 0.27942825537360366\n",
+      "  time_since_restore: 165.73263382911682\n",
+      "  time_this_iter_s: 17.928666591644287\n",
+      "  time_total_s: 165.73263382911682\n",
+      "  timers:\n",
+      "    learn_throughput: 6804.452\n",
+      "    learn_time_ms: 11888.687\n",
+      "    sample_throughput: 12556.493\n",
+      "    sample_time_ms: 6442.563\n",
+      "    update_time_ms: 36.573\n",
+      "  timestamp: 1602433093\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 728064\n",
+      "  training_iteration: 9\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |      9 |          165.733 | 728064 |  221.836 |              275.717 |              149.354 |            863.708 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3588.164212910532\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-11_16-18-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 859.8516421291054\n",
+      "  episode_reward_max: 275.7171717171716\n",
+      "  episode_reward_mean: 222.35895763981821\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 93\n",
+      "  episodes_total: 883\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.0437617642538888\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.007118354751063245\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017273931497974054\n",
+      "        total_loss: 26.358385358537948\n",
+      "        vf_explained_var: 0.9660363793373108\n",
+      "        vf_loss: 26.374339512416295\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.442857142857147\n",
+      "    gpu_util_percent0: 0.35190476190476194\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4809523809523806\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12631327428200384\n",
+      "    mean_env_wait_ms: 0.6485025433533471\n",
+      "    mean_inference_ms: 4.955339784300054\n",
+      "    mean_raw_obs_processing_ms: 0.2777230061320137\n",
+      "  time_since_restore: 183.98267531394958\n",
+      "  time_this_iter_s: 18.250041484832764\n",
+      "  time_total_s: 183.98267531394958\n",
+      "  timers:\n",
+      "    learn_throughput: 6798.509\n",
+      "    learn_time_ms: 11899.079\n",
+      "    sample_throughput: 12607.726\n",
+      "    sample_time_ms: 6416.383\n",
+      "    update_time_ms: 36.159\n",
+      "  timestamp: 1602433112\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 10\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     10 |          183.983 | 808960 |  222.359 |              275.717 |              149.354 |            859.852 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3579.2076023391814\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-11_16-18-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 855.2738791423002\n",
+      "  episode_reward_max: 275.7171717171716\n",
+      "  episode_reward_mean: 223.71601984759866\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 143\n",
+      "  episodes_total: 1026\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.0532989501953125\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005947550958288568\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017168237029441764\n",
+      "        total_loss: 19.90403720310756\n",
+      "        vf_explained_var: 0.9746130108833313\n",
+      "        vf_loss: 19.920121056692942\n",
+      "    num_steps_sampled: 889856\n",
+      "    num_steps_trained: 889856\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.025000000000006\n",
+      "    gpu_util_percent0: 0.3265\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.475\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12550035463846962\n",
+      "    mean_env_wait_ms: 0.6490592316159273\n",
+      "    mean_inference_ms: 4.899542005270903\n",
+      "    mean_raw_obs_processing_ms: 0.275590835737541\n",
+      "  time_since_restore: 201.92880582809448\n",
+      "  time_this_iter_s: 17.946130514144897\n",
+      "  time_total_s: 201.92880582809448\n",
+      "  timers:\n",
+      "    learn_throughput: 6809.929\n",
+      "    learn_time_ms: 11879.125\n",
+      "    sample_throughput: 13139.535\n",
+      "    sample_time_ms: 6156.687\n",
+      "    update_time_ms: 33.649\n",
+      "  timestamp: 1602433130\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 889856\n",
+      "  training_iteration: 11\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     11 |          201.929 | 889856 |  223.716 |              275.717 |              149.354 |            855.274 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3575.6121157323687\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-11_16-19-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 852.746835443038\n",
+      "  episode_reward_max: 275.7171717171716\n",
+      "  episode_reward_mean: 224.26079054560057\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 80\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.0376896517617362\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006494693790695497\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017213530838489532\n",
+      "        total_loss: 15.385991505214147\n",
+      "        vf_explained_var: 0.9749676585197449\n",
+      "        vf_loss: 15.402009963989258\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.647619047619052\n",
+      "    gpu_util_percent0: 0.2523809523809524\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12511358324318259\n",
+      "    mean_env_wait_ms: 0.6493616281163671\n",
+      "    mean_inference_ms: 4.8731012510452\n",
+      "    mean_raw_obs_processing_ms: 0.27457766992040916\n",
+      "  time_since_restore: 219.99315357208252\n",
+      "  time_this_iter_s: 18.064347743988037\n",
+      "  time_total_s: 219.99315357208252\n",
+      "  timers:\n",
+      "    learn_throughput: 6821.55\n",
+      "    learn_time_ms: 11858.889\n",
+      "    sample_throughput: 13307.796\n",
+      "    sample_time_ms: 6078.843\n",
+      "    update_time_ms: 32.585\n",
+      "  timestamp: 1602433148\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 12\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     12 |          219.993 | 970752 |  224.261 |              275.717 |              149.354 |            852.747 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3571.8481012658226\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-11_16-19-26\n",
+      "  done: false\n",
+      "  episode_len_mean: 850.7628691983123\n",
+      "  episode_reward_max: 275.7171717171716\n",
+      "  episode_reward_mean: 224.83109576780456\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1185\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 1.019127641405378\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.007594235574028322\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01849585006545697\n",
+      "        total_loss: 14.956309591020856\n",
+      "        vf_explained_var: 0.9742900133132935\n",
+      "        vf_loss: 14.973388808114189\n",
+      "    num_steps_sampled: 1051648\n",
+      "    num_steps_trained: 1051648\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.109523809523814\n",
+      "    gpu_util_percent0: 0.21095238095238095\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12476645523409689\n",
+      "    mean_env_wait_ms: 0.6496467586134247\n",
+      "    mean_inference_ms: 4.849312962133114\n",
+      "    mean_raw_obs_processing_ms: 0.2736662153836395\n",
+      "  time_since_restore: 237.87757992744446\n",
+      "  time_this_iter_s: 17.88442635536194\n",
+      "  time_total_s: 237.87757992744446\n",
+      "  timers:\n",
+      "    learn_throughput: 6820.96\n",
+      "    learn_time_ms: 11859.915\n",
+      "    sample_throughput: 13383.561\n",
+      "    sample_time_ms: 6044.43\n",
+      "    update_time_ms: 32.91\n",
+      "  timestamp: 1602433166\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1051648\n",
+      "  training_iteration: 13\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     13 |          237.878 | 1051648 |  224.831 |              275.717 |              149.354 |            850.763 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3567.480407523511\n",
+      "    time_step_min: 3236\n",
+      "  date: 2020-10-11_16-19-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 848.564263322884\n",
+      "  episode_reward_max: 275.7171717171716\n",
+      "  episode_reward_mean: 225.49286754694268\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 91\n",
+      "  episodes_total: 1276\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.9859031098229545\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006209247945142644\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015815080343080417\n",
+      "        total_loss: 22.0059392111642\n",
+      "        vf_explained_var: 0.9709354043006897\n",
+      "        vf_loss: 22.02061108180455\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.1\n",
+      "    gpu_util_percent0: 0.2561904761904762\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12440590023740428\n",
+      "    mean_env_wait_ms: 0.6500161752138565\n",
+      "    mean_inference_ms: 4.824470182458269\n",
+      "    mean_raw_obs_processing_ms: 0.27270381848447495\n",
+      "  time_since_restore: 256.0939621925354\n",
+      "  time_this_iter_s: 18.216382265090942\n",
+      "  time_total_s: 256.0939621925354\n",
+      "  timers:\n",
+      "    learn_throughput: 6819.798\n",
+      "    learn_time_ms: 11861.934\n",
+      "    sample_throughput: 13351.452\n",
+      "    sample_time_ms: 6058.967\n",
+      "    update_time_ms: 33.426\n",
+      "  timestamp: 1602433184\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 14\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     14 |          256.094 | 1132544 |  225.493 |              275.717 |              149.354 |            848.564 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3559.1558533145276\n",
+      "    time_step_min: 3231\n",
+      "  date: 2020-10-11_16-20-02\n",
+      "  done: false\n",
+      "  episode_len_mean: 845.444287729196\n",
+      "  episode_reward_max: 276.47474747474723\n",
+      "  episode_reward_mean: 226.7541636392129\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 142\n",
+      "  episodes_total: 1418\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.9841553313391549\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006351638518806014\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016068647761130705\n",
+      "        total_loss: 18.397855486188615\n",
+      "        vf_explained_var: 0.977173924446106\n",
+      "        vf_loss: 18.41275133405413\n",
+      "    num_steps_sampled: 1213440\n",
+      "    num_steps_trained: 1213440\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.575000000000006\n",
+      "    gpu_util_percent0: 0.23499999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.475\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12391098352348277\n",
+      "    mean_env_wait_ms: 0.650553499448869\n",
+      "    mean_inference_ms: 4.790647346666216\n",
+      "    mean_raw_obs_processing_ms: 0.2714149181579573\n",
+      "  time_since_restore: 273.77138781547546\n",
+      "  time_this_iter_s: 17.677425622940063\n",
+      "  time_total_s: 273.77138781547546\n",
+      "  timers:\n",
+      "    learn_throughput: 6829.723\n",
+      "    learn_time_ms: 11844.697\n",
+      "    sample_throughput: 13356.997\n",
+      "    sample_time_ms: 6056.451\n",
+      "    update_time_ms: 30.306\n",
+      "  timestamp: 1602433202\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1213440\n",
+      "  training_iteration: 15\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     15 |          273.771 | 1213440 |  226.754 |              276.475 |              149.354 |            845.444 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3554.4263824117256\n",
+      "    time_step_min: 3231\n",
+      "  date: 2020-10-11_16-20-20\n",
+      "  done: false\n",
+      "  episode_len_mean: 843.487674883411\n",
+      "  episode_reward_max: 276.47474747474723\n",
+      "  episode_reward_mean: 227.47075013963746\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 83\n",
+      "  episodes_total: 1501\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.9706924217087882\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006457218434661627\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017864259225981578\n",
+      "        total_loss: 12.351537431989398\n",
+      "        vf_explained_var: 0.9794679284095764\n",
+      "        vf_loss: 12.368207114083427\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.05714285714286\n",
+      "    gpu_util_percent0: 0.2666666666666667\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12366096253505773\n",
+      "    mean_env_wait_ms: 0.6508345164140612\n",
+      "    mean_inference_ms: 4.773345365170736\n",
+      "    mean_raw_obs_processing_ms: 0.2707580912826306\n",
+      "  time_since_restore: 291.6409411430359\n",
+      "  time_this_iter_s: 17.869553327560425\n",
+      "  time_total_s: 291.6409411430359\n",
+      "  timers:\n",
+      "    learn_throughput: 6832.205\n",
+      "    learn_time_ms: 11840.395\n",
+      "    sample_throughput: 13338.974\n",
+      "    sample_time_ms: 6064.634\n",
+      "    update_time_ms: 30.189\n",
+      "  timestamp: 1602433220\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 16\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     16 |          291.641 | 1294336 |  227.471 |              276.475 |              149.354 |            843.488 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3549.3708860759493\n",
+      "    time_step_min: 3231\n",
+      "  date: 2020-10-11_16-20-38\n",
+      "  done: false\n",
+      "  episode_len_mean: 841.8506329113924\n",
+      "  episode_reward_max: 276.47474747474723\n",
+      "  episode_reward_mean: 228.23673443293686\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.9509219697543553\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.0061031510787350795\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01630664457167898\n",
+      "        total_loss: 13.894207954406738\n",
+      "        vf_explained_var: 0.975964367389679\n",
+      "        vf_loss: 13.909389223371234\n",
+      "    num_steps_sampled: 1375232\n",
+      "    num_steps_trained: 1375232\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.16190476190476\n",
+      "    gpu_util_percent0: 0.3095238095238096\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12343837132751707\n",
+      "    mean_env_wait_ms: 0.6510906399362479\n",
+      "    mean_inference_ms: 4.758010510979952\n",
+      "    mean_raw_obs_processing_ms: 0.27016668535832183\n",
+      "  time_since_restore: 309.67595911026\n",
+      "  time_this_iter_s: 18.03501796722412\n",
+      "  time_total_s: 309.67595911026\n",
+      "  timers:\n",
+      "    learn_throughput: 6832.998\n",
+      "    learn_time_ms: 11839.02\n",
+      "    sample_throughput: 13356.996\n",
+      "    sample_time_ms: 6056.452\n",
+      "    update_time_ms: 28.12\n",
+      "  timestamp: 1602433238\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1375232\n",
+      "  training_iteration: 17\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     17 |          309.676 | 1375232 |  228.237 |              276.475 |              149.354 |            841.851 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3543.2877526753864\n",
+      "    time_step_min: 3220\n",
+      "  date: 2020-10-11_16-20-56\n",
+      "  done: false\n",
+      "  episode_len_mean: 840.3252080856124\n",
+      "  episode_reward_max: 278.1414141414138\n",
+      "  episode_reward_mean: 229.15842131181006\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 102\n",
+      "  episodes_total: 1682\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.9166804041181292\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006260165612080267\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014970483524458749\n",
+      "        total_loss: 15.519641603742327\n",
+      "        vf_explained_var: 0.9795632362365723\n",
+      "        vf_loss: 15.533452033996582\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.885\n",
+      "    gpu_util_percent0: 0.24550000000000005\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12317131619295082\n",
+      "    mean_env_wait_ms: 0.6513984586795933\n",
+      "    mean_inference_ms: 4.739667866243492\n",
+      "    mean_raw_obs_processing_ms: 0.26945875896825744\n",
+      "  time_since_restore: 327.5367546081543\n",
+      "  time_this_iter_s: 17.860795497894287\n",
+      "  time_total_s: 327.5367546081543\n",
+      "  timers:\n",
+      "    learn_throughput: 6834.494\n",
+      "    learn_time_ms: 11836.429\n",
+      "    sample_throughput: 13356.865\n",
+      "    sample_time_ms: 6056.511\n",
+      "    update_time_ms: 26.021\n",
+      "  timestamp: 1602433256\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 18\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     18 |          327.537 | 1456128 |  229.158 |              278.141 |              149.354 |            840.325 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3536.5250965250966\n",
+      "    time_step_min: 3181\n",
+      "  date: 2020-10-11_16-21-14\n",
+      "  done: false\n",
+      "  episode_len_mean: 839.1671263099835\n",
+      "  episode_reward_max: 284.05050505050457\n",
+      "  episode_reward_mean: 230.1830661830661\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 131\n",
+      "  episodes_total: 1813\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.9101576294217791\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.0055511897163731715\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013219582049974374\n",
+      "        total_loss: 15.21727466583252\n",
+      "        vf_explained_var: 0.9794386625289917\n",
+      "        vf_loss: 15.22947461264474\n",
+      "    num_steps_sampled: 1537024\n",
+      "    num_steps_trained: 1537024\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.795238095238098\n",
+      "    gpu_util_percent0: 0.2866666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4809523809523806\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12286276401652159\n",
+      "    mean_env_wait_ms: 0.6517618829218221\n",
+      "    mean_inference_ms: 4.71866162159186\n",
+      "    mean_raw_obs_processing_ms: 0.2686600257587414\n",
+      "  time_since_restore: 345.5379207134247\n",
+      "  time_this_iter_s: 18.001166105270386\n",
+      "  time_total_s: 345.5379207134247\n",
+      "  timers:\n",
+      "    learn_throughput: 6833.207\n",
+      "    learn_time_ms: 11838.658\n",
+      "    sample_throughput: 13331.164\n",
+      "    sample_time_ms: 6068.187\n",
+      "    update_time_ms: 25.559\n",
+      "  timestamp: 1602433274\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1537024\n",
+      "  training_iteration: 19\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     19 |          345.538 | 1537024 |  230.183 |              284.051 |              149.354 |            839.167 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3532.4077004219407\n",
+      "    time_step_min: 3181\n",
+      "  date: 2020-10-11_16-21-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 838.5385021097046\n",
+      "  episode_reward_max: 284.05050505050457\n",
+      "  episode_reward_mean: 230.8069140774836\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 83\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8989295278276715\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006024706177413464\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016748275740870407\n",
+      "        total_loss: 8.856049401419503\n",
+      "        vf_explained_var: 0.985133707523346\n",
+      "        vf_loss: 8.87168298448835\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.2904761904762\n",
+      "    gpu_util_percent0: 0.27\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12269316854403324\n",
+      "    mean_env_wait_ms: 0.6519743856489882\n",
+      "    mean_inference_ms: 4.70681419425705\n",
+      "    mean_raw_obs_processing_ms: 0.26821655590462323\n",
+      "  time_since_restore: 363.4639821052551\n",
+      "  time_this_iter_s: 17.926061391830444\n",
+      "  time_total_s: 363.4639821052551\n",
+      "  timers:\n",
+      "    learn_throughput: 6843.975\n",
+      "    learn_time_ms: 11820.031\n",
+      "    sample_throughput: 13360.485\n",
+      "    sample_time_ms: 6054.87\n",
+      "    update_time_ms: 25.441\n",
+      "  timestamp: 1602433292\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 20\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     20 |          363.464 | 1617920 |  230.807 |              284.051 |              149.354 |            838.539 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3528.400506329114\n",
+      "    time_step_min: 3181\n",
+      "  date: 2020-10-11_16-21-50\n",
+      "  done: false\n",
+      "  episode_len_mean: 837.9822784810127\n",
+      "  episode_reward_max: 284.05050505050457\n",
+      "  episode_reward_mean: 231.41406469760892\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1975\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8814251933779035\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006353956514171192\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016337690276226828\n",
+      "        total_loss: 8.809574127197266\n",
+      "        vf_explained_var: 0.9844195246696472\n",
+      "        vf_loss: 8.824729646955218\n",
+      "    num_steps_sampled: 1698816\n",
+      "    num_steps_trained: 1698816\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.99000000000001\n",
+      "    gpu_util_percent0: 0.26549999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12253687669271257\n",
+      "    mean_env_wait_ms: 0.6521445343420229\n",
+      "    mean_inference_ms: 4.696037997486925\n",
+      "    mean_raw_obs_processing_ms: 0.26780478502415517\n",
+      "  time_since_restore: 381.23959612846375\n",
+      "  time_this_iter_s: 17.775614023208618\n",
+      "  time_total_s: 381.23959612846375\n",
+      "  timers:\n",
+      "    learn_throughput: 6850.451\n",
+      "    learn_time_ms: 11808.857\n",
+      "    sample_throughput: 13375.051\n",
+      "    sample_time_ms: 6048.276\n",
+      "    update_time_ms: 26.002\n",
+      "  timestamp: 1602433310\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1698816\n",
+      "  training_iteration: 21\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     21 |           381.24 | 1698816 |  231.414 |              284.051 |              149.354 |            837.982 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3524.522409638554\n",
+      "    time_step_min: 3181\n",
+      "  date: 2020-10-11_16-22-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 837.0515662650603\n",
+      "  episode_reward_max: 284.05050505050457\n",
+      "  episode_reward_mean: 232.0016551052695\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 100\n",
+      "  episodes_total: 2075\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8468929103442601\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.006101464320506368\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014634852497173207\n",
+      "        total_loss: 13.325916017804827\n",
+      "        vf_explained_var: 0.9815999865531921\n",
+      "        vf_loss: 13.339415413992745\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.580952380952382\n",
+      "    gpu_util_percent0: 0.31190476190476196\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12235089383127508\n",
+      "    mean_env_wait_ms: 0.6523542058186689\n",
+      "    mean_inference_ms: 4.683351063520958\n",
+      "    mean_raw_obs_processing_ms: 0.2673125083760541\n",
+      "  time_since_restore: 399.2973039150238\n",
+      "  time_this_iter_s: 18.05770778656006\n",
+      "  time_total_s: 399.2973039150238\n",
+      "  timers:\n",
+      "    learn_throughput: 6845.537\n",
+      "    learn_time_ms: 11817.335\n",
+      "    sample_throughput: 13396.713\n",
+      "    sample_time_ms: 6038.496\n",
+      "    update_time_ms: 26.119\n",
+      "  timestamp: 1602433328\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 22\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     22 |          399.297 | 1779712 |  232.002 |              284.051 |              149.354 |            837.052 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3520.280598368087\n",
+      "    time_step_min: 3181\n",
+      "  date: 2020-10-11_16-22-26\n",
+      "  done: false\n",
+      "  episode_len_mean: 836.0838621940163\n",
+      "  episode_reward_max: 284.05050505050457\n",
+      "  episode_reward_mean: 232.64435378261302\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 131\n",
+      "  episodes_total: 2206\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8442171726908002\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.0062143402839345595\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01575768951858793\n",
+      "        total_loss: 15.60951382773263\n",
+      "        vf_explained_var: 0.9803310036659241\n",
+      "        vf_loss: 15.624112946646553\n",
+      "    num_steps_sampled: 1860608\n",
+      "    num_steps_trained: 1860608\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 29.81904761904762\n",
+      "    gpu_util_percent0: 0.3495238095238095\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4809523809523806\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12212652245379878\n",
+      "    mean_env_wait_ms: 0.6525856242265216\n",
+      "    mean_inference_ms: 4.667880347689874\n",
+      "    mean_raw_obs_processing_ms: 0.2667260125902466\n",
+      "  time_since_restore: 417.2645218372345\n",
+      "  time_this_iter_s: 17.967217922210693\n",
+      "  time_total_s: 417.2645218372345\n",
+      "  timers:\n",
+      "    learn_throughput: 6853.638\n",
+      "    learn_time_ms: 11803.367\n",
+      "    sample_throughput: 13345.687\n",
+      "    sample_time_ms: 6061.584\n",
+      "    update_time_ms: 25.135\n",
+      "  timestamp: 1602433346\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1860608\n",
+      "  training_iteration: 23\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     23 |          417.265 | 1860608 |  232.644 |              284.051 |              149.354 |            836.084 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3516.2487996508075\n",
+      "    time_step_min: 3181\n",
+      "  date: 2020-10-11_16-22-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 835.2937581841991\n",
+      "  episode_reward_max: 284.05050505050457\n",
+      "  episode_reward_mean: 233.25523237614019\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 85\n",
+      "  episodes_total: 2291\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8486343026161194\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005781072724078383\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01596627783562456\n",
+      "        total_loss: 9.746046611240931\n",
+      "        vf_explained_var: 0.9830135703086853\n",
+      "        vf_loss: 9.760941914149694\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.376190476190487\n",
+      "    gpu_util_percent0: 0.3838095238095238\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1219983612056573\n",
+      "    mean_env_wait_ms: 0.6527434071832637\n",
+      "    mean_inference_ms: 4.658896681324457\n",
+      "    mean_raw_obs_processing_ms: 0.26638959910373616\n",
+      "  time_since_restore: 435.35903000831604\n",
+      "  time_this_iter_s: 18.094508171081543\n",
+      "  time_total_s: 435.35903000831604\n",
+      "  timers:\n",
+      "    learn_throughput: 6849.785\n",
+      "    learn_time_ms: 11810.006\n",
+      "    sample_throughput: 13389.983\n",
+      "    sample_time_ms: 6041.531\n",
+      "    update_time_ms: 25.961\n",
+      "  timestamp: 1602433364\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 24\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     24 |          435.359 | 1941504 |  233.255 |              284.051 |              149.354 |            835.294 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3512.595529312526\n",
+      "    time_step_min: 3181\n",
+      "  date: 2020-10-11_16-23-02\n",
+      "  done: false\n",
+      "  episode_len_mean: 834.419232391396\n",
+      "  episode_reward_max: 284.05050505050457\n",
+      "  episode_reward_mean: 233.80875818497074\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 80\n",
+      "  episodes_total: 2371\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8333808183670044\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005867979555789914\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01597744705421584\n",
+      "        total_loss: 9.252091816493444\n",
+      "        vf_explained_var: 0.9832115769386292\n",
+      "        vf_loss: 9.266979081290108\n",
+      "    num_steps_sampled: 2022400\n",
+      "    num_steps_trained: 2022400\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.7904761904762\n",
+      "    gpu_util_percent0: 0.24666666666666665\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12188093159795932\n",
+      "    mean_env_wait_ms: 0.6528875931644009\n",
+      "    mean_inference_ms: 4.65074909708012\n",
+      "    mean_raw_obs_processing_ms: 0.2660778839811452\n",
+      "  time_since_restore: 453.2706034183502\n",
+      "  time_this_iter_s: 17.91157341003418\n",
+      "  time_total_s: 453.2706034183502\n",
+      "  timers:\n",
+      "    learn_throughput: 6847.1\n",
+      "    learn_time_ms: 11814.637\n",
+      "    sample_throughput: 13351.853\n",
+      "    sample_time_ms: 6058.784\n",
+      "    update_time_ms: 27.431\n",
+      "  timestamp: 1602433382\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2022400\n",
+      "  training_iteration: 25\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     25 |          453.271 | 2022400 |  233.809 |              284.051 |              149.354 |            834.419 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3507.8851732473813\n",
+      "    time_step_min: 3181\n",
+      "  date: 2020-10-11_16-23-20\n",
+      "  done: false\n",
+      "  episode_len_mean: 832.9838839645447\n",
+      "  episode_reward_max: 284.05050505050457\n",
+      "  episode_reward_mean: 234.52244849787147\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 111\n",
+      "  episodes_total: 2482\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8008829014641898\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005799769623471158\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014681054593113783\n",
+      "        total_loss: 11.853715079171318\n",
+      "        vf_explained_var: 0.9833112359046936\n",
+      "        vf_loss: 11.867315701075963\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.104761904761908\n",
+      "    gpu_util_percent0: 0.27952380952380956\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12172447167281233\n",
+      "    mean_env_wait_ms: 0.6530839641954829\n",
+      "    mean_inference_ms: 4.64008255868639\n",
+      "    mean_raw_obs_processing_ms: 0.26565535913099086\n",
+      "  time_since_restore: 471.2589874267578\n",
+      "  time_this_iter_s: 17.988384008407593\n",
+      "  time_total_s: 471.2589874267578\n",
+      "  timers:\n",
+      "    learn_throughput: 6839.696\n",
+      "    learn_time_ms: 11827.426\n",
+      "    sample_throughput: 13352.685\n",
+      "    sample_time_ms: 6058.407\n",
+      "    update_time_ms: 25.87\n",
+      "  timestamp: 1602433400\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 26\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     26 |          471.259 | 2103296 |  234.522 |              284.051 |              149.354 |            832.984 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3502.5111281657714\n",
+      "    time_step_min: 3181\n",
+      "  date: 2020-10-11_16-23-38\n",
+      "  done: false\n",
+      "  episode_len_mean: 831.4370683039141\n",
+      "  episode_reward_max: 284.05050505050457\n",
+      "  episode_reward_mean: 235.33669775266085\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 124\n",
+      "  episodes_total: 2606\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.8017460022653852\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005671164553080287\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014465352753177285\n",
+      "        total_loss: 8.887888090951103\n",
+      "        vf_explained_var: 0.9866734743118286\n",
+      "        vf_loss: 8.901299612862724\n",
+      "    num_steps_sampled: 2184192\n",
+      "    num_steps_trained: 2184192\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.825\n",
+      "    gpu_util_percent0: 0.3435\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4850000000000003\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12156732403321287\n",
+      "    mean_env_wait_ms: 0.6532861211607012\n",
+      "    mean_inference_ms: 4.6290150078958066\n",
+      "    mean_raw_obs_processing_ms: 0.2652468964390611\n",
+      "  time_since_restore: 489.113144159317\n",
+      "  time_this_iter_s: 17.854156732559204\n",
+      "  time_total_s: 489.113144159317\n",
+      "  timers:\n",
+      "    learn_throughput: 6849.659\n",
+      "    learn_time_ms: 11810.223\n",
+      "    sample_throughput: 13342.226\n",
+      "    sample_time_ms: 6063.156\n",
+      "    update_time_ms: 26.04\n",
+      "  timestamp: 1602433418\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2184192\n",
+      "  training_iteration: 27\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     27 |          489.113 | 2184192 |  235.337 |              284.051 |              149.354 |            831.437 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3499.0528667163067\n",
+      "    time_step_min: 3181\n",
+      "  date: 2020-10-11_16-23-56\n",
+      "  done: false\n",
+      "  episode_len_mean: 830.5487714072971\n",
+      "  episode_reward_max: 284.05050505050457\n",
+      "  episode_reward_mean: 235.86067676015548\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 80\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.7950462784085955\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005771402269601822\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01582781528122723\n",
+      "        total_loss: 8.700923919677734\n",
+      "        vf_explained_var: 0.9843843579292297\n",
+      "        vf_loss: 8.715677533830915\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.099999999999994\n",
+      "    gpu_util_percent0: 0.28095238095238095\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12147265025706677\n",
+      "    mean_env_wait_ms: 0.6534144924872379\n",
+      "    mean_inference_ms: 4.6224064736646024\n",
+      "    mean_raw_obs_processing_ms: 0.26499446109715585\n",
+      "  time_since_restore: 507.1111900806427\n",
+      "  time_this_iter_s: 17.998045921325684\n",
+      "  time_total_s: 507.1111900806427\n",
+      "  timers:\n",
+      "    learn_throughput: 6850.595\n",
+      "    learn_time_ms: 11808.61\n",
+      "    sample_throughput: 13312.65\n",
+      "    sample_time_ms: 6076.626\n",
+      "    update_time_ms: 27.686\n",
+      "  timestamp: 1602433436\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 28\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     28 |          507.111 | 2265088 |  235.861 |              284.051 |              149.354 |            830.549 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3495.485755499459\n",
+      "    time_step_min: 3181\n",
+      "  date: 2020-10-11_16-24-14\n",
+      "  done: false\n",
+      "  episode_len_mean: 829.419401370357\n",
+      "  episode_reward_max: 284.05050505050457\n",
+      "  episode_reward_mean: 236.40114815664757\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 87\n",
+      "  episodes_total: 2773\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.7676581995827811\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.0057737694254943305\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016033925049539124\n",
+      "        total_loss: 8.688706806727819\n",
+      "        vf_explained_var: 0.9849727749824524\n",
+      "        vf_loss: 8.703662736075264\n",
+      "    num_steps_sampled: 2345984\n",
+      "    num_steps_trained: 2345984\n",
+      "  iterations_since_restore: 29\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.225000000000005\n",
+      "    gpu_util_percent0: 0.2625\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12136899684599552\n",
+      "    mean_env_wait_ms: 0.6535625623156652\n",
+      "    mean_inference_ms: 4.615496740040499\n",
+      "    mean_raw_obs_processing_ms: 0.26471858086588224\n",
+      "  time_since_restore: 524.9049787521362\n",
+      "  time_this_iter_s: 17.79378867149353\n",
+      "  time_total_s: 524.9049787521362\n",
+      "  timers:\n",
+      "    learn_throughput: 6857.319\n",
+      "    learn_time_ms: 11797.03\n",
+      "    sample_throughput: 13331.287\n",
+      "    sample_time_ms: 6068.131\n",
+      "    update_time_ms: 26.89\n",
+      "  timestamp: 1602433454\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2345984\n",
+      "  training_iteration: 29\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     29 |          524.905 | 2345984 |  236.401 |              284.051 |              149.354 |            829.419 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3490.869370917841\n",
+      "    time_step_min: 3181\n",
+      "  date: 2020-10-11_16-24-32\n",
+      "  done: false\n",
+      "  episode_len_mean: 827.9295290477827\n",
+      "  episode_reward_max: 284.05050505050457\n",
+      "  episode_reward_mean: 237.1006003659836\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 136\n",
+      "  episodes_total: 2909\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.754608290536063\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.0056725469683962205\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014731894646372114\n",
+      "        total_loss: 10.76213536943708\n",
+      "        vf_explained_var: 0.9853909611701965\n",
+      "        vf_loss: 10.775808334350586\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 30\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.371428571428574\n",
+      "    gpu_util_percent0: 0.2623809523809524\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12122488602374934\n",
+      "    mean_env_wait_ms: 0.6537992204560652\n",
+      "    mean_inference_ms: 4.605299970823488\n",
+      "    mean_raw_obs_processing_ms: 0.2643337813548178\n",
+      "  time_since_restore: 542.7597060203552\n",
+      "  time_this_iter_s: 17.854727268218994\n",
+      "  time_total_s: 542.7597060203552\n",
+      "  timers:\n",
+      "    learn_throughput: 6859.082\n",
+      "    learn_time_ms: 11793.998\n",
+      "    sample_throughput: 13340.167\n",
+      "    sample_time_ms: 6064.092\n",
+      "    update_time_ms: 25.739\n",
+      "  timestamp: 1602433472\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 30\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     30 |           542.76 | 2426880 |  237.101 |              284.051 |              149.354 |             827.93 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3488.1255829447036\n",
+      "    time_step_min: 3167\n",
+      "  date: 2020-10-11_16-24-51\n",
+      "  done: false\n",
+      "  episode_len_mean: 827.1465689540306\n",
+      "  episode_reward_max: 286.1717171717171\n",
+      "  episode_reward_mean: 237.51632581645902\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 93\n",
+      "  episodes_total: 3002\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.7502403259277344\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005389300108488117\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015990441931145533\n",
+      "        total_loss: 8.786728995186943\n",
+      "        vf_explained_var: 0.9851738214492798\n",
+      "        vf_loss: 8.801716668265206\n",
+      "    num_steps_sampled: 2507776\n",
+      "    num_steps_trained: 2507776\n",
+      "  iterations_since_restore: 31\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.41428571428571\n",
+      "    gpu_util_percent0: 0.3657142857142857\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12113321401035924\n",
+      "    mean_env_wait_ms: 0.6539503979829405\n",
+      "    mean_inference_ms: 4.598897069532904\n",
+      "    mean_raw_obs_processing_ms: 0.26409110198934116\n",
+      "  time_since_restore: 560.7473194599152\n",
+      "  time_this_iter_s: 17.987613439559937\n",
+      "  time_total_s: 560.7473194599152\n",
+      "  timers:\n",
+      "    learn_throughput: 6851.57\n",
+      "    learn_time_ms: 11806.929\n",
+      "    sample_throughput: 13324.93\n",
+      "    sample_time_ms: 6071.026\n",
+      "    update_time_ms: 26.328\n",
+      "  timestamp: 1602433491\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2507776\n",
+      "  training_iteration: 31\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     31 |          560.747 | 2507776 |  237.516 |              286.172 |              149.354 |            827.147 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3485.4686790003248\n",
+      "    time_step_min: 3167\n",
+      "  date: 2020-10-11_16-25-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 826.4852320675105\n",
+      "  episode_reward_max: 286.1717171717171\n",
+      "  episode_reward_mean: 237.91888702015282\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 3081\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.7436325294630868\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005975004219050918\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016552875034644136\n",
+      "        total_loss: 7.9364085878644675\n",
+      "        vf_explained_var: 0.9853001236915588\n",
+      "        vf_loss: 7.951840877532959\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 32\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.41904761904762\n",
+      "    gpu_util_percent0: 0.28428571428571425\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12105725915307468\n",
+      "    mean_env_wait_ms: 0.6540754170232392\n",
+      "    mean_inference_ms: 4.593636902182076\n",
+      "    mean_raw_obs_processing_ms: 0.2638873249083529\n",
+      "  time_since_restore: 578.7367494106293\n",
+      "  time_this_iter_s: 17.98942995071411\n",
+      "  time_total_s: 578.7367494106293\n",
+      "  timers:\n",
+      "    learn_throughput: 6855.226\n",
+      "    learn_time_ms: 11800.632\n",
+      "    sample_throughput: 13331.603\n",
+      "    sample_time_ms: 6067.988\n",
+      "    update_time_ms: 28.595\n",
+      "  timestamp: 1602433509\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 32\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     32 |          578.737 | 2588672 |  237.919 |              286.172 |              149.354 |            826.485 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3482.42893081761\n",
+      "    time_step_min: 3167\n",
+      "  date: 2020-10-11_16-25-27\n",
+      "  done: false\n",
+      "  episode_len_mean: 825.9084905660377\n",
+      "  episode_reward_max: 286.1717171717171\n",
+      "  episode_reward_mean: 238.3794549266247\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 99\n",
+      "  episodes_total: 3180\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.7142769013132367\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.005908405807401452\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01583481377123722\n",
+      "        total_loss: 8.07387890134539\n",
+      "        vf_explained_var: 0.9876317977905273\n",
+      "        vf_loss: 8.08860342843192\n",
+      "    num_steps_sampled: 2669568\n",
+      "    num_steps_trained: 2669568\n",
+      "  iterations_since_restore: 33\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.533333333333342\n",
+      "    gpu_util_percent0: 0.20523809523809522\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12096483136185682\n",
+      "    mean_env_wait_ms: 0.6542389904427562\n",
+      "    mean_inference_ms: 4.587449996773385\n",
+      "    mean_raw_obs_processing_ms: 0.2636353107501833\n",
+      "  time_since_restore: 596.7136299610138\n",
+      "  time_this_iter_s: 17.97688055038452\n",
+      "  time_total_s: 596.7136299610138\n",
+      "  timers:\n",
+      "    learn_throughput: 6851.096\n",
+      "    learn_time_ms: 11807.746\n",
+      "    sample_throughput: 13344.606\n",
+      "    sample_time_ms: 6062.075\n",
+      "    update_time_ms: 27.62\n",
+      "  timestamp: 1602433527\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2669568\n",
+      "  training_iteration: 33\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | RUNNING  | 172.17.0.4:25709 |     33 |          596.714 | 2669568 |  238.379 |              286.172 |              149.354 |            825.908 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_f5a8f_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3479.037730153939\n",
+      "    time_step_min: 3167\n",
+      "  date: 2020-10-11_16-25-45\n",
+      "  done: true\n",
+      "  episode_len_mean: 825.1364322366435\n",
+      "  episode_reward_max: 286.1717171717171\n",
+      "  episode_reward_mean: 238.8932732089991\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 133\n",
+      "  episodes_total: 3313\n",
+      "  experiment_id: 9ca8105c499c47c8a96ac59004499d6d\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.19999999999999998\n",
+      "        cur_lr: 5.000000000000001e-05\n",
+      "        entropy: 0.7120769960539681\n",
+      "        entropy_coeff: 0.00010000000000000002\n",
+      "        kl: 0.004977691253381116\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013245187367179565\n",
+      "        total_loss: 9.229144777570452\n",
+      "        vf_explained_var: 0.9872849583625793\n",
+      "        vf_loss: 9.241465432303292\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 34\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.757142857142867\n",
+      "    gpu_util_percent0: 0.2871428571428571\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.09732699245654314\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 25709\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12084952624888429\n",
+      "    mean_env_wait_ms: 0.6544306434885966\n",
+      "    mean_inference_ms: 4.579308231399524\n",
+      "    mean_raw_obs_processing_ms: 0.2633344225374542\n",
+      "  time_since_restore: 614.8885405063629\n",
+      "  time_this_iter_s: 18.17491054534912\n",
+      "  time_total_s: 614.8885405063629\n",
+      "  timers:\n",
+      "    learn_throughput: 6849.811\n",
+      "    learn_time_ms: 11809.961\n",
+      "    sample_throughput: 13333.898\n",
+      "    sample_time_ms: 6066.943\n",
+      "    update_time_ms: 28.07\n",
+      "  timestamp: 1602433545\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 34\n",
+      "  trial_id: f5a8f_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | TERMINATED |       |     34 |          614.889 | 2750464 |  238.893 |              286.172 |              149.354 |            825.136 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_f5a8f_00000 | TERMINATED |       |     34 |          614.889 | 2750464 |  238.893 |              286.172 |              149.354 |            825.136 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Traceback (most recent call last):\n",
+      "  File \"train.py\", line 72, in <module>\n",
+      "    train_func()\n",
+      "  File \"train.py\", line 57, in train_func\n",
+      "    result = analysis.dataframe().to_dict('index')[0]\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 89, in dataframe\n",
+      "    metric = self._validate_metric(metric)\n",
+      "  File \"/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py\", line 64, in _validate_metric\n",
+      "    raise ValueError(\n",
+      "ValueError: No `metric` has been passed and  `default_metric` has not been set. Please specify the `metric` parameter.\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 25466\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program failed with code 1.  Press ctrl-c to abort syncing.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_161515-55q7t0lv/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_161515-55q7t0lv/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdrawn-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/55q7t0lv\u001b[0m\n",
+      "2020-10-11 16:25:54,983 - wandb.wandb_agent - INFO - Cleaning up finished run: 55q7t0lv\n",
+      "2020-10-11 16:25:55,313 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-11 16:25:55,313 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tnum_envs_per_worker: 1\n",
+      "\trollout_fragment_length: 1024\n",
+      "\tsgd_minibatch_size: 18384\n",
+      "2020-10-11 16:25:55,316 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --num_envs_per_worker=1 --rollout_fragment_length=1024 --sgd_minibatch_size=18384\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-11 16:26:00,335 - wandb.wandb_agent - INFO - Running runs: ['uxm9v59j']\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmagic-sweep-4\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/gd9q4pbz\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/uxm9v59j\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_162557-uxm9v59j\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
+      "\n",
+      "2020-10-11 16:26:01,173\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "== Status ==\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+-------+\n",
+      "| Trial name              | status   | loc   |\n",
+      "|-------------------------+----------+-------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  |       |\n",
+      "+-------------------------+----------+-------+\n",
+      "\n",
+      "\n",
+      "\u001b[2m\u001b[36m(pid=61121)\u001b[0m 2020-10-11 16:26:04,041\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=61029)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61029)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61043)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61043)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61046)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61046)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61086)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61086)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61030)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61030)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61108)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61108)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61104)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61104)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61129)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61129)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61115)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61115)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61136)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61136)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61015)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61015)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61131)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61131)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61095)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61095)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61025)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61025)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61088)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61088)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61074)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61074)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61080)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61080)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61109)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61109)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61119)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61119)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61132)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61132)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61035)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61035)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61117)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61117)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61126)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61126)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61106)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61106)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61077)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61077)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61100)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61100)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61091)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61091)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61038)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61038)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61026)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61026)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61090)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61090)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61011)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61011)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61013)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61013)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61028)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61028)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61116)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61116)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61016)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61016)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61032)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61032)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61079)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61079)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61045)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61045)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61031)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61031)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61022)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61022)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61014)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61014)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61112)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61112)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61020)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61020)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61023)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61023)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61018)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61018)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61113)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61113)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61033)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61033)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61081)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61081)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61012)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61012)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61021)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61021)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61110)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61110)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61040)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61040)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61089)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61089)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61087)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61087)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61102)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61102)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61048)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61048)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61017)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61017)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61107)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61107)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61037)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61037)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61027)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61027)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61071)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61071)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61097)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61097)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61039)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61039)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61092)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61092)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=61093)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=61093)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3604.8101265822784\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_16-26-29\n",
+      "  done: false\n",
+      "  episode_len_mean: 891.0759493670886\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 219.83684950773548\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 79\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1821814060211182\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005178337823599577\n",
+      "        model: {}\n",
+      "        policy_loss: -0.008954001311212777\n",
+      "        total_loss: 598.7196044921875\n",
+      "        vf_explained_var: 0.23389902710914612\n",
+      "        vf_loss: 598.7276489257813\n",
+      "    num_steps_sampled: 80896\n",
+      "    num_steps_trained: 80896\n",
+      "  iterations_since_restore: 1\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 37.26521739130435\n",
+      "    gpu_util_percent0: 0.34043478260869564\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.3260869565217397\n",
+      "    vram_util_percent0: 0.08697434654270111\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.14098399728490604\n",
+      "    mean_env_wait_ms: 0.6503997359904437\n",
+      "    mean_inference_ms: 6.135537582402172\n",
+      "    mean_raw_obs_processing_ms: 0.3147314418499467\n",
+      "  time_since_restore: 19.96707534790039\n",
+      "  time_this_iter_s: 19.96707534790039\n",
+      "  time_total_s: 19.96707534790039\n",
+      "  timers:\n",
+      "    learn_throughput: 7329.195\n",
+      "    learn_time_ms: 11037.501\n",
+      "    sample_throughput: 9113.969\n",
+      "    sample_time_ms: 8876.046\n",
+      "    update_time_ms: 22.126\n",
+      "  timestamp: 1602433589\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 80896\n",
+      "  training_iteration: 1\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 25.7/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |    ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      1 |          19.9671 | 80896 |  219.837 |              273.444 |              149.354 |            891.076 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+-------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4070\n",
+      "    time_step_mean: 3613.8734177215188\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_16-26-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 890.2088607594936\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 218.46362357754748\n",
+      "  episode_reward_min: 149.35353535353508\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 158\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1610076427459717\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005721182934939862\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010106014460325241\n",
+      "        total_loss: 247.57249755859374\n",
+      "        vf_explained_var: 0.652772068977356\n",
+      "        vf_loss: 247.58157653808593\n",
+      "    num_steps_sampled: 161792\n",
+      "    num_steps_trained: 161792\n",
+      "  iterations_since_restore: 2\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.68095238095238\n",
+      "    gpu_util_percent0: 0.24428571428571427\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4666666666666672\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1367699090573646\n",
+      "    mean_env_wait_ms: 0.6473635573763007\n",
+      "    mean_inference_ms: 5.847798019074019\n",
+      "    mean_raw_obs_processing_ms: 0.3044004033168521\n",
+      "  time_since_restore: 37.92630052566528\n",
+      "  time_this_iter_s: 17.959225177764893\n",
+      "  time_total_s: 37.92630052566528\n",
+      "  timers:\n",
+      "    learn_throughput: 7374.544\n",
+      "    learn_time_ms: 10969.627\n",
+      "    sample_throughput: 10255.278\n",
+      "    sample_time_ms: 7888.231\n",
+      "    update_time_ms: 29.399\n",
+      "  timestamp: 1602433607\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 161792\n",
+      "  training_iteration: 2\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      2 |          37.9263 | 161792 |  218.464 |              273.444 |              149.354 |            890.209 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3614.9113924050635\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_16-27-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 888.590717299578\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 218.30635468610134\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 237\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.159032130241394\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0057226565666496755\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01224328400567174\n",
+      "        total_loss: 104.11964721679688\n",
+      "        vf_explained_var: 0.8229959607124329\n",
+      "        vf_loss: 104.13086395263672\n",
+      "    num_steps_sampled: 242688\n",
+      "    num_steps_trained: 242688\n",
+      "  iterations_since_restore: 3\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.39\n",
+      "    gpu_util_percent0: 0.35550000000000004\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.13413430262435888\n",
+      "    mean_env_wait_ms: 0.645414029757357\n",
+      "    mean_inference_ms: 5.638892347495418\n",
+      "    mean_raw_obs_processing_ms: 0.29784452198874656\n",
+      "  time_since_restore: 55.47215390205383\n",
+      "  time_this_iter_s: 17.54585337638855\n",
+      "  time_total_s: 55.47215390205383\n",
+      "  timers:\n",
+      "    learn_throughput: 7380.249\n",
+      "    learn_time_ms: 10961.147\n",
+      "    sample_throughput: 10878.676\n",
+      "    sample_time_ms: 7436.199\n",
+      "    update_time_ms: 31.95\n",
+      "  timestamp: 1602433624\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 242688\n",
+      "  training_iteration: 3\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      3 |          55.4722 | 242688 |  218.306 |              273.444 |               146.02 |            888.591 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3604.6075949367087\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_16-27-22\n",
+      "  done: false\n",
+      "  episode_len_mean: 886.3354430379746\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 219.86753612070044\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 316\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.142055583000183\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006965293735265732\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013879792392253875\n",
+      "        total_loss: 68.49144897460937\n",
+      "        vf_explained_var: 0.8709942698478699\n",
+      "        vf_loss: 68.504052734375\n",
+      "    num_steps_sampled: 323584\n",
+      "    num_steps_trained: 323584\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.025\n",
+      "    gpu_util_percent0: 0.3430000000000001\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.13222634804207714\n",
+      "    mean_env_wait_ms: 0.6442073777421974\n",
+      "    mean_inference_ms: 5.483053264492972\n",
+      "    mean_raw_obs_processing_ms: 0.29300762395835384\n",
+      "  time_since_restore: 72.73297452926636\n",
+      "  time_this_iter_s: 17.260820627212524\n",
+      "  time_total_s: 72.73297452926636\n",
+      "  timers:\n",
+      "    learn_throughput: 7378.992\n",
+      "    learn_time_ms: 10963.015\n",
+      "    sample_throughput: 11342.711\n",
+      "    sample_time_ms: 7131.981\n",
+      "    update_time_ms: 33.251\n",
+      "  timestamp: 1602433642\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 323584\n",
+      "  training_iteration: 4\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      4 |           72.733 | 323584 |  219.868 |              273.444 |               146.02 |            886.335 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3599.4151898734176\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_16-27-39\n",
+      "  done: false\n",
+      "  episode_len_mean: 884.0708860759494\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 220.6542641605931\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 395\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1255623817443847\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006865937076508999\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0142045047134161\n",
+      "        total_loss: 57.66709518432617\n",
+      "        vf_explained_var: 0.8982939720153809\n",
+      "        vf_loss: 57.68003768920899\n",
+      "    num_steps_sampled: 404480\n",
+      "    num_steps_trained: 404480\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 33.31052631578948\n",
+      "    gpu_util_percent0: 0.3789473684210526\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.13073350551274238\n",
+      "    mean_env_wait_ms: 0.6435351135109532\n",
+      "    mean_inference_ms: 5.3628082783487665\n",
+      "    mean_raw_obs_processing_ms: 0.2890854961303385\n",
+      "  time_since_restore: 89.73851156234741\n",
+      "  time_this_iter_s: 17.005537033081055\n",
+      "  time_total_s: 89.73851156234741\n",
+      "  timers:\n",
+      "    learn_throughput: 7381.18\n",
+      "    learn_time_ms: 10959.765\n",
+      "    sample_throughput: 11718.685\n",
+      "    sample_time_ms: 6903.163\n",
+      "    update_time_ms: 33.944\n",
+      "  timestamp: 1602433659\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 404480\n",
+      "  training_iteration: 5\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      5 |          89.7385 | 404480 |  220.654 |              273.444 |               146.02 |            884.071 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3588.4762808349146\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_16-27-56\n",
+      "  done: false\n",
+      "  episode_len_mean: 876.9468690702088\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 222.31167462097235\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 132\n",
+      "  episodes_total: 527\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1013608694076538\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006304158177226782\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016743747983127832\n",
+      "        total_loss: 61.22104263305664\n",
+      "        vf_explained_var: 0.9264847636222839\n",
+      "        vf_loss: 61.23663177490234\n",
+      "    num_steps_sampled: 485376\n",
+      "    num_steps_trained: 485376\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.909999999999997\n",
+      "    gpu_util_percent0: 0.29600000000000004\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4799999999999995\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12892989278774483\n",
+      "    mean_env_wait_ms: 0.6439252620955168\n",
+      "    mean_inference_ms: 5.217598169319564\n",
+      "    mean_raw_obs_processing_ms: 0.28441227899644844\n",
+      "  time_since_restore: 107.00913977622986\n",
+      "  time_this_iter_s: 17.270628213882446\n",
+      "  time_total_s: 107.00913977622986\n",
+      "  timers:\n",
+      "    learn_throughput: 7369.101\n",
+      "    learn_time_ms: 10977.729\n",
+      "    sample_throughput: 11940.558\n",
+      "    sample_time_ms: 6774.893\n",
+      "    update_time_ms: 34.153\n",
+      "  timestamp: 1602433676\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 485376\n",
+      "  training_iteration: 6\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      6 |          107.009 | 485376 |  222.312 |              273.444 |               146.02 |            876.947 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3579.4794303797466\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_16-28-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 872.9651898734177\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 223.67483378084626\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 105\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1148772478103637\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00640232590958476\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01414772029966116\n",
+      "        total_loss: 40.958674621582034\n",
+      "        vf_explained_var: 0.9319775700569153\n",
+      "        vf_loss: 40.97165451049805\n",
+      "    num_steps_sampled: 566272\n",
+      "    num_steps_trained: 566272\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.98\n",
+      "    gpu_util_percent0: 0.263\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4799999999999995\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12790341844197173\n",
+      "    mean_env_wait_ms: 0.6437003581697455\n",
+      "    mean_inference_ms: 5.136787395294866\n",
+      "    mean_raw_obs_processing_ms: 0.28171729219255803\n",
+      "  time_since_restore: 124.0984423160553\n",
+      "  time_this_iter_s: 17.08930253982544\n",
+      "  time_total_s: 124.0984423160553\n",
+      "  timers:\n",
+      "    learn_throughput: 7377.592\n",
+      "    learn_time_ms: 10965.095\n",
+      "    sample_throughput: 12106.989\n",
+      "    sample_time_ms: 6681.761\n",
+      "    update_time_ms: 34.781\n",
+      "  timestamp: 1602433693\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 566272\n",
+      "  training_iteration: 7\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      7 |          124.098 | 566272 |  223.675 |              273.444 |               146.02 |            872.965 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3571.4486638537273\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_16-28-30\n",
+      "  done: false\n",
+      "  episode_len_mean: 869.395218002813\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 224.891616587819\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 711\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0891266345977784\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006864890549331903\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012392168352380394\n",
+      "        total_loss: 29.909460067749023\n",
+      "        vf_explained_var: 0.9454657435417175\n",
+      "        vf_loss: 29.92058868408203\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.326315789473693\n",
+      "    gpu_util_percent0: 0.2757894736842105\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12726324582919984\n",
+      "    mean_env_wait_ms: 0.643819807986483\n",
+      "    mean_inference_ms: 5.085353953921927\n",
+      "    mean_raw_obs_processing_ms: 0.28001263883160427\n",
+      "  time_since_restore: 141.00454926490784\n",
+      "  time_this_iter_s: 16.90610694885254\n",
+      "  time_total_s: 141.00454926490784\n",
+      "  timers:\n",
+      "    learn_throughput: 7379.784\n",
+      "    learn_time_ms: 10961.838\n",
+      "    sample_throughput: 12286.631\n",
+      "    sample_time_ms: 6584.067\n",
+      "    update_time_ms: 34.566\n",
+      "  timestamp: 1602433710\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 8\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      8 |          141.005 | 647168 |  224.892 |              273.444 |               146.02 |            869.395 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3564.345569620253\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_16-28-47\n",
+      "  done: false\n",
+      "  episode_len_mean: 866.1582278481013\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 225.96784298683022\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0771050453186035\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006526902969926596\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0148372957482934\n",
+      "        total_loss: 26.008992385864257\n",
+      "        vf_explained_var: 0.9503160715103149\n",
+      "        vf_loss: 26.0226318359375\n",
+      "    num_steps_sampled: 728064\n",
+      "    num_steps_trained: 728064\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.05263157894737\n",
+      "    gpu_util_percent0: 0.3431578947368421\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12670080580046472\n",
+      "    mean_env_wait_ms: 0.6439832765656371\n",
+      "    mean_inference_ms: 5.039983960032047\n",
+      "    mean_raw_obs_processing_ms: 0.2784847809173593\n",
+      "  time_since_restore: 157.93700242042542\n",
+      "  time_this_iter_s: 16.932453155517578\n",
+      "  time_total_s: 157.93700242042542\n",
+      "  timers:\n",
+      "    learn_throughput: 7378.034\n",
+      "    learn_time_ms: 10964.438\n",
+      "    sample_throughput: 12434.892\n",
+      "    sample_time_ms: 6505.565\n",
+      "    update_time_ms: 34.362\n",
+      "  timestamp: 1602433727\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 728064\n",
+      "  training_iteration: 9\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |      9 |          157.937 | 728064 |  225.968 |              273.444 |               146.02 |            866.158 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3557.8855835240274\n",
+      "    time_step_min: 3251\n",
+      "  date: 2020-10-11_16-29-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 862.9096109839817\n",
+      "  episode_reward_max: 273.4444444444444\n",
+      "  episode_reward_mean: 226.94662875898564\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 84\n",
+      "  episodes_total: 874\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0427801609039307\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006021166313439607\n",
+      "        model: {}\n",
+      "        policy_loss: -0.010975334793329239\n",
+      "        total_loss: 26.823484039306642\n",
+      "        vf_explained_var: 0.9570068120956421\n",
+      "        vf_loss: 26.833358764648438\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.763157894736842\n",
+      "    gpu_util_percent0: 0.27473684210526317\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.478947368421052\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1261609020467685\n",
+      "    mean_env_wait_ms: 0.644256949020595\n",
+      "    mean_inference_ms: 4.997260628493306\n",
+      "    mean_raw_obs_processing_ms: 0.27703591018381557\n",
+      "  time_since_restore: 174.87086534500122\n",
+      "  time_this_iter_s: 16.933862924575806\n",
+      "  time_total_s: 174.87086534500122\n",
+      "  timers:\n",
+      "    learn_throughput: 7374.023\n",
+      "    learn_time_ms: 10970.402\n",
+      "    sample_throughput: 12560.425\n",
+      "    sample_time_ms: 6440.547\n",
+      "    update_time_ms: 32.9\n",
+      "  timestamp: 1602433744\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 10\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     10 |          174.871 | 808960 |  226.947 |              273.444 |               146.02 |             862.91 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3546.17738791423\n",
+      "    time_step_min: 3229\n",
+      "  date: 2020-10-11_16-29-21\n",
+      "  done: false\n",
+      "  episode_len_mean: 856.958089668616\n",
+      "  episode_reward_max: 276.77777777777794\n",
+      "  episode_reward_mean: 228.72059779077313\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 152\n",
+      "  episodes_total: 1026\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.047643208503723\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0061458229087293145\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012535271141678095\n",
+      "        total_loss: 28.427783584594728\n",
+      "        vf_explained_var: 0.9625579118728638\n",
+      "        vf_loss: 28.439194107055663\n",
+      "    num_steps_sampled: 889856\n",
+      "    num_steps_trained: 889856\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.94000000000001\n",
+      "    gpu_util_percent0: 0.28300000000000003\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.475\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12537372726315876\n",
+      "    mean_env_wait_ms: 0.6449531962595608\n",
+      "    mean_inference_ms: 4.93422262579392\n",
+      "    mean_raw_obs_processing_ms: 0.2749005239350073\n",
+      "  time_since_restore: 191.87603378295898\n",
+      "  time_this_iter_s: 17.005168437957764\n",
+      "  time_total_s: 191.87603378295898\n",
+      "  timers:\n",
+      "    learn_throughput: 7376.233\n",
+      "    learn_time_ms: 10967.116\n",
+      "    sample_throughput: 13164.584\n",
+      "    sample_time_ms: 6144.972\n",
+      "    update_time_ms: 34.87\n",
+      "  timestamp: 1602433761\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 889856\n",
+      "  training_iteration: 11\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.1/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     11 |          191.876 | 889856 |  228.721 |              276.778 |               146.02 |            856.958 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3537.3589511754067\n",
+      "    time_step_min: 3229\n",
+      "  date: 2020-10-11_16-29-38\n",
+      "  done: false\n",
+      "  episode_len_mean: 853.8372513562387\n",
+      "  episode_reward_max: 276.77777777777794\n",
+      "  episode_reward_mean: 230.0567245693827\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 80\n",
+      "  episodes_total: 1106\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.029042935371399\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006281163450330496\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015307414811104536\n",
+      "        total_loss: 15.060502815246583\n",
+      "        vf_explained_var: 0.9696897268295288\n",
+      "        vf_loss: 15.074656867980957\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.42105263157895\n",
+      "    gpu_util_percent0: 0.4105263157894737\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12502306966866958\n",
+      "    mean_env_wait_ms: 0.6452948919573521\n",
+      "    mean_inference_ms: 4.906176534092823\n",
+      "    mean_raw_obs_processing_ms: 0.2739435716455957\n",
+      "  time_since_restore: 208.82465434074402\n",
+      "  time_this_iter_s: 16.948620557785034\n",
+      "  time_total_s: 208.82465434074402\n",
+      "  timers:\n",
+      "    learn_throughput: 7369.215\n",
+      "    learn_time_ms: 10977.56\n",
+      "    sample_throughput: 13389.541\n",
+      "    sample_time_ms: 6041.731\n",
+      "    update_time_ms: 34.692\n",
+      "  timestamp: 1602433778\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 12\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     12 |          208.825 | 970752 |  230.057 |              276.778 |               146.02 |            853.837 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3530.604219409283\n",
+      "    time_step_min: 3225\n",
+      "  date: 2020-10-11_16-29-55\n",
+      "  done: false\n",
+      "  episode_len_mean: 851.1873417721519\n",
+      "  episode_reward_max: 277.38383838383817\n",
+      "  episode_reward_mean: 231.0801687763712\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1185\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.020499587059021\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0058583361096680164\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014010852668434381\n",
+      "        total_loss: 17.26035079956055\n",
+      "        vf_explained_var: 0.9643712043762207\n",
+      "        vf_loss: 17.273291778564452\n",
+      "    num_steps_sampled: 1051648\n",
+      "    num_steps_trained: 1051648\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.90526315789474\n",
+      "    gpu_util_percent0: 0.27631578947368424\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1247077601096726\n",
+      "    mean_env_wait_ms: 0.6456171996062807\n",
+      "    mean_inference_ms: 4.88091950153211\n",
+      "    mean_raw_obs_processing_ms: 0.27306084750810783\n",
+      "  time_since_restore: 225.67816257476807\n",
+      "  time_this_iter_s: 16.853508234024048\n",
+      "  time_total_s: 225.67816257476807\n",
+      "  timers:\n",
+      "    learn_throughput: 7370.749\n",
+      "    learn_time_ms: 10975.276\n",
+      "    sample_throughput: 13537.832\n",
+      "    sample_time_ms: 5975.551\n",
+      "    update_time_ms: 33.247\n",
+      "  timestamp: 1602433795\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1051648\n",
+      "  training_iteration: 13\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     13 |          225.678 | 1051648 |   231.08 |              277.384 |               146.02 |            851.187 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3522.7099296325255\n",
+      "    time_step_min: 3184\n",
+      "  date: 2020-10-11_16-30-12\n",
+      "  done: false\n",
+      "  episode_len_mean: 848.0969507427678\n",
+      "  episode_reward_max: 283.59595959595947\n",
+      "  episode_reward_mean: 232.27627328800114\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 94\n",
+      "  episodes_total: 1279\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.988058340549469\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006182871200144291\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014513058867305518\n",
+      "        total_loss: 22.752033996582032\n",
+      "        vf_explained_var: 0.9629007577896118\n",
+      "        vf_loss: 22.76541061401367\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.43500000000001\n",
+      "    gpu_util_percent0: 0.2615\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12436254057564351\n",
+      "    mean_env_wait_ms: 0.6461020970423146\n",
+      "    mean_inference_ms: 4.853592419273776\n",
+      "    mean_raw_obs_processing_ms: 0.27210988741028075\n",
+      "  time_since_restore: 242.62031650543213\n",
+      "  time_this_iter_s: 16.942153930664062\n",
+      "  time_total_s: 242.62031650543213\n",
+      "  timers:\n",
+      "    learn_throughput: 7375.065\n",
+      "    learn_time_ms: 10968.852\n",
+      "    sample_throughput: 13597.7\n",
+      "    sample_time_ms: 5949.242\n",
+      "    update_time_ms: 33.29\n",
+      "  timestamp: 1602433812\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 14\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     14 |           242.62 | 1132544 |  232.276 |              283.596 |               146.02 |            848.097 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3513.834739803094\n",
+      "    time_step_min: 3184\n",
+      "  date: 2020-10-11_16-30-29\n",
+      "  done: false\n",
+      "  episode_len_mean: 843.6962025316456\n",
+      "  episode_reward_max: 283.59595959595947\n",
+      "  episode_reward_mean: 233.62099901973312\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 143\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9878270983695984\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005273265577852726\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01443924605846405\n",
+      "        total_loss: 19.540371704101563\n",
+      "        vf_explained_var: 0.9709212183952332\n",
+      "        vf_loss: 19.55385627746582\n",
+      "    num_steps_sampled: 1213440\n",
+      "    num_steps_trained: 1213440\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.763157894736842\n",
+      "    gpu_util_percent0: 0.33473684210526317\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.478947368421052\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12391073808355933\n",
+      "    mean_env_wait_ms: 0.6467882051144439\n",
+      "    mean_inference_ms: 4.81757522324978\n",
+      "    mean_raw_obs_processing_ms: 0.2708519663997358\n",
+      "  time_since_restore: 259.55595803260803\n",
+      "  time_this_iter_s: 16.935641527175903\n",
+      "  time_total_s: 259.55595803260803\n",
+      "  timers:\n",
+      "    learn_throughput: 7377.326\n",
+      "    learn_time_ms: 10965.491\n",
+      "    sample_throughput: 13609.618\n",
+      "    sample_time_ms: 5944.032\n",
+      "    update_time_ms: 33.054\n",
+      "  timestamp: 1602433829\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1213440\n",
+      "  training_iteration: 15\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     15 |          259.556 | 1213440 |  233.621 |              283.596 |               146.02 |            843.696 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3507.775483011326\n",
+      "    time_step_min: 3184\n",
+      "  date: 2020-10-11_16-30-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 841.0646235842771\n",
+      "  episode_reward_max: 283.59595959595947\n",
+      "  episode_reward_mean: 234.53906823060714\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1501\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.97277330160141\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005540623422712087\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01531378725776449\n",
+      "        total_loss: 12.622322082519531\n",
+      "        vf_explained_var: 0.9739503860473633\n",
+      "        vf_loss: 12.636624717712403\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.68\n",
+      "    gpu_util_percent0: 0.3145\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12368770892289047\n",
+      "    mean_env_wait_ms: 0.6471635713741419\n",
+      "    mean_inference_ms: 4.799930085863596\n",
+      "    mean_raw_obs_processing_ms: 0.2702354887858795\n",
+      "  time_since_restore: 276.57739901542664\n",
+      "  time_this_iter_s: 17.021440982818604\n",
+      "  time_total_s: 276.57739901542664\n",
+      "  timers:\n",
+      "    learn_throughput: 7379.887\n",
+      "    learn_time_ms: 10961.685\n",
+      "    sample_throughput: 13657.722\n",
+      "    sample_time_ms: 5923.096\n",
+      "    update_time_ms: 32.54\n",
+      "  timestamp: 1602433846\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 16\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     16 |          276.577 | 1294336 |  234.539 |              283.596 |               146.02 |            841.065 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3502.0474383301707\n",
+      "    time_step_min: 3167\n",
+      "  date: 2020-10-11_16-31-04\n",
+      "  done: false\n",
+      "  episode_len_mean: 838.7457305502846\n",
+      "  episode_reward_max: 286.1717171717169\n",
+      "  episode_reward_mean: 235.40695378835792\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 80\n",
+      "  episodes_total: 1581\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9531836867332458\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005672357883304358\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013997910264879464\n",
+      "        total_loss: 14.515528297424316\n",
+      "        vf_explained_var: 0.9702242016792297\n",
+      "        vf_loss: 14.528486824035644\n",
+      "    num_steps_sampled: 1375232\n",
+      "    num_steps_trained: 1375232\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.18421052631579\n",
+      "    gpu_util_percent0: 0.27999999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12347598325254748\n",
+      "    mean_env_wait_ms: 0.6475391807235957\n",
+      "    mean_inference_ms: 4.783241483975615\n",
+      "    mean_raw_obs_processing_ms: 0.2696401929180935\n",
+      "  time_since_restore: 293.35855436325073\n",
+      "  time_this_iter_s: 16.781155347824097\n",
+      "  time_total_s: 293.35855436325073\n",
+      "  timers:\n",
+      "    learn_throughput: 7383.637\n",
+      "    learn_time_ms: 10956.118\n",
+      "    sample_throughput: 13717.343\n",
+      "    sample_time_ms: 5897.352\n",
+      "    update_time_ms: 32.495\n",
+      "  timestamp: 1602433864\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1375232\n",
+      "  training_iteration: 17\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     17 |          293.359 | 1375232 |  235.407 |              286.172 |               146.02 |            838.746 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3492.5957200694043\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_16-31-20\n",
+      "  done: false\n",
+      "  episode_len_mean: 834.5801041064199\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 236.83903231271648\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 148\n",
+      "  episodes_total: 1729\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.926102340221405\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005256259627640247\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011589129082858562\n",
+      "        total_loss: 17.027903366088868\n",
+      "        vf_explained_var: 0.976334273815155\n",
+      "        vf_loss: 17.03853416442871\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.078947368421055\n",
+      "    gpu_util_percent0: 0.30736842105263157\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12312441460932014\n",
+      "    mean_env_wait_ms: 0.648343690032881\n",
+      "    mean_inference_ms: 4.755624730657635\n",
+      "    mean_raw_obs_processing_ms: 0.2686697171666438\n",
+      "  time_since_restore: 310.24891924858093\n",
+      "  time_this_iter_s: 16.8903648853302\n",
+      "  time_total_s: 310.24891924858093\n",
+      "  timers:\n",
+      "    learn_throughput: 7382.71\n",
+      "    learn_time_ms: 10957.494\n",
+      "    sample_throughput: 13726.563\n",
+      "    sample_time_ms: 5893.391\n",
+      "    update_time_ms: 32.684\n",
+      "  timestamp: 1602433880\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 18\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     18 |          310.249 | 1456128 |  236.839 |              288.899 |               146.02 |             834.58 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3488.034672537149\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_16-31-38\n",
+      "  done: false\n",
+      "  episode_len_mean: 832.3307649972483\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 237.53010012063393\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 88\n",
+      "  episodes_total: 1817\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9310240507125854\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005109604261815548\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01098379292525351\n",
+      "        total_loss: 14.388118743896484\n",
+      "        vf_explained_var: 0.9739601016044617\n",
+      "        vf_loss: 14.39817409515381\n",
+      "    num_steps_sampled: 1537024\n",
+      "    num_steps_trained: 1537024\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.665000000000003\n",
+      "    gpu_util_percent0: 0.3235\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12294127448875178\n",
+      "    mean_env_wait_ms: 0.6486993428048557\n",
+      "    mean_inference_ms: 4.740853319106202\n",
+      "    mean_raw_obs_processing_ms: 0.26813263802760673\n",
+      "  time_since_restore: 327.2235713005066\n",
+      "  time_this_iter_s: 16.97465205192566\n",
+      "  time_total_s: 327.2235713005066\n",
+      "  timers:\n",
+      "    learn_throughput: 7381.381\n",
+      "    learn_time_ms: 10959.466\n",
+      "    sample_throughput: 13738.498\n",
+      "    sample_time_ms: 5888.271\n",
+      "    update_time_ms: 39.048\n",
+      "  timestamp: 1602433898\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1537024\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     19 |          327.224 | 1537024 |   237.53 |              288.899 |               146.02 |            832.331 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3484.7273206751056\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_16-31-55\n",
+      "  done: false\n",
+      "  episode_len_mean: 830.3449367088608\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 238.03121403912542\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 1896\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9225889205932617\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005407916381955147\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014131060149520636\n",
+      "        total_loss: 14.700571441650391\n",
+      "        vf_explained_var: 0.9705582857131958\n",
+      "        vf_loss: 14.713712692260742\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.373684210526314\n",
+      "    gpu_util_percent0: 0.2631578947368421\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12278455012592983\n",
+      "    mean_env_wait_ms: 0.6490578024317554\n",
+      "    mean_inference_ms: 4.72843451159651\n",
+      "    mean_raw_obs_processing_ms: 0.26768106747298975\n",
+      "  time_since_restore: 344.2278187274933\n",
+      "  time_this_iter_s: 17.004247426986694\n",
+      "  time_total_s: 344.2278187274933\n",
+      "  timers:\n",
+      "    learn_throughput: 7378.816\n",
+      "    learn_time_ms: 10963.277\n",
+      "    sample_throughput: 13736.616\n",
+      "    sample_time_ms: 5889.078\n",
+      "    update_time_ms: 40.776\n",
+      "  timestamp: 1602433915\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     20 |          344.228 | 1617920 |  238.031 |              288.899 |               146.02 |            830.345 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3479.526524541398\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_16-32-12\n",
+      "  done: false\n",
+      "  episode_len_mean: 827.4918195339613\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 238.81921345332347\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 121\n",
+      "  episodes_total: 2017\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8949668288230896\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00522464383393526\n",
+      "        model: {}\n",
+      "        policy_loss: -0.015539329266175628\n",
+      "        total_loss: 16.214202308654784\n",
+      "        vf_explained_var: 0.9754984974861145\n",
+      "        vf_loss: 16.228786277770997\n",
+      "    num_steps_sampled: 1698816\n",
+      "    num_steps_trained: 1698816\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.69473684210527\n",
+      "    gpu_util_percent0: 0.33999999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1225520215946057\n",
+      "    mean_env_wait_ms: 0.6497088133943331\n",
+      "    mean_inference_ms: 4.710737726018366\n",
+      "    mean_raw_obs_processing_ms: 0.26705498019710205\n",
+      "  time_since_restore: 361.12535190582275\n",
+      "  time_this_iter_s: 16.897533178329468\n",
+      "  time_total_s: 361.12535190582275\n",
+      "  timers:\n",
+      "    learn_throughput: 7385.687\n",
+      "    learn_time_ms: 10953.077\n",
+      "    sample_throughput: 13738.814\n",
+      "    sample_time_ms: 5888.136\n",
+      "    update_time_ms: 40.739\n",
+      "  timestamp: 1602433932\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1698816\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     21 |          361.125 | 1698816 |  238.819 |              288.899 |               146.02 |            827.492 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3474.1439287388653\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_16-32-29\n",
+      "  done: false\n",
+      "  episode_len_mean: 825.413033286451\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 239.63475827188907\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 116\n",
+      "  episodes_total: 2133\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8959186911582947\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00528133912011981\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011150027438998223\n",
+      "        total_loss: 11.039695358276367\n",
+      "        vf_explained_var: 0.9806930422782898\n",
+      "        vf_loss: 11.04987850189209\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.763157894736842\n",
+      "    gpu_util_percent0: 0.3678947368421053\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.4842105263157896\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12236587347955238\n",
+      "    mean_env_wait_ms: 0.6501740845442628\n",
+      "    mean_inference_ms: 4.69544019947536\n",
+      "    mean_raw_obs_processing_ms: 0.26648938245529985\n",
+      "  time_since_restore: 378.08043003082275\n",
+      "  time_this_iter_s: 16.955078125\n",
+      "  time_total_s: 378.08043003082275\n",
+      "  timers:\n",
+      "    learn_throughput: 7380.602\n",
+      "    learn_time_ms: 10960.624\n",
+      "    sample_throughput: 13752.486\n",
+      "    sample_time_ms: 5882.282\n",
+      "    update_time_ms: 39.439\n",
+      "  timestamp: 1602433949\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     22 |           378.08 | 1779712 |  239.635 |              288.899 |               146.02 |            825.413 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3471.4570524412297\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_16-32-46\n",
+      "  done: false\n",
+      "  episode_len_mean: 824.0126582278481\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 240.0418607412278\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 79\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8983033895492554\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005707137286663055\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011461784783750772\n",
+      "        total_loss: 10.742603302001953\n",
+      "        vf_explained_var: 0.9777244329452515\n",
+      "        vf_loss: 10.753013420104981\n",
+      "    num_steps_sampled: 1860608\n",
+      "    num_steps_trained: 1860608\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.334999999999997\n",
+      "    gpu_util_percent0: 0.2815\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12224187395329024\n",
+      "    mean_env_wait_ms: 0.6505199073617374\n",
+      "    mean_inference_ms: 4.685692670587312\n",
+      "    mean_raw_obs_processing_ms: 0.26613615202034235\n",
+      "  time_since_restore: 394.8987329006195\n",
+      "  time_this_iter_s: 16.818302869796753\n",
+      "  time_total_s: 394.8987329006195\n",
+      "  timers:\n",
+      "    learn_throughput: 7383.038\n",
+      "    learn_time_ms: 10957.008\n",
+      "    sample_throughput: 13757.499\n",
+      "    sample_time_ms: 5880.138\n",
+      "    update_time_ms: 41.136\n",
+      "  timestamp: 1602433966\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1860608\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     23 |          394.899 | 1860608 |  240.042 |              288.899 |               146.02 |            824.013 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3468.180911062907\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_16-33-03\n",
+      "  done: false\n",
+      "  episode_len_mean: 822.7310195227766\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 240.53824579854947\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 93\n",
+      "  episodes_total: 2305\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8726944923400879\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005827944166958332\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012724796333350242\n",
+      "        total_loss: 12.167643547058105\n",
+      "        vf_explained_var: 0.9788719415664673\n",
+      "        vf_loss: 12.179289817810059\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 24\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.563157894736854\n",
+      "    gpu_util_percent0: 0.38999999999999996\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1221003815882753\n",
+      "    mean_env_wait_ms: 0.6509422861487458\n",
+      "    mean_inference_ms: 4.674851482809558\n",
+      "    mean_raw_obs_processing_ms: 0.2657481067948324\n",
+      "  time_since_restore: 411.8134672641754\n",
+      "  time_this_iter_s: 16.914734363555908\n",
+      "  time_total_s: 411.8134672641754\n",
+      "  timers:\n",
+      "    learn_throughput: 7378.802\n",
+      "    learn_time_ms: 10963.297\n",
+      "    sample_throughput: 13780.188\n",
+      "    sample_time_ms: 5870.457\n",
+      "    update_time_ms: 40.887\n",
+      "  timestamp: 1602433983\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 24\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     24 |          411.813 | 1941504 |  240.538 |              288.899 |               146.02 |            822.731 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3462.297794117647\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_16-33-19\n",
+      "  done: false\n",
+      "  episode_len_mean: 820.6352124183006\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 241.42962715389186\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 143\n",
+      "  episodes_total: 2448\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.2\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8506251096725463\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.004865732230246067\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011699284473434091\n",
+      "        total_loss: 13.54094352722168\n",
+      "        vf_explained_var: 0.9798793792724609\n",
+      "        vf_loss: 13.551755332946778\n",
+      "    num_steps_sampled: 2022400\n",
+      "    num_steps_trained: 2022400\n",
+      "  iterations_since_restore: 25\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.863157894736847\n",
+      "    gpu_util_percent0: 0.24789473684210525\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1219047600643383\n",
+      "    mean_env_wait_ms: 0.6515183312848983\n",
+      "    mean_inference_ms: 4.659499636596185\n",
+      "    mean_raw_obs_processing_ms: 0.2651838569848832\n",
+      "  time_since_restore: 428.57146096229553\n",
+      "  time_this_iter_s: 16.757993698120117\n",
+      "  time_total_s: 428.57146096229553\n",
+      "  timers:\n",
+      "    learn_throughput: 7383.23\n",
+      "    learn_time_ms: 10956.722\n",
+      "    sample_throughput: 13801.215\n",
+      "    sample_time_ms: 5861.513\n",
+      "    update_time_ms: 39.443\n",
+      "  timestamp: 1602433999\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2022400\n",
+      "  training_iteration: 25\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     25 |          428.571 | 2022400 |   241.43 |              288.899 |               146.02 |            820.635 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3460.0423259493673\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_16-33-37\n",
+      "  done: false\n",
+      "  episode_len_mean: 819.539161392405\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 241.7713647551464\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 80\n",
+      "  episodes_total: 2528\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8542515873908997\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005588684789836406\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013171911868266762\n",
+      "        total_loss: 15.62488899230957\n",
+      "        vf_explained_var: 0.9691354632377625\n",
+      "        vf_loss: 15.637587738037109\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 26\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.915\n",
+      "    gpu_util_percent0: 0.2845\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12180448369067126\n",
+      "    mean_env_wait_ms: 0.6518283478915357\n",
+      "    mean_inference_ms: 4.651488543781857\n",
+      "    mean_raw_obs_processing_ms: 0.2648939093712547\n",
+      "  time_since_restore: 445.5921413898468\n",
+      "  time_this_iter_s: 17.02068042755127\n",
+      "  time_total_s: 445.5921413898468\n",
+      "  timers:\n",
+      "    learn_throughput: 7386.73\n",
+      "    learn_time_ms: 10951.531\n",
+      "    sample_throughput: 13808.288\n",
+      "    sample_time_ms: 5858.51\n",
+      "    update_time_ms: 46.879\n",
+      "  timestamp: 1602434017\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 26\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     26 |          445.592 | 2103296 |  241.771 |              288.899 |               146.02 |            819.539 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3456.8169984686065\n",
+      "    time_step_min: 3149\n",
+      "  date: 2020-10-11_16-33-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 818.4391271056661\n",
+      "  episode_reward_max: 288.89898989899024\n",
+      "  episode_reward_mean: 242.26005073707984\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 84\n",
+      "  episodes_total: 2612\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8317709803581238\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00648640925064683\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016052717715501784\n",
+      "        total_loss: 10.588752174377442\n",
+      "        vf_explained_var: 0.9785087704658508\n",
+      "        vf_loss: 10.60423927307129\n",
+      "    num_steps_sampled: 2184192\n",
+      "    num_steps_trained: 2184192\n",
+      "  iterations_since_restore: 27\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.04210526315789\n",
+      "    gpu_util_percent0: 0.33999999999999997\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12170000229942377\n",
+      "    mean_env_wait_ms: 0.6521662077100546\n",
+      "    mean_inference_ms: 4.643533374018082\n",
+      "    mean_raw_obs_processing_ms: 0.26460304791080924\n",
+      "  time_since_restore: 462.44021677970886\n",
+      "  time_this_iter_s: 16.84807538986206\n",
+      "  time_total_s: 462.44021677970886\n",
+      "  timers:\n",
+      "    learn_throughput: 7383.646\n",
+      "    learn_time_ms: 10956.105\n",
+      "    sample_throughput: 13798.625\n",
+      "    sample_time_ms: 5862.613\n",
+      "    update_time_ms: 45.061\n",
+      "  timestamp: 1602434033\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2184192\n",
+      "  training_iteration: 27\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     27 |           462.44 | 2184192 |   242.26 |              288.899 |               146.02 |            818.439 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3452.055938975663\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-34-10\n",
+      "  done: false\n",
+      "  episode_len_mean: 816.755539411551\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 242.98142338752584\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 141\n",
+      "  episodes_total: 2753\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8073569655418396\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007314516603946686\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012918723002076148\n",
+      "        total_loss: 14.855539894104004\n",
+      "        vf_explained_var: 0.9783770442008972\n",
+      "        vf_loss: 14.867807388305664\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 28\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.88421052631579\n",
+      "    gpu_util_percent0: 0.3910526315789474\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12153785932976834\n",
+      "    mean_env_wait_ms: 0.6527151245819349\n",
+      "    mean_inference_ms: 4.630862286777733\n",
+      "    mean_raw_obs_processing_ms: 0.2641544072429254\n",
+      "  time_since_restore: 479.31437849998474\n",
+      "  time_this_iter_s: 16.87416172027588\n",
+      "  time_total_s: 479.31437849998474\n",
+      "  timers:\n",
+      "    learn_throughput: 7390.723\n",
+      "    learn_time_ms: 10945.614\n",
+      "    sample_throughput: 13777.872\n",
+      "    sample_time_ms: 5871.444\n",
+      "    update_time_ms: 44.828\n",
+      "  timestamp: 1602434050\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 28\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     28 |          479.314 | 2265088 |  242.981 |              294.657 |               146.02 |            816.756 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3449.462728551336\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-34-28\n",
+      "  done: false\n",
+      "  episode_len_mean: 815.731364275668\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 243.3743340578784\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 91\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8145095586776734\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005709170270711184\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011662486474961042\n",
+      "        total_loss: 12.014441299438477\n",
+      "        vf_explained_var: 0.9769560098648071\n",
+      "        vf_loss: 12.025614356994629\n",
+      "    num_steps_sampled: 2345984\n",
+      "    num_steps_trained: 2345984\n",
+      "  iterations_since_restore: 29\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 30.785000000000004\n",
+      "    gpu_util_percent0: 0.274\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1214422344724671\n",
+      "    mean_env_wait_ms: 0.6530009353317395\n",
+      "    mean_inference_ms: 4.623333907881865\n",
+      "    mean_raw_obs_processing_ms: 0.26387314444224774\n",
+      "  time_since_restore: 496.35931181907654\n",
+      "  time_this_iter_s: 17.044933319091797\n",
+      "  time_total_s: 496.35931181907654\n",
+      "  timers:\n",
+      "    learn_throughput: 7390.31\n",
+      "    learn_time_ms: 10946.225\n",
+      "    sample_throughput: 13767.349\n",
+      "    sample_time_ms: 5875.932\n",
+      "    update_time_ms: 38.656\n",
+      "  timestamp: 1602434068\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2345984\n",
+      "  training_iteration: 29\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     29 |          496.359 | 2345984 |  243.374 |              294.657 |               146.02 |            815.731 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3446.7897435897435\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-34-45\n",
+      "  done: false\n",
+      "  episode_len_mean: 814.8417094017094\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 243.7793317793318\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 81\n",
+      "  episodes_total: 2925\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8143168568611145\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006050251703709364\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014920068671926856\n",
+      "        total_loss: 10.06276626586914\n",
+      "        vf_explained_var: 0.9785787463188171\n",
+      "        vf_loss: 10.07716236114502\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 30\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.821052631578944\n",
+      "    gpu_util_percent0: 0.3684210526315789\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12135757858033507\n",
+      "    mean_env_wait_ms: 0.6532775139903034\n",
+      "    mean_inference_ms: 4.616883042420374\n",
+      "    mean_raw_obs_processing_ms: 0.26363995161920145\n",
+      "  time_since_restore: 513.1962876319885\n",
+      "  time_this_iter_s: 16.836975812911987\n",
+      "  time_total_s: 513.1962876319885\n",
+      "  timers:\n",
+      "    learn_throughput: 7405.345\n",
+      "    learn_time_ms: 10924.001\n",
+      "    sample_throughput: 13750.589\n",
+      "    sample_time_ms: 5883.093\n",
+      "    update_time_ms: 36.706\n",
+      "  timestamp: 1602434085\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 30\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     30 |          513.196 | 2426880 |  243.779 |              294.657 |               146.02 |            814.842 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3443.8039408866994\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-35-02\n",
+      "  done: false\n",
+      "  episode_len_mean: 813.6032840722496\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 244.2317261282779\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 120\n",
+      "  episodes_total: 3045\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7847271919250488\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006011144630610943\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0123886376619339\n",
+      "        total_loss: 13.336679077148437\n",
+      "        vf_explained_var: 0.9797344207763672\n",
+      "        vf_loss: 13.348544883728028\n",
+      "    num_steps_sampled: 2507776\n",
+      "    num_steps_trained: 2507776\n",
+      "  iterations_since_restore: 31\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.92105263157895\n",
+      "    gpu_util_percent0: 0.26315789473684204\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12123641241438077\n",
+      "    mean_env_wait_ms: 0.6537218561047831\n",
+      "    mean_inference_ms: 4.6077991278621475\n",
+      "    mean_raw_obs_processing_ms: 0.2633179398646692\n",
+      "  time_since_restore: 530.1246099472046\n",
+      "  time_this_iter_s: 16.928322315216064\n",
+      "  time_total_s: 530.1246099472046\n",
+      "  timers:\n",
+      "    learn_throughput: 7404.912\n",
+      "    learn_time_ms: 10924.641\n",
+      "    sample_throughput: 13747.273\n",
+      "    sample_time_ms: 5884.513\n",
+      "    update_time_ms: 36.485\n",
+      "  timestamp: 1602434102\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2507776\n",
+      "  training_iteration: 31\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     31 |          530.125 | 2507776 |  244.232 |              294.657 |               146.02 |            813.603 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3441.074050632911\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-35-19\n",
+      "  done: false\n",
+      "  episode_len_mean: 812.5060126582279\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 244.64534586370036\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 115\n",
+      "  episodes_total: 3160\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7759140849113464\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005504181887954473\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011239721812307835\n",
+      "        total_loss: 11.656171417236328\n",
+      "        vf_explained_var: 0.9791274070739746\n",
+      "        vf_loss: 11.666938591003419\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 32\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.235000000000003\n",
+      "    gpu_util_percent0: 0.31\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12113687445987069\n",
+      "    mean_env_wait_ms: 0.6540608571178146\n",
+      "    mean_inference_ms: 4.599696534562951\n",
+      "    mean_raw_obs_processing_ms: 0.26302098056308076\n",
+      "  time_since_restore: 547.3567974567413\n",
+      "  time_this_iter_s: 17.232187509536743\n",
+      "  time_total_s: 547.3567974567413\n",
+      "  timers:\n",
+      "    learn_throughput: 7410.863\n",
+      "    learn_time_ms: 10915.868\n",
+      "    sample_throughput: 13667.621\n",
+      "    sample_time_ms: 5918.806\n",
+      "    update_time_ms: 37.934\n",
+      "  timestamp: 1602434119\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 32\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     32 |          547.357 | 2588672 |  244.645 |              294.657 |               146.02 |            812.506 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3439.0583333333334\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-35-36\n",
+      "  done: false\n",
+      "  episode_len_mean: 811.7601851851852\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 244.95075757575762\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 80\n",
+      "  episodes_total: 3240\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7811835169792175\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006416494492441416\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012559976987540722\n",
+      "        total_loss: 8.990324211120605\n",
+      "        vf_explained_var: 0.9806587100028992\n",
+      "        vf_loss: 9.002320289611816\n",
+      "    num_steps_sampled: 2669568\n",
+      "    num_steps_trained: 2669568\n",
+      "  iterations_since_restore: 33\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.16315789473685\n",
+      "    gpu_util_percent0: 0.3494736842105263\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12106636804940506\n",
+      "    mean_env_wait_ms: 0.654308418437876\n",
+      "    mean_inference_ms: 4.594290281235995\n",
+      "    mean_raw_obs_processing_ms: 0.26282625189540965\n",
+      "  time_since_restore: 564.2302570343018\n",
+      "  time_this_iter_s: 16.873459577560425\n",
+      "  time_total_s: 564.2302570343018\n",
+      "  timers:\n",
+      "    learn_throughput: 7407.876\n",
+      "    learn_time_ms: 10920.269\n",
+      "    sample_throughput: 13664.264\n",
+      "    sample_time_ms: 5920.26\n",
+      "    update_time_ms: 37.37\n",
+      "  timestamp: 1602434136\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2669568\n",
+      "  training_iteration: 33\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     33 |           564.23 | 2669568 |  244.951 |              294.657 |               146.02 |             811.76 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3436.664176874813\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-35-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 810.7051090528831\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 245.3135085543213\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 107\n",
+      "  episodes_total: 3347\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7612020254135132\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005618926044553519\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014426779658242595\n",
+      "        total_loss: 10.50188980102539\n",
+      "        vf_explained_var: 0.9819744229316711\n",
+      "        vf_loss: 10.515831184387206\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 34\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 31.440000000000005\n",
+      "    gpu_util_percent0: 0.2825\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715647\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12097591505642284\n",
+      "    mean_env_wait_ms: 0.654678447565111\n",
+      "    mean_inference_ms: 4.587428459993633\n",
+      "    mean_raw_obs_processing_ms: 0.26258601176828894\n",
+      "  time_since_restore: 581.2578387260437\n",
+      "  time_this_iter_s: 17.027581691741943\n",
+      "  time_total_s: 581.2578387260437\n",
+      "  timers:\n",
+      "    learn_throughput: 7403.63\n",
+      "    learn_time_ms: 10926.532\n",
+      "    sample_throughput: 13652.925\n",
+      "    sample_time_ms: 5925.177\n",
+      "    update_time_ms: 37.988\n",
+      "  timestamp: 1602434153\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 34\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     34 |          581.258 | 2750464 |  245.314 |              294.657 |               146.02 |            810.705 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_742c8_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4092\n",
+      "    time_step_mean: 3433.486323063634\n",
+      "    time_step_min: 3111\n",
+      "  date: 2020-10-11_16-36-10\n",
+      "  done: false\n",
+      "  episode_len_mean: 809.8491217967176\n",
+      "  episode_reward_max: 294.65656565656593\n",
+      "  episode_reward_mean: 245.79500155601514\n",
+      "  episode_reward_min: 146.02020202020225\n",
+      "  episodes_this_iter: 126\n",
+      "  episodes_total: 3473\n",
+      "  experiment_id: a3fbaca112274408b5a61ebe00de0bbd\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.1\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.755747628211975\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00591852879151702\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012422900833189487\n",
+      "        total_loss: 9.482335662841797\n",
+      "        vf_explained_var: 0.9842199087142944\n",
+      "        vf_loss: 9.494241714477539\n",
+      "    num_steps_sampled: 2831360\n",
+      "    num_steps_trained: 2831360\n",
+      "  iterations_since_restore: 35\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 32.01578947368421\n",
+      "    gpu_util_percent0: 0.38684210526315793\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.5\n",
+      "    vram_util_percent0: 0.11634962282715645\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 61121\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.12087802096321525\n",
+      "    mean_env_wait_ms: 0.6550253058413934\n",
+      "    mean_inference_ms: 4.579750068083864\n",
+      "    mean_raw_obs_processing_ms: 0.2623052128500548\n",
+      "  time_since_restore: 598.2881736755371\n",
+      "  time_this_iter_s: 17.030334949493408\n",
+      "  time_total_s: 598.2881736755371\n",
+      "  timers:\n",
+      "    learn_throughput: 7403.573\n",
+      "    learn_time_ms: 10926.617\n",
+      "    sample_throughput: 13595.729\n",
+      "    sample_time_ms: 5950.104\n",
+      "    update_time_ms: 39.679\n",
+      "  timestamp: 1602434170\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2831360\n",
+      "  training_iteration: 35\n",
+      "  trial_id: 742c8_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 26.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_742c8_00000 | RUNNING  | 172.17.0.4:61121 |     35 |          598.288 | 2831360 |  245.795 |              294.657 |               146.02 |            809.849 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent rfs7la4y"
+    "!wandb agent gd9q4pbz"
    ]
   },
   {
diff --git a/JSS/__pycache__/default_config.cpython-38.pyc b/JSS/__pycache__/default_config.cpython-38.pyc
index 768b7fd..9492e2c 100644
Binary files a/JSS/__pycache__/default_config.cpython-38.pyc and b/JSS/__pycache__/default_config.cpython-38.pyc differ
diff --git a/JSS/default_config.py b/JSS/default_config.py
index c91ecc1..5149870 100644
--- a/JSS/default_config.py
+++ b/JSS/default_config.py
@@ -12,7 +12,7 @@ default_config = {
     'num_envs_per_worker': 2,
     'rollout_fragment_length': 1024,
     'num_workers': mp.cpu_count() - 1,
-    'sgd_minibatch_size': 16112,
+    'sgd_minibatch_size': 18384,
     'evaluation_interval': None,
     'metrics_smoothing_episodes': 100000,
     'layer_size': 1024,
@@ -30,7 +30,7 @@ default_config = {
     "lr_schedule": None,
     "vf_share_layers": False,
     "vf_loss_coeff": 1.0,
-    "entropy_coeff": 0.0,
+    "entropy_coeff": 1e-4,
     "entropy_coeff_schedule": None,
     "grad_clip": None,
     "batch_mode": "truncate_episodes",
diff --git a/JSS/train.py b/JSS/train.py
index 568cc37..74405ef 100644
--- a/JSS/train.py
+++ b/JSS/train.py
@@ -54,7 +54,7 @@ def train_func():
     }
 
     analysis = tune.run(PPOTrainer, config=config, stop=stop, name="ppo-jss")
-    result = analysis.dataframe(metric='custom_metrics/time_step_min', mode='min').to_dict('index')[0]
+    result = analysis.dataframe().to_dict('index')[0]
     wandb.log({'time_step_min': result['custom_metrics/time_step_min']})
     if result['custom_metrics/time_step_max'] != float('inf'):
         wandb.log({'time_step_max': result['custom_metrics/time_step_max']})
diff --git a/JSS/wandb/debug-internal.log b/JSS/wandb/debug-internal.log
index 593fb77..bf44400 120000
--- a/JSS/wandb/debug-internal.log
+++ b/JSS/wandb/debug-internal.log
@@ -1 +1 @@
-run-20201009_141415-7t1r8tef/logs/debug-internal.log
\ No newline at end of file
+run-20201011_163638-4qxusrpa/logs/debug-internal.log
\ No newline at end of file
diff --git a/JSS/wandb/debug.log b/JSS/wandb/debug.log
index 4ee8a74..ffc957d 120000
--- a/JSS/wandb/debug.log
+++ b/JSS/wandb/debug.log
@@ -1 +1 @@
-run-20201009_141415-7t1r8tef/logs/debug.log
\ No newline at end of file
+run-20201011_163638-4qxusrpa/logs/debug.log
\ No newline at end of file
diff --git a/JSS/wandb/latest-run b/JSS/wandb/latest-run
index 086031d..b44fe7e 120000
--- a/JSS/wandb/latest-run
+++ b/JSS/wandb/latest-run
@@ -1 +1 @@
-run-20201009_141415-7t1r8tef
\ No newline at end of file
+run-20201011_163638-4qxusrpa
\ No newline at end of file
