2020-10-11 16:36:42,176	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_f2484_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=16912)[0m 2020-10-11 16:36:45,049	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=16795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16837)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16837)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16782)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16782)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16910)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16910)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16845)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16845)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16901)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16901)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16906)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16906)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16781)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16781)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16868)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16868)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16863)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16863)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16838)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16838)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16792)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16792)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16811)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16811)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16857)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16857)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16835)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16835)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16780)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16780)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16841)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16841)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16870)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16870)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16797)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16829)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16829)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16871)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16871)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16840)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16840)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16886)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16886)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=16789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=16789)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_f2484_00000:
  custom_metrics: {}
  date: 2020-10-11_16-37-14
  done: false
  episode_len_mean: .nan
  episode_reward_max: .nan
  episode_reward_mean: .nan
  episode_reward_min: .nan
  episodes_this_iter: 0
  episodes_total: 0
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1959591507911682
        entropy_coeff: 0.0001
        kl: 0.00692124580964446
        model: {}
        policy_loss: -0.015828011673875153
        total_loss: 527.1372497558593
        vf_explained_var: -0.016922414302825928
        vf_loss: 527.151806640625
    num_steps_sampled: 121344
    num_steps_trained: 121344
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.766666666666666
    gpu_util_percent0: 0.33866666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.4299999999999993
    vram_util_percent0: 0.08249152727670271
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf: {}
  time_since_restore: 24.098042011260986
  time_this_iter_s: 24.098042011260986
  time_total_s: 24.098042011260986
  timers:
    learn_throughput: 7215.983
    learn_time_ms: 16816.005
    sample_throughput: 16827.068
    sample_time_ms: 7211.238
    update_time_ms: 33.907
  timestamp: 1602434234
  timesteps_since_restore: 0
  timesteps_total: 121344
  training_iteration: 1
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 26.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |      1 |           24.098 | 121344 |      nan |                  nan |                  nan |                nan |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4112
    time_step_mean: 3615.864
    time_step_min: 3300
  date: 2020-10-11_16-37-37
  done: false
  episode_len_mean: 893.4430379746835
  episode_reward_max: 266.0202020202018
  episode_reward_mean: 215.418936197417
  episode_reward_min: 142.98989898989888
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1592355012893676
        entropy_coeff: 0.0001
        kl: 0.005351887689903379
        model: {}
        policy_loss: -0.012733178376220167
        total_loss: 409.77147521972654
        vf_explained_var: 0.6207262277603149
        vf_loss: 409.78326110839845
    num_steps_sampled: 242688
    num_steps_trained: 242688
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.55714285714286
    gpu_util_percent0: 0.38
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5714285714285707
    vram_util_percent0: 0.0973269924565431
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16703970712694244
    mean_env_wait_ms: 1.162625664490399
    mean_inference_ms: 5.724001838725741
    mean_raw_obs_processing_ms: 0.437739609692192
  time_since_restore: 46.886953353881836
  time_this_iter_s: 22.78891134262085
  time_total_s: 46.886953353881836
  timers:
    learn_throughput: 7269.959
    learn_time_ms: 16691.153
    sample_throughput: 18239.714
    sample_time_ms: 6652.736
    update_time_ms: 58.768
  timestamp: 1602434257
  timesteps_since_restore: 0
  timesteps_total: 242688
  training_iteration: 2
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |      2 |           46.887 | 242688 |  215.419 |               266.02 |               142.99 |            893.443 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3618.632508833922
    time_step_min: 3292
  date: 2020-10-11_16-37-59
  done: false
  episode_len_mean: 886.7879746835443
  episode_reward_max: 267.2323232323228
  episode_reward_mean: 217.1488940033242
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.145239007472992
        entropy_coeff: 0.0001
        kl: 0.0058763557579368355
        model: {}
        policy_loss: -0.014578591380268336
        total_loss: 164.11632690429687
        vf_explained_var: 0.8207401037216187
        vf_loss: 164.12984161376954
    num_steps_sampled: 364032
    num_steps_trained: 364032
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.581481481481482
    gpu_util_percent0: 0.3903703703703703
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.65925925925926
    vram_util_percent0: 0.0973269924565431
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16409045496967706
    mean_env_wait_ms: 1.1650251580754594
    mean_inference_ms: 5.5185406269704
    mean_raw_obs_processing_ms: 0.43005883494788955
  time_since_restore: 68.99611377716064
  time_this_iter_s: 22.10916042327881
  time_total_s: 68.99611377716064
  timers:
    learn_throughput: 7292.328
    learn_time_ms: 16639.954
    sample_throughput: 19410.824
    sample_time_ms: 6251.358
    update_time_ms: 66.902
  timestamp: 1602434279
  timesteps_since_restore: 0
  timesteps_total: 364032
  training_iteration: 3
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |      3 |          68.9961 | 364032 |  217.149 |              267.232 |              110.111 |            886.788 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3604.988662131519
    time_step_min: 3272
  date: 2020-10-11_16-38-21
  done: false
  episode_len_mean: 880.5253164556962
  episode_reward_max: 270.26262626262576
  episode_reward_mean: 219.73264288454146
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1261111617088317
        entropy_coeff: 0.0001
        kl: 0.006357423542067408
        model: {}
        policy_loss: -0.014120475715026259
        total_loss: 65.97172393798829
        vf_explained_var: 0.9051922559738159
        vf_loss: 65.98468742370605
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.36923076923077
    gpu_util_percent0: 0.39192307692307693
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6653846153846157
    vram_util_percent0: 0.09732699245654311
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16188208553292752
    mean_env_wait_ms: 1.1675806694759454
    mean_inference_ms: 5.367952099280228
    mean_raw_obs_processing_ms: 0.4240901989549573
  time_since_restore: 90.997474193573
  time_this_iter_s: 22.001360416412354
  time_total_s: 90.997474193573
  timers:
    learn_throughput: 7295.671
    learn_time_ms: 16632.33
    sample_throughput: 20173.054
    sample_time_ms: 6015.153
    update_time_ms: 59.751
  timestamp: 1602434301
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 4
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |      4 |          90.9975 | 485376 |  219.733 |              270.263 |              110.111 |            880.525 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3598.3088480801334
    time_step_min: 3272
  date: 2020-10-11_16-38-43
  done: false
  episode_len_mean: 876.5996835443038
  episode_reward_max: 270.26262626262576
  episode_reward_mean: 220.90512722158277
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.113484752178192
        entropy_coeff: 0.0001
        kl: 0.006746772350743413
        model: {}
        policy_loss: -0.016326938942074775
        total_loss: 48.30865249633789
        vf_explained_var: 0.9295428991317749
        vf_loss: 48.323740768432614
    num_steps_sampled: 606720
    num_steps_trained: 606720
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.97307692307692
    gpu_util_percent0: 0.40769230769230774
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6076923076923078
    vram_util_percent0: 0.09732699245654311
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16019939668919866
    mean_env_wait_ms: 1.1700073409707372
    mean_inference_ms: 5.252505554549704
    mean_raw_obs_processing_ms: 0.41949598707402735
  time_since_restore: 112.61101269721985
  time_this_iter_s: 21.61353850364685
  time_total_s: 112.61101269721985
  timers:
    learn_throughput: 7307.729
    learn_time_ms: 16604.886
    sample_throughput: 20846.619
    sample_time_ms: 5820.8
    update_time_ms: 54.946
  timestamp: 1602434323
  timesteps_since_restore: 0
  timesteps_total: 606720
  training_iteration: 5
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |      5 |          112.611 | 606720 |  220.905 |              270.263 |              110.111 |              876.6 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3590.6195508586525
    time_step_min: 3272
  date: 2020-10-11_16-39-05
  done: false
  episode_len_mean: 873.2291139240506
  episode_reward_max: 270.26262626262576
  episode_reward_mean: 221.84394578698357
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0971333622932433
        entropy_coeff: 0.0001
        kl: 0.0070683910511434075
        model: {}
        policy_loss: -0.017142200935631992
        total_loss: 38.89528465270996
        vf_explained_var: 0.9435901641845703
        vf_loss: 38.911122512817386
    num_steps_sampled: 728064
    num_steps_trained: 728064
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.607407407407404
    gpu_util_percent0: 0.38518518518518513
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.674074074074074
    vram_util_percent0: 0.0973269924565431
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1588646372903801
    mean_env_wait_ms: 1.1717999106202264
    mean_inference_ms: 5.161362854729731
    mean_raw_obs_processing_ms: 0.4158526997499123
  time_since_restore: 134.52145266532898
  time_this_iter_s: 21.91043996810913
  time_total_s: 134.52145266532898
  timers:
    learn_throughput: 7296.247
    learn_time_ms: 16631.017
    sample_throughput: 21308.191
    sample_time_ms: 5694.712
    update_time_ms: 51.617
  timestamp: 1602434345
  timesteps_since_restore: 0
  timesteps_total: 728064
  training_iteration: 6
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |      6 |          134.521 | 728064 |  221.844 |              270.263 |              110.111 |            873.229 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3582.8021857923495
    time_step_min: 3260
  date: 2020-10-11_16-39-27
  done: false
  episode_len_mean: 869.717299578059
  episode_reward_max: 275.1111111111109
  episode_reward_mean: 222.99469377317462
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 948
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.085950994491577
        entropy_coeff: 0.0001
        kl: 0.006661517266184092
        model: {}
        policy_loss: -0.016626653913408517
        total_loss: 34.853887939453124
        vf_explained_var: 0.949724018573761
        vf_loss: 34.869289779663085
    num_steps_sampled: 849408
    num_steps_trained: 849408
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.54074074074074
    gpu_util_percent0: 0.39185185185185184
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.677777777777778
    vram_util_percent0: 0.0973269924565431
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15779611839510835
    mean_env_wait_ms: 1.173106475283323
    mean_inference_ms: 5.087796902702605
    mean_raw_obs_processing_ms: 0.41284898908635725
  time_since_restore: 156.31748390197754
  time_this_iter_s: 21.79603123664856
  time_total_s: 156.31748390197754
  timers:
    learn_throughput: 7293.668
    learn_time_ms: 16636.896
    sample_throughput: 21670.097
    sample_time_ms: 5599.606
    update_time_ms: 49.328
  timestamp: 1602434367
  timesteps_since_restore: 0
  timesteps_total: 849408
  training_iteration: 7
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |      7 |          156.317 | 849408 |  222.995 |              275.111 |              110.111 |            869.717 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3570.246024321796
    time_step_min: 3219
  date: 2020-10-11_16-39-49
  done: false
  episode_len_mean: 865.510889292196
  episode_reward_max: 278.2929292929293
  episode_reward_mean: 225.40149223633782
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 154
  episodes_total: 1102
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0690657138824462
        entropy_coeff: 0.0001
        kl: 0.007089599361643195
        model: {}
        policy_loss: -0.016672549676150082
        total_loss: 20.739563369750975
        vf_explained_var: 0.9659794569015503
        vf_loss: 20.75492458343506
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.253846153846155
    gpu_util_percent0: 0.3915384615384615
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676923076923077
    vram_util_percent0: 0.09732699245654311
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15692773793229206
    mean_env_wait_ms: 1.1743125901256064
    mean_inference_ms: 5.0278469106980985
    mean_raw_obs_processing_ms: 0.41035835056939
  time_since_restore: 178.13531041145325
  time_this_iter_s: 21.817826509475708
  time_total_s: 178.13531041145325
  timers:
    learn_throughput: 7291.971
    learn_time_ms: 16640.769
    sample_throughput: 21930.251
    sample_time_ms: 5533.179
    update_time_ms: 47.727
  timestamp: 1602434389
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 8
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |      8 |          178.135 | 970752 |  225.401 |              278.293 |              110.111 |            865.511 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3562.2047377326567
    time_step_min: 3219
  date: 2020-10-11_16-40-11
  done: false
  episode_len_mean: 862.475720164609
  episode_reward_max: 278.2929292929293
  episode_reward_mean: 226.71592467888752
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 113
  episodes_total: 1215
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0479537963867187
        entropy_coeff: 0.0001
        kl: 0.007272624736651778
        model: {}
        policy_loss: -0.016208201344124974
        total_loss: 17.856405448913574
        vf_explained_var: 0.9698473811149597
        vf_loss: 17.871263313293458
    num_steps_sampled: 1092096
    num_steps_trained: 1092096
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.599999999999998
    gpu_util_percent0: 0.38333333333333336
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.677777777777778
    vram_util_percent0: 0.0973269924565431
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15637815604843594
    mean_env_wait_ms: 1.1751318625982314
    mean_inference_ms: 4.989079750717604
    mean_raw_obs_processing_ms: 0.4087219399752651
  time_since_restore: 200.0217535495758
  time_this_iter_s: 21.88644313812256
  time_total_s: 200.0217535495758
  timers:
    learn_throughput: 7284.834
    learn_time_ms: 16657.072
    sample_throughput: 22152.833
    sample_time_ms: 5477.584
    update_time_ms: 44.862
  timestamp: 1602434411
  timesteps_since_restore: 0
  timesteps_total: 1092096
  training_iteration: 9
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |      9 |          200.022 | 1092096 |  226.716 |              278.293 |              110.111 |            862.476 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3557.529832935561
    time_step_min: 3219
  date: 2020-10-11_16-40-32
  done: false
  episode_len_mean: 861.0279069767441
  episode_reward_max: 278.2929292929293
  episode_reward_mean: 227.34449142588662
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 75
  episodes_total: 1290
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0403279900550841
        entropy_coeff: 0.0001
        kl: 0.006842035334557295
        model: {}
        policy_loss: -0.01800845763646066
        total_loss: 12.261977481842042
        vf_explained_var: 0.9752925038337708
        vf_loss: 12.278721237182618
    num_steps_sampled: 1213440
    num_steps_trained: 1213440
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.25
    gpu_util_percent0: 0.3880769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676923076923077
    vram_util_percent0: 0.09732699245654311
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15602873098161937
    mean_env_wait_ms: 1.1757294424460496
    mean_inference_ms: 4.965160273641742
    mean_raw_obs_processing_ms: 0.40765652954109544
  time_since_restore: 221.75921273231506
  time_this_iter_s: 21.737459182739258
  time_total_s: 221.75921273231506
  timers:
    learn_throughput: 7285.901
    learn_time_ms: 16654.632
    sample_throughput: 22342.812
    sample_time_ms: 5431.008
    update_time_ms: 44.199
  timestamp: 1602434432
  timesteps_since_restore: 0
  timesteps_total: 1213440
  training_iteration: 10
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     10 |          221.759 | 1213440 |  227.344 |              278.293 |              110.111 |            861.028 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3550.0424155283968
    time_step_min: 3219
  date: 2020-10-11_16-40-54
  done: false
  episode_len_mean: 857.9740168539325
  episode_reward_max: 278.2929292929293
  episode_reward_mean: 228.53860940869353
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 134
  episodes_total: 1424
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0321320176124573
        entropy_coeff: 0.0001
        kl: 0.006566867278888821
        model: {}
        policy_loss: -0.01710017560981214
        total_loss: 13.715909004211426
        vf_explained_var: 0.972159743309021
        vf_loss: 13.731798839569091
    num_steps_sampled: 1334784
    num_steps_trained: 1334784
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.333333333333332
    gpu_util_percent0: 0.4103703703703704
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5999999999999996
    vram_util_percent0: 0.0973269924565431
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1554467600844411
    mean_env_wait_ms: 1.176808902717664
    mean_inference_ms: 4.92559409581624
    mean_raw_obs_processing_ms: 0.4058834841407863
  time_since_restore: 243.61976194381714
  time_this_iter_s: 21.860549211502075
  time_total_s: 243.61976194381714
  timers:
    learn_throughput: 7290.466
    learn_time_ms: 16644.204
    sample_throughput: 23255.538
    sample_time_ms: 5217.854
    update_time_ms: 43.24
  timestamp: 1602434454
  timesteps_since_restore: 0
  timesteps_total: 1334784
  training_iteration: 11
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     11 |           243.62 | 1334784 |  228.539 |              278.293 |              110.111 |            857.974 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3541.4453781512607
    time_step_min: 3219
  date: 2020-10-11_16-41-16
  done: false
  episode_len_mean: 854.4170886075949
  episode_reward_max: 281.929292929293
  episode_reward_mean: 229.692526531134
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 156
  episodes_total: 1580
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.020197904109955
        entropy_coeff: 0.0001
        kl: 0.006058456469327211
        model: {}
        policy_loss: -0.01470049675554037
        total_loss: 18.573369026184082
        vf_explained_var: 0.9681007266044617
        vf_loss: 18.58696002960205
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.99230769230769
    gpu_util_percent0: 0.36423076923076925
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5999999999999996
    vram_util_percent0: 0.09732699245654311
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15486317020205911
    mean_env_wait_ms: 1.1780553127491602
    mean_inference_ms: 4.88531041630842
    mean_raw_obs_processing_ms: 0.40403456396361004
  time_since_restore: 265.33378744125366
  time_this_iter_s: 21.714025497436523
  time_total_s: 265.33378744125366
  timers:
    learn_throughput: 7286.671
    learn_time_ms: 16652.873
    sample_throughput: 23755.314
    sample_time_ms: 5108.078
    update_time_ms: 36.82
  timestamp: 1602434476
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 12
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     12 |          265.334 | 1456128 |  229.693 |              281.929 |              110.111 |            854.417 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3534.0310850439882
    time_step_min: 3200
  date: 2020-10-11_16-41-38
  done: false
  episode_len_mean: 850.952243958573
  episode_reward_max: 281.929292929293
  episode_reward_mean: 230.98672571514902
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 1738
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9970218181610108
        entropy_coeff: 0.0001
        kl: 0.006452261889353395
        model: {}
        policy_loss: -0.015842192876152694
        total_loss: 14.247142505645751
        vf_explained_var: 0.9768832921981812
        vf_loss: 14.261793899536134
    num_steps_sampled: 1577472
    num_steps_trained: 1577472
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.18888888888889
    gpu_util_percent0: 0.3714814814814815
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.65925925925926
    vram_util_percent0: 0.0973269924565431
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15434426935955783
    mean_env_wait_ms: 1.1792058922171589
    mean_inference_ms: 4.849801458716814
    mean_raw_obs_processing_ms: 0.40236770482553535
  time_since_restore: 287.33973145484924
  time_this_iter_s: 22.00594401359558
  time_total_s: 287.33973145484924
  timers:
    learn_throughput: 7275.117
    learn_time_ms: 16679.32
    sample_throughput: 23915.196
    sample_time_ms: 5073.929
    update_time_ms: 32.053
  timestamp: 1602434498
  timesteps_since_restore: 0
  timesteps_total: 1577472
  training_iteration: 13
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     13 |           287.34 | 1577472 |  230.987 |              281.929 |              110.111 |            850.952 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3525.8615136876006
    time_step_min: 3200
  date: 2020-10-11_16-42-00
  done: false
  episode_len_mean: 847.826476793249
  episode_reward_max: 287.3838383838388
  episode_reward_mean: 232.27028193325648
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9747326076030731
        entropy_coeff: 0.0001
        kl: 0.00612424616701901
        model: {}
        policy_loss: -0.014966693823225796
        total_loss: 16.16988077163696
        vf_explained_var: 0.9753187298774719
        vf_loss: 16.18372049331665
    num_steps_sampled: 1698816
    num_steps_trained: 1698816
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.42962962962963
    gpu_util_percent0: 0.38000000000000006
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.662962962962964
    vram_util_percent0: 0.0973269924565431
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15388915900016012
    mean_env_wait_ms: 1.180299604681557
    mean_inference_ms: 4.8186361684167105
    mean_raw_obs_processing_ms: 0.4009146118604479
  time_since_restore: 309.19514083862305
  time_this_iter_s: 21.855409383773804
  time_total_s: 309.19514083862305
  timers:
    learn_throughput: 7267.718
    learn_time_ms: 16696.3
    sample_throughput: 24060.749
    sample_time_ms: 5043.235
    update_time_ms: 31.46
  timestamp: 1602434520
  timesteps_since_restore: 0
  timesteps_total: 1698816
  training_iteration: 14
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     14 |          309.195 | 1698816 |   232.27 |              287.384 |              110.111 |            847.826 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3516.675903018308
    time_step_min: 3184
  date: 2020-10-11_16-42-22
  done: false
  episode_len_mean: 844.9576436222006
  episode_reward_max: 287.6868686868687
  episode_reward_mean: 233.5491182516498
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9621578693389893
        entropy_coeff: 0.0001
        kl: 0.006318121962249279
        model: {}
        policy_loss: -0.015574407507665455
        total_loss: 15.80780487060547
        vf_explained_var: 0.9761217832565308
        vf_loss: 15.822211933135986
    num_steps_sampled: 1820160
    num_steps_trained: 1820160
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.953846153846158
    gpu_util_percent0: 0.36538461538461536
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6615384615384623
    vram_util_percent0: 0.09732699245654311
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1534850800904733
    mean_env_wait_ms: 1.18136581210225
    mean_inference_ms: 4.790993739645384
    mean_raw_obs_processing_ms: 0.3996255337407799
  time_since_restore: 331.2720055580139
  time_this_iter_s: 22.07686471939087
  time_total_s: 331.2720055580139
  timers:
    learn_throughput: 7256.562
    learn_time_ms: 16721.968
    sample_throughput: 23965.527
    sample_time_ms: 5063.273
    update_time_ms: 31.266
  timestamp: 1602434542
  timesteps_since_restore: 0
  timesteps_total: 1820160
  training_iteration: 15
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     15 |          331.272 | 1820160 |  233.549 |              287.687 |              110.111 |            844.958 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3509.5048187241855
    time_step_min: 3183
  date: 2020-10-11_16-42-44
  done: false
  episode_len_mean: 842.0167269439421
  episode_reward_max: 287.6868686868687
  episode_reward_mean: 234.8509598699471
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9393698751926423
        entropy_coeff: 0.0001
        kl: 0.007056502206251025
        model: {}
        policy_loss: -0.016813380899839102
        total_loss: 12.618824291229249
        vf_explained_var: 0.9797784090042114
        vf_loss: 12.634320831298828
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.9037037037037
    gpu_util_percent0: 0.3777777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.662962962962964
    vram_util_percent0: 0.0973269924565431
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15312128748443055
    mean_env_wait_ms: 1.1823777546373242
    mean_inference_ms: 4.766249952155808
    mean_raw_obs_processing_ms: 0.3984603275109183
  time_since_restore: 353.18275022506714
  time_this_iter_s: 21.910744667053223
  time_total_s: 353.18275022506714
  timers:
    learn_throughput: 7253.74
    learn_time_ms: 16728.474
    sample_throughput: 23999.961
    sample_time_ms: 5056.008
    update_time_ms: 31.815
  timestamp: 1602434564
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 16
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     16 |          353.183 | 1941504 |  234.851 |              287.687 |              110.111 |            842.017 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3502.0449293966626
    time_step_min: 3183
  date: 2020-10-11_16-43-06
  done: false
  episode_len_mean: 839.7181434599156
  episode_reward_max: 287.6868686868687
  episode_reward_mean: 236.05159186804747
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9273344576358795
        entropy_coeff: 0.0001
        kl: 0.006462834915146232
        model: {}
        policy_loss: -0.016018430789699778
        total_loss: 12.192332553863526
        vf_explained_var: 0.9808918237686157
        vf_loss: 12.207151126861572
    num_steps_sampled: 2062848
    num_steps_trained: 2062848
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.32592592592593
    gpu_util_percent0: 0.38999999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6666666666666674
    vram_util_percent0: 0.0973269924565431
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1527921550180224
    mean_env_wait_ms: 1.1833238680359617
    mean_inference_ms: 4.7439296141122105
    mean_raw_obs_processing_ms: 0.39740913026647645
  time_since_restore: 375.0259099006653
  time_this_iter_s: 21.843159675598145
  time_total_s: 375.0259099006653
  timers:
    learn_throughput: 7251.184
    learn_time_ms: 16734.37
    sample_throughput: 23998.973
    sample_time_ms: 5056.216
    update_time_ms: 31.654
  timestamp: 1602434586
  timesteps_since_restore: 0
  timesteps_total: 2062848
  training_iteration: 17
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     17 |          375.026 | 2062848 |  236.052 |              287.687 |              110.111 |            839.718 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3495.7138276553105
    time_step_min: 3178
  date: 2020-10-11_16-43-28
  done: false
  episode_len_mean: 837.8939873417721
  episode_reward_max: 287.6868686868687
  episode_reward_mean: 236.9882687635851
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.9161362051963806
        entropy_coeff: 0.0001
        kl: 0.006297056609764695
        model: {}
        policy_loss: -0.015995782846584917
        total_loss: 15.527367401123048
        vf_explained_var: 0.9763310551643372
        vf_loss: 15.542195320129395
    num_steps_sampled: 2184192
    num_steps_trained: 2184192
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.861538461538462
    gpu_util_percent0: 0.3888461538461539
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6692307692307695
    vram_util_percent0: 0.09732699245654311
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15249379904652172
    mean_env_wait_ms: 1.1842167578319593
    mean_inference_ms: 4.723690980484702
    mean_raw_obs_processing_ms: 0.3964583253266998
  time_since_restore: 396.92454290390015
  time_this_iter_s: 21.898633003234863
  time_total_s: 396.92454290390015
  timers:
    learn_throughput: 7247.456
    learn_time_ms: 16742.977
    sample_throughput: 24002.76
    sample_time_ms: 5055.419
    update_time_ms: 31.663
  timestamp: 1602434608
  timesteps_since_restore: 0
  timesteps_total: 2184192
  training_iteration: 18
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     18 |          396.925 | 2184192 |  236.988 |              287.687 |              110.111 |            837.894 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3488.3833396155296
    time_step_min: 3157
  date: 2020-10-11_16-43-50
  done: false
  episode_len_mean: 836.2915115413253
  episode_reward_max: 287.6868686868687
  episode_reward_mean: 238.08664079363993
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8943499863147736
        entropy_coeff: 0.0001
        kl: 0.0066445536445826296
        model: {}
        policy_loss: -0.016367476899176836
        total_loss: 12.655834197998047
        vf_explained_var: 0.9791094660758972
        vf_loss: 12.670962524414062
    num_steps_sampled: 2305536
    num_steps_trained: 2305536
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.55185185185185
    gpu_util_percent0: 0.4237037037037037
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.674074074074074
    vram_util_percent0: 0.0973269924565431
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15222064582790043
    mean_env_wait_ms: 1.1850498322786744
    mean_inference_ms: 4.705232306134515
    mean_raw_obs_processing_ms: 0.3955913518156595
  time_since_restore: 418.74510741233826
  time_this_iter_s: 21.82056450843811
  time_total_s: 418.74510741233826
  timers:
    learn_throughput: 7249.121
    learn_time_ms: 16739.132
    sample_throughput: 24018.302
    sample_time_ms: 5052.147
    update_time_ms: 31.568
  timestamp: 1602434630
  timesteps_since_restore: 0
  timesteps_total: 2305536
  training_iteration: 19
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     19 |          418.745 | 2305536 |  238.087 |              287.687 |              110.111 |            836.292 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3483.075773745998
    time_step_min: 3157
  date: 2020-10-11_16-44-12
  done: false
  episode_len_mean: 834.9268635724331
  episode_reward_max: 287.6868686868687
  episode_reward_mean: 238.8350594553125
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8824259817600251
        entropy_coeff: 0.0001
        kl: 0.0066049045883119105
        model: {}
        policy_loss: -0.01594212418422103
        total_loss: 13.915754318237305
        vf_explained_var: 0.9783811569213867
        vf_loss: 13.930463600158692
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.973076923076924
    gpu_util_percent0: 0.39192307692307693
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6692307692307695
    vram_util_percent0: 0.09732699245654311
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15196993438801737
    mean_env_wait_ms: 1.1858329504263683
    mean_inference_ms: 4.688292736714494
    mean_raw_obs_processing_ms: 0.39480083175668484
  time_since_restore: 440.3540325164795
  time_this_iter_s: 21.608925104141235
  time_total_s: 440.3540325164795
  timers:
    learn_throughput: 7256.75
    learn_time_ms: 16721.536
    sample_throughput: 23991.822
    sample_time_ms: 5057.723
    update_time_ms: 31.186
  timestamp: 1602434652
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 20
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     20 |          440.354 | 2426880 |  238.835 |              287.687 |              110.111 |            834.927 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3478.1919838329404
    time_step_min: 3157
  date: 2020-10-11_16-44-34
  done: false
  episode_len_mean: 833.4763491005996
  episode_reward_max: 287.6868686868687
  episode_reward_mean: 239.55966056299155
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8729820370674133
        entropy_coeff: 0.0001
        kl: 0.006137691112235189
        model: {}
        policy_loss: -0.015474413114134222
        total_loss: 12.55329246520996
        vf_explained_var: 0.9798005223274231
        vf_loss: 12.567626857757569
    num_steps_sampled: 2548224
    num_steps_trained: 2548224
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.21111111111111
    gpu_util_percent0: 0.36925925925925923
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.677777777777778
    vram_util_percent0: 0.0973269924565431
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15173972745034928
    mean_env_wait_ms: 1.1865758024340365
    mean_inference_ms: 4.6727096694370704
    mean_raw_obs_processing_ms: 0.39407733608893397
  time_since_restore: 462.12070655822754
  time_this_iter_s: 21.766674041748047
  time_total_s: 462.12070655822754
  timers:
    learn_throughput: 7261.283
    learn_time_ms: 16711.096
    sample_throughput: 23997.659
    sample_time_ms: 5056.493
    update_time_ms: 32.48
  timestamp: 1602434674
  timesteps_since_restore: 0
  timesteps_total: 2548224
  training_iteration: 21
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     21 |          462.121 | 2548224 |   239.56 |              287.687 |              110.111 |            833.476 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3474.348576910777
    time_step_min: 3157
  date: 2020-10-11_16-44-55
  done: false
  episode_len_mean: 832.2056962025316
  episode_reward_max: 287.6868686868687
  episode_reward_mean: 240.25442718322455
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8568673670291901
        entropy_coeff: 0.0001
        kl: 0.006439585238695145
        model: {}
        policy_loss: -0.016009854199364782
        total_loss: 12.150525093078613
        vf_explained_var: 0.9801128506660461
        vf_loss: 12.165333080291749
    num_steps_sampled: 2669568
    num_steps_trained: 2669568
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.04615384615385
    gpu_util_percent0: 0.41307692307692306
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676923076923077
    vram_util_percent0: 0.09732699245654311
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1515264258991886
    mean_env_wait_ms: 1.1872870461730451
    mean_inference_ms: 4.658284162198899
    mean_raw_obs_processing_ms: 0.3934153094869322
  time_since_restore: 483.5546758174896
  time_this_iter_s: 21.433969259262085
  time_total_s: 483.5546758174896
  timers:
    learn_throughput: 7274.49
    learn_time_ms: 16680.758
    sample_throughput: 23990.181
    sample_time_ms: 5058.069
    update_time_ms: 32.512
  timestamp: 1602434695
  timesteps_since_restore: 0
  timesteps_total: 2669568
  training_iteration: 22
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     22 |          483.555 | 2669568 |  240.254 |              287.687 |              110.111 |            832.206 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3469.855098934551
    time_step_min: 3157
  date: 2020-10-11_16-45-17
  done: false
  episode_len_mean: 830.7730560578661
  episode_reward_max: 288.1414141414141
  episode_reward_mean: 240.93147569729837
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8448180139064789
        entropy_coeff: 0.0001
        kl: 0.006154089560732245
        model: {}
        policy_loss: -0.016657658107578754
        total_loss: 10.374671173095702
        vf_explained_var: 0.9826952815055847
        vf_loss: 10.39018268585205
    num_steps_sampled: 2790912
    num_steps_trained: 2790912
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.834615384615386
    gpu_util_percent0: 0.3734615384615384
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676923076923077
    vram_util_percent0: 0.09732699245654311
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15132909337482997
    mean_env_wait_ms: 1.1879763630820677
    mean_inference_ms: 4.644888028405979
    mean_raw_obs_processing_ms: 0.39280839782127347
  time_since_restore: 505.0770471096039
  time_this_iter_s: 21.522371292114258
  time_total_s: 505.0770471096039
  timers:
    learn_throughput: 7291.666
    learn_time_ms: 16641.465
    sample_throughput: 24032.653
    sample_time_ms: 5049.13
    update_time_ms: 33.066
  timestamp: 1602434717
  timesteps_since_restore: 0
  timesteps_total: 2790912
  training_iteration: 23
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     23 |          505.077 | 2790912 |  240.931 |              288.141 |              110.111 |            830.773 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3465.4574498983443
    time_step_min: 3157
  date: 2020-10-11_16-45-39
  done: false
  episode_len_mean: 829.7966052934407
  episode_reward_max: 288.1414141414141
  episode_reward_mean: 241.6251293138519
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8337712466716767
        entropy_coeff: 0.0001
        kl: 0.006214128108695149
        model: {}
        policy_loss: -0.015278310980647802
        total_loss: 10.57435188293457
        vf_explained_var: 0.982189953327179
        vf_loss: 10.588470840454102
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.00769230769231
    gpu_util_percent0: 0.39730769230769225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676923076923077
    vram_util_percent0: 0.09732699245654311
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15114548139556097
    mean_env_wait_ms: 1.188623193142598
    mean_inference_ms: 4.632415759736831
    mean_raw_obs_processing_ms: 0.39224825849810663
  time_since_restore: 526.4109735488892
  time_this_iter_s: 21.33392643928528
  time_total_s: 526.4109735488892
  timers:
    learn_throughput: 7317.135
    learn_time_ms: 16583.54
    sample_throughput: 24004.923
    sample_time_ms: 5054.963
    update_time_ms: 32.183
  timestamp: 1602434739
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 24
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     24 |          526.411 | 2912256 |  241.625 |              288.141 |              110.111 |            829.797 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3461.1734778982486
    time_step_min: 3157
  date: 2020-10-11_16-46-00
  done: false
  episode_len_mean: 828.7471074380165
  episode_reward_max: 288.1414141414141
  episode_reward_mean: 242.3075799315468
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 154
  episodes_total: 3630
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8217187225818634
        entropy_coeff: 0.0001
        kl: 0.0061708759982138876
        model: {}
        policy_loss: -0.016470591770485044
        total_loss: 9.451776313781739
        vf_explained_var: 0.9835542440414429
        vf_loss: 9.467094898223877
    num_steps_sampled: 3033600
    num_steps_trained: 3033600
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.130769230769236
    gpu_util_percent0: 0.46153846153846156
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676923076923077
    vram_util_percent0: 0.09732699245654311
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15097968214306134
    mean_env_wait_ms: 1.1892291888801316
    mean_inference_ms: 4.621003313497133
    mean_raw_obs_processing_ms: 0.3917410029926535
  time_since_restore: 547.8153209686279
  time_this_iter_s: 21.40434741973877
  time_total_s: 547.8153209686279
  timers:
    learn_throughput: 7337.77
    learn_time_ms: 16536.904
    sample_throughput: 24105.818
    sample_time_ms: 5033.806
    update_time_ms: 32.004
  timestamp: 1602434760
  timesteps_since_restore: 0
  timesteps_total: 3033600
  training_iteration: 25
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     25 |          547.815 | 3033600 |  242.308 |              288.141 |              110.111 |            828.747 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3457.6454108858056
    time_step_min: 3157
  date: 2020-10-11_16-46-22
  done: false
  episode_len_mean: 827.7249404919334
  episode_reward_max: 291.6262626262624
  episode_reward_mean: 242.82532011466148
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 151
  episodes_total: 3781
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.8122868180274964
        entropy_coeff: 0.0001
        kl: 0.0061836780048906805
        model: {}
        policy_loss: -0.01570358211174607
        total_loss: 9.494609355926514
        vf_explained_var: 0.9842739105224609
        vf_loss: 9.50915756225586
    num_steps_sampled: 3154944
    num_steps_trained: 3154944
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.42592592592592
    gpu_util_percent0: 0.40962962962962973
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.677777777777778
    vram_util_percent0: 0.0973269924565431
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15082666993751456
    mean_env_wait_ms: 1.189773009944503
    mean_inference_ms: 4.6105702112402325
    mean_raw_obs_processing_ms: 0.3912660964260133
  time_since_restore: 569.5162391662598
  time_this_iter_s: 21.700918197631836
  time_total_s: 569.5162391662598
  timers:
    learn_throughput: 7351.678
    learn_time_ms: 16505.619
    sample_throughput: 24056.403
    sample_time_ms: 5044.146
    update_time_ms: 31.598
  timestamp: 1602434782
  timesteps_since_restore: 0
  timesteps_total: 3154944
  training_iteration: 26
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     26 |          569.516 | 3154944 |  242.825 |              291.626 |              110.111 |            827.725 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3454.6357087728325
    time_step_min: 3157
  date: 2020-10-11_16-46-44
  done: false
  episode_len_mean: 826.7635204081632
  episode_reward_max: 291.6262626262624
  episode_reward_mean: 243.37320913213765
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 139
  episodes_total: 3920
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.7935346961021423
        entropy_coeff: 0.0001
        kl: 0.0062863645143806934
        model: {}
        policy_loss: -0.01642861692234874
        total_loss: 8.58299903869629
        vf_explained_var: 0.9851622581481934
        vf_loss: 8.598249912261963
    num_steps_sampled: 3276288
    num_steps_trained: 3276288
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.876923076923074
    gpu_util_percent0: 0.38038461538461543
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676923076923077
    vram_util_percent0: 0.09732699245654311
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15069204053586813
    mean_env_wait_ms: 1.1902572118876569
    mean_inference_ms: 4.6013360993135
    mean_raw_obs_processing_ms: 0.39086958748957557
  time_since_restore: 591.0502119064331
  time_this_iter_s: 21.53397274017334
  time_total_s: 591.0502119064331
  timers:
    learn_throughput: 7368.015
    learn_time_ms: 16469.022
    sample_throughput: 24029.505
    sample_time_ms: 5049.792
    update_time_ms: 30.989
  timestamp: 1602434804
  timesteps_since_restore: 0
  timesteps_total: 3276288
  training_iteration: 27
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | RUNNING  | 172.17.0.4:16912 |     27 |           591.05 | 3276288 |  243.373 |              291.626 |              110.111 |            826.764 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f2484_00000:
  custom_metrics:
    time_step_max: 4329
    time_step_mean: 3450.4371747211894
    time_step_min: 3145
  date: 2020-10-11_16-47-06
  done: true
  episode_len_mean: 825.7268928220255
  episode_reward_max: 291.6262626262624
  episode_reward_mean: 243.9282649503888
  episode_reward_min: 110.11111111111082
  episodes_this_iter: 148
  episodes_total: 4068
  experiment_id: ebd3f103edb14f5ca08d6b7faea78620
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 0.7831395208835602
        entropy_coeff: 0.0001
        kl: 0.006107834447175264
        model: {}
        policy_loss: -0.01623650984838605
        total_loss: 8.15590958595276
        vf_explained_var: 0.9852229356765747
        vf_loss: 8.171002912521363
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 28
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.165384615384614
    gpu_util_percent0: 0.4019230769230769
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.676923076923077
    vram_util_percent0: 0.09732699245654311
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 16912
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15055850222489173
    mean_env_wait_ms: 1.1907917359565645
    mean_inference_ms: 4.592184910235987
    mean_raw_obs_processing_ms: 0.39047059691591474
  time_since_restore: 612.7445266246796
  time_this_iter_s: 21.69431471824646
  time_total_s: 612.7445266246796
  timers:
    learn_throughput: 7377.379
    learn_time_ms: 16448.117
    sample_throughput: 24030.39
    sample_time_ms: 5049.606
    update_time_ms: 31.094
  timestamp: 1602434826
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 28
  trial_id: f2484_00000
  
== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | TERMINATED |       |     28 |          612.745 | 3397632 |  243.928 |              291.626 |              110.111 |            825.727 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 27.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f2484_00000 | TERMINATED |       |     28 |          612.745 | 3397632 |  243.928 |              291.626 |              110.111 |            825.727 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Traceback (most recent call last):
  File "train.py", line 72, in <module>
    train_func()
  File "train.py", line 57, in train_func
    result = analysis.dataframe().to_dict('index')[0]
  File "/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py", line 89, in dataframe
    metric = self._validate_metric(metric)
  File "/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py", line 64, in _validate_metric
    raise ValueError(
ValueError: No `metric` has been passed and  `default_metric` has not been set. Please specify the `metric` parameter.
