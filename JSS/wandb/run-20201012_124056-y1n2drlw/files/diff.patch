diff --git a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
index d0ca168..df51374 100644
--- a/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
+++ b/JSS/.ipynb_checkpoints/Untitled-checkpoint.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [
     {
@@ -11,12 +11,22 @@
      "text": [
       "I have detected 80 CPUs here, so I'm going to create 79 actors\n"
      ]
+    },
+    {
+     "ename": "NameError",
+     "evalue": "name 'os' is not defined",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
+      "\u001b[0;32m<ipython-input-2-615597bbcda5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I have detected {} CPUs here, so I'm going to create {} actors\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"WANDB_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'3487a01956bf67cc7882bca2a38f70c8c95f8463'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     sweep_config = {\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m'program'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'train.py'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
+      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
+     ]
     }
    ],
    "source": [
-    "##### import os\n",
+    "import os\n",
     "import multiprocessing as mp\n",
-    "\n",
     "import plotly.io as pio\n",
     "import ray\n",
     "from ray import tune\n",
@@ -29,7 +39,7 @@
     "from ray.tune.integration.wandb import WandbLogger\n",
     "\n",
     "from JSS.env_wrapper import BestActionsWrapper\n",
-    "2\n",
+    "\n",
     "from JSS.models import FCMaskedActionsModel\n",
     "\n",
     "pio.orca.config.use_xvfb = True\n",
@@ -64,17 +74,10 @@
     "            'goal': 'minimize',\n",
     "        },\n",
     "        'parameters': {\n",
-    "            'clip_param': {\n",
-    "                'values': [0.3, 0.5]\n",
-    "            },\n",
-    "            'kl_coeff': {\n",
-    "                 'values': [0.1, 0.2, 0.3]\n",
-    "            },\n",
-    "            'entropy_coeff': {\n",
-    "                'values': [5e-4, 1e-4]\n",
-    "            },\n",
-    "            'num_sgd_iter': {\n",
-    "                'values': [25, 30, 35]\n",
+    "            'instance': {\n",
+    "                'values': ['env/instances/ta51', 'env/instances/ta52', 'env/instances/ta53', 'env/instances/ta54',\n",
+    "                           'env/instances/ta55', 'env/instances/ta56', 'env/instances/ta57', 'env/instances/ta58',\n",
+    "                           'env/instances/ta59', 'env/instances/ta60']\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -82,25 +85,16 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": null,
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "Create sweep with ID: h0kna0bx\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "sweep_id = wandb.sweep(sweep_config, project=\"RLLIB_SWEEP_2\")"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 16,
    "metadata": {},
    "outputs": [
     {
@@ -108,203 +102,201 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-11 20:17:59,838 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-11 20:18:00,194 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:18:00,195 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "2020-10-12 10:34:03,998 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-12 10:34:04,420 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 10:34:04,420 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
       "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:18:00,197 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=25\n",
+      "2020-10-12 10:34:04,423 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --num_sgd_iter=25\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
+      "2020-10-12 10:34:09,440 - wandb.wandb_agent - INFO - Running runs: ['2deggwjd']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgrateful-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mchocolate-sweep-1\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_201802-90w2swxq\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/y2n6znmq\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/2deggwjd\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_103406-2deggwjd\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-11 20:18:05,215 - wandb.wandb_agent - INFO - Running runs: ['90w2swxq']\n",
-      "2020-10-11 20:18:05,800\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "2020-10-12 10:34:10,061\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
       "Memory usage on this node: 11.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=48597)\u001b[0m 2020-10-11 20:18:08,590\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "\u001b[2m\u001b[36m(pid=732)\u001b[0m 2020-10-12 10:34:12,767\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=699)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=699)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=716)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=716)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=722)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=722)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=680)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=680)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=695)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=695)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=730)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=730)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=687)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=687)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=708)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=708)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=679)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=679)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=729)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=729)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=691)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=691)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=727)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=727)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=705)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=705)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=668)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=668)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=735)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=735)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=714)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=714)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=604)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=604)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=696)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=696)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=720)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=720)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=671)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=671)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=689)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=689)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=623)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=623)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=620)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=620)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=673)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=673)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=698)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=698)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=663)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=663)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=660)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=660)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=640)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=640)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=603)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=603)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=607)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=607)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=686)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=686)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=609)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=609)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=739)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=739)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=612)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=612)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=674)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=674)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=618)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=618)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=619)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=619)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=611)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=611)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=606)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=606)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=683)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=683)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=616)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=616)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=624)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=624)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=667)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=667)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=704)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=704)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=676)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=676)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=662)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=662)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=626)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=626)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=685)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=685)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=666)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=666)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=711)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=711)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=693)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=693)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=675)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=675)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=633)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=633)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=709)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=709)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=628)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=628)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=608)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=608)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=617)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=617)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=706)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=706)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=713)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=713)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=670)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=670)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=684)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=684)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=682)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=682)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=690)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=690)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=712)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=712)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=622)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=622)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: 4054\n",
       "    time_step_mean: 3615.0923076923077\n",
       "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-18-42\n",
+      "  date: 2020-10-12_10-34-46\n",
       "  done: false\n",
       "  episode_len_mean: 891.1139240506329\n",
       "  episode_reward_max: 258.59595959595964\n",
@@ -312,21 +304,21 @@
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1826184193293254\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006616147429061432\n",
+      "        entropy: 1.1850829323132832\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.004093626630492508\n",
       "        model: {}\n",
-      "        policy_loss: -0.008133015158819035\n",
-      "        total_loss: 507.07523854573566\n",
+      "        policy_loss: -0.007868677183675269\n",
+      "        total_loss: 507.0761362711589\n",
       "        vf_explained_var: 0.540532648563385\n",
       "        vf_loss: 507.0832926432292\n",
       "    num_steps_sampled: 161792\n",
@@ -336,65 +328,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.127272727272725\n",
-      "    gpu_util_percent0: 0.3506060606060606\n",
+      "    cpu_util_percent: 28.13030303030303\n",
+      "    gpu_util_percent0: 0.34545454545454546\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5606060606060606\n",
-      "    vram_util_percent0: 0.08582297226114873\n",
+      "    ram_util_percent: 3.566666666666667\n",
+      "    vram_util_percent0: 0.08750757824224535\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1683247269727301\n",
-      "    mean_env_wait_ms: 1.1628085015989742\n",
-      "    mean_inference_ms: 6.007336148070346\n",
-      "    mean_raw_obs_processing_ms: 0.4543961680719389\n",
-      "  time_since_restore: 28.43995237350464\n",
-      "  time_this_iter_s: 28.43995237350464\n",
-      "  time_total_s: 28.43995237350464\n",
+      "    mean_action_processing_ms: 0.16933092256871662\n",
+      "    mean_env_wait_ms: 1.1741114030763227\n",
+      "    mean_inference_ms: 5.667092522635582\n",
+      "    mean_raw_obs_processing_ms: 0.4496598044969888\n",
+      "  time_since_restore: 28.243332386016846\n",
+      "  time_this_iter_s: 28.243332386016846\n",
+      "  time_total_s: 28.243332386016846\n",
       "  timers:\n",
-      "    learn_throughput: 8628.213\n",
-      "    learn_time_ms: 18751.508\n",
-      "    sample_throughput: 16823.05\n",
-      "    sample_time_ms: 9617.281\n",
-      "    update_time_ms: 31.059\n",
-      "  timestamp: 1602447522\n",
+      "    learn_throughput: 8451.021\n",
+      "    learn_time_ms: 19144.668\n",
+      "    sample_throughput: 17931.057\n",
+      "    sample_time_ms: 9023.004\n",
+      "    update_time_ms: 32.461\n",
+      "  timestamp: 1602498886\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 27.7/754.6 GiB\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      1 |            28.44 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      1 |          28.2433 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3620.503472222222\n",
-      "    time_step_min: 3313\n",
-      "  date: 2020-10-11_20-19-08\n",
+      "    time_step_max: 4139\n",
+      "    time_step_mean: 3608.8055555555557\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_10-35-13\n",
       "  done: false\n",
-      "  episode_len_mean: 889.1613924050633\n",
-      "  episode_reward_max: 265.8686868686868\n",
-      "  episode_reward_mean: 217.79810765886694\n",
-      "  episode_reward_min: 145.7171717171716\n",
+      "  episode_len_mean: 890.7056962025316\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 217.07793121084234\n",
+      "  episode_reward_min: 138.89898989898958\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -403,14 +395,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1493095755577087\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008436032105237246\n",
+      "        entropy: 1.1567376752694447\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0070590757532045245\n",
       "        model: {}\n",
-      "        policy_loss: -0.010742687620222569\n",
-      "        total_loss: 128.25170707702637\n",
-      "        vf_explained_var: 0.8104302883148193\n",
-      "        vf_loss: 128.26218032836914\n",
+      "        policy_loss: -0.010883362002156597\n",
+      "        total_loss: 129.9215234120687\n",
+      "        vf_explained_var: 0.8072310090065002\n",
+      "        vf_loss: 129.93181800842285\n",
       "    num_steps_sampled: 323584\n",
       "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 2\n",
@@ -418,65 +410,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.041935483870965\n",
-      "    gpu_util_percent0: 0.2812903225806452\n",
+      "    cpu_util_percent: 26.084374999999998\n",
+      "    gpu_util_percent0: 0.3503125\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.754838709677419\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
+      "    ram_util_percent: 3.7593750000000004\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641174120999257\n",
-      "    mean_env_wait_ms: 1.161537109361996\n",
-      "    mean_inference_ms: 5.692598517415019\n",
-      "    mean_raw_obs_processing_ms: 0.44176304933602323\n",
-      "  time_since_restore: 54.913392305374146\n",
-      "  time_this_iter_s: 26.473439931869507\n",
-      "  time_total_s: 54.913392305374146\n",
+      "    mean_action_processing_ms: 0.1649267986261869\n",
+      "    mean_env_wait_ms: 1.1701357295854296\n",
+      "    mean_inference_ms: 5.452435751356474\n",
+      "    mean_raw_obs_processing_ms: 0.4394414823862937\n",
+      "  time_since_restore: 55.3238570690155\n",
+      "  time_this_iter_s: 27.080524682998657\n",
+      "  time_total_s: 55.3238570690155\n",
       "  timers:\n",
-      "    learn_throughput: 8644.657\n",
-      "    learn_time_ms: 18715.839\n",
-      "    sample_throughput: 18672.544\n",
-      "    sample_time_ms: 8664.701\n",
-      "    update_time_ms: 34.541\n",
-      "  timestamp: 1602447548\n",
+      "    learn_throughput: 8423.471\n",
+      "    learn_time_ms: 19207.283\n",
+      "    sample_throughput: 19301.756\n",
+      "    sample_time_ms: 8382.242\n",
+      "    update_time_ms: 25.876\n",
+      "  timestamp: 1602498913\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      2 |          54.9134 | 323584 |  217.798 |              265.869 |              145.717 |            889.161 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      2 |          55.3239 | 323584 |  217.078 |              273.596 |              138.899 |            890.706 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4376\n",
-      "    time_step_mean: 3623.385650224215\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-19-34\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3602.798206278027\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_10-35-39\n",
       "  done: false\n",
-      "  episode_len_mean: 884.6371308016878\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 217.91957550185379\n",
-      "  episode_reward_min: 102.98989898989872\n",
+      "  episode_len_mean: 886.1392405063291\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 218.34343434343413\n",
+      "  episode_reward_min: 137.98989898989845\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -485,14 +477,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1392555435498555\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00957879020522038\n",
+      "        entropy: 1.143834412097931\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00900065409950912\n",
       "        model: {}\n",
-      "        policy_loss: -0.013498059211997315\n",
-      "        total_loss: 65.20246982574463\n",
-      "        vf_explained_var: 0.8920263648033142\n",
-      "        vf_loss: 65.21557839711507\n",
+      "        policy_loss: -0.012952111646882258\n",
+      "        total_loss: 62.266885121663414\n",
+      "        vf_explained_var: 0.8935738205909729\n",
+      "        vf_loss: 62.279051780700684\n",
       "    num_steps_sampled: 485376\n",
       "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 3\n",
@@ -500,65 +492,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.12333333333333\n",
-      "    gpu_util_percent0: 0.29900000000000004\n",
+      "    cpu_util_percent: 24.68064516129032\n",
+      "    gpu_util_percent0: 0.30032258064516126\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7741935483870965\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16137101559306874\n",
-      "    mean_env_wait_ms: 1.1624113133988414\n",
-      "    mean_inference_ms: 5.471956785195863\n",
-      "    mean_raw_obs_processing_ms: 0.4328824318519803\n",
-      "  time_since_restore: 80.61326289176941\n",
-      "  time_this_iter_s: 25.699870586395264\n",
-      "  time_total_s: 80.61326289176941\n",
+      "    mean_action_processing_ms: 0.16206126907167195\n",
+      "    mean_env_wait_ms: 1.1694681355227807\n",
+      "    mean_inference_ms: 5.281464279659669\n",
+      "    mean_raw_obs_processing_ms: 0.43116658445242273\n",
+      "  time_since_restore: 81.6922254562378\n",
+      "  time_this_iter_s: 26.36836838722229\n",
+      "  time_total_s: 81.6922254562378\n",
       "  timers:\n",
-      "    learn_throughput: 8673.855\n",
-      "    learn_time_ms: 18652.836\n",
-      "    sample_throughput: 19886.525\n",
-      "    sample_time_ms: 8135.76\n",
-      "    update_time_ms: 37.024\n",
-      "  timestamp: 1602447574\n",
+      "    learn_throughput: 8411.993\n",
+      "    learn_time_ms: 19233.491\n",
+      "    sample_throughput: 20490.931\n",
+      "    sample_time_ms: 7895.786\n",
+      "    update_time_ms: 31.698\n",
+      "  timestamp: 1602498939\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      3 |          80.6133 | 485376 |   217.92 |              280.566 |               102.99 |            884.637 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      3 |          81.6922 | 485376 |  218.343 |              273.596 |               137.99 |            886.139 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3621.849337748344\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-20-00\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3596.7533112582782\n",
+      "    time_step_min: 3250\n",
+      "  date: 2020-10-12_10-36-06\n",
       "  done: false\n",
-      "  episode_len_mean: 881.6772151898734\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 218.88892085411052\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 882.5870253164557\n",
+      "  episode_reward_max: 273.5959595959592\n",
+      "  episode_reward_mean: 219.16725802327048\n",
+      "  episode_reward_min: 137.98989898989845\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -567,14 +559,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1236704488595326\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007535708253271878\n",
+      "        entropy: 1.1256821552912395\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00838832138106227\n",
       "        model: {}\n",
-      "        policy_loss: -0.013356986630242318\n",
-      "        total_loss: 48.56767304738363\n",
-      "        vf_explained_var: 0.9157173037528992\n",
-      "        vf_loss: 48.58083724975586\n",
+      "        policy_loss: -0.013208418832315752\n",
+      "        total_loss: 44.44708792368571\n",
+      "        vf_explained_var: 0.9239999651908875\n",
+      "        vf_loss: 44.45957056681315\n",
       "    num_steps_sampled: 647168\n",
       "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 4\n",
@@ -582,65 +574,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.296666666666663\n",
-      "    gpu_util_percent0: 0.4023333333333333\n",
+      "    cpu_util_percent: 24.003225806451614\n",
+      "    gpu_util_percent0: 0.3496774193548387\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7709677419354835\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1593975281871441\n",
-      "    mean_env_wait_ms: 1.1630363827485917\n",
-      "    mean_inference_ms: 5.315944442746125\n",
-      "    mean_raw_obs_processing_ms: 0.42613695533758145\n",
-      "  time_since_restore: 106.19969916343689\n",
-      "  time_this_iter_s: 25.58643627166748\n",
-      "  time_total_s: 106.19969916343689\n",
+      "    mean_action_processing_ms: 0.16006576052477228\n",
+      "    mean_env_wait_ms: 1.1692682755662736\n",
+      "    mean_inference_ms: 5.156015909406596\n",
+      "    mean_raw_obs_processing_ms: 0.42467633120668596\n",
+      "  time_since_restore: 108.28819131851196\n",
+      "  time_this_iter_s: 26.59596586227417\n",
+      "  time_total_s: 108.28819131851196\n",
       "  timers:\n",
-      "    learn_throughput: 8681.107\n",
-      "    learn_time_ms: 18637.255\n",
-      "    sample_throughput: 20668.006\n",
-      "    sample_time_ms: 7828.138\n",
-      "    update_time_ms: 38.696\n",
-      "  timestamp: 1602447600\n",
+      "    learn_throughput: 8384.595\n",
+      "    learn_time_ms: 19296.341\n",
+      "    sample_throughput: 21117.84\n",
+      "    sample_time_ms: 7661.39\n",
+      "    update_time_ms: 31.674\n",
+      "  timestamp: 1602498966\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      4 |            106.2 | 647168 |  218.889 |              280.566 |              75.8687 |            881.677 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      4 |          108.288 | 647168 |  219.167 |              273.596 |               137.99 |            882.587 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3610.6456692913384\n",
-      "    time_step_min: 3278\n",
-      "  date: 2020-10-11_20-20-26\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3591.5629921259842\n",
+      "    time_step_min: 3242\n",
+      "  date: 2020-10-12_10-36-32\n",
       "  done: false\n",
-      "  episode_len_mean: 878.0367088607595\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 220.18495077355817\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 878.2569620253165\n",
+      "  episode_reward_max: 274.8080808080809\n",
+      "  episode_reward_mean: 220.1586753612068\n",
+      "  episode_reward_min: 137.98989898989845\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 790\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -649,14 +641,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.090914100408554\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0074959762472038465\n",
+      "        entropy: 1.0966354012489319\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008652650052681565\n",
       "        model: {}\n",
-      "        policy_loss: -0.012363930135810127\n",
-      "        total_loss: 36.32484753926595\n",
-      "        vf_explained_var: 0.9411559104919434\n",
-      "        vf_loss: 36.33700720469157\n",
+      "        policy_loss: -0.013121832271281164\n",
+      "        total_loss: 35.068282763163246\n",
+      "        vf_explained_var: 0.9439868927001953\n",
+      "        vf_loss: 35.080649058024086\n",
       "    num_steps_sampled: 808960\n",
       "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 5\n",
@@ -664,65 +656,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.69\n",
-      "    gpu_util_percent0: 0.27466666666666667\n",
+      "    cpu_util_percent: 25.403333333333332\n",
+      "    gpu_util_percent0: 0.2933333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7733333333333334\n",
+      "    ram_util_percent: 3.769999999999999\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15796218411921265\n",
-      "    mean_env_wait_ms: 1.1639934756279489\n",
-      "    mean_inference_ms: 5.2000617098190585\n",
-      "    mean_raw_obs_processing_ms: 0.4209348049282861\n",
-      "  time_since_restore: 131.93419408798218\n",
-      "  time_this_iter_s: 25.734494924545288\n",
-      "  time_total_s: 131.93419408798218\n",
+      "    mean_action_processing_ms: 0.1586091055156298\n",
+      "    mean_env_wait_ms: 1.1701168023423736\n",
+      "    mean_inference_ms: 5.060829505330093\n",
+      "    mean_raw_obs_processing_ms: 0.41969310004805094\n",
+      "  time_since_restore: 134.52119374275208\n",
+      "  time_this_iter_s: 26.233002424240112\n",
+      "  time_total_s: 134.52119374275208\n",
       "  timers:\n",
-      "    learn_throughput: 8680.33\n",
-      "    learn_time_ms: 18638.923\n",
-      "    sample_throughput: 21108.552\n",
-      "    sample_time_ms: 7664.761\n",
-      "    update_time_ms: 36.284\n",
-      "  timestamp: 1602447626\n",
+      "    learn_throughput: 8384.916\n",
+      "    learn_time_ms: 19295.602\n",
+      "    sample_throughput: 21571.257\n",
+      "    sample_time_ms: 7500.351\n",
+      "    update_time_ms: 33.014\n",
+      "  timestamp: 1602498992\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      5 |          131.934 | 808960 |  220.185 |              280.566 |              75.8687 |            878.037 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      5 |          134.521 | 808960 |  220.159 |              274.808 |               137.99 |            878.257 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3584.0131208997186\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-20-51\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3575.0697674418607\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-12_10-36-59\n",
       "  done: false\n",
-      "  episode_len_mean: 870.7881278538813\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 224.09796596097948\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 305\n",
-      "  episodes_total: 1095\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 868.2937443336356\n",
+      "  episode_reward_max: 283.14141414141375\n",
+      "  episode_reward_mean: 223.16600272901252\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 313\n",
+      "  episodes_total: 1103\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -731,14 +723,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0736289421717327\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0076567893071721\n",
+      "        entropy: 1.0826950172583263\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.008017374784685671\n",
       "        model: {}\n",
-      "        policy_loss: -0.012293024260240296\n",
-      "        total_loss: 33.63621966044108\n",
-      "        vf_explained_var: 0.9586592316627502\n",
-      "        vf_loss: 33.64828300476074\n",
+      "        policy_loss: -0.009852176726174852\n",
+      "        total_loss: 37.77317714691162\n",
+      "        vf_explained_var: 0.9565708637237549\n",
+      "        vf_loss: 37.78233687082926\n",
       "    num_steps_sampled: 970752\n",
       "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 6\n",
@@ -746,65 +738,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.536666666666672\n",
-      "    gpu_util_percent0: 0.28833333333333333\n",
+      "    cpu_util_percent: 24.190322580645162\n",
+      "    gpu_util_percent0: 0.23612903225806453\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.764516129032258\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15607596891536865\n",
-      "    mean_env_wait_ms: 1.1671366247994843\n",
-      "    mean_inference_ms: 5.0500729045139465\n",
-      "    mean_raw_obs_processing_ms: 0.4143215108904387\n",
-      "  time_since_restore: 157.5549192428589\n",
-      "  time_this_iter_s: 25.62072515487671\n",
-      "  time_total_s: 157.5549192428589\n",
+      "    mean_action_processing_ms: 0.15664185353614687\n",
+      "    mean_env_wait_ms: 1.1733919147808136\n",
+      "    mean_inference_ms: 4.933464734194755\n",
+      "    mean_raw_obs_processing_ms: 0.41334844709820934\n",
+      "  time_since_restore: 161.07573556900024\n",
+      "  time_this_iter_s: 26.55454182624817\n",
+      "  time_total_s: 161.07573556900024\n",
       "  timers:\n",
-      "    learn_throughput: 8674.401\n",
-      "    learn_time_ms: 18651.663\n",
-      "    sample_throughput: 21499.526\n",
-      "    sample_time_ms: 7525.375\n",
-      "    update_time_ms: 33.988\n",
-      "  timestamp: 1602447651\n",
+      "    learn_throughput: 8371.537\n",
+      "    learn_time_ms: 19326.439\n",
+      "    sample_throughput: 21813.622\n",
+      "    sample_time_ms: 7417.017\n",
+      "    update_time_ms: 30.93\n",
+      "  timestamp: 1602499019\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      6 |          157.555 | 970752 |  224.098 |              280.566 |              75.8687 |            870.788 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      6 |          161.076 | 970752 |  223.166 |              283.141 |               137.99 |            868.294 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3570.73786407767\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-17\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3561.846278317152\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-12_10-37-26\n",
       "  done: false\n",
-      "  episode_len_mean: 867.189082278481\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 226.04501502365406\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 169\n",
+      "  episode_len_mean: 862.3742088607595\n",
+      "  episode_reward_max: 283.14141414141375\n",
+      "  episode_reward_mean: 225.2731747858328\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 161\n",
       "  episodes_total: 1264\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -813,14 +805,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0686622162659962\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007437769207172096\n",
+      "        entropy: 1.0706466734409332\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007869300238477686\n",
       "        model: {}\n",
-      "        policy_loss: -0.012086212953969758\n",
-      "        total_loss: 20.895000457763672\n",
-      "        vf_explained_var: 0.9618611931800842\n",
-      "        vf_loss: 20.906877199808758\n",
+      "        policy_loss: -0.013351764432930699\n",
+      "        total_loss: 18.482054869333904\n",
+      "        vf_explained_var: 0.9659532904624939\n",
+      "        vf_loss: 18.49472649892171\n",
       "    num_steps_sampled: 1132544\n",
       "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 7\n",
@@ -828,65 +820,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.313\n",
+      "    cpu_util_percent: 24.938709677419357\n",
+      "    gpu_util_percent0: 0.3\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7838709677419353\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1553269146624884\n",
-      "    mean_env_wait_ms: 1.1685347068037049\n",
-      "    mean_inference_ms: 4.989185923698291\n",
-      "    mean_raw_obs_processing_ms: 0.41171449184267606\n",
-      "  time_since_restore: 183.35250997543335\n",
-      "  time_this_iter_s: 25.797590732574463\n",
-      "  time_total_s: 183.35250997543335\n",
+      "    mean_action_processing_ms: 0.15591166101973544\n",
+      "    mean_env_wait_ms: 1.1749379809941753\n",
+      "    mean_inference_ms: 4.886064883205583\n",
+      "    mean_raw_obs_processing_ms: 0.41093302096182477\n",
+      "  time_since_restore: 187.52741384506226\n",
+      "  time_this_iter_s: 26.45167827606201\n",
+      "  time_total_s: 187.52741384506226\n",
       "  timers:\n",
-      "    learn_throughput: 8659.305\n",
-      "    learn_time_ms: 18684.179\n",
-      "    sample_throughput: 21782.079\n",
-      "    sample_time_ms: 7427.757\n",
-      "    update_time_ms: 32.583\n",
-      "  timestamp: 1602447677\n",
+      "    learn_throughput: 8363.488\n",
+      "    learn_time_ms: 19345.04\n",
+      "    sample_throughput: 22033.156\n",
+      "    sample_time_ms: 7343.115\n",
+      "    update_time_ms: 33.276\n",
+      "  timestamp: 1602499046\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      7 |          183.353 | 1132544 |  226.045 |              280.566 |              75.8687 |            867.189 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      7 |          187.527 | 1132544 |  225.273 |              283.141 |               137.99 |            862.374 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3558.4670014347203\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-43\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3551.647776183644\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-12_10-37-52\n",
       "  done: false\n",
-      "  episode_len_mean: 863.3881856540085\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 227.5396155649319\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 858.2130801687764\n",
+      "  episode_reward_max: 286.9292929292936\n",
+      "  episode_reward_mean: 227.1781954566763\n",
+      "  episode_reward_min: 137.98989898989845\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1422\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -895,14 +887,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0467442870140076\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00735667875657479\n",
+      "        entropy: 1.0530053079128265\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007424288894981146\n",
       "        model: {}\n",
-      "        policy_loss: -0.012476529033544162\n",
-      "        total_loss: 16.631463209788006\n",
-      "        vf_explained_var: 0.9689691066741943\n",
-      "        vf_loss: 16.643727620442707\n",
+      "        policy_loss: -0.014031020080437884\n",
+      "        total_loss: 18.28844420115153\n",
+      "        vf_explained_var: 0.9650914669036865\n",
+      "        vf_loss: 18.30183744430542\n",
       "    num_steps_sampled: 1294336\n",
       "    num_steps_trained: 1294336\n",
       "  iterations_since_restore: 8\n",
@@ -910,65 +902,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666667\n",
-      "    gpu_util_percent0: 0.3546666666666667\n",
+      "    cpu_util_percent: 24.380645161290314\n",
+      "    gpu_util_percent0: 0.22225806451612906\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7866666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7806451612903227\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547256264044939\n",
-      "    mean_env_wait_ms: 1.1697889323469424\n",
-      "    mean_inference_ms: 4.941149080036455\n",
-      "    mean_raw_obs_processing_ms: 0.4095648767577179\n",
-      "  time_since_restore: 208.95958399772644\n",
-      "  time_this_iter_s: 25.60707402229309\n",
-      "  time_total_s: 208.95958399772644\n",
+      "    mean_action_processing_ms: 0.15530326568095648\n",
+      "    mean_env_wait_ms: 1.1764298007735843\n",
+      "    mean_inference_ms: 4.846314058519118\n",
+      "    mean_raw_obs_processing_ms: 0.40887256534763894\n",
+      "  time_since_restore: 214.2479329109192\n",
+      "  time_this_iter_s: 26.720519065856934\n",
+      "  time_total_s: 214.2479329109192\n",
       "  timers:\n",
-      "    learn_throughput: 8657.699\n",
-      "    learn_time_ms: 18687.644\n",
-      "    sample_throughput: 22008.019\n",
-      "    sample_time_ms: 7351.502\n",
-      "    update_time_ms: 31.768\n",
-      "  timestamp: 1602447703\n",
+      "    learn_throughput: 8345.973\n",
+      "    learn_time_ms: 19385.636\n",
+      "    sample_throughput: 22180.4\n",
+      "    sample_time_ms: 7294.368\n",
+      "    update_time_ms: 34.431\n",
+      "  timestamp: 1602499072\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1294336\n",
       "  training_iteration: 8\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      8 |           208.96 | 1294336 |   227.54 |              280.566 |              75.8687 |            863.388 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      8 |          214.248 | 1294336 |  227.178 |              286.929 |               137.99 |            858.213 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3548.3775773195875\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-22-08\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3540.2345360824743\n",
+      "    time_step_min: 3187\n",
+      "  date: 2020-10-12_10-38-19\n",
       "  done: false\n",
-      "  episode_len_mean: 859.5791139240506\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 229.39314026339326\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 854.4341772151898\n",
+      "  episode_reward_max: 286.9292929292936\n",
+      "  episode_reward_mean: 228.90886715253788\n",
+      "  episode_reward_min: 137.98989898989845\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1580\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -977,14 +969,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0254518787066143\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007505126879550517\n",
+      "        entropy: 1.0118485788504283\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007579043585186203\n",
       "        model: {}\n",
-      "        policy_loss: -0.013200220981768021\n",
-      "        total_loss: 16.60719045003255\n",
-      "        vf_explained_var: 0.9654716849327087\n",
-      "        vf_loss: 16.620153188705444\n",
+      "        policy_loss: -0.010258643926742176\n",
+      "        total_loss: 15.40296204884847\n",
+      "        vf_explained_var: 0.9705337882041931\n",
+      "        vf_loss: 15.412563880284628\n",
       "    num_steps_sampled: 1456128\n",
       "    num_steps_trained: 1456128\n",
       "  iterations_since_restore: 9\n",
@@ -992,65 +984,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.97586206896552\n",
-      "    gpu_util_percent0: 0.373103448275862\n",
+      "    cpu_util_percent: 24.158064516129027\n",
+      "    gpu_util_percent0: 0.38258064516129037\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7689655172413787\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7741935483870965\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15420505835699988\n",
-      "    mean_env_wait_ms: 1.1709664764376828\n",
-      "    mean_inference_ms: 4.899308239449433\n",
-      "    mean_raw_obs_processing_ms: 0.4076704455336656\n",
-      "  time_since_restore: 234.6318006515503\n",
-      "  time_this_iter_s: 25.672216653823853\n",
-      "  time_total_s: 234.6318006515503\n",
+      "    mean_action_processing_ms: 0.15476785735377394\n",
+      "    mean_env_wait_ms: 1.1778500832508265\n",
+      "    mean_inference_ms: 4.811731373476194\n",
+      "    mean_raw_obs_processing_ms: 0.40699710981876513\n",
+      "  time_since_restore: 240.72339725494385\n",
+      "  time_this_iter_s: 26.475464344024658\n",
+      "  time_total_s: 240.72339725494385\n",
       "  timers:\n",
-      "    learn_throughput: 8657.476\n",
-      "    learn_time_ms: 18688.125\n",
-      "    sample_throughput: 22163.621\n",
-      "    sample_time_ms: 7299.89\n",
-      "    update_time_ms: 32.627\n",
-      "  timestamp: 1602447728\n",
+      "    learn_throughput: 8342.974\n",
+      "    learn_time_ms: 19392.605\n",
+      "    sample_throughput: 22304.999\n",
+      "    sample_time_ms: 7253.621\n",
+      "    update_time_ms: 34.828\n",
+      "  timestamp: 1602499099\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1456128\n",
       "  training_iteration: 9\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      9 |          234.632 | 1456128 |  229.393 |              280.566 |              75.8687 |            859.579 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |      9 |          240.723 | 1456128 |  228.909 |              286.929 |               137.99 |            854.434 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3530.453984287318\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-22-34\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3518.7373791621912\n",
+      "    time_step_min: 3186\n",
+      "  date: 2020-10-12_10-38-45\n",
       "  done: false\n",
-      "  episode_len_mean: 855.0779005524862\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 231.6610859981024\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 230\n",
-      "  episodes_total: 1810\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 847.1243386243386\n",
+      "  episode_reward_max: 286.9292929292936\n",
+      "  episode_reward_mean: 232.65247715247702\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 310\n",
+      "  episodes_total: 1890\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1059,14 +1051,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9783310542503992\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007558321657901009\n",
+      "        entropy: 0.9885825465122858\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00694818701595068\n",
       "        model: {}\n",
-      "        policy_loss: -0.012323003092509074\n",
-      "        total_loss: 21.252121289571125\n",
-      "        vf_explained_var: 0.9696983695030212\n",
-      "        vf_loss: 21.264177322387695\n",
+      "        policy_loss: -0.011202118165480593\n",
+      "        total_loss: 19.333553791046143\n",
+      "        vf_explained_var: 0.9741263389587402\n",
+      "        vf_loss: 19.344160079956055\n",
       "    num_steps_sampled: 1617920\n",
       "    num_steps_trained: 1617920\n",
       "  iterations_since_restore: 10\n",
@@ -1074,65 +1066,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.10322580645162\n",
-      "    gpu_util_percent0: 0.44322580645161286\n",
+      "    cpu_util_percent: 24.709677419354836\n",
+      "    gpu_util_percent0: 0.27290322580645165\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
+      "    ram_util_percent: 3.7677419354838704\n",
       "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15357945616241028\n",
-      "    mean_env_wait_ms: 1.1729293401628718\n",
-      "    mean_inference_ms: 4.848476154423788\n",
-      "    mean_raw_obs_processing_ms: 0.4053396875096163\n",
-      "  time_since_restore: 260.496376991272\n",
-      "  time_this_iter_s: 25.86457633972168\n",
-      "  time_total_s: 260.496376991272\n",
+      "    mean_action_processing_ms: 0.15392287472502042\n",
+      "    mean_env_wait_ms: 1.1807863849799112\n",
+      "    mean_inference_ms: 4.7571964111281115\n",
+      "    mean_raw_obs_processing_ms: 0.4041469352140854\n",
+      "  time_since_restore: 267.1956088542938\n",
+      "  time_this_iter_s: 26.472211599349976\n",
+      "  time_total_s: 267.1956088542938\n",
       "  timers:\n",
-      "    learn_throughput: 8649.232\n",
-      "    learn_time_ms: 18705.938\n",
-      "    sample_throughput: 22309.364\n",
-      "    sample_time_ms: 7252.201\n",
-      "    update_time_ms: 32.981\n",
-      "  timestamp: 1602447754\n",
+      "    learn_throughput: 8346.803\n",
+      "    learn_time_ms: 19383.71\n",
+      "    sample_throughput: 22356.441\n",
+      "    sample_time_ms: 7236.93\n",
+      "    update_time_ms: 33.941\n",
+      "  timestamp: 1602499125\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1617920\n",
       "  training_iteration: 10\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     10 |          260.496 | 1617920 |  231.661 |              282.838 |              75.8687 |            855.078 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     10 |          267.196 | 1617920 |  232.652 |              286.929 |               137.99 |            847.124 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3515.8815399802565\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-23-00\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3508.0286278381045\n",
+      "    time_step_min: 3186\n",
+      "  date: 2020-10-12_10-39-12\n",
       "  done: false\n",
-      "  episode_len_mean: 851.3515092502435\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 233.5874027519596\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 244\n",
+      "  episode_len_mean: 843.8758519961052\n",
+      "  episode_reward_max: 286.9292929292936\n",
+      "  episode_reward_mean: 234.34446214825948\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 164\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1141,14 +1133,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9831370264291763\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007093390799127519\n",
+      "        entropy: 0.9782296568155289\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0074202436953783035\n",
       "        model: {}\n",
-      "        policy_loss: -0.012145887061099833\n",
-      "        total_loss: 15.38879140218099\n",
-      "        vf_explained_var: 0.9745174050331116\n",
-      "        vf_loss: 15.400719245274862\n",
+      "        policy_loss: -0.011524421182305863\n",
+      "        total_loss: 11.349893887837728\n",
+      "        vf_explained_var: 0.9778836369514465\n",
+      "        vf_loss: 11.360774596532186\n",
       "    num_steps_sampled: 1779712\n",
       "    num_steps_trained: 1779712\n",
       "  iterations_since_restore: 11\n",
@@ -1156,65 +1148,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.058620689655175\n",
-      "    gpu_util_percent0: 0.34068965517241384\n",
+      "    cpu_util_percent: 24.56129032258064\n",
+      "    gpu_util_percent0: 0.3477419354838709\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.772413793103448\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.783870967741935\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15299769941749414\n",
-      "    mean_env_wait_ms: 1.174449037632307\n",
-      "    mean_inference_ms: 4.802499299001492\n",
-      "    mean_raw_obs_processing_ms: 0.40323562982226707\n",
-      "  time_since_restore: 285.89834547042847\n",
-      "  time_this_iter_s: 25.401968479156494\n",
-      "  time_total_s: 285.89834547042847\n",
+      "    mean_action_processing_ms: 0.15355425518756677\n",
+      "    mean_env_wait_ms: 1.1820984902846068\n",
+      "    mean_inference_ms: 4.73331126022154\n",
+      "    mean_raw_obs_processing_ms: 0.4029051173011415\n",
+      "  time_since_restore: 293.6323890686035\n",
+      "  time_this_iter_s: 26.436780214309692\n",
+      "  time_total_s: 293.6323890686035\n",
       "  timers:\n",
-      "    learn_throughput: 8657.708\n",
-      "    learn_time_ms: 18687.626\n",
-      "    sample_throughput: 23227.447\n",
-      "    sample_time_ms: 6965.552\n",
-      "    update_time_ms: 32.734\n",
-      "  timestamp: 1602447780\n",
+      "    learn_throughput: 8335.377\n",
+      "    learn_time_ms: 19410.281\n",
+      "    sample_throughput: 23016.163\n",
+      "    sample_time_ms: 7029.495\n",
+      "    update_time_ms: 32.961\n",
+      "  timestamp: 1602499152\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
       "  training_iteration: 11\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     11 |          285.898 | 1779712 |  233.587 |              282.838 |              75.8687 |            851.352 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     11 |          293.632 | 1779712 |  234.344 |              286.929 |               137.99 |            843.876 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3507.2843406593406\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-26\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3497.526098901099\n",
+      "    time_step_min: 3186\n",
+      "  date: 2020-10-12_10-39-39\n",
       "  done: false\n",
-      "  episode_len_mean: 849.3214285714286\n",
-      "  episode_reward_max: 283.1414141414142\n",
-      "  episode_reward_mean: 234.8278764133193\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 840.8141952983725\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 236.0104069629385\n",
+      "  episode_reward_min: 137.98989898989845\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2212\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1223,14 +1215,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9695532222588857\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006893695720161001\n",
+      "        entropy: 0.9659954756498337\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00687529263086617\n",
       "        model: {}\n",
-      "        policy_loss: -0.013366622074196735\n",
-      "        total_loss: 11.94997787475586\n",
-      "        vf_explained_var: 0.9762477278709412\n",
-      "        vf_loss: 11.963139851888021\n",
+      "        policy_loss: -0.011743300943635404\n",
+      "        total_loss: 12.973399877548218\n",
+      "        vf_explained_var: 0.9719108939170837\n",
+      "        vf_loss: 12.984552383422852\n",
       "    num_steps_sampled: 1941504\n",
       "    num_steps_trained: 1941504\n",
       "  iterations_since_restore: 12\n",
@@ -1238,65 +1230,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.98\n",
-      "    gpu_util_percent0: 0.39133333333333326\n",
+      "    cpu_util_percent: 24.412903225806446\n",
+      "    gpu_util_percent0: 0.3206451612903226\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7838709677419353\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15267911592020442\n",
-      "    mean_env_wait_ms: 1.1754082858107124\n",
-      "    mean_inference_ms: 4.7771672423033875\n",
-      "    mean_raw_obs_processing_ms: 0.40206413935896457\n",
-      "  time_since_restore: 311.4134485721588\n",
-      "  time_this_iter_s: 25.515103101730347\n",
-      "  time_total_s: 311.4134485721588\n",
+      "    mean_action_processing_ms: 0.15323285279483564\n",
+      "    mean_env_wait_ms: 1.1832804784605555\n",
+      "    mean_inference_ms: 4.712784382778184\n",
+      "    mean_raw_obs_processing_ms: 0.4018179425599785\n",
+      "  time_since_restore: 320.4737470149994\n",
+      "  time_this_iter_s: 26.841357946395874\n",
+      "  time_total_s: 320.4737470149994\n",
       "  timers:\n",
-      "    learn_throughput: 8665.219\n",
-      "    learn_time_ms: 18671.427\n",
-      "    sample_throughput: 23495.398\n",
-      "    sample_time_ms: 6886.115\n",
-      "    update_time_ms: 31.361\n",
-      "  timestamp: 1602447806\n",
+      "    learn_throughput: 8319.589\n",
+      "    learn_time_ms: 19447.113\n",
+      "    sample_throughput: 23226.654\n",
+      "    sample_time_ms: 6965.79\n",
+      "    update_time_ms: 33.642\n",
+      "  timestamp: 1602499179\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1941504\n",
       "  training_iteration: 12\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     12 |          311.413 | 1941504 |  234.828 |              283.141 |              75.8687 |            849.321 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     12 |          320.474 | 1941504 |   236.01 |              289.505 |               137.99 |            840.814 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3499.359948761742\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-51\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3487.3178360101438\n",
+      "    time_step_min: 3170\n",
+      "  date: 2020-10-12_10-40-06\n",
       "  done: false\n",
-      "  episode_len_mean: 847.2481012658228\n",
-      "  episode_reward_max: 284.2020202020199\n",
-      "  episode_reward_mean: 236.03087840429595\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 837.5388471177945\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 237.452001215159\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 182\n",
+      "  episodes_total: 2394\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1305,14 +1297,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9525636037190756\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007253999511400859\n",
+      "        entropy: 0.9220593820015589\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.007104225301494201\n",
       "        model: {}\n",
-      "        policy_loss: -0.011778777848424701\n",
-      "        total_loss: 12.683573007583618\n",
-      "        vf_explained_var: 0.9729364514350891\n",
-      "        vf_loss: 12.695102532704672\n",
+      "        policy_loss: -0.013087665856194993\n",
+      "        total_loss: 14.173670689264933\n",
+      "        vf_explained_var: 0.976102352142334\n",
+      "        vf_loss: 14.186140378316244\n",
       "    num_steps_sampled: 2103296\n",
       "    num_steps_trained: 2103296\n",
       "  iterations_since_restore: 13\n",
@@ -1320,65 +1312,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.848275862068967\n",
-      "    gpu_util_percent0: 0.4362068965517242\n",
+      "    cpu_util_percent: 24.419354838709673\n",
+      "    gpu_util_percent0: 0.2954838709677419\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7758620689655173\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7774193548387096\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15238677910288023\n",
-      "    mean_env_wait_ms: 1.1762651426265218\n",
-      "    mean_inference_ms: 4.754077360657\n",
-      "    mean_raw_obs_processing_ms: 0.40096428130312095\n",
-      "  time_since_restore: 336.9129900932312\n",
-      "  time_this_iter_s: 25.499541521072388\n",
-      "  time_total_s: 336.9129900932312\n",
+      "    mean_action_processing_ms: 0.15289814529481696\n",
+      "    mean_env_wait_ms: 1.1846964701491667\n",
+      "    mean_inference_ms: 4.691346183301928\n",
+      "    mean_raw_obs_processing_ms: 0.40064349388162007\n",
+      "  time_since_restore: 347.0233097076416\n",
+      "  time_this_iter_s: 26.549562692642212\n",
+      "  time_total_s: 347.0233097076416\n",
       "  timers:\n",
-      "    learn_throughput: 8658.975\n",
-      "    learn_time_ms: 18684.892\n",
-      "    sample_throughput: 23608.495\n",
-      "    sample_time_ms: 6853.126\n",
-      "    update_time_ms: 29.201\n",
-      "  timestamp: 1602447831\n",
+      "    learn_throughput: 8314.854\n",
+      "    learn_time_ms: 19458.189\n",
+      "    sample_throughput: 23179.376\n",
+      "    sample_time_ms: 6979.998\n",
+      "    update_time_ms: 31.984\n",
+      "  timestamp: 1602499206\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2103296\n",
       "  training_iteration: 13\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     13 |          336.913 | 2103296 |  236.031 |              284.202 |              75.8687 |            847.248 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     13 |          347.023 | 2103296 |  237.452 |              289.505 |               137.99 |            837.539 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3489.3022256930885\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-24-17\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3473.3540255831454\n",
+      "    time_step_min: 3170\n",
+      "  date: 2020-10-12_10-40-32\n",
       "  done: false\n",
-      "  episode_len_mean: 845.1205098493626\n",
-      "  episode_reward_max: 285.111111111111\n",
-      "  episode_reward_mean: 237.57315916991453\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 219\n",
-      "  episodes_total: 2589\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 833.4810126582279\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 239.5821054927532\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 292\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1387,14 +1379,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9141986866792043\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006633194202246766\n",
+      "        entropy: 0.9201588133970896\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006468101870268583\n",
       "        model: {}\n",
-      "        policy_loss: -0.011397288045069823\n",
-      "        total_loss: 14.408097267150879\n",
-      "        vf_explained_var: 0.9782162308692932\n",
-      "        vf_loss: 14.419288237889608\n",
+      "        policy_loss: -0.012541183774980405\n",
+      "        total_loss: 12.514065821965536\n",
+      "        vf_explained_var: 0.980458676815033\n",
+      "        vf_loss: 12.526052554448446\n",
       "    num_steps_sampled: 2265088\n",
       "    num_steps_trained: 2265088\n",
       "  iterations_since_restore: 14\n",
@@ -1402,65 +1394,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.483333333333338\n",
-      "    gpu_util_percent0: 0.38299999999999995\n",
+      "    cpu_util_percent: 24.877419354838718\n",
+      "    gpu_util_percent0: 0.23096774193548392\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.770967741935483\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15203612506882044\n",
-      "    mean_env_wait_ms: 1.177434403681755\n",
-      "    mean_inference_ms: 4.725975916232662\n",
-      "    mean_raw_obs_processing_ms: 0.3996285154228699\n",
-      "  time_since_restore: 362.68629479408264\n",
-      "  time_this_iter_s: 25.77330470085144\n",
-      "  time_total_s: 362.68629479408264\n",
+      "    mean_action_processing_ms: 0.1524375582923526\n",
+      "    mean_env_wait_ms: 1.1867413039923655\n",
+      "    mean_inference_ms: 4.662413518353599\n",
+      "    mean_raw_obs_processing_ms: 0.39911492607401206\n",
+      "  time_since_restore: 373.6990442276001\n",
+      "  time_this_iter_s: 26.675734519958496\n",
+      "  time_total_s: 373.6990442276001\n",
       "  timers:\n",
-      "    learn_throughput: 8642.561\n",
-      "    learn_time_ms: 18720.378\n",
-      "    sample_throughput: 23665.671\n",
-      "    sample_time_ms: 6836.569\n",
-      "    update_time_ms: 27.867\n",
-      "  timestamp: 1602447857\n",
+      "    learn_throughput: 8311.21\n",
+      "    learn_time_ms: 19466.719\n",
+      "    sample_throughput: 23157.733\n",
+      "    sample_time_ms: 6986.522\n",
+      "    update_time_ms: 31.223\n",
+      "  timestamp: 1602499232\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2265088\n",
       "  training_iteration: 14\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     14 |          362.686 | 2265088 |  237.573 |              285.111 |              75.8687 |            845.121 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     14 |          373.699 | 2265088 |  239.582 |              289.505 |               137.99 |            833.481 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3478.2078152753106\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-24-43\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3466.54296875\n",
+      "    time_step_min: 3170\n",
+      "  date: 2020-10-12_10-40-59\n",
       "  done: false\n",
-      "  episode_len_mean: 843.0049243756595\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 239.0910085732455\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 254\n",
-      "  episodes_total: 2843\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 831.3913502109705\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 240.64524996803468\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1469,14 +1461,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.906439483165741\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00629633719411989\n",
+      "        entropy: 0.9064158648252487\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.00678737946630766\n",
       "        model: {}\n",
-      "        policy_loss: -0.008484600538698336\n",
-      "        total_loss: 13.794315973917643\n",
-      "        vf_explained_var: 0.977971076965332\n",
-      "        vf_loss: 13.802624225616455\n",
+      "        policy_loss: -0.012710827655003717\n",
+      "        total_loss: 10.679505268732706\n",
+      "        vf_explained_var: 0.9777107238769531\n",
+      "        vf_loss: 10.691628138224283\n",
       "    num_steps_sampled: 2426880\n",
       "    num_steps_trained: 2426880\n",
       "  iterations_since_restore: 15\n",
@@ -1484,65 +1476,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.4\n",
-      "    gpu_util_percent0: 0.2956666666666666\n",
+      "    cpu_util_percent: 24.619354838709675\n",
+      "    gpu_util_percent0: 0.3261290322580645\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769999999999999\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7838709677419353\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15166958436902533\n",
-      "    mean_env_wait_ms: 1.1785378851431692\n",
-      "    mean_inference_ms: 4.696807133847539\n",
-      "    mean_raw_obs_processing_ms: 0.39823878821593045\n",
-      "  time_since_restore: 388.19724225997925\n",
-      "  time_this_iter_s: 25.510947465896606\n",
-      "  time_total_s: 388.19724225997925\n",
+      "    mean_action_processing_ms: 0.15222078204296272\n",
+      "    mean_env_wait_ms: 1.1877630325702035\n",
+      "    mean_inference_ms: 4.648666565690875\n",
+      "    mean_raw_obs_processing_ms: 0.39837897466394867\n",
+      "  time_since_restore: 400.2849922180176\n",
+      "  time_this_iter_s: 26.58594799041748\n",
+      "  time_total_s: 400.2849922180176\n",
       "  timers:\n",
-      "    learn_throughput: 8641.51\n",
-      "    learn_time_ms: 18722.653\n",
-      "    sample_throughput: 23758.911\n",
-      "    sample_time_ms: 6809.74\n",
-      "    update_time_ms: 28.865\n",
-      "  timestamp: 1602447883\n",
+      "    learn_throughput: 8302.729\n",
+      "    learn_time_ms: 19486.604\n",
+      "    sample_throughput: 23107.773\n",
+      "    sample_time_ms: 7001.627\n",
+      "    update_time_ms: 29.563\n",
+      "  timestamp: 1602499259\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2426880\n",
       "  training_iteration: 15\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     15 |          388.197 | 2426880 |  239.091 |              294.202 |              75.8687 |            843.005 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     15 |          400.285 | 2426880 |  240.645 |              289.505 |               137.99 |            831.391 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3471.2484868863485\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-08\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3459.892737054472\n",
+      "    time_step_min: 3170\n",
+      "  date: 2020-10-12_10-41-26\n",
       "  done: false\n",
-      "  episode_len_mean: 841.4696868754164\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.07658867152526\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 159\n",
+      "  episode_len_mean: 830.020652898068\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 241.5691289981762\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 3002\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1551,14 +1543,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8939206699530283\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007120410058026512\n",
+      "        entropy: 0.8919036090373993\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0065164086408913136\n",
       "        model: {}\n",
-      "        policy_loss: -0.013225489509447167\n",
-      "        total_loss: 11.056419531504313\n",
-      "        vf_explained_var: 0.977925717830658\n",
-      "        vf_loss: 11.069379409154257\n",
+      "        policy_loss: -0.011898661767190788\n",
+      "        total_loss: 10.162490367889404\n",
+      "        vf_explained_var: 0.9785982966423035\n",
+      "        vf_loss: 10.173826615015665\n",
       "    num_steps_sampled: 2588672\n",
       "    num_steps_trained: 2588672\n",
       "  iterations_since_restore: 16\n",
@@ -1566,65 +1558,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.989655172413798\n",
-      "    gpu_util_percent0: 0.32172413793103455\n",
+      "    cpu_util_percent: 24.887096774193544\n",
+      "    gpu_util_percent0: 0.3709677419354839\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.787096774193548\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15146700941909105\n",
-      "    mean_env_wait_ms: 1.1791897641952667\n",
-      "    mean_inference_ms: 4.6806621211616175\n",
-      "    mean_raw_obs_processing_ms: 0.3974652038101286\n",
-      "  time_since_restore: 413.7767312526703\n",
-      "  time_this_iter_s: 25.57948899269104\n",
-      "  time_total_s: 413.7767312526703\n",
+      "    mean_action_processing_ms: 0.15202076624090607\n",
+      "    mean_env_wait_ms: 1.1887146176559318\n",
+      "    mean_inference_ms: 4.635949922921678\n",
+      "    mean_raw_obs_processing_ms: 0.39768803533396757\n",
+      "  time_since_restore: 426.76628279685974\n",
+      "  time_this_iter_s: 26.481290578842163\n",
+      "  time_total_s: 426.76628279685974\n",
       "  timers:\n",
-      "    learn_throughput: 8641.857\n",
-      "    learn_time_ms: 18721.903\n",
-      "    sample_throughput: 23771.571\n",
-      "    sample_time_ms: 6806.113\n",
-      "    update_time_ms: 28.84\n",
-      "  timestamp: 1602447908\n",
+      "    learn_throughput: 8309.412\n",
+      "    learn_time_ms: 19470.933\n",
+      "    sample_throughput: 23085.494\n",
+      "    sample_time_ms: 7008.384\n",
+      "    update_time_ms: 29.45\n",
+      "  timestamp: 1602499286\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2588672\n",
       "  training_iteration: 16\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     16 |          413.777 | 2588672 |  240.077 |              294.202 |              75.8687 |             841.47 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     16 |          426.766 | 2588672 |  241.569 |              289.505 |               137.99 |            830.021 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3464.836845466156\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-34\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3451.432941903585\n",
+      "    time_step_min: 3158\n",
+      "  date: 2020-10-12_10-41-52\n",
       "  done: false\n",
-      "  episode_len_mean: 839.8240506329114\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.94871180155977\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3160\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 827.9087009803922\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 242.70980020796188\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 262\n",
+      "  episodes_total: 3264\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1633,14 +1625,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823149502277374\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006691928138025105\n",
+      "        entropy: 0.8572876205046972\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006706862438780566\n",
       "        model: {}\n",
-      "        policy_loss: -0.011884851943856726\n",
-      "        total_loss: 10.509639422098795\n",
-      "        vf_explained_var: 0.9782719612121582\n",
-      "        vf_loss: 10.521296262741089\n",
+      "        policy_loss: -0.011741302907466888\n",
+      "        total_loss: 15.199506441752115\n",
+      "        vf_explained_var: 0.97942715883255\n",
+      "        vf_loss: 15.210662841796875\n",
       "    num_steps_sampled: 2750464\n",
       "    num_steps_trained: 2750464\n",
       "  iterations_since_restore: 17\n",
@@ -1648,65 +1640,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.383333333333336\n",
-      "    gpu_util_percent0: 0.266\n",
+      "    cpu_util_percent: 24.719354838709684\n",
+      "    gpu_util_percent0: 0.32548387096774195\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7612903225806447\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1512813004386509\n",
-      "    mean_env_wait_ms: 1.179821308066897\n",
-      "    mean_inference_ms: 4.665766796337426\n",
-      "    mean_raw_obs_processing_ms: 0.3967421105344154\n",
-      "  time_since_restore: 439.20659351348877\n",
-      "  time_this_iter_s: 25.42986226081848\n",
-      "  time_total_s: 439.20659351348877\n",
+      "    mean_action_processing_ms: 0.15172864965332547\n",
+      "    mean_env_wait_ms: 1.1902196110419858\n",
+      "    mean_inference_ms: 4.617188440695888\n",
+      "    mean_raw_obs_processing_ms: 0.3966868085580042\n",
+      "  time_since_restore: 453.4419045448303\n",
+      "  time_this_iter_s: 26.67562174797058\n",
+      "  time_total_s: 453.4419045448303\n",
       "  timers:\n",
-      "    learn_throughput: 8657.028\n",
-      "    learn_time_ms: 18689.092\n",
-      "    sample_throughput: 23787.343\n",
-      "    sample_time_ms: 6801.6\n",
-      "    update_time_ms: 28.419\n",
-      "  timestamp: 1602447934\n",
+      "    learn_throughput: 8310.197\n",
+      "    learn_time_ms: 19469.093\n",
+      "    sample_throughput: 23005.301\n",
+      "    sample_time_ms: 7032.814\n",
+      "    update_time_ms: 28.266\n",
+      "  timestamp: 1602499312\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2750464\n",
       "  training_iteration: 17\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     17 |          439.207 | 2750464 |  240.949 |              294.202 |              75.8687 |            839.824 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     17 |          453.442 | 2750464 |   242.71 |              289.505 |               137.99 |            827.909 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3454.8194444444443\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-59\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3445.4002320185614\n",
+      "    time_step_min: 3146\n",
+      "  date: 2020-10-12_10-42-19\n",
       "  done: false\n",
-      "  episode_len_mean: 837.3622508792497\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 242.37695536845584\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 252\n",
-      "  episodes_total: 3412\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 826.5290563866513\n",
+      "  episode_reward_max: 289.5050505050505\n",
+      "  episode_reward_mean: 243.6558072090292\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 212\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1715,14 +1707,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.851616899172465\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006081323605030775\n",
+      "        entropy: 0.8529605269432068\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005917649987774591\n",
       "        model: {}\n",
-      "        policy_loss: -0.010536718415096402\n",
-      "        total_loss: 13.626426935195923\n",
-      "        vf_explained_var: 0.9793136715888977\n",
-      "        vf_loss: 13.636781613032023\n",
+      "        policy_loss: -0.011277009830034027\n",
+      "        total_loss: 11.547587235768637\n",
+      "        vf_explained_var: 0.9794904589653015\n",
+      "        vf_loss: 11.558358192443848\n",
       "    num_steps_sampled: 2912256\n",
       "    num_steps_trained: 2912256\n",
       "  iterations_since_restore: 18\n",
@@ -1730,65 +1722,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.302\n",
+      "    cpu_util_percent: 24.622580645161293\n",
+      "    gpu_util_percent0: 0.407741935483871\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7633333333333328\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7709677419354835\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.151021285653716\n",
-      "    mean_env_wait_ms: 1.1808787240074101\n",
-      "    mean_inference_ms: 4.644646637518742\n",
-      "    mean_raw_obs_processing_ms: 0.395716154310957\n",
-      "  time_since_restore: 464.71025347709656\n",
-      "  time_this_iter_s: 25.503659963607788\n",
-      "  time_total_s: 464.71025347709656\n",
+      "    mean_action_processing_ms: 0.15151245459591453\n",
+      "    mean_env_wait_ms: 1.191304723107444\n",
+      "    mean_inference_ms: 4.603265801752061\n",
+      "    mean_raw_obs_processing_ms: 0.39595422067554054\n",
+      "  time_since_restore: 479.8950695991516\n",
+      "  time_this_iter_s: 26.45316505432129\n",
+      "  time_total_s: 479.8950695991516\n",
       "  timers:\n",
-      "    learn_throughput: 8660.443\n",
-      "    learn_time_ms: 18681.723\n",
-      "    sample_throughput: 23804.094\n",
-      "    sample_time_ms: 6796.814\n",
-      "    update_time_ms: 29.145\n",
-      "  timestamp: 1602447959\n",
+      "    learn_throughput: 8321.629\n",
+      "    learn_time_ms: 19442.346\n",
+      "    sample_throughput: 23005.85\n",
+      "    sample_time_ms: 7032.646\n",
+      "    update_time_ms: 28.083\n",
+      "  timestamp: 1602499339\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2912256\n",
       "  training_iteration: 18\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     18 |           464.71 | 2912256 |  242.377 |              294.202 |              75.8687 |            837.362 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     18 |          479.895 | 2912256 |  243.656 |              289.505 |               137.99 |            826.529 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3447.6802551303385\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-25\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3440.769828064337\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_10-42-46\n",
       "  done: false\n",
-      "  episode_len_mean: 835.4837644468905\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 243.5167414374898\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 222\n",
+      "  episode_len_mean: 825.8247110621904\n",
+      "  episode_reward_max: 294.80808080808083\n",
+      "  episode_reward_mean: 244.29612303552858\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 3634\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1797,14 +1789,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8403268406788508\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006061406301644941\n",
+      "        entropy: 0.8457075009743372\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.0065199139062315226\n",
       "        model: {}\n",
-      "        policy_loss: -0.008233758644716241\n",
-      "        total_loss: 10.79630970954895\n",
-      "        vf_explained_var: 0.9808487892150879\n",
-      "        vf_loss: 10.804357449213663\n",
+      "        policy_loss: -0.01116289470034341\n",
+      "        total_loss: 10.043978214263916\n",
+      "        vf_explained_var: 0.9801807403564453\n",
+      "        vf_loss: 10.05457361539205\n",
       "    num_steps_sampled: 3074048\n",
       "    num_steps_trained: 3074048\n",
       "  iterations_since_restore: 19\n",
@@ -1812,65 +1804,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.273333333333333\n",
-      "    gpu_util_percent0: 0.40166666666666667\n",
+      "    cpu_util_percent: 24.23548387096774\n",
+      "    gpu_util_percent0: 0.29129032258064513\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7766666666666664\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7806451612903222\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15079811866017936\n",
-      "    mean_env_wait_ms: 1.1816707724435114\n",
-      "    mean_inference_ms: 4.627169590964196\n",
-      "    mean_raw_obs_processing_ms: 0.3948970998715084\n",
-      "  time_since_restore: 490.4313905239105\n",
-      "  time_this_iter_s: 25.721137046813965\n",
-      "  time_total_s: 490.4313905239105\n",
+      "    mean_action_processing_ms: 0.1513673572672517\n",
+      "    mean_env_wait_ms: 1.1920175917054816\n",
+      "    mean_inference_ms: 4.593864716977697\n",
+      "    mean_raw_obs_processing_ms: 0.39545767616024086\n",
+      "  time_since_restore: 506.6568546295166\n",
+      "  time_this_iter_s: 26.76178503036499\n",
+      "  time_total_s: 506.6568546295166\n",
       "  timers:\n",
-      "    learn_throughput: 8653.987\n",
-      "    learn_time_ms: 18695.661\n",
-      "    sample_throughput: 23843.805\n",
-      "    sample_time_ms: 6785.494\n",
-      "    update_time_ms: 30.641\n",
-      "  timestamp: 1602447985\n",
+      "    learn_throughput: 8311.575\n",
+      "    learn_time_ms: 19465.865\n",
+      "    sample_throughput: 22990.042\n",
+      "    sample_time_ms: 7037.482\n",
+      "    update_time_ms: 28.491\n",
+      "  timestamp: 1602499366\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3074048\n",
       "  training_iteration: 19\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     19 |          490.431 | 3074048 |  243.517 |              294.202 |              75.8687 |            835.484 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     19 |          506.657 | 3074048 |  244.296 |              294.808 |               137.99 |            825.825 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3442.4577577045698\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-51\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3436.3805732484075\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_10-43-12\n",
       "  done: false\n",
-      "  episode_len_mean: 833.8357067510549\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 244.24585251246634\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 825.2513171759747\n",
+      "  episode_reward_max: 294.80808080808083\n",
+      "  episode_reward_mean: 244.92866228140193\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 162\n",
+      "  episodes_total: 3796\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1879,14 +1871,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8331598043441772\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006495586984480421\n",
+      "        entropy: 0.8178661465644836\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006614145318356653\n",
       "        model: {}\n",
-      "        policy_loss: -0.011495542149835577\n",
-      "        total_loss: 9.008565505345663\n",
-      "        vf_explained_var: 0.9805734753608704\n",
-      "        vf_loss: 9.019828001658121\n",
+      "        policy_loss: -0.012304873768395433\n",
+      "        total_loss: 9.505411148071289\n",
+      "        vf_explained_var: 0.9820902943611145\n",
+      "        vf_loss: 9.517136255900065\n",
       "    num_steps_sampled: 3235840\n",
       "    num_steps_trained: 3235840\n",
       "  iterations_since_restore: 20\n",
@@ -1894,65 +1886,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.196551724137933\n",
-      "    gpu_util_percent0: 0.44793103448275867\n",
+      "    cpu_util_percent: 24.777419354838703\n",
+      "    gpu_util_percent0: 0.3029032258064516\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.774193548387097\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1506571880081456\n",
-      "    mean_env_wait_ms: 1.1822421411112307\n",
-      "    mean_inference_ms: 4.615975210350845\n",
-      "    mean_raw_obs_processing_ms: 0.39436020417931467\n",
-      "  time_since_restore: 515.9194169044495\n",
-      "  time_this_iter_s: 25.48802638053894\n",
-      "  time_total_s: 515.9194169044495\n",
+      "    mean_action_processing_ms: 0.15122639986088446\n",
+      "    mean_env_wait_ms: 1.1926882058948682\n",
+      "    mean_inference_ms: 4.584833213203808\n",
+      "    mean_raw_obs_processing_ms: 0.3949704778072739\n",
+      "  time_since_restore: 533.0624232292175\n",
+      "  time_this_iter_s: 26.405568599700928\n",
+      "  time_total_s: 533.0624232292175\n",
       "  timers:\n",
-      "    learn_throughput: 8662.909\n",
-      "    learn_time_ms: 18676.405\n",
-      "    sample_throughput: 23887.718\n",
-      "    sample_time_ms: 6773.02\n",
-      "    update_time_ms: 31.114\n",
-      "  timestamp: 1602448011\n",
+      "    learn_throughput: 8310.33\n",
+      "    learn_time_ms: 19468.781\n",
+      "    sample_throughput: 23027.336\n",
+      "    sample_time_ms: 7026.084\n",
+      "    update_time_ms: 29.68\n",
+      "  timestamp: 1602499392\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3235840\n",
       "  training_iteration: 20\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     20 |          515.919 | 3235840 |  244.246 |              294.202 |              75.8687 |            833.836 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     20 |          533.062 | 3235840 |  244.929 |              294.808 |               137.99 |            825.251 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3437.3735398679532\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-17\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3430.280848963475\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_10-43-39\n",
       "  done: false\n",
-      "  episode_len_mean: 832.0063035804337\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 245.05460810831454\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 174\n",
-      "  episodes_total: 3966\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 824.5730392156863\n",
+      "  episode_reward_max: 297.6868686868688\n",
+      "  episode_reward_mean: 245.9245023767082\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 284\n",
+      "  episodes_total: 4080\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -1961,14 +1953,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8113537778457006\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00662113749422133\n",
+      "        entropy: 0.7949359466632208\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005695687839761376\n",
       "        model: {}\n",
-      "        policy_loss: -0.010862251704869172\n",
-      "        total_loss: 9.200959205627441\n",
-      "        vf_explained_var: 0.9829750061035156\n",
-      "        vf_loss: 9.211564620335897\n",
+      "        policy_loss: -0.010721294248166183\n",
+      "        total_loss: 15.119903961817423\n",
+      "        vf_explained_var: 0.9795476794242859\n",
+      "        vf_loss: 15.13013505935669\n",
       "    num_steps_sampled: 3397632\n",
       "    num_steps_trained: 3397632\n",
       "  iterations_since_restore: 21\n",
@@ -1976,65 +1968,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.746666666666666\n",
-      "    gpu_util_percent0: 0.43233333333333335\n",
+      "    cpu_util_percent: 24.409677419354836\n",
+      "    gpu_util_percent0: 0.41064516129032247\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.783333333333333\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7612903225806447\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1505154580684014\n",
-      "    mean_env_wait_ms: 1.1829182364579118\n",
-      "    mean_inference_ms: 4.604545436836301\n",
-      "    mean_raw_obs_processing_ms: 0.393806888186482\n",
-      "  time_since_restore: 541.447582244873\n",
-      "  time_this_iter_s: 25.528165340423584\n",
-      "  time_total_s: 541.447582244873\n",
+      "    mean_action_processing_ms: 0.15100422673970484\n",
+      "    mean_env_wait_ms: 1.1937338300371503\n",
+      "    mean_inference_ms: 4.57043850055062\n",
+      "    mean_raw_obs_processing_ms: 0.39420999465212736\n",
+      "  time_since_restore: 559.6542797088623\n",
+      "  time_this_iter_s: 26.591856479644775\n",
+      "  time_total_s: 559.6542797088623\n",
       "  timers:\n",
-      "    learn_throughput: 8659.833\n",
-      "    learn_time_ms: 18683.039\n",
-      "    sample_throughput: 23874.125\n",
-      "    sample_time_ms: 6776.877\n",
-      "    update_time_ms: 32.246\n",
-      "  timestamp: 1602448037\n",
+      "    learn_throughput: 8309.624\n",
+      "    learn_time_ms: 19470.435\n",
+      "    sample_throughput: 22984.662\n",
+      "    sample_time_ms: 7039.129\n",
+      "    update_time_ms: 29.704\n",
+      "  timestamp: 1602499419\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3397632\n",
       "  training_iteration: 21\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     21 |          541.448 | 3397632 |  245.055 |              294.202 |              75.8687 |            832.006 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     21 |          559.654 | 3397632 |  245.925 |              297.687 |               137.99 |            824.573 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3429.0718336483933\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-42\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3425.592968381312\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_10-44-06\n",
       "  done: false\n",
-      "  episode_len_mean: 829.4262910798122\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 246.28809218950053\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 4260\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 824.3506797937177\n",
+      "  episode_reward_max: 297.6868686868688\n",
+      "  episode_reward_mean: 246.62825157339924\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 186\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2043,14 +2035,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7864142805337906\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006753043349211414\n",
+      "        entropy: 0.7829316059748331\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.006042617450778683\n",
       "        model: {}\n",
-      "        policy_loss: -0.010421635362339051\n",
-      "        total_loss: 12.085295756657919\n",
-      "        vf_explained_var: 0.9821670055389404\n",
-      "        vf_loss: 12.095435539881388\n",
+      "        policy_loss: -0.012270252065112194\n",
+      "        total_loss: 7.568831443786621\n",
+      "        vf_explained_var: 0.9859895706176758\n",
+      "        vf_loss: 7.580575466156006\n",
       "    num_steps_sampled: 3559424\n",
       "    num_steps_trained: 3559424\n",
       "  iterations_since_restore: 22\n",
@@ -2058,65 +2050,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.77666666666666\n",
-      "    gpu_util_percent0: 0.35666666666666663\n",
+      "    cpu_util_percent: 24.18125\n",
+      "    gpu_util_percent0: 0.234375\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.773333333333333\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7843750000000003\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15028690275812004\n",
-      "    mean_env_wait_ms: 1.1839689693172888\n",
-      "    mean_inference_ms: 4.58657535166017\n",
-      "    mean_raw_obs_processing_ms: 0.39294259805891246\n",
-      "  time_since_restore: 567.0153458118439\n",
-      "  time_this_iter_s: 25.567763566970825\n",
-      "  time_total_s: 567.0153458118439\n",
+      "    mean_action_processing_ms: 0.1508696818648715\n",
+      "    mean_env_wait_ms: 1.1943520393111597\n",
+      "    mean_inference_ms: 4.5617273912222736\n",
+      "    mean_raw_obs_processing_ms: 0.3937429550222564\n",
+      "  time_since_restore: 586.5587210655212\n",
+      "  time_this_iter_s: 26.904441356658936\n",
+      "  time_total_s: 586.5587210655212\n",
       "  timers:\n",
-      "    learn_throughput: 8657.11\n",
-      "    learn_time_ms: 18688.916\n",
-      "    sample_throughput: 23884.796\n",
-      "    sample_time_ms: 6773.849\n",
-      "    update_time_ms: 33.756\n",
-      "  timestamp: 1602448062\n",
+      "    learn_throughput: 8309.025\n",
+      "    learn_time_ms: 19471.84\n",
+      "    sample_throughput: 22972.149\n",
+      "    sample_time_ms: 7042.963\n",
+      "    update_time_ms: 31.012\n",
+      "  timestamp: 1602499446\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3559424\n",
       "  training_iteration: 22\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     22 |          567.015 | 3559424 |  246.288 |              294.202 |              75.8687 |            829.426 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | RUNNING  | 172.17.0.4:732 |     22 |          586.559 | 3559424 |  246.628 |              297.687 |               137.99 |            824.351 |\n",
+      "+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_7762f_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3424.5079617834394\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-08\n",
-      "  done: false\n",
-      "  episode_len_mean: 828.3363471971066\n",
-      "  episode_reward_max: 296.9292929292926\n",
-      "  episode_reward_mean: 246.92703253146288\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 164\n",
+      "    time_step_max: 4145\n",
+      "    time_step_mean: 3422.125568698817\n",
+      "    time_step_min: 3110\n",
+      "  date: 2020-10-12_10-44-33\n",
+      "  done: true\n",
+      "  episode_len_mean: 823.993444846293\n",
+      "  episode_reward_max: 297.6868686868688\n",
+      "  episode_reward_mean: 247.1778681936909\n",
+      "  episode_reward_min: 137.98989898989845\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 4424\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: 63ae217839db4112bfec6bdab0a75ac9\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2125,14 +2117,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7751223593950272\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006270660436712205\n",
+      "        entropy: 0.7830241670211157\n",
+      "        entropy_coeff: 0.0001\n",
+      "        kl: 0.005572947518279155\n",
       "        model: {}\n",
-      "        policy_loss: -0.012993110887085399\n",
-      "        total_loss: 9.126743952433268\n",
-      "        vf_explained_var: 0.9815302491188049\n",
-      "        vf_loss: 9.13949735959371\n",
+      "        policy_loss: -0.008857697199952478\n",
+      "        total_loss: 9.253699541091919\n",
+      "        vf_explained_var: 0.9810841679573059\n",
+      "        vf_loss: 9.262078205744425\n",
       "    num_steps_sampled: 3721216\n",
       "    num_steps_trained: 3721216\n",
       "  iterations_since_restore: 23\n",
@@ -2140,164 +2132,82 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.034482758620694\n",
-      "    gpu_util_percent0: 0.37655172413793103\n",
+      "    cpu_util_percent: 24.612903225806452\n",
+      "    gpu_util_percent0: 0.3764516129032258\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7793103448275853\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7838709677419353\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 732\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15016941325618596\n",
-      "    mean_env_wait_ms: 1.1844954628333266\n",
-      "    mean_inference_ms: 4.577346269372596\n",
-      "    mean_raw_obs_processing_ms: 0.3924992256454737\n",
-      "  time_since_restore: 592.4772689342499\n",
-      "  time_this_iter_s: 25.461923122406006\n",
-      "  time_total_s: 592.4772689342499\n",
+      "    mean_action_processing_ms: 0.1507628397075941\n",
+      "    mean_env_wait_ms: 1.1948203537338653\n",
+      "    mean_inference_ms: 4.554879763789217\n",
+      "    mean_raw_obs_processing_ms: 0.3933762180280804\n",
+      "  time_since_restore: 613.339967250824\n",
+      "  time_this_iter_s: 26.781246185302734\n",
+      "  time_total_s: 613.339967250824\n",
       "  timers:\n",
-      "    learn_throughput: 8658.163\n",
-      "    learn_time_ms: 18686.643\n",
-      "    sample_throughput: 23893.516\n",
-      "    sample_time_ms: 6771.377\n",
-      "    update_time_ms: 35.505\n",
-      "  timestamp: 1602448088\n",
+      "    learn_throughput: 8307.761\n",
+      "    learn_time_ms: 19474.802\n",
+      "    sample_throughput: 22910.952\n",
+      "    sample_time_ms: 7061.775\n",
+      "    update_time_ms: 32.075\n",
+      "  timestamp: 1602499473\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3721216\n",
       "  training_iteration: 23\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: 7762f_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     23 |          592.477 | 3721216 |  246.927 |              296.929 |              75.8687 |            828.336 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_7762f_00000 | TERMINATED |       |     23 |           613.34 | 3721216 |  247.178 |              297.687 |               137.99 |            823.993 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3420.217391304348\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-34\n",
-      "  done: true\n",
-      "  episode_len_mean: 827.2712789175033\n",
-      "  episode_reward_max: 298.59595959595964\n",
-      "  episode_reward_mean: 247.62179190420122\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4582\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7690570255120596\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006819716926353673\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011298634965593616\n",
-      "        total_loss: 7.405012885729472\n",
-      "        vf_explained_var: 0.9835589528083801\n",
-      "        vf_loss: 7.416013916333516\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.09666666666667\n",
-      "    gpu_util_percent0: 0.37433333333333335\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7899999999999996\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1500637869801008\n",
-      "    mean_env_wait_ms: 1.1850024778129549\n",
-      "    mean_inference_ms: 4.568983072556478\n",
-      "    mean_raw_obs_processing_ms: 0.3920924925269654\n",
-      "  time_since_restore: 618.0373919010162\n",
-      "  time_this_iter_s: 25.560122966766357\n",
-      "  time_total_s: 618.0373919010162\n",
-      "  timers:\n",
-      "    learn_throughput: 8670.217\n",
-      "    learn_time_ms: 18660.662\n",
-      "    sample_throughput: 23876.765\n",
-      "    sample_time_ms: 6776.127\n",
-      "    update_time_ms: 34.493\n",
-      "  timestamp: 1602448114\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
+      "| PPO_jss_env_7762f_00000 | TERMINATED |       |     23 |           613.34 | 3721216 |  247.178 |              297.687 |               137.99 |            823.993 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 48369\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 488\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_103406-2deggwjd/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_103406-2deggwjd/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3096\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3110\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 632\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448114\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4555\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3420.21739\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 298.59596\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 75.86869\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.62179\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4582\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 24\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 627\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602499473\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4145\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3422.12557\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 297.68687\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 137.9899\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.17787\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4424\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 23\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
@@ -2313,204 +2223,202 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgrateful-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "2020-10-11 20:28:41,103 - wandb.wandb_agent - INFO - Cleaning up finished run: 90w2swxq\n",
-      "2020-10-11 20:28:41,455 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:28:41,456 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mchocolate-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/2deggwjd\u001b[0m\n",
+      "2020-10-12 10:44:45,312 - wandb.wandb_agent - INFO - Cleaning up finished run: 2deggwjd\n",
+      "2020-10-12 10:44:45,804 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 10:44:45,804 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
       "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
       "\tnum_sgd_iter: 30\n",
-      "2020-10-11 20:28:41,460 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=30\n",
+      "2020-10-12 10:44:45,807 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --num_sgd_iter=30\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:28:46,478 - wandb.wandb_agent - INFO - Running runs: ['4ndtcjlt']\n",
+      "2020-10-12 10:44:50,823 - wandb.wandb_agent - INFO - Running runs: ['zrncloep']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpolar-sweep-2\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcrimson-sweep-2\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_202843-4ndtcjlt\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/y2n6znmq\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/zrncloep\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_104447-zrncloep\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-11 20:28:47,317\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "2020-10-12 10:44:51,511\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
       "Memory usage on this node: 11.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=74346)\u001b[0m 2020-10-11 20:28:50,076\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "\u001b[2m\u001b[36m(pid=27951)\u001b[0m 2020-10-12 10:44:54,244\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=27941)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27941)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27897)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27897)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27907)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27907)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27878)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27878)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27933)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27933)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27911)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27911)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27890)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27890)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27922)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27922)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27931)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27931)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27944)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27944)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27917)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27917)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27912)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27912)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27900)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27900)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27888)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27888)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27923)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27923)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27886)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27886)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27893)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27893)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27905)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27905)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27939)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27939)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27892)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27892)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27935)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27935)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27918)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27918)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27930)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27930)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27856)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27856)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27946)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27946)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27953)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27953)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27920)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27920)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27848)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27848)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27891)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27891)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27821)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27821)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27885)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27885)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27903)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27903)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27841)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27841)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27879)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27879)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27904)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27904)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27902)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27902)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27887)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27887)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27822)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27822)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27929)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27929)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27843)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27843)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27823)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27823)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27829)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27829)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27945)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27945)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27901)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27901)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27882)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27882)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27924)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27924)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27850)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27850)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27926)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27926)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27815)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27815)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27921)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27921)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27938)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27938)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27909)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27909)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27894)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27894)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27883)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27883)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27836)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27836)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27913)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27913)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27914)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27914)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27831)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27831)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27884)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27884)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=27880)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=27880)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: 4054\n",
       "    time_step_mean: 3615.0923076923077\n",
       "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-29-27\n",
+      "  date: 2020-10-12_10-45-32\n",
       "  done: false\n",
       "  episode_len_mean: 891.1139240506329\n",
       "  episode_reward_max: 258.59595959595964\n",
@@ -2518,21 +2426,21 @@
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1820389827092488\n",
+      "        entropy: 1.1846147278944652\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007561812836987277\n",
+      "        kl: 0.004924804321490228\n",
       "        model: {}\n",
-      "        policy_loss: -0.01091390458168462\n",
-      "        total_loss: 502.23597717285156\n",
+      "        policy_loss: -0.010641525208484381\n",
+      "        total_loss: 502.23648834228516\n",
       "        vf_explained_var: 0.5664147734642029\n",
       "        vf_loss: 502.24672444661456\n",
       "    num_steps_sampled: 161792\n",
@@ -2542,65 +2450,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 27.674358974358974\n",
-      "    gpu_util_percent0: 0.37230769230769234\n",
+      "    cpu_util_percent: 25.06578947368421\n",
+      "    gpu_util_percent0: 0.23210526315789473\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5717948717948715\n",
-      "    vram_util_percent0: 0.08725223065990534\n",
+      "    ram_util_percent: 3.581578947368421\n",
+      "    vram_util_percent0: 0.08847163004263696\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17197728193847803\n",
-      "    mean_env_wait_ms: 1.178965817339886\n",
-      "    mean_inference_ms: 6.060176406535295\n",
-      "    mean_raw_obs_processing_ms: 0.4615727896011697\n",
-      "  time_since_restore: 31.85646414756775\n",
-      "  time_this_iter_s: 31.85646414756775\n",
-      "  time_total_s: 31.85646414756775\n",
+      "    mean_action_processing_ms: 0.1715364924328089\n",
+      "    mean_env_wait_ms: 1.1764125023111955\n",
+      "    mean_inference_ms: 6.053061519150528\n",
+      "    mean_raw_obs_processing_ms: 0.4638343403537392\n",
+      "  time_since_restore: 32.95468473434448\n",
+      "  time_this_iter_s: 32.95468473434448\n",
+      "  time_total_s: 32.95468473434448\n",
       "  timers:\n",
-      "    learn_throughput: 7259.825\n",
-      "    learn_time_ms: 22285.937\n",
-      "    sample_throughput: 17058.896\n",
-      "    sample_time_ms: 9484.318\n",
-      "    update_time_ms: 45.763\n",
-      "  timestamp: 1602448167\n",
+      "    learn_throughput: 6948.182\n",
+      "    learn_time_ms: 23285.516\n",
+      "    sample_throughput: 16871.285\n",
+      "    sample_time_ms: 9589.785\n",
+      "    update_time_ms: 44.906\n",
+      "  timestamp: 1602499532\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 27.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      1 |          31.8565 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      1 |          32.9547 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4081\n",
-      "    time_step_mean: 3626.375\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-29-57\n",
+      "    time_step_max: 4185\n",
+      "    time_step_mean: 3622.6423611111113\n",
+      "    time_step_min: 3341\n",
+      "  date: 2020-10-12_10-46-03\n",
       "  done: false\n",
-      "  episode_len_mean: 889.8101265822785\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 216.46036312491984\n",
-      "  episode_reward_min: 139.20202020202004\n",
+      "  episode_len_mean: 890.2246835443038\n",
+      "  episode_reward_max: 262.6868686868683\n",
+      "  episode_reward_mean: 216.1472637770104\n",
+      "  episode_reward_min: 131.9292929292925\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2609,14 +2517,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1471269528071086\n",
+      "        entropy: 1.1507324576377869\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010032878257334232\n",
+      "        kl: 0.007903704070486128\n",
       "        model: {}\n",
-      "        policy_loss: -0.01112406033401688\n",
-      "        total_loss: 125.25241088867188\n",
-      "        vf_explained_var: 0.815872848033905\n",
-      "        vf_loss: 125.26310539245605\n",
+      "        policy_loss: -0.010593259202626845\n",
+      "        total_loss: 127.33559099833171\n",
+      "        vf_explained_var: 0.8138229846954346\n",
+      "        vf_loss: 127.34597078959148\n",
       "    num_steps_sampled: 323584\n",
       "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 2\n",
@@ -2624,65 +2532,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.586486486486486\n",
-      "    gpu_util_percent0: 0.37729729729729733\n",
+      "    cpu_util_percent: 23.180555555555557\n",
+      "    gpu_util_percent0: 0.26916666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7567567567567575\n",
+      "    ram_util_percent: 3.766666666666668\n",
       "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16762130233769734\n",
-      "    mean_env_wait_ms: 1.173220641390085\n",
-      "    mean_inference_ms: 5.799851321192781\n",
-      "    mean_raw_obs_processing_ms: 0.45053682537598116\n",
-      "  time_since_restore: 61.79887557029724\n",
-      "  time_this_iter_s: 29.942411422729492\n",
-      "  time_total_s: 61.79887557029724\n",
+      "    mean_action_processing_ms: 0.16686884579590536\n",
+      "    mean_env_wait_ms: 1.1726176230359397\n",
+      "    mean_inference_ms: 5.762905636344878\n",
+      "    mean_raw_obs_processing_ms: 0.4520184496332657\n",
+      "  time_since_restore: 63.70615220069885\n",
+      "  time_this_iter_s: 30.75146746635437\n",
+      "  time_total_s: 63.70615220069885\n",
       "  timers:\n",
-      "    learn_throughput: 7317.922\n",
-      "    learn_time_ms: 22109.009\n",
-      "    sample_throughput: 18578.114\n",
-      "    sample_time_ms: 8708.742\n",
-      "    update_time_ms: 34.225\n",
-      "  timestamp: 1602448197\n",
+      "    learn_throughput: 7022.83\n",
+      "    learn_time_ms: 23038.005\n",
+      "    sample_throughput: 18514.195\n",
+      "    sample_time_ms: 8738.808\n",
+      "    update_time_ms: 35.829\n",
+      "  timestamp: 1602499563\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      2 |          61.7989 | 323584 |   216.46 |              269.505 |              139.202 |             889.81 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      2 |          63.7062 | 323584 |  216.147 |              262.687 |              131.929 |            890.225 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3622.3206278026905\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-30-27\n",
+      "    time_step_max: 4185\n",
+      "    time_step_mean: 3625.3340807174886\n",
+      "    time_step_min: 3341\n",
+      "  date: 2020-10-12_10-46-33\n",
       "  done: false\n",
-      "  episode_len_mean: 885.367088607595\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 217.77988748241893\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 885.3924050632911\n",
+      "  episode_reward_max: 262.6868686868683\n",
+      "  episode_reward_mean: 216.5537015726887\n",
+      "  episode_reward_min: 88.59595959595944\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2691,14 +2599,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.138877511024475\n",
+      "        entropy: 1.1411346793174744\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010077035520225763\n",
+      "        kl: 0.009678286267444491\n",
       "        model: {}\n",
-      "        policy_loss: -0.014173034539756676\n",
-      "        total_loss: 56.67084821065267\n",
-      "        vf_explained_var: 0.9027066826820374\n",
-      "        vf_loss: 56.68458398183187\n",
+      "        policy_loss: -0.014822538554047545\n",
+      "        total_loss: 59.26638380686442\n",
+      "        vf_explained_var: 0.9010727405548096\n",
+      "        vf_loss: 59.28081130981445\n",
       "    num_steps_sampled: 485376\n",
       "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 3\n",
@@ -2706,65 +2614,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.597222222222225\n",
-      "    gpu_util_percent0: 0.36972222222222223\n",
+      "    cpu_util_percent: 22.72285714285714\n",
+      "    gpu_util_percent0: 0.278\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7777777777777786\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.7771428571428576\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16479804064831216\n",
-      "    mean_env_wait_ms: 1.1720182606622203\n",
-      "    mean_inference_ms: 5.603008625003064\n",
-      "    mean_raw_obs_processing_ms: 0.4426390955890892\n",
-      "  time_since_restore: 91.3730297088623\n",
-      "  time_this_iter_s: 29.574154138565063\n",
-      "  time_total_s: 91.3730297088623\n",
+      "    mean_action_processing_ms: 0.16389218629932192\n",
+      "    mean_env_wait_ms: 1.1723028183524362\n",
+      "    mean_inference_ms: 5.549334093675588\n",
+      "    mean_raw_obs_processing_ms: 0.44287348924922826\n",
+      "  time_since_restore: 93.79876685142517\n",
+      "  time_this_iter_s: 30.09261465072632\n",
+      "  time_total_s: 93.79876685142517\n",
       "  timers:\n",
-      "    learn_throughput: 7328.404\n",
-      "    learn_time_ms: 22077.385\n",
-      "    sample_throughput: 19490.783\n",
-      "    sample_time_ms: 8300.949\n",
-      "    update_time_ms: 32.102\n",
-      "  timestamp: 1602448227\n",
+      "    learn_throughput: 7048.038\n",
+      "    learn_time_ms: 22955.609\n",
+      "    sample_throughput: 19641.219\n",
+      "    sample_time_ms: 8237.371\n",
+      "    update_time_ms: 31.797\n",
+      "  timestamp: 1602499593\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      3 |           91.373 | 485376 |   217.78 |              269.505 |              121.929 |            885.367 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      3 |          93.7988 | 485376 |  216.554 |              262.687 |               88.596 |            885.392 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3609.298013245033\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-30-56\n",
+      "    time_step_max: 4214\n",
+      "    time_step_mean: 3625.890728476821\n",
+      "    time_step_min: 3319\n",
+      "  date: 2020-10-12_10-47-03\n",
       "  done: false\n",
-      "  episode_len_mean: 880.4335443037975\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 219.6016653880576\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 881.0474683544304\n",
+      "  episode_reward_max: 263.1414141414135\n",
+      "  episode_reward_mean: 216.6672580232705\n",
+      "  episode_reward_min: 88.59595959595944\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2773,14 +2681,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1205872495969136\n",
+      "        entropy: 1.1199288368225098\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008317627167950073\n",
+      "        kl: 0.008813565596938133\n",
       "        model: {}\n",
-      "        policy_loss: -0.014852196210995317\n",
-      "        total_loss: 35.135284423828125\n",
-      "        vf_explained_var: 0.9348650574684143\n",
-      "        vf_loss: 35.149864196777344\n",
+      "        policy_loss: -0.01598833860286201\n",
+      "        total_loss: 43.194626808166504\n",
+      "        vf_explained_var: 0.9295213222503662\n",
+      "        vf_loss: 43.21029249827067\n",
       "    num_steps_sampled: 647168\n",
       "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 4\n",
@@ -2788,65 +2696,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.81142857142857\n",
-      "    gpu_util_percent0: 0.38428571428571434\n",
+      "    cpu_util_percent: 21.75277777777778\n",
+      "    gpu_util_percent0: 0.2755555555555556\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.775000000000001\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16266713864790658\n",
-      "    mean_env_wait_ms: 1.1719507465280838\n",
-      "    mean_inference_ms: 5.452768291637971\n",
-      "    mean_raw_obs_processing_ms: 0.436093704889682\n",
-      "  time_since_restore: 120.51979207992554\n",
-      "  time_this_iter_s: 29.146762371063232\n",
-      "  time_total_s: 120.51979207992554\n",
+      "    mean_action_processing_ms: 0.16171133782142091\n",
+      "    mean_env_wait_ms: 1.172442399851389\n",
+      "    mean_inference_ms: 5.393240447801279\n",
+      "    mean_raw_obs_processing_ms: 0.43569823102312366\n",
+      "  time_since_restore: 124.19757580757141\n",
+      "  time_this_iter_s: 30.39880895614624\n",
+      "  time_total_s: 124.19757580757141\n",
       "  timers:\n",
-      "    learn_throughput: 7340.701\n",
-      "    learn_time_ms: 22040.402\n",
-      "    sample_throughput: 20214.027\n",
-      "    sample_time_ms: 8003.947\n",
-      "    update_time_ms: 33.725\n",
-      "  timestamp: 1602448256\n",
+      "    learn_throughput: 7029.44\n",
+      "    learn_time_ms: 23016.343\n",
+      "    sample_throughput: 20329.92\n",
+      "    sample_time_ms: 7958.32\n",
+      "    update_time_ms: 32.048\n",
+      "  timestamp: 1602499623\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      4 |           120.52 | 647168 |  219.602 |              269.505 |              121.929 |            880.434 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      4 |          124.198 | 647168 |  216.667 |              263.141 |               88.596 |            881.047 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3595.94750656168\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-31-25\n",
+      "    time_step_max: 4270\n",
+      "    time_step_mean: 3617.989501312336\n",
+      "    time_step_min: 3319\n",
+      "  date: 2020-10-12_10-47-34\n",
       "  done: false\n",
-      "  episode_len_mean: 875.0151898734177\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 221.3562204321696\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 876.6645569620254\n",
+      "  episode_reward_max: 266.4747474747477\n",
+      "  episode_reward_mean: 217.92468993734798\n",
+      "  episode_reward_min: 88.59595959595944\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 790\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2855,14 +2763,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0882032910982768\n",
+      "        entropy: 1.0852691729863484\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008978756920744976\n",
+      "        kl: 0.008571949942658344\n",
       "        model: {}\n",
-      "        policy_loss: -0.014062516507692635\n",
-      "        total_loss: 24.341053009033203\n",
-      "        vf_explained_var: 0.9578109383583069\n",
-      "        vf_loss: 24.354761441548664\n",
+      "        policy_loss: -0.015522021086023111\n",
+      "        total_loss: 32.49041668574015\n",
+      "        vf_explained_var: 0.9495692253112793\n",
+      "        vf_loss: 32.50562445322672\n",
       "    num_steps_sampled: 808960\n",
       "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 5\n",
@@ -2870,65 +2778,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.808333333333337\n",
-      "    gpu_util_percent0: 0.41361111111111115\n",
+      "    cpu_util_percent: 22.04857142857143\n",
+      "    gpu_util_percent0: 0.28485714285714286\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.782857142857143\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16103095813233778\n",
-      "    mean_env_wait_ms: 1.172911624714945\n",
-      "    mean_inference_ms: 5.334074757563843\n",
-      "    mean_raw_obs_processing_ms: 0.4305471554597205\n",
-      "  time_since_restore: 149.58945155143738\n",
-      "  time_this_iter_s: 29.06965947151184\n",
-      "  time_total_s: 149.58945155143738\n",
+      "    mean_action_processing_ms: 0.16012965724921266\n",
+      "    mean_env_wait_ms: 1.1736239690286292\n",
+      "    mean_inference_ms: 5.2755181225819605\n",
+      "    mean_raw_obs_processing_ms: 0.42999393542261516\n",
+      "  time_since_restore: 154.43998551368713\n",
+      "  time_this_iter_s: 30.242409706115723\n",
+      "  time_total_s: 154.43998551368713\n",
       "  timers:\n",
-      "    learn_throughput: 7347.418\n",
-      "    learn_time_ms: 22020.252\n",
-      "    sample_throughput: 20703.622\n",
-      "    sample_time_ms: 7814.671\n",
-      "    update_time_ms: 31.711\n",
-      "  timestamp: 1602448285\n",
+      "    learn_throughput: 7022.643\n",
+      "    learn_time_ms: 23038.62\n",
+      "    sample_throughput: 20815.054\n",
+      "    sample_time_ms: 7772.836\n",
+      "    update_time_ms: 32.127\n",
+      "  timestamp: 1602499654\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      5 |          149.589 | 808960 |  221.356 |              269.505 |              121.929 |            875.015 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      5 |           154.44 | 808960 |  217.925 |              266.475 |               88.596 |            876.665 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3570.9396471680593\n",
-      "    time_step_min: 3272\n",
-      "  date: 2020-10-11_20-31-54\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3598.4014869888474\n",
+      "    time_step_min: 3287\n",
+      "  date: 2020-10-12_10-48-04\n",
       "  done: false\n",
-      "  episode_len_mean: 865.3411764705883\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 225.14456785045004\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 315\n",
-      "  episodes_total: 1105\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 867.0471014492754\n",
+      "  episode_reward_max: 267.98989898989913\n",
+      "  episode_reward_mean: 220.5384826526129\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 314\n",
+      "  episodes_total: 1104\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -2937,14 +2845,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.081368327140808\n",
+      "        entropy: 1.0762771268685658\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008393583974490562\n",
+      "        kl: 0.00847935164347291\n",
       "        model: {}\n",
-      "        policy_loss: -0.01229041333620747\n",
-      "        total_loss: 30.566396554311115\n",
-      "        vf_explained_var: 0.9602224230766296\n",
-      "        vf_loss: 30.578388055165608\n",
+      "        policy_loss: -0.014069491167902015\n",
+      "        total_loss: 36.22017447153727\n",
+      "        vf_explained_var: 0.9600384831428528\n",
+      "        vf_loss: 36.23393313090006\n",
       "    num_steps_sampled: 970752\n",
       "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 6\n",
@@ -2952,65 +2860,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3971428571428571\n",
+      "    cpu_util_percent: 22.274285714285714\n",
+      "    gpu_util_percent0: 0.35999999999999993\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.765714285714286\n",
+      "    ram_util_percent: 3.7771428571428576\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1587676819904807\n",
-      "    mean_env_wait_ms: 1.1762866754320034\n",
-      "    mean_inference_ms: 5.169591608338926\n",
-      "    mean_raw_obs_processing_ms: 0.42300377666355576\n",
-      "  time_since_restore: 178.9720721244812\n",
-      "  time_this_iter_s: 29.382620573043823\n",
-      "  time_total_s: 178.9720721244812\n",
+      "    mean_action_processing_ms: 0.157985195797773\n",
+      "    mean_env_wait_ms: 1.176888885605026\n",
+      "    mean_inference_ms: 5.117378266251005\n",
+      "    mean_raw_obs_processing_ms: 0.4225404292097058\n",
+      "  time_since_restore: 184.78620219230652\n",
+      "  time_this_iter_s: 30.346216678619385\n",
+      "  time_total_s: 184.78620219230652\n",
       "  timers:\n",
-      "    learn_throughput: 7334.048\n",
-      "    learn_time_ms: 22060.394\n",
-      "    sample_throughput: 21058.022\n",
-      "    sample_time_ms: 7683.153\n",
-      "    update_time_ms: 33.041\n",
-      "  timestamp: 1602448314\n",
+      "    learn_throughput: 7013.777\n",
+      "    learn_time_ms: 23067.743\n",
+      "    sample_throughput: 21143.968\n",
+      "    sample_time_ms: 7651.922\n",
+      "    update_time_ms: 32.739\n",
+      "  timestamp: 1602499684\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      6 |          178.972 | 970752 |  225.145 |              276.778 |              121.929 |            865.341 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      6 |          184.786 | 970752 |  220.538 |               267.99 |               88.596 |            867.047 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3559.6480582524273\n",
-      "    time_step_min: 3259\n",
-      "  date: 2020-10-11_20-32-24\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3586.6108414239484\n",
+      "    time_step_min: 3287\n",
+      "  date: 2020-10-12_10-48-35\n",
       "  done: false\n",
-      "  episode_len_mean: 861.2610759493671\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 226.75584164429083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 159\n",
+      "  episode_len_mean: 862.6424050632911\n",
+      "  episode_reward_max: 272.53535353535324\n",
+      "  episode_reward_mean: 222.52336657716384\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 160\n",
       "  episodes_total: 1264\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3019,14 +2927,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0704743762811024\n",
+      "        entropy: 1.0611263513565063\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008557675794387857\n",
+      "        kl: 0.00855419528670609\n",
       "        model: {}\n",
-      "        policy_loss: -0.01505787695835655\n",
-      "        total_loss: 16.039914925893147\n",
-      "        vf_explained_var: 0.9693781733512878\n",
-      "        vf_loss: 16.054652611414593\n",
+      "        policy_loss: -0.01313585601747036\n",
+      "        total_loss: 17.229157129923504\n",
+      "        vf_explained_var: 0.9695212244987488\n",
+      "        vf_loss: 17.24196783701579\n",
       "    num_steps_sampled: 1132544\n",
       "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 7\n",
@@ -3034,65 +2942,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.458333333333332\n",
-      "    gpu_util_percent0: 0.3652777777777778\n",
+      "    cpu_util_percent: 21.344444444444445\n",
+      "    gpu_util_percent0: 0.3055555555555556\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7861111111111123\n",
+      "    ram_util_percent: 3.7805555555555554\n",
       "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15792926470213106\n",
-      "    mean_env_wait_ms: 1.1776823803388836\n",
-      "    mean_inference_ms: 5.108482278862465\n",
-      "    mean_raw_obs_processing_ms: 0.4201292178903985\n",
-      "  time_since_restore: 208.08675360679626\n",
-      "  time_this_iter_s: 29.114681482315063\n",
-      "  time_total_s: 208.08675360679626\n",
+      "    mean_action_processing_ms: 0.15721883999003455\n",
+      "    mean_env_wait_ms: 1.1784417316102376\n",
+      "    mean_inference_ms: 5.059418580537698\n",
+      "    mean_raw_obs_processing_ms: 0.41974201605546413\n",
+      "  time_since_restore: 215.12676668167114\n",
+      "  time_this_iter_s: 30.340564489364624\n",
+      "  time_total_s: 215.12676668167114\n",
       "  timers:\n",
-      "    learn_throughput: 7335.151\n",
-      "    learn_time_ms: 22057.079\n",
-      "    sample_throughput: 21336.833\n",
-      "    sample_time_ms: 7582.756\n",
-      "    update_time_ms: 32.936\n",
-      "  timestamp: 1602448344\n",
+      "    learn_throughput: 7013.954\n",
+      "    learn_time_ms: 23067.159\n",
+      "    sample_throughput: 21358.13\n",
+      "    sample_time_ms: 7575.195\n",
+      "    update_time_ms: 33.358\n",
+      "  timestamp: 1602499715\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      7 |          208.087 | 1132544 |  226.756 |              276.778 |              121.929 |            861.261 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      7 |          215.127 | 1132544 |  222.523 |              272.535 |               88.596 |            862.642 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3547.9497847919656\n",
-      "    time_step_min: 3243\n",
-      "  date: 2020-10-11_20-32-53\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3574.7453371592537\n",
+      "    time_step_min: 3224\n",
+      "  date: 2020-10-12_10-49-05\n",
       "  done: false\n",
-      "  episode_len_mean: 858.2039381153305\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 228.44124792226046\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 858.2257383966245\n",
+      "  episode_reward_max: 277.5353535353528\n",
+      "  episode_reward_mean: 224.2597707028085\n",
+      "  episode_reward_min: 88.59595959595944\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1422\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3101,14 +3009,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0472288727760315\n",
+      "        entropy: 1.0459068516890209\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008639561710879207\n",
+      "        kl: 0.007586693585229416\n",
       "        model: {}\n",
-      "        policy_loss: -0.015043328690808266\n",
-      "        total_loss: 14.895620028177897\n",
-      "        vf_explained_var: 0.9694356322288513\n",
-      "        vf_loss: 14.910322825113932\n",
+      "        policy_loss: -0.01487944574910216\n",
+      "        total_loss: 17.728309154510498\n",
+      "        vf_explained_var: 0.9674603343009949\n",
+      "        vf_loss: 17.742952823638916\n",
       "    num_steps_sampled: 1294336\n",
       "    num_steps_trained: 1294336\n",
       "  iterations_since_restore: 8\n",
@@ -3116,65 +3024,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.274285714285718\n",
-      "    gpu_util_percent0: 0.3857142857142858\n",
+      "    cpu_util_percent: 22.362857142857145\n",
+      "    gpu_util_percent0: 0.3745714285714286\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
+      "    ram_util_percent: 3.7857142857142865\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15720379894543632\n",
-      "    mean_env_wait_ms: 1.1788712271360022\n",
-      "    mean_inference_ms: 5.055485147389075\n",
-      "    mean_raw_obs_processing_ms: 0.41757554097071403\n",
-      "  time_since_restore: 237.2246127128601\n",
-      "  time_this_iter_s: 29.137859106063843\n",
-      "  time_total_s: 237.2246127128601\n",
+      "    mean_action_processing_ms: 0.15656386820306947\n",
+      "    mean_env_wait_ms: 1.1799183178085746\n",
+      "    mean_inference_ms: 5.009826195708607\n",
+      "    mean_raw_obs_processing_ms: 0.41727490601484446\n",
+      "  time_since_restore: 245.46431922912598\n",
+      "  time_this_iter_s: 30.337552547454834\n",
+      "  time_total_s: 245.46431922912598\n",
       "  timers:\n",
-      "    learn_throughput: 7334.405\n",
-      "    learn_time_ms: 22059.322\n",
-      "    sample_throughput: 21547.818\n",
-      "    sample_time_ms: 7508.51\n",
-      "    update_time_ms: 31.659\n",
-      "  timestamp: 1602448373\n",
+      "    learn_throughput: 7013.118\n",
+      "    learn_time_ms: 23069.91\n",
+      "    sample_throughput: 21502.897\n",
+      "    sample_time_ms: 7524.195\n",
+      "    update_time_ms: 33.171\n",
+      "  timestamp: 1602499745\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1294336\n",
       "  training_iteration: 8\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      8 |          237.225 | 1294336 |  228.441 |              276.778 |              121.929 |            858.204 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      8 |          245.464 | 1294336 |   224.26 |              277.535 |               88.596 |            858.226 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3537.53543814433\n",
-      "    time_step_min: 3226\n",
-      "  date: 2020-10-11_20-33-22\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3562.860824742268\n",
+      "    time_step_min: 3224\n",
+      "  date: 2020-10-12_10-49-35\n",
       "  done: false\n",
-      "  episode_len_mean: 855.6518987341772\n",
-      "  episode_reward_max: 281.17171717171726\n",
-      "  episode_reward_mean: 229.99124152921607\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 854.1151898734178\n",
+      "  episode_reward_max: 277.5353535353528\n",
+      "  episode_reward_mean: 226.03343562204307\n",
+      "  episode_reward_min: 88.59595959595944\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1580\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3183,14 +3091,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.015722543001175\n",
+      "        entropy: 1.009189561009407\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008050314267165959\n",
+      "        kl: 0.008226582664065063\n",
       "        model: {}\n",
-      "        policy_loss: -0.016199174404998\n",
-      "        total_loss: 14.030672391255697\n",
-      "        vf_explained_var: 0.9713940024375916\n",
-      "        vf_loss: 14.046574354171753\n",
+      "        policy_loss: -0.015366594326527169\n",
+      "        total_loss: 15.938408533732096\n",
+      "        vf_explained_var: 0.9702828526496887\n",
+      "        vf_loss: 15.953457037607828\n",
       "    num_steps_sampled: 1456128\n",
       "    num_steps_trained: 1456128\n",
       "  iterations_since_restore: 9\n",
@@ -3198,65 +3106,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.55\n",
-      "    gpu_util_percent0: 0.3569444444444445\n",
+      "    cpu_util_percent: 22.262857142857147\n",
+      "    gpu_util_percent0: 0.32799999999999996\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7750000000000004\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.774285714285715\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1565664082884177\n",
-      "    mean_env_wait_ms: 1.179921473586243\n",
-      "    mean_inference_ms: 5.008992086650131\n",
-      "    mean_raw_obs_processing_ms: 0.4152688863683933\n",
-      "  time_since_restore: 266.55099987983704\n",
-      "  time_this_iter_s: 29.32638716697693\n",
-      "  time_total_s: 266.55099987983704\n",
+      "    mean_action_processing_ms: 0.15599313435917495\n",
+      "    mean_env_wait_ms: 1.1813674882165615\n",
+      "    mean_inference_ms: 4.966630800288264\n",
+      "    mean_raw_obs_processing_ms: 0.41506544527338496\n",
+      "  time_since_restore: 275.5794014930725\n",
+      "  time_this_iter_s: 30.115082263946533\n",
+      "  time_total_s: 275.5794014930725\n",
       "  timers:\n",
-      "    learn_throughput: 7326.864\n",
-      "    learn_time_ms: 22082.026\n",
-      "    sample_throughput: 21714.677\n",
-      "    sample_time_ms: 7450.813\n",
-      "    update_time_ms: 30.511\n",
-      "  timestamp: 1602448402\n",
+      "    learn_throughput: 7017.998\n",
+      "    learn_time_ms: 23053.868\n",
+      "    sample_throughput: 21639.369\n",
+      "    sample_time_ms: 7476.743\n",
+      "    update_time_ms: 32.887\n",
+      "  timestamp: 1602499775\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1456128\n",
       "  training_iteration: 9\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      9 |          266.551 | 1456128 |  229.991 |              281.172 |              121.929 |            855.652 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |      9 |          275.579 | 1456128 |  226.033 |              277.535 |               88.596 |            854.115 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3520.743295019157\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-33-52\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3538.880580957504\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-12_10-50-06\n",
       "  done: false\n",
-      "  episode_len_mean: 850.9762803234502\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 232.5573252743063\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 275\n",
-      "  episodes_total: 1855\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 847.3190249072602\n",
+      "  episode_reward_max: 280.2626262626269\n",
+      "  episode_reward_mean: 229.68314303608406\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 307\n",
+      "  episodes_total: 1887\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3265,14 +3173,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9801995704571406\n",
+      "        entropy: 0.9917601197957993\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008376963630629083\n",
+      "        kl: 0.00740070086127768\n",
       "        model: {}\n",
-      "        policy_loss: -0.013380672792360807\n",
-      "        total_loss: 17.90494426091512\n",
-      "        vf_explained_var: 0.9745662212371826\n",
-      "        vf_loss: 17.91797685623169\n",
+      "        policy_loss: -0.013341124024009332\n",
+      "        total_loss: 19.074730396270752\n",
+      "        vf_explained_var: 0.9753614068031311\n",
+      "        vf_loss: 19.08782688776652\n",
       "    num_steps_sampled: 1617920\n",
       "    num_steps_trained: 1617920\n",
       "  iterations_since_restore: 10\n",
@@ -3280,65 +3188,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.352777777777774\n",
-      "    gpu_util_percent0: 0.4316666666666667\n",
+      "    cpu_util_percent: 21.191666666666663\n",
+      "    gpu_util_percent0: 0.30111111111111105\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.761111111111111\n",
+      "    ram_util_percent: 3.7722222222222226\n",
       "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1556438503127995\n",
-      "    mean_env_wait_ms: 1.1818997761514678\n",
-      "    mean_inference_ms: 4.942037577056882\n",
-      "    mean_raw_obs_processing_ms: 0.4119487772103422\n",
-      "  time_since_restore: 295.92345571517944\n",
-      "  time_this_iter_s: 29.372455835342407\n",
-      "  time_total_s: 295.92345571517944\n",
+      "    mean_action_processing_ms: 0.1550921774885076\n",
+      "    mean_env_wait_ms: 1.1841642257143155\n",
+      "    mean_inference_ms: 4.898659841728468\n",
+      "    mean_raw_obs_processing_ms: 0.4116808708719114\n",
+      "  time_since_restore: 305.95650362968445\n",
+      "  time_this_iter_s: 30.37710213661194\n",
+      "  time_total_s: 305.95650362968445\n",
       "  timers:\n",
-      "    learn_throughput: 7317.051\n",
-      "    learn_time_ms: 22111.64\n",
-      "    sample_throughput: 21890.999\n",
-      "    sample_time_ms: 7390.8\n",
-      "    update_time_ms: 31.144\n",
-      "  timestamp: 1602448432\n",
+      "    learn_throughput: 7015.346\n",
+      "    learn_time_ms: 23062.584\n",
+      "    sample_throughput: 21757.544\n",
+      "    sample_time_ms: 7436.133\n",
+      "    update_time_ms: 33.038\n",
+      "  timestamp: 1602499806\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1617920\n",
       "  training_iteration: 10\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     10 |          295.923 | 1617920 |  232.557 |              286.929 |              121.929 |            850.976 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     10 |          305.957 | 1617920 |  229.683 |              280.263 |               88.596 |            847.319 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3511.523692003949\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-21\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3528.9536031589337\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-12_10-50-36\n",
       "  done: false\n",
-      "  episode_len_mean: 848.3286270691334\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 233.83599382333549\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 199\n",
+      "  episode_len_mean: 844.2448880233691\n",
+      "  episode_reward_max: 280.2626262626269\n",
+      "  episode_reward_mean: 231.221140322406\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 167\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3347,14 +3255,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9715732336044312\n",
+      "        entropy: 0.9727244724829992\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007677830173633993\n",
+      "        kl: 0.0071904356591403484\n",
       "        model: {}\n",
-      "        policy_loss: -0.01453752441254134\n",
-      "        total_loss: 11.66528328259786\n",
-      "        vf_explained_var: 0.9783375859260559\n",
-      "        vf_loss: 11.679538249969482\n",
+      "        policy_loss: -0.014005071396240965\n",
+      "        total_loss: 11.84699296951294\n",
+      "        vf_explained_var: 0.9785725474357605\n",
+      "        vf_loss: 11.860765298207602\n",
       "    num_steps_sampled: 1779712\n",
       "    num_steps_trained: 1779712\n",
       "  iterations_since_restore: 11\n",
@@ -3362,65 +3270,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.15714285714286\n",
-      "    gpu_util_percent0: 0.39285714285714285\n",
+      "    cpu_util_percent: 21.597142857142856\n",
+      "    gpu_util_percent0: 0.3817142857142857\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.782857142857143\n",
+      "    ram_util_percent: 3.788571428571429\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15509423026677763\n",
-      "    mean_env_wait_ms: 1.1832091255108494\n",
-      "    mean_inference_ms: 4.901368530769214\n",
-      "    mean_raw_obs_processing_ms: 0.41003195858099223\n",
-      "  time_since_restore: 325.0179567337036\n",
-      "  time_this_iter_s: 29.09450101852417\n",
-      "  time_total_s: 325.0179567337036\n",
+      "    mean_action_processing_ms: 0.15469427227659796\n",
+      "    mean_env_wait_ms: 1.1855035444070465\n",
+      "    mean_inference_ms: 4.868324146809752\n",
+      "    mean_raw_obs_processing_ms: 0.410149660829387\n",
+      "  time_since_restore: 336.20317029953003\n",
+      "  time_this_iter_s: 30.24666666984558\n",
+      "  time_total_s: 336.20317029953003\n",
       "  timers:\n",
-      "    learn_throughput: 7322.545\n",
-      "    learn_time_ms: 22095.051\n",
-      "    sample_throughput: 22691.255\n",
-      "    sample_time_ms: 7130.148\n",
-      "    update_time_ms: 30.79\n",
-      "  timestamp: 1602448461\n",
+      "    learn_throughput: 7024.762\n",
+      "    learn_time_ms: 23031.671\n",
+      "    sample_throughput: 22484.123\n",
+      "    sample_time_ms: 7195.833\n",
+      "    update_time_ms: 31.936\n",
+      "  timestamp: 1602499836\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
       "  training_iteration: 11\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     11 |          325.018 | 1779712 |  233.836 |              286.929 |              121.929 |            848.329 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     11 |          336.203 | 1779712 |  231.221 |              280.263 |               88.596 |            844.245 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3504.3699633699634\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-50\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3520.5668498168498\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-12_10-51-06\n",
       "  done: false\n",
-      "  episode_len_mean: 846.2716998191681\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 235.09083602754478\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 841.4041591320072\n",
+      "  episode_reward_max: 280.2626262626269\n",
+      "  episode_reward_mean: 232.48480282024573\n",
+      "  episode_reward_min: 88.59595959595944\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2212\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3429,14 +3337,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9553611228863398\n",
+      "        entropy: 0.9606796552737554\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007482029924479623\n",
+      "        kl: 0.007471592941631873\n",
       "        model: {}\n",
-      "        policy_loss: -0.014144674564401308\n",
-      "        total_loss: 11.647562901178995\n",
-      "        vf_explained_var: 0.9759584069252014\n",
-      "        vf_loss: 11.661436955134073\n",
+      "        policy_loss: -0.015197008498944342\n",
+      "        total_loss: 13.117705742518107\n",
+      "        vf_explained_var: 0.9743028283119202\n",
+      "        vf_loss: 13.132635911305746\n",
       "    num_steps_sampled: 1941504\n",
       "    num_steps_trained: 1941504\n",
       "  iterations_since_restore: 12\n",
@@ -3444,65 +3352,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.317142857142855\n",
-      "    gpu_util_percent0: 0.39085714285714285\n",
+      "    cpu_util_percent: 21.165714285714287\n",
+      "    gpu_util_percent0: 0.3628571428571429\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
       "    ram_util_percent: 3.782857142857143\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15470167612416874\n",
-      "    mean_env_wait_ms: 1.184108459453786\n",
-      "    mean_inference_ms: 4.872707948353993\n",
-      "    mean_raw_obs_processing_ms: 0.40860797230340906\n",
-      "  time_since_restore: 354.16708421707153\n",
-      "  time_this_iter_s: 29.14912748336792\n",
-      "  time_total_s: 354.16708421707153\n",
+      "    mean_action_processing_ms: 0.15435514340299025\n",
+      "    mean_env_wait_ms: 1.186665990444814\n",
+      "    mean_inference_ms: 4.842549195167609\n",
+      "    mean_raw_obs_processing_ms: 0.4087971802318489\n",
+      "  time_since_restore: 366.355286359787\n",
+      "  time_this_iter_s: 30.152116060256958\n",
+      "  time_total_s: 366.355286359787\n",
       "  timers:\n",
-      "    learn_throughput: 7315.174\n",
-      "    learn_time_ms: 22117.314\n",
-      "    sample_throughput: 23025.185\n",
-      "    sample_time_ms: 7026.74\n",
-      "    update_time_ms: 32.609\n",
-      "  timestamp: 1602448490\n",
+      "    learn_throughput: 7018.363\n",
+      "    learn_time_ms: 23052.67\n",
+      "    sample_throughput: 22740.933\n",
+      "    sample_time_ms: 7114.572\n",
+      "    update_time_ms: 31.556\n",
+      "  timestamp: 1602499866\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1941504\n",
       "  training_iteration: 12\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     12 |          354.167 | 1941504 |  235.091 |              286.929 |              121.929 |            846.272 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     12 |          366.355 | 1941504 |  232.485 |              280.263 |               88.596 |            841.404 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3497.5670367207513\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-20\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3511.8174872665536\n",
+      "    time_step_min: 3206\n",
+      "  date: 2020-10-12_10-51-37\n",
       "  done: false\n",
-      "  episode_len_mean: 844.135864978903\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 236.12517580872006\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 838.8875838926175\n",
+      "  episode_reward_max: 284.20202020202026\n",
+      "  episode_reward_mean: 233.88233848552625\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 172\n",
+      "  episodes_total: 2384\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3511,14 +3419,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9278469234704971\n",
+      "        entropy: 0.9221795598665873\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007884405087679625\n",
+      "        kl: 0.007596092570262651\n",
       "        model: {}\n",
-      "        policy_loss: -0.015948789776302874\n",
-      "        total_loss: 10.545268694559732\n",
-      "        vf_explained_var: 0.9787933826446533\n",
-      "        vf_loss: 10.560892899831137\n",
+      "        policy_loss: -0.015219444719453653\n",
+      "        total_loss: 13.35711113611857\n",
+      "        vf_explained_var: 0.977639377117157\n",
+      "        vf_loss: 13.372032086054483\n",
       "    num_steps_sampled: 2103296\n",
       "    num_steps_trained: 2103296\n",
       "  iterations_since_restore: 13\n",
@@ -3526,65 +3434,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.094444444444445\n",
-      "    gpu_util_percent0: 0.4186111111111111\n",
+      "    cpu_util_percent: 21.697142857142858\n",
+      "    gpu_util_percent0: 0.29714285714285715\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7722222222222235\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.7800000000000002\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15434316168002962\n",
-      "    mean_env_wait_ms: 1.184977046153128\n",
-      "    mean_inference_ms: 4.846469455238201\n",
-      "    mean_raw_obs_processing_ms: 0.40728119664442336\n",
-      "  time_since_restore: 383.4679665565491\n",
-      "  time_this_iter_s: 29.30088233947754\n",
-      "  time_total_s: 383.4679665565491\n",
+      "    mean_action_processing_ms: 0.15402548836072014\n",
+      "    mean_env_wait_ms: 1.187927580487614\n",
+      "    mean_inference_ms: 4.817554249564923\n",
+      "    mean_raw_obs_processing_ms: 0.40744852108449703\n",
+      "  time_since_restore: 396.4389011859894\n",
+      "  time_this_iter_s: 30.083614826202393\n",
+      "  time_total_s: 396.4389011859894\n",
       "  timers:\n",
-      "    learn_throughput: 7300.976\n",
-      "    learn_time_ms: 22160.325\n",
-      "    sample_throughput: 23265.469\n",
-      "    sample_time_ms: 6954.169\n",
-      "    update_time_ms: 33.753\n",
-      "  timestamp: 1602448520\n",
+      "    learn_throughput: 7011.034\n",
+      "    learn_time_ms: 23076.768\n",
+      "    sample_throughput: 22827.071\n",
+      "    sample_time_ms: 7087.725\n",
+      "    update_time_ms: 32.421\n",
+      "  timestamp: 1602499897\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2103296\n",
       "  training_iteration: 13\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     13 |          383.468 | 2103296 |  236.125 |              286.929 |              121.929 |            844.136 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     13 |          396.439 | 2103296 |  233.882 |              284.202 |               88.596 |            838.888 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3485.74210726512\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-49\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3498.1188863807374\n",
+      "    time_step_min: 3188\n",
+      "  date: 2020-10-12_10-52-07\n",
       "  done: false\n",
-      "  episode_len_mean: 840.0508091832894\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.07121649312083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 287\n",
-      "  episodes_total: 2657\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 834.5979151154132\n",
+      "  episode_reward_max: 284.20202020202026\n",
+      "  episode_reward_mean: 235.96700813044805\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 302\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3593,14 +3501,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9033511777718862\n",
+      "        entropy: 0.9214861939350764\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006811460247263312\n",
+      "        kl: 0.0071946926570187015\n",
       "        model: {}\n",
-      "        policy_loss: -0.013252816175130041\n",
-      "        total_loss: 14.124323924382528\n",
-      "        vf_explained_var: 0.9795716404914856\n",
-      "        vf_loss: 14.137347300847372\n",
+      "        policy_loss: -0.013351308540829146\n",
+      "        total_loss: 14.835413376490274\n",
+      "        vf_explained_var: 0.979828417301178\n",
+      "        vf_loss: 14.848505894343058\n",
       "    num_steps_sampled: 2265088\n",
       "    num_steps_trained: 2265088\n",
       "  iterations_since_restore: 14\n",
@@ -3608,65 +3516,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.24\n",
-      "    gpu_util_percent0: 0.37342857142857144\n",
+      "    cpu_util_percent: 21.805714285714288\n",
+      "    gpu_util_percent0: 0.36428571428571427\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
       "    ram_util_percent: 3.7714285714285714\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15377376909228957\n",
-      "    mean_env_wait_ms: 1.1865557477384137\n",
-      "    mean_inference_ms: 4.804878489409233\n",
-      "    mean_raw_obs_processing_ms: 0.4051869038850363\n",
-      "  time_since_restore: 412.62345147132874\n",
-      "  time_this_iter_s: 29.155484914779663\n",
-      "  time_total_s: 412.62345147132874\n",
+      "    mean_action_processing_ms: 0.15351155806648764\n",
+      "    mean_env_wait_ms: 1.190011853534101\n",
+      "    mean_inference_ms: 4.778664218564182\n",
+      "    mean_raw_obs_processing_ms: 0.405442385544107\n",
+      "  time_since_restore: 426.4023401737213\n",
+      "  time_this_iter_s: 29.963438987731934\n",
+      "  time_total_s: 426.4023401737213\n",
       "  timers:\n",
-      "    learn_throughput: 7291.538\n",
-      "    learn_time_ms: 22189.008\n",
-      "    sample_throughput: 23355.346\n",
-      "    sample_time_ms: 6927.408\n",
-      "    update_time_ms: 33.737\n",
-      "  timestamp: 1602448549\n",
+      "    learn_throughput: 7017.406\n",
+      "    learn_time_ms: 23055.812\n",
+      "    sample_throughput: 22903.105\n",
+      "    sample_time_ms: 7064.195\n",
+      "    update_time_ms: 32.756\n",
+      "  timestamp: 1602499927\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2265088\n",
       "  training_iteration: 14\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     14 |          412.623 | 2265088 |  238.071 |              286.929 |              121.929 |            840.051 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     14 |          426.402 | 2265088 |  235.967 |              284.202 |               88.596 |            834.598 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3479.8014914772725\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-18\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3491.8394886363635\n",
+      "    time_step_min: 3188\n",
+      "  date: 2020-10-12_10-52-37\n",
       "  done: false\n",
-      "  episode_len_mean: 838.0256680731364\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.9295166858457\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 187\n",
+      "  episode_len_mean: 832.3867791842475\n",
+      "  episode_reward_max: 284.20202020202026\n",
+      "  episode_reward_mean: 236.9671717171716\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 2844\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3675,14 +3583,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823518455028534\n",
+      "        entropy: 0.9004226724306742\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007345292794828613\n",
+      "        kl: 0.007208069786429405\n",
       "        model: {}\n",
-      "        policy_loss: -0.014912535432207127\n",
-      "        total_loss: 9.4028111298879\n",
-      "        vf_explained_var: 0.9823583960533142\n",
-      "        vf_loss: 9.41743008295695\n",
+      "        policy_loss: -0.013761558337137103\n",
+      "        total_loss: 10.551711877187094\n",
+      "        vf_explained_var: 0.9797658324241638\n",
+      "        vf_loss: 10.565202951431274\n",
       "    num_steps_sampled: 2426880\n",
       "    num_steps_trained: 2426880\n",
       "  iterations_since_restore: 15\n",
@@ -3690,65 +3598,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.594285714285714\n",
-      "    gpu_util_percent0: 0.4091428571428571\n",
+      "    cpu_util_percent: 21.92571428571428\n",
+      "    gpu_util_percent0: 0.27685714285714286\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7885714285714283\n",
+      "    ram_util_percent: 3.788571428571429\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1534524084488191\n",
-      "    mean_env_wait_ms: 1.1875469379038355\n",
-      "    mean_inference_ms: 4.781234687782602\n",
-      "    mean_raw_obs_processing_ms: 0.4040137555262904\n",
-      "  time_since_restore: 441.5714144706726\n",
-      "  time_this_iter_s: 28.947962999343872\n",
-      "  time_total_s: 441.5714144706726\n",
+      "    mean_action_processing_ms: 0.15327906662279647\n",
+      "    mean_env_wait_ms: 1.1910056333044456\n",
+      "    mean_inference_ms: 4.761055339662379\n",
+      "    mean_raw_obs_processing_ms: 0.40451655661329533\n",
+      "  time_since_restore: 456.6521706581116\n",
+      "  time_this_iter_s: 30.24983048439026\n",
+      "  time_total_s: 456.6521706581116\n",
       "  timers:\n",
-      "    learn_throughput: 7287.175\n",
-      "    learn_time_ms: 22202.292\n",
-      "    sample_throughput: 23451.507\n",
-      "    sample_time_ms: 6899.002\n",
-      "    update_time_ms: 35.815\n",
-      "  timestamp: 1602448578\n",
+      "    learn_throughput: 7020.873\n",
+      "    learn_time_ms: 23044.428\n",
+      "    sample_throughput: 22861.865\n",
+      "    sample_time_ms: 7076.938\n",
+      "    update_time_ms: 31.497\n",
+      "  timestamp: 1602499957\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2426880\n",
       "  training_iteration: 15\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     15 |          441.571 | 2426880 |   238.93 |              286.929 |              121.929 |            838.026 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     15 |          456.652 | 2426880 |  236.967 |              284.202 |               88.596 |            832.387 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3475.086751849361\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-47\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3485.892064559516\n",
+      "    time_step_min: 3188\n",
+      "  date: 2020-10-12_10-53-07\n",
       "  done: false\n",
-      "  episode_len_mean: 836.580946035976\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 239.68230607204615\n",
-      "  episode_reward_min: 121.92929292929249\n",
+      "  episode_len_mean: 830.3870752831446\n",
+      "  episode_reward_max: 287.98989898989873\n",
+      "  episode_reward_mean: 237.99570320123274\n",
+      "  episode_reward_min: 88.59595959595944\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 3002\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3757,14 +3665,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8759780476490656\n",
+      "        entropy: 0.883683979511261\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007468625747909148\n",
+      "        kl: 0.006876855467756589\n",
       "        model: {}\n",
-      "        policy_loss: -0.012898257254467657\n",
-      "        total_loss: 10.490220069885254\n",
-      "        vf_explained_var: 0.9782711863517761\n",
-      "        vf_loss: 10.502809524536133\n",
+      "        policy_loss: -0.015000158843273917\n",
+      "        total_loss: 9.659654299418131\n",
+      "        vf_explained_var: 0.9799847602844238\n",
+      "        vf_loss: 9.674408833185831\n",
       "    num_steps_sampled: 2588672\n",
       "    num_steps_trained: 2588672\n",
       "  iterations_since_restore: 16\n",
@@ -3772,65 +3680,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.662857142857145\n",
-      "    gpu_util_percent0: 0.42\n",
+      "    cpu_util_percent: 21.666666666666668\n",
+      "    gpu_util_percent0: 0.4347222222222223\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.788571428571429\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7916666666666674\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1532049529621475\n",
-      "    mean_env_wait_ms: 1.1882989106782562\n",
-      "    mean_inference_ms: 4.7629533971774105\n",
-      "    mean_raw_obs_processing_ms: 0.40308729415103295\n",
-      "  time_since_restore: 470.55639243125916\n",
-      "  time_this_iter_s: 28.984977960586548\n",
-      "  time_total_s: 470.55639243125916\n",
+      "    mean_action_processing_ms: 0.15306299362268355\n",
+      "    mean_env_wait_ms: 1.191954532027558\n",
+      "    mean_inference_ms: 4.744688514554501\n",
+      "    mean_raw_obs_processing_ms: 0.40362988460399163\n",
+      "  time_since_restore: 487.09628772735596\n",
+      "  time_this_iter_s: 30.444117069244385\n",
+      "  time_total_s: 487.09628772735596\n",
       "  timers:\n",
-      "    learn_throughput: 7291.648\n",
-      "    learn_time_ms: 22188.674\n",
-      "    sample_throughput: 23534.563\n",
-      "    sample_time_ms: 6874.655\n",
-      "    update_time_ms: 34.0\n",
-      "  timestamp: 1602448607\n",
+      "    learn_throughput: 7017.009\n",
+      "    learn_time_ms: 23057.118\n",
+      "    sample_throughput: 22879.197\n",
+      "    sample_time_ms: 7071.577\n",
+      "    update_time_ms: 32.472\n",
+      "  timestamp: 1602499987\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2588672\n",
       "  training_iteration: 16\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     16 |          470.556 | 2588672 |  239.682 |              286.929 |              121.929 |            836.581 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     16 |          487.096 | 2588672 |  237.996 |               287.99 |               88.596 |            830.387 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3469.9057024530107\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-16\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3475.6844047985237\n",
+      "    time_step_min: 3167\n",
+      "  date: 2020-10-12_10-53-38\n",
       "  done: false\n",
-      "  episode_len_mean: 835.2096621408273\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 240.46451888636915\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 165\n",
-      "  episodes_total: 3167\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 827.1854223848734\n",
+      "  episode_reward_max: 287.98989898989873\n",
+      "  episode_reward_mean: 239.62352712855906\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 277\n",
+      "  episodes_total: 3279\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3839,14 +3747,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.852495531241099\n",
+      "        entropy: 0.8587738970915476\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00796507477449874\n",
+      "        kl: 0.006916678316580753\n",
       "        model: {}\n",
-      "        policy_loss: -0.014005369856022298\n",
-      "        total_loss: 12.690512498219809\n",
-      "        vf_explained_var: 0.977016270160675\n",
-      "        vf_loss: 12.704147736231485\n",
+      "        policy_loss: -0.012511584752549728\n",
+      "        total_loss: 14.398477554321289\n",
+      "        vf_explained_var: 0.9803693890571594\n",
+      "        vf_loss: 14.41072670618693\n",
       "    num_steps_sampled: 2750464\n",
       "    num_steps_trained: 2750464\n",
       "  iterations_since_restore: 17\n",
@@ -3854,65 +3762,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3897142857142857\n",
+      "    cpu_util_percent: 21.645714285714284\n",
+      "    gpu_util_percent0: 0.37799999999999995\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
+      "    ram_util_percent: 3.7714285714285714\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1529640052308357\n",
-      "    mean_env_wait_ms: 1.1890237117333837\n",
-      "    mean_inference_ms: 4.74519824859565\n",
-      "    mean_raw_obs_processing_ms: 0.4021687288610967\n",
-      "  time_since_restore: 499.5002360343933\n",
-      "  time_this_iter_s: 28.943843603134155\n",
-      "  time_total_s: 499.5002360343933\n",
+      "    mean_action_processing_ms: 0.15273481962961288\n",
+      "    mean_env_wait_ms: 1.1936538248240764\n",
+      "    mean_inference_ms: 4.7192378919427\n",
+      "    mean_raw_obs_processing_ms: 0.40228302607192723\n",
+      "  time_since_restore: 517.2829170227051\n",
+      "  time_this_iter_s: 30.18662929534912\n",
+      "  time_total_s: 517.2829170227051\n",
       "  timers:\n",
-      "    learn_throughput: 7290.38\n",
-      "    learn_time_ms: 22192.533\n",
-      "    sample_throughput: 23605.312\n",
-      "    sample_time_ms: 6854.051\n",
-      "    update_time_ms: 34.588\n",
-      "  timestamp: 1602448636\n",
+      "    learn_throughput: 7016.909\n",
+      "    learn_time_ms: 23057.447\n",
+      "    sample_throughput: 22903.263\n",
+      "    sample_time_ms: 7064.146\n",
+      "    update_time_ms: 30.629\n",
+      "  timestamp: 1602500018\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2750464\n",
       "  training_iteration: 17\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     17 |            499.5 | 2750464 |  240.465 |              286.929 |              121.929 |             835.21 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     17 |          517.283 | 2750464 |  239.624 |               287.99 |               88.596 |            827.185 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3460.8975254730713\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-45\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3469.3190255220416\n",
+      "    time_step_min: 3144\n",
+      "  date: 2020-10-12_10-54-08\n",
       "  done: false\n",
-      "  episode_len_mean: 833.2304360381172\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 241.8702269591671\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 296\n",
-      "  episodes_total: 3463\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  episode_len_mean: 824.9479286536249\n",
+      "  episode_reward_max: 289.65656565656536\n",
+      "  episode_reward_mean: 240.624545222071\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 197\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -3921,14 +3829,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8307255059480667\n",
+      "        entropy: 0.8442238519589106\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007045873751242955\n",
+      "        kl: 0.007084058636489014\n",
       "        model: {}\n",
-      "        policy_loss: -0.01215925798896933\n",
-      "        total_loss: 12.891058842341105\n",
-      "        vf_explained_var: 0.9813470840454102\n",
-      "        vf_loss: 12.902929147084555\n",
+      "        policy_loss: -0.014629053592216223\n",
+      "        total_loss: 10.824065446853638\n",
+      "        vf_explained_var: 0.9808571338653564\n",
+      "        vf_loss: 10.83840799331665\n",
       "    num_steps_sampled: 2912256\n",
       "    num_steps_trained: 2912256\n",
       "  iterations_since_restore: 18\n",
@@ -3936,65 +3844,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.39444444444444\n",
-      "    gpu_util_percent0: 0.37611111111111106\n",
+      "    cpu_util_percent: 22.057142857142853\n",
+      "    gpu_util_percent0: 0.3442857142857143\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.7857142857142865\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15257348075562227\n",
-      "    mean_env_wait_ms: 1.190223232808066\n",
-      "    mean_inference_ms: 4.716765364778451\n",
-      "    mean_raw_obs_processing_ms: 0.4007276342320052\n",
-      "  time_since_restore: 528.7100386619568\n",
-      "  time_this_iter_s: 29.209802627563477\n",
-      "  time_total_s: 528.7100386619568\n",
+      "    mean_action_processing_ms: 0.15250983796903406\n",
+      "    mean_env_wait_ms: 1.194694048196607\n",
+      "    mean_inference_ms: 4.70271967975275\n",
+      "    mean_raw_obs_processing_ms: 0.4014121366382054\n",
+      "  time_since_restore: 547.3402900695801\n",
+      "  time_this_iter_s: 30.057373046875\n",
+      "  time_total_s: 547.3402900695801\n",
       "  timers:\n",
-      "    learn_throughput: 7282.324\n",
-      "    learn_time_ms: 22217.084\n",
-      "    sample_throughput: 23670.713\n",
-      "    sample_time_ms: 6835.113\n",
-      "    update_time_ms: 35.605\n",
-      "  timestamp: 1602448665\n",
+      "    learn_throughput: 7017.142\n",
+      "    learn_time_ms: 23056.679\n",
+      "    sample_throughput: 23001.567\n",
+      "    sample_time_ms: 7033.956\n",
+      "    update_time_ms: 32.23\n",
+      "  timestamp: 1602500048\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2912256\n",
       "  training_iteration: 18\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     18 |           528.71 | 2912256 |   241.87 |              291.778 |              121.929 |             833.23 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     18 |           547.34 | 2912256 |  240.625 |              289.657 |               88.596 |            824.948 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3454.902384914032\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-15\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3465.189961175818\n",
+      "    time_step_min: 3144\n",
+      "  date: 2020-10-12_10-54-38\n",
       "  done: false\n",
-      "  episode_len_mean: 831.9851403412218\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 242.68078139679676\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 171\n",
+      "  episode_len_mean: 823.5038525041277\n",
+      "  episode_reward_max: 289.65656565656536\n",
+      "  episode_reward_mean: 241.21011713169108\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 3634\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4003,14 +3911,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259735157092413\n",
+      "        entropy: 0.8410505006710688\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006872209099431832\n",
+      "        kl: 0.007028338382951915\n",
       "        model: {}\n",
-      "        policy_loss: -0.013244140621585151\n",
-      "        total_loss: 8.755500555038452\n",
-      "        vf_explained_var: 0.9823317527770996\n",
-      "        vf_loss: 8.768470366795858\n",
+      "        policy_loss: -0.012794313098614415\n",
+      "        total_loss: 10.480183601379395\n",
+      "        vf_explained_var: 0.9795172810554504\n",
+      "        vf_loss: 10.492695411046347\n",
       "    num_steps_sampled: 3074048\n",
       "    num_steps_trained: 3074048\n",
       "  iterations_since_restore: 19\n",
@@ -4018,65 +3926,65 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.4\n",
+      "    cpu_util_percent: 21.87142857142857\n",
+      "    gpu_util_percent0: 0.4517142857142856\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
+      "    ram_util_percent: 3.7800000000000002\n",
       "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15237407849355733\n",
-      "    mean_env_wait_ms: 1.1908777392592924\n",
-      "    mean_inference_ms: 4.701934814500055\n",
-      "    mean_raw_obs_processing_ms: 0.3999776278068825\n",
-      "  time_since_restore: 557.9314706325531\n",
-      "  time_this_iter_s: 29.221431970596313\n",
-      "  time_total_s: 557.9314706325531\n",
+      "    mean_action_processing_ms: 0.15234923422949861\n",
+      "    mean_env_wait_ms: 1.1954980474610577\n",
+      "    mean_inference_ms: 4.690587971836767\n",
+      "    mean_raw_obs_processing_ms: 0.4007655976235748\n",
+      "  time_since_restore: 577.2354960441589\n",
+      "  time_this_iter_s: 29.895205974578857\n",
+      "  time_total_s: 577.2354960441589\n",
       "  timers:\n",
-      "    learn_throughput: 7280.232\n",
-      "    learn_time_ms: 22223.467\n",
-      "    sample_throughput: 23734.777\n",
-      "    sample_time_ms: 6816.664\n",
-      "    update_time_ms: 36.199\n",
-      "  timestamp: 1602448695\n",
+      "    learn_throughput: 7018.912\n",
+      "    learn_time_ms: 23050.867\n",
+      "    sample_throughput: 23055.833\n",
+      "    sample_time_ms: 7017.4\n",
+      "    update_time_ms: 32.148\n",
+      "  timestamp: 1602500078\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3074048\n",
       "  training_iteration: 19\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     19 |          557.931 | 3074048 |  242.681 |              291.778 |              121.929 |            831.985 |\n",
+      "| PPO_jss_env_f5b28_00000 | RUNNING  | 172.17.0.4:27951 |     19 |          577.235 | 3074048 |   241.21 |              289.657 |               88.596 |            823.504 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
+      "Result for PPO_jss_env_f5b28_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3450.175345377258\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-44\n",
-      "  done: false\n",
-      "  episode_len_mean: 830.9298523206751\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 243.33396464646458\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
+      "    time_step_max: 4329\n",
+      "    time_step_mean: 3460.29231581727\n",
+      "    time_step_min: 3144\n",
+      "  date: 2020-10-12_10-55-08\n",
+      "  done: true\n",
+      "  episode_len_mean: 822.3347313237222\n",
+      "  episode_reward_max: 289.65656565656536\n",
+      "  episode_reward_mean: 241.98501396666526\n",
+      "  episode_reward_min: 88.59595959595944\n",
+      "  episodes_this_iter: 181\n",
+      "  episodes_total: 3815\n",
+      "  experiment_id: 5ef3d16fd3334461acd97dac32f79b0c\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -4085,14 +3993,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.10000000000000002\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259675403436025\n",
+      "        entropy: 0.8101343264182409\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007086256169714034\n",
+      "        kl: 0.007008894269044201\n",
       "        model: {}\n",
-      "        policy_loss: -0.014026373353165885\n",
-      "        total_loss: 8.932533502578735\n",
-      "        vf_explained_var: 0.9804465770721436\n",
-      "        vf_loss: 8.946264505386353\n",
+      "        policy_loss: -0.014301851236571869\n",
+      "        total_loss: 10.842975616455078\n",
+      "        vf_explained_var: 0.9824185371398926\n",
+      "        vf_loss: 10.856981674830118\n",
       "    num_steps_sampled: 3235840\n",
       "    num_steps_trained: 3235840\n",
       "  iterations_since_restore: 20\n",
@@ -4100,164 +4008,82 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 22.333333333333332\n",
-      "    gpu_util_percent0: 0.34388888888888886\n",
+      "    cpu_util_percent: 22.217142857142857\n",
+      "    gpu_util_percent0: 0.3108571428571429\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7888888888888896\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
+      "    ram_util_percent: 3.782857142857144\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
+      "  pid: 27951\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1521992790788445\n",
-      "    mean_env_wait_ms: 1.1914171815739172\n",
-      "    mean_inference_ms: 4.6890953823501\n",
-      "    mean_raw_obs_processing_ms: 0.39931785266421166\n",
-      "  time_since_restore: 587.2469084262848\n",
-      "  time_this_iter_s: 29.31543779373169\n",
-      "  time_total_s: 587.2469084262848\n",
+      "    mean_action_processing_ms: 0.1521794438483494\n",
+      "    mean_env_wait_ms: 1.196420012756342\n",
+      "    mean_inference_ms: 4.677725917597975\n",
+      "    mean_raw_obs_processing_ms: 0.400067930451597\n",
+      "  time_since_restore: 607.449939250946\n",
+      "  time_this_iter_s: 30.21444320678711\n",
+      "  time_total_s: 607.449939250946\n",
       "  timers:\n",
-      "    learn_throughput: 7277.52\n",
-      "    learn_time_ms: 22231.749\n",
-      "    sample_throughput: 23771.576\n",
-      "    sample_time_ms: 6806.112\n",
-      "    update_time_ms: 35.896\n",
-      "  timestamp: 1602448724\n",
+      "    learn_throughput: 7020.345\n",
+      "    learn_time_ms: 23046.161\n",
+      "    sample_throughput: 23073.191\n",
+      "    sample_time_ms: 7012.121\n",
+      "    update_time_ms: 32.424\n",
+      "  timestamp: 1602500108\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3235840\n",
       "  training_iteration: 20\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     20 |          587.247 | 3235840 |  243.334 |              291.778 |              121.929 |             830.93 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3444.209372637944\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-39-13\n",
-      "  done: true\n",
-      "  episode_len_mean: 829.7485614210658\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 244.23336947154803\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 205\n",
-      "  episodes_total: 3997\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7932304640611013\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007863614863405624\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013052704744040966\n",
-      "        total_loss: 8.696449995040894\n",
-      "        vf_explained_var: 0.9847684502601624\n",
-      "        vf_loss: 8.709113121032715\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.822857142857142\n",
-      "    gpu_util_percent0: 0.41600000000000004\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7714285714285722\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15199085982895233\n",
-      "    mean_env_wait_ms: 1.1921048958466818\n",
-      "    mean_inference_ms: 4.67351707422206\n",
-      "    mean_raw_obs_processing_ms: 0.3985042407825798\n",
-      "  time_since_restore: 616.376526594162\n",
-      "  time_this_iter_s: 29.129618167877197\n",
-      "  time_total_s: 616.376526594162\n",
-      "  timers:\n",
-      "    learn_throughput: 7273.12\n",
-      "    learn_time_ms: 22245.198\n",
-      "    sample_throughput: 23807.886\n",
-      "    sample_time_ms: 6795.731\n",
-      "    update_time_ms: 35.623\n",
-      "  timestamp: 1602448753\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 5e4a4_00000\n",
+      "  trial_id: f5b28_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
+      "| PPO_jss_env_f5b28_00000 | TERMINATED |       |     20 |           607.45 | 3235840 |  241.985 |              289.657 |               88.596 |            822.335 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
+      "| PPO_jss_env_f5b28_00000 | TERMINATED |       |     20 |           607.45 | 3235840 |  241.985 |              289.657 |               88.596 |            822.335 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 74132\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 27680\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_104447-zrncloep/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_104447-zrncloep/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3135\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3144\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 631\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448754\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4251\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3444.20937\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 291.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 121.92929\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 244.23337\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3997\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 21\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 622\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602500109\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4329\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3460.29232\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 289.65657\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 88.59596\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 241.98501\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3815\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 20\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
@@ -4273,204 +4099,202 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mpolar-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "2020-10-11 20:39:22,411 - wandb.wandb_agent - INFO - Cleaning up finished run: 4ndtcjlt\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 35\n",
-      "2020-10-11 20:39:22,755 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=35\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mcrimson-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/zrncloep\u001b[0m\n",
+      "2020-10-12 10:55:16,372 - wandb.wandb_agent - INFO - Cleaning up finished run: zrncloep\n",
+      "2020-10-12 10:55:16,688 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 10:55:16,688 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.5\n",
+      "\tnum_sgd_iter: 25\n",
+      "2020-10-12 10:55:16,690 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.5 --num_sgd_iter=25\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:39:27,770 - wandb.wandb_agent - INFO - Running runs: ['4lvdkknr']\n",
+      "2020-10-12 10:55:21,708 - wandb.wandb_agent - INFO - Running runs: ['f0zxmbgr']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msplendid-sweep-3\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfeasible-sweep-3\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_203924-4lvdkknr\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/y2n6znmq\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/f0zxmbgr\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_105518-f0zxmbgr\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-11 20:39:28,572\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "2020-10-12 10:55:22,455\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
       "Memory usage on this node: 11.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=15842)\u001b[0m 2020-10-11 20:39:31,348\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "\u001b[2m\u001b[36m(pid=52163)\u001b[0m 2020-10-12 10:55:25,246\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=52158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52183)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52183)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52203)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52203)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52167)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52167)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52185)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52185)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52175)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52175)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52125)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52125)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52138)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52138)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52136)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52136)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52144)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52144)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52169)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52169)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52067)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52067)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52168)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52168)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52159)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52159)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52084)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52084)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52119)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52119)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52094)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52094)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52101)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52101)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52135)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52135)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52146)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52146)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52093)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52093)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52181)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52181)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52077)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52077)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52180)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52180)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52075)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52075)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52089)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52089)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52191)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52191)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52073)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52073)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52190)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52190)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52139)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52139)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52187)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52187)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52118)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52118)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52062)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52062)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52132)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52132)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52196)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52196)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52082)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52082)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52072)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52072)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52096)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52096)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52063)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52063)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52091)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52091)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52080)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52080)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52064)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52064)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52134)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52134)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52103)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52103)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52128)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52128)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52098)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52098)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52071)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52071)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52099)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52099)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52123)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52123)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52172)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52172)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52070)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52070)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52068)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52068)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52078)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52078)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52066)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52066)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52079)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52079)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52199)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52199)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52081)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52081)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52122)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52122)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52076)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52076)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52065)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52065)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52086)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52086)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52137)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52137)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52131)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52131)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=52178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=52178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: 4054\n",
       "    time_step_mean: 3615.0923076923077\n",
       "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-40-12\n",
+      "  date: 2020-10-12_10-55-59\n",
       "  done: false\n",
       "  episode_len_mean: 891.1139240506329\n",
       "  episode_reward_max: 258.59595959595964\n",
@@ -4478,23 +4302,23 @@
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1813993354638417\n",
+      "        entropy: 1.1823383669058483\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007591694826260209\n",
+      "        kl: 0.006917016425480445\n",
       "        model: {}\n",
-      "        policy_loss: -0.012553695759076314\n",
-      "        total_loss: 500.41192626953125\n",
-      "        vf_explained_var: 0.5819632411003113\n",
-      "        vf_loss: 500.42430623372394\n",
+      "        policy_loss: -0.009157503198366612\n",
+      "        total_loss: 507.07493591308594\n",
+      "        vf_explained_var: 0.540532648563385\n",
+      "        vf_loss: 507.0832926432292\n",
       "    num_steps_sampled: 161792\n",
       "    num_steps_trained: 161792\n",
       "  iterations_since_restore: 1\n",
@@ -4502,81 +4326,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.811363636363637\n",
-      "    gpu_util_percent0: 0.31227272727272726\n",
+      "    cpu_util_percent: 28.251515151515154\n",
+      "    gpu_util_percent0: 0.3718181818181819\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5909090909090895\n",
-      "    vram_util_percent0: 0.08942201616029101\n",
+      "    ram_util_percent: 3.566666666666667\n",
+      "    vram_util_percent0: 0.08736346740610434\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16739492248554\n",
-      "    mean_env_wait_ms: 1.1652346855698266\n",
-      "    mean_inference_ms: 5.5060321204858855\n",
-      "    mean_raw_obs_processing_ms: 0.44000907090020136\n",
-      "  time_since_restore: 35.872936725616455\n",
-      "  time_this_iter_s: 35.872936725616455\n",
-      "  time_total_s: 35.872936725616455\n",
+      "    mean_action_processing_ms: 0.17147091885855553\n",
+      "    mean_env_wait_ms: 1.1835253551514953\n",
+      "    mean_inference_ms: 5.7652556215329245\n",
+      "    mean_raw_obs_processing_ms: 0.4616651007995889\n",
+      "  time_since_restore: 28.869199991226196\n",
+      "  time_this_iter_s: 28.869199991226196\n",
+      "  time_total_s: 28.869199991226196\n",
       "  timers:\n",
-      "    learn_throughput: 6001.037\n",
-      "    learn_time_ms: 26960.675\n",
-      "    sample_throughput: 18322.175\n",
-      "    sample_time_ms: 8830.393\n",
-      "    update_time_ms: 41.968\n",
-      "  timestamp: 1602448812\n",
+      "    learn_throughput: 8237.186\n",
+      "    learn_time_ms: 19641.659\n",
+      "    sample_throughput: 17651.248\n",
+      "    sample_time_ms: 9166.037\n",
+      "    update_time_ms: 28.822\n",
+      "  timestamp: 1602500159\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 27.6/754.6 GiB\n",
+      "Memory usage on this node: 27.7/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      1 |          35.8729 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      1 |          28.8692 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3613.684027777778\n",
-      "    time_step_min: 3358\n",
-      "  date: 2020-10-11_20-40-47\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3614.2256944444443\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_10-56-26\n",
       "  done: false\n",
-      "  episode_len_mean: 888.5917721518987\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 217.0985487789283\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 892.4873417721519\n",
+      "  episode_reward_max: 264.3535353535352\n",
+      "  episode_reward_mean: 217.54734049354283\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.149230072895686\n",
+      "        entropy: 1.149937113126119\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00951601347575585\n",
+      "        kl: 0.007523950111741821\n",
       "        model: {}\n",
-      "        policy_loss: -0.01619932148605585\n",
-      "        total_loss: 120.9416898091634\n",
-      "        vf_explained_var: 0.8221778273582458\n",
-      "        vf_loss: 120.95751126607259\n",
+      "        policy_loss: -0.00998671705989788\n",
+      "        total_loss: 126.33550771077473\n",
+      "        vf_explained_var: 0.8110877871513367\n",
+      "        vf_loss: 126.34455998738606\n",
       "    num_steps_sampled: 323584\n",
       "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 2\n",
@@ -4584,81 +4408,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 21.199999999999996\n",
-      "    gpu_util_percent0: 0.32047619047619047\n",
+      "    cpu_util_percent: 26.475\n",
+      "    gpu_util_percent0: 0.3421875\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.76904761904762\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.75625\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16326572534453276\n",
-      "    mean_env_wait_ms: 1.1632587587181373\n",
-      "    mean_inference_ms: 5.312069869064258\n",
-      "    mean_raw_obs_processing_ms: 0.43039064260126914\n",
-      "  time_since_restore: 70.36755323410034\n",
-      "  time_this_iter_s: 34.49461650848389\n",
-      "  time_total_s: 70.36755323410034\n",
+      "    mean_action_processing_ms: 0.16716277233710714\n",
+      "    mean_env_wait_ms: 1.1780378196190102\n",
+      "    mean_inference_ms: 5.585069303097012\n",
+      "    mean_raw_obs_processing_ms: 0.4514916274955019\n",
+      "  time_since_restore: 56.27803659439087\n",
+      "  time_this_iter_s: 27.408836603164673\n",
+      "  time_total_s: 56.27803659439087\n",
       "  timers:\n",
-      "    learn_throughput: 6017.136\n",
-      "    learn_time_ms: 26888.542\n",
-      "    sample_throughput: 19703.911\n",
-      "    sample_time_ms: 8211.162\n",
-      "    update_time_ms: 40.266\n",
-      "  timestamp: 1602448847\n",
+      "    learn_throughput: 8276.418\n",
+      "    learn_time_ms: 19548.553\n",
+      "    sample_throughput: 18989.984\n",
+      "    sample_time_ms: 8519.86\n",
+      "    update_time_ms: 32.285\n",
+      "  timestamp: 1602500186\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      2 |          70.3676 | 323584 |  217.099 |              258.596 |              106.778 |            888.592 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      2 |           56.278 | 323584 |  217.547 |              264.354 |              133.899 |            892.487 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3616.4686098654706\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-21\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3605.479820627803\n",
+      "    time_step_min: 3310\n",
+      "  date: 2020-10-12_10-56-53\n",
       "  done: false\n",
-      "  episode_len_mean: 885.3459915611814\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 217.68079529471913\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 888.5801687763714\n",
+      "  episode_reward_max: 264.50505050505006\n",
+      "  episode_reward_mean: 219.20585602864062\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.137440989414851\n",
+      "        entropy: 1.1411352157592773\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010796306344370047\n",
+      "        kl: 0.010440803055341044\n",
       "        model: {}\n",
-      "        policy_loss: -0.017557858838699758\n",
-      "        total_loss: 47.99287382761637\n",
-      "        vf_explained_var: 0.9169993996620178\n",
-      "        vf_loss: 48.00991948445638\n",
+      "        policy_loss: -0.013970387983135879\n",
+      "        total_loss: 54.93683338165283\n",
+      "        vf_explained_var: 0.8966913819313049\n",
+      "        vf_loss: 54.94928582509359\n",
       "    num_steps_sampled: 485376\n",
       "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 3\n",
@@ -4666,81 +4490,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.892857142857146\n",
-      "    gpu_util_percent0: 0.34785714285714286\n",
+      "    cpu_util_percent: 23.906451612903226\n",
+      "    gpu_util_percent0: 0.2567741935483871\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.770967741935483\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16056212834421194\n",
-      "    mean_env_wait_ms: 1.1634296276589942\n",
-      "    mean_inference_ms: 5.15785089440761\n",
-      "    mean_raw_obs_processing_ms: 0.4230651018633661\n",
-      "  time_since_restore: 104.36089730262756\n",
-      "  time_this_iter_s: 33.99334406852722\n",
-      "  time_total_s: 104.36089730262756\n",
+      "    mean_action_processing_ms: 0.16416068482864943\n",
+      "    mean_env_wait_ms: 1.1764073313687264\n",
+      "    mean_inference_ms: 5.41271049974388\n",
+      "    mean_raw_obs_processing_ms: 0.44254761530967934\n",
+      "  time_since_restore: 82.95011138916016\n",
+      "  time_this_iter_s: 26.672074794769287\n",
+      "  time_total_s: 82.95011138916016\n",
       "  timers:\n",
-      "    learn_throughput: 6029.227\n",
-      "    learn_time_ms: 26834.618\n",
-      "    sample_throughput: 20609.33\n",
-      "    sample_time_ms: 7850.425\n",
-      "    update_time_ms: 56.456\n",
-      "  timestamp: 1602448881\n",
+      "    learn_throughput: 8275.25\n",
+      "    learn_time_ms: 19551.314\n",
+      "    sample_throughput: 20161.139\n",
+      "    sample_time_ms: 8024.943\n",
+      "    update_time_ms: 30.097\n",
+      "  timestamp: 1602500213\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Memory usage on this node: 28.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      3 |          104.361 | 485376 |  217.681 |              260.414 |              106.778 |            885.346 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      3 |          82.9501 | 485376 |  219.206 |              264.505 |              133.899 |             888.58 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3614.6423841059604\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-55\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3591.1639072847684\n",
+      "    time_step_min: 3227\n",
+      "  date: 2020-10-12_10-57-20\n",
       "  done: false\n",
-      "  episode_len_mean: 881.8196202531645\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 218.72613796189725\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 885.4873417721519\n",
+      "  episode_reward_max: 277.0808080808083\n",
+      "  episode_reward_mean: 221.420326684567\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1155910591284435\n",
+      "        entropy: 1.1191200812657673\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009656987541044751\n",
+      "        kl: 0.011468215147033334\n",
       "        model: {}\n",
-      "        policy_loss: -0.01651762195736713\n",
-      "        total_loss: 28.95356051127116\n",
-      "        vf_explained_var: 0.9477614760398865\n",
-      "        vf_loss: 28.969671090443928\n",
+      "        policy_loss: -0.013862663588952273\n",
+      "        total_loss: 39.326786041259766\n",
+      "        vf_explained_var: 0.9241357445716858\n",
+      "        vf_loss: 39.33891359965006\n",
       "    num_steps_sampled: 647168\n",
       "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 4\n",
@@ -4748,81 +4572,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.343902439024394\n",
-      "    gpu_util_percent0: 0.35048780487804876\n",
+      "    cpu_util_percent: 24.122580645161296\n",
+      "    gpu_util_percent0: 0.3067741935483871\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7774193548387096\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1586801646218421\n",
-      "    mean_env_wait_ms: 1.164152942958408\n",
-      "    mean_inference_ms: 5.046484781278792\n",
-      "    mean_raw_obs_processing_ms: 0.41745109450024254\n",
-      "  time_since_restore: 138.51990175247192\n",
-      "  time_this_iter_s: 34.15900444984436\n",
-      "  time_total_s: 138.51990175247192\n",
+      "    mean_action_processing_ms: 0.16203772838314764\n",
+      "    mean_env_wait_ms: 1.1756419669558824\n",
+      "    mean_inference_ms: 5.281175406047125\n",
+      "    mean_raw_obs_processing_ms: 0.43528602585015497\n",
+      "  time_since_restore: 109.46789050102234\n",
+      "  time_this_iter_s: 26.517779111862183\n",
+      "  time_total_s: 109.46789050102234\n",
       "  timers:\n",
-      "    learn_throughput: 6020.605\n",
-      "    learn_time_ms: 26873.045\n",
-      "    sample_throughput: 21117.842\n",
-      "    sample_time_ms: 7661.389\n",
-      "    update_time_ms: 48.665\n",
-      "  timestamp: 1602448915\n",
+      "    learn_throughput: 8295.557\n",
+      "    learn_time_ms: 19503.452\n",
+      "    sample_throughput: 20769.091\n",
+      "    sample_time_ms: 7790.038\n",
+      "    update_time_ms: 28.106\n",
+      "  timestamp: 1602500240\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      4 |           138.52 | 647168 |  218.726 |              260.414 |              106.778 |             881.82 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      4 |          109.468 | 647168 |   221.42 |              277.081 |              133.899 |            885.487 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3605.250656167979\n",
-      "    time_step_min: 3304\n",
-      "  date: 2020-10-11_20-42-29\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3577.469816272966\n",
+      "    time_step_min: 3227\n",
+      "  date: 2020-10-12_10-57-46\n",
       "  done: false\n",
-      "  episode_len_mean: 877.9139240506329\n",
-      "  episode_reward_max: 265.41414141414134\n",
-      "  episode_reward_mean: 220.00543408771236\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 882.6164556962025\n",
+      "  episode_reward_max: 277.0808080808083\n",
+      "  episode_reward_mean: 223.37348165196246\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 790\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0832295417785645\n",
+      "        entropy: 1.0904998779296875\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009306296007707715\n",
+      "        kl: 0.010465693194419146\n",
       "        model: {}\n",
-      "        policy_loss: -0.018154682746777933\n",
-      "        total_loss: 23.046836853027344\n",
-      "        vf_explained_var: 0.9613752365112305\n",
-      "        vf_loss: 23.06460205713908\n",
+      "        policy_loss: -0.013936646308138734\n",
+      "        total_loss: 29.070746898651123\n",
+      "        vf_explained_var: 0.9454066157341003\n",
+      "        vf_loss: 29.0831356048584\n",
       "    num_steps_sampled: 808960\n",
       "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 5\n",
@@ -4830,81 +4654,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.524390243902438\n",
-      "    gpu_util_percent0: 0.31585365853658537\n",
+      "    cpu_util_percent: 24.53870967741935\n",
+      "    gpu_util_percent0: 0.2938709677419355\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.777419354838709\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15728991577564908\n",
-      "    mean_env_wait_ms: 1.165519039293983\n",
-      "    mean_inference_ms: 4.9625030190174435\n",
-      "    mean_raw_obs_processing_ms: 0.41304544879908506\n",
-      "  time_since_restore: 172.49350261688232\n",
-      "  time_this_iter_s: 33.9736008644104\n",
-      "  time_total_s: 172.49350261688232\n",
+      "    mean_action_processing_ms: 0.1604253042931813\n",
+      "    mean_env_wait_ms: 1.1754901553139634\n",
+      "    mean_inference_ms: 5.1789854550669325\n",
+      "    mean_raw_obs_processing_ms: 0.4294192239943622\n",
+      "  time_since_restore: 135.85770750045776\n",
+      "  time_this_iter_s: 26.389816999435425\n",
+      "  time_total_s: 135.85770750045776\n",
       "  timers:\n",
-      "    learn_throughput: 6022.129\n",
-      "    learn_time_ms: 26866.247\n",
-      "    sample_throughput: 21465.213\n",
-      "    sample_time_ms: 7537.405\n",
-      "    update_time_ms: 47.824\n",
-      "  timestamp: 1602448949\n",
+      "    learn_throughput: 8303.132\n",
+      "    learn_time_ms: 19485.659\n",
+      "    sample_throughput: 21259.941\n",
+      "    sample_time_ms: 7610.181\n",
+      "    update_time_ms: 29.296\n",
+      "  timestamp: 1602500266\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      5 |          172.494 | 808960 |  220.005 |              265.414 |              106.778 |            877.914 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      5 |          135.858 | 808960 |  223.373 |              277.081 |              133.899 |            882.616 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3589.0765639589167\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-43-03\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3562.2380487804876\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_10-58-13\n",
       "  done: false\n",
-      "  episode_len_mean: 868.1392174704276\n",
-      "  episode_reward_max: 267.6868686868687\n",
-      "  episode_reward_mean: 222.3442707328056\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 309\n",
-      "  episodes_total: 1099\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 875.4055080721747\n",
+      "  episode_reward_max: 278.89898989898927\n",
+      "  episode_reward_mean: 225.90998302109395\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 263\n",
+      "  episodes_total: 1053\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0729438364505768\n",
+      "        entropy: 1.0669801433881123\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008983297661567727\n",
+      "        kl: 0.010119187956055006\n",
       "        model: {}\n",
-      "        policy_loss: -0.014856907461459437\n",
-      "        total_loss: 27.952880541483562\n",
-      "        vf_explained_var: 0.967507541179657\n",
-      "        vf_loss: 27.96737511952718\n",
+      "        policy_loss: -0.014624884177464992\n",
+      "        total_loss: 30.67037757237752\n",
+      "        vf_explained_var: 0.9617660641670227\n",
+      "        vf_loss: 30.683512210845947\n",
       "    num_steps_sampled: 970752\n",
       "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 6\n",
@@ -4912,81 +4736,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.916666666666668\n",
-      "    gpu_util_percent0: 0.32166666666666666\n",
+      "    cpu_util_percent: 24.938709677419357\n",
+      "    gpu_util_percent0: 0.2916129032258064\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7677419354838704\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15544227505819425\n",
-      "    mean_env_wait_ms: 1.1697635491006715\n",
-      "    mean_inference_ms: 4.850780353416123\n",
-      "    mean_raw_obs_processing_ms: 0.4076391069538378\n",
-      "  time_since_restore: 206.787859916687\n",
-      "  time_this_iter_s: 34.29435729980469\n",
-      "  time_total_s: 206.787859916687\n",
+      "    mean_action_processing_ms: 0.1586324585785928\n",
+      "    mean_env_wait_ms: 1.176979295536505\n",
+      "    mean_inference_ms: 5.05538347401539\n",
+      "    mean_raw_obs_processing_ms: 0.4225521220118445\n",
+      "  time_since_restore: 162.56656551361084\n",
+      "  time_this_iter_s: 26.708858013153076\n",
+      "  time_total_s: 162.56656551361084\n",
       "  timers:\n",
-      "    learn_throughput: 6012.676\n",
-      "    learn_time_ms: 26908.487\n",
-      "    sample_throughput: 21686.82\n",
-      "    sample_time_ms: 7460.384\n",
-      "    update_time_ms: 46.403\n",
-      "  timestamp: 1602448983\n",
+      "    learn_throughput: 8290.95\n",
+      "    learn_time_ms: 19514.291\n",
+      "    sample_throughput: 21567.052\n",
+      "    sample_time_ms: 7501.813\n",
+      "    update_time_ms: 31.603\n",
+      "  timestamp: 1602500293\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      6 |          206.788 | 970752 |  222.344 |              267.687 |              106.778 |            868.139 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      6 |          162.567 | 970752 |   225.91 |              278.899 |              133.899 |            875.406 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3580.65857605178\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-43-37\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3547.7540453074434\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_10-58-40\n",
       "  done: false\n",
-      "  episode_len_mean: 864.2848101265823\n",
-      "  episode_reward_max: 280.2626262626266\n",
-      "  episode_reward_mean: 223.69569108809597\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 165\n",
+      "  episode_len_mean: 868.5514240506329\n",
+      "  episode_reward_max: 278.89898989898927\n",
+      "  episode_reward_mean: 228.15807601329732\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 211\n",
       "  episodes_total: 1264\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.058151125907898\n",
+      "        entropy: 1.0668786863485973\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009279307521258792\n",
+      "        kl: 0.012256689059237639\n",
       "        model: {}\n",
-      "        policy_loss: -0.01645077992967951\n",
-      "        total_loss: 15.616268157958984\n",
-      "        vf_explained_var: 0.9726335406303406\n",
-      "        vf_loss: 15.632320404052734\n",
+      "        policy_loss: -0.01610318278350557\n",
+      "        total_loss: 20.370780150095623\n",
+      "        vf_explained_var: 0.963979959487915\n",
+      "        vf_loss: 20.384966214497883\n",
       "    num_steps_sampled: 1132544\n",
       "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 7\n",
@@ -4994,81 +4818,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.31219512195122\n",
-      "    gpu_util_percent0: 0.39048780487804874\n",
+      "    cpu_util_percent: 24.616129032258065\n",
+      "    gpu_util_percent0: 0.23774193548387104\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7709677419354835\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547533973210653\n",
-      "    mean_env_wait_ms: 1.1714575614665215\n",
-      "    mean_inference_ms: 4.8082734759399735\n",
-      "    mean_raw_obs_processing_ms: 0.4055719972688042\n",
-      "  time_since_restore: 240.5369439125061\n",
-      "  time_this_iter_s: 33.74908399581909\n",
-      "  time_total_s: 240.5369439125061\n",
+      "    mean_action_processing_ms: 0.15748831276889352\n",
+      "    mean_env_wait_ms: 1.1783620018052106\n",
+      "    mean_inference_ms: 4.984924423970675\n",
+      "    mean_raw_obs_processing_ms: 0.4185332833118741\n",
+      "  time_since_restore: 189.28819298744202\n",
+      "  time_this_iter_s: 26.721627473831177\n",
+      "  time_total_s: 189.28819298744202\n",
       "  timers:\n",
-      "    learn_throughput: 6015.051\n",
-      "    learn_time_ms: 26897.858\n",
-      "    sample_throughput: 21950.814\n",
-      "    sample_time_ms: 7370.661\n",
-      "    update_time_ms: 43.835\n",
-      "  timestamp: 1602449017\n",
+      "    learn_throughput: 8282.185\n",
+      "    learn_time_ms: 19534.941\n",
+      "    sample_throughput: 21790.152\n",
+      "    sample_time_ms: 7425.005\n",
+      "    update_time_ms: 33.042\n",
+      "  timestamp: 1602500320\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      7 |          240.537 | 1132544 |  223.696 |              280.263 |              106.778 |            864.285 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      7 |          189.288 | 1132544 |  228.158 |              278.899 |              133.899 |            868.551 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3572.3407460545195\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-11\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3536.647776183644\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_10-59-06\n",
       "  done: false\n",
-      "  episode_len_mean: 860.7060478199719\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 224.74979755359487\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 862.704641350211\n",
+      "  episode_reward_max: 278.89898989898927\n",
+      "  episode_reward_mean: 229.98016025231198\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1422\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0435506701469421\n",
+      "        entropy: 1.0334690809249878\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00859822037940224\n",
+      "        kl: 0.010793289790550867\n",
       "        model: {}\n",
-      "        policy_loss: -0.017028980733205874\n",
-      "        total_loss: 14.67722193400065\n",
-      "        vf_explained_var: 0.973932683467865\n",
-      "        vf_loss: 14.693913221359253\n",
+      "        policy_loss: -0.015747709141578525\n",
+      "        total_loss: 15.715624650319418\n",
+      "        vf_explained_var: 0.969296395778656\n",
+      "        vf_loss: 15.729730685551962\n",
       "    num_steps_sampled: 1294336\n",
       "    num_steps_trained: 1294336\n",
       "  iterations_since_restore: 8\n",
@@ -5076,81 +4900,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.33658536585366\n",
-      "    gpu_util_percent0: 0.3939024390243903\n",
+      "    cpu_util_percent: 24.24838709677419\n",
+      "    gpu_util_percent0: 0.28161290322580645\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7806451612903222\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15419709361525985\n",
-      "    mean_env_wait_ms: 1.173051547586474\n",
-      "    mean_inference_ms: 4.773140764750721\n",
-      "    mean_raw_obs_processing_ms: 0.4038527557885323\n",
-      "  time_since_restore: 274.5138940811157\n",
-      "  time_this_iter_s: 33.97695016860962\n",
-      "  time_total_s: 274.5138940811157\n",
+      "    mean_action_processing_ms: 0.15681990846501556\n",
+      "    mean_env_wait_ms: 1.1795715076372215\n",
+      "    mean_inference_ms: 4.940636360012669\n",
+      "    mean_raw_obs_processing_ms: 0.4160430537362301\n",
+      "  time_since_restore: 215.92076349258423\n",
+      "  time_this_iter_s: 26.632570505142212\n",
+      "  time_total_s: 215.92076349258423\n",
       "  timers:\n",
-      "    learn_throughput: 6015.4\n",
-      "    learn_time_ms: 26896.299\n",
-      "    sample_throughput: 22088.803\n",
-      "    sample_time_ms: 7324.616\n",
-      "    update_time_ms: 42.976\n",
-      "  timestamp: 1602449051\n",
+      "    learn_throughput: 8284.815\n",
+      "    learn_time_ms: 19528.74\n",
+      "    sample_throughput: 21920.108\n",
+      "    sample_time_ms: 7380.986\n",
+      "    update_time_ms: 31.907\n",
+      "  timestamp: 1602500346\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1294336\n",
       "  training_iteration: 8\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      8 |          274.514 | 1294336 |   224.75 |              283.747 |              106.778 |            860.706 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      8 |          215.921 | 1294336 |   229.98 |              278.899 |              133.899 |            862.705 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3564.5992268041236\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-45\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3525.568943298969\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_10-59-33\n",
       "  done: false\n",
-      "  episode_len_mean: 857.1246835443038\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 226.1820739035928\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 857.1208860759493\n",
+      "  episode_reward_max: 279.3535353535359\n",
+      "  episode_reward_mean: 231.70662319396482\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1580\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0148475964864094\n",
+      "        entropy: 1.0033017992973328\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008687774262701472\n",
+      "        kl: 0.010770521514738599\n",
       "        model: {}\n",
-      "        policy_loss: -0.019221531343646348\n",
-      "        total_loss: 13.16464869181315\n",
-      "        vf_explained_var: 0.974395751953125\n",
-      "        vf_loss: 13.18350887298584\n",
+      "        policy_loss: -0.015525121105990062\n",
+      "        total_loss: 16.273523728052776\n",
+      "        vf_explained_var: 0.9674468040466309\n",
+      "        vf_loss: 16.28739635149638\n",
       "    num_steps_sampled: 1456128\n",
       "    num_steps_trained: 1456128\n",
       "  iterations_since_restore: 9\n",
@@ -5158,81 +4982,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.164285714285715\n",
-      "    gpu_util_percent0: 0.3242857142857143\n",
+      "    cpu_util_percent: 24.63225806451613\n",
+      "    gpu_util_percent0: 0.26741935483870966\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523817\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.774193548387097\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15371439312164148\n",
-      "    mean_env_wait_ms: 1.1745967344936128\n",
-      "    mean_inference_ms: 4.742392873103581\n",
-      "    mean_raw_obs_processing_ms: 0.40227968154243166\n",
-      "  time_since_restore: 308.6301050186157\n",
-      "  time_this_iter_s: 34.1162109375\n",
-      "  time_total_s: 308.6301050186157\n",
+      "    mean_action_processing_ms: 0.1562294682658002\n",
+      "    mean_env_wait_ms: 1.1809391128188538\n",
+      "    mean_inference_ms: 4.901836322882982\n",
+      "    mean_raw_obs_processing_ms: 0.41382111977571656\n",
+      "  time_since_restore: 242.5742666721344\n",
+      "  time_this_iter_s: 26.65350317955017\n",
+      "  time_total_s: 242.5742666721344\n",
       "  timers:\n",
-      "    learn_throughput: 6008.991\n",
-      "    learn_time_ms: 26924.987\n",
-      "    sample_throughput: 22237.247\n",
-      "    sample_time_ms: 7275.721\n",
-      "    update_time_ms: 40.494\n",
-      "  timestamp: 1602449085\n",
+      "    learn_throughput: 8289.336\n",
+      "    learn_time_ms: 19518.09\n",
+      "    sample_throughput: 21999.761\n",
+      "    sample_time_ms: 7354.262\n",
+      "    update_time_ms: 31.829\n",
+      "  timestamp: 1602500373\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1456128\n",
       "  training_iteration: 9\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      9 |           308.63 | 1456128 |  226.182 |              283.747 |              106.778 |            857.125 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |      9 |          242.574 | 1456128 |  231.707 |              279.354 |              133.899 |            857.121 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3552.531868131868\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-20\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3504.7218934911243\n",
+      "    time_step_min: 3186\n",
+      "  date: 2020-10-12_11-00-00\n",
       "  done: false\n",
-      "  episode_len_mean: 852.1964285714286\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 228.07582316673216\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 1848\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 847.3826179120297\n",
+      "  episode_reward_max: 284.0505050505049\n",
+      "  episode_reward_mean: 234.9192882722293\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 307\n",
+      "  episodes_total: 1887\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9734643250703812\n",
+      "        entropy: 0.9698180854320526\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00841127677510182\n",
+      "        kl: 0.008762541770314177\n",
       "        model: {}\n",
-      "        policy_loss: -0.015553771576378495\n",
-      "        total_loss: 19.610436121622723\n",
-      "        vf_explained_var: 0.9750833511352539\n",
-      "        vf_loss: 19.625635147094727\n",
+      "        policy_loss: -0.011754670903125467\n",
+      "        total_loss: 22.15676514307658\n",
+      "        vf_explained_var: 0.9699413776397705\n",
+      "        vf_loss: 22.167253017425537\n",
       "    num_steps_sampled: 1617920\n",
       "    num_steps_trained: 1617920\n",
       "  iterations_since_restore: 10\n",
@@ -5240,81 +5064,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.104878048780492\n",
-      "    gpu_util_percent0: 0.3853658536585366\n",
+      "    cpu_util_percent: 24.21612903225806\n",
+      "    gpu_util_percent0: 0.23774193548387096\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7731707317073173\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7709677419354835\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1530331197150846\n",
-      "    mean_env_wait_ms: 1.1772620710886672\n",
-      "    mean_inference_ms: 4.6989199095298195\n",
-      "    mean_raw_obs_processing_ms: 0.40005810250385193\n",
-      "  time_since_restore: 342.688401222229\n",
-      "  time_this_iter_s: 34.05829620361328\n",
-      "  time_total_s: 342.688401222229\n",
+      "    mean_action_processing_ms: 0.15529209587370074\n",
+      "    mean_env_wait_ms: 1.184021604402104\n",
+      "    mean_inference_ms: 4.840365767194604\n",
+      "    mean_raw_obs_processing_ms: 0.4103636780759023\n",
+      "  time_since_restore: 269.3142466545105\n",
+      "  time_this_iter_s: 26.7399799823761\n",
+      "  time_total_s: 269.3142466545105\n",
       "  timers:\n",
-      "    learn_throughput: 6005.184\n",
-      "    learn_time_ms: 26942.055\n",
-      "    sample_throughput: 22362.798\n",
-      "    sample_time_ms: 7234.873\n",
-      "    update_time_ms: 40.393\n",
-      "  timestamp: 1602449120\n",
+      "    learn_throughput: 8283.409\n",
+      "    learn_time_ms: 19532.055\n",
+      "    sample_throughput: 22108.221\n",
+      "    sample_time_ms: 7318.183\n",
+      "    update_time_ms: 30.681\n",
+      "  timestamp: 1602500400\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1617920\n",
       "  training_iteration: 10\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     10 |          342.688 | 1617920 |  228.076 |              283.747 |              106.778 |            852.196 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     10 |          269.314 | 1617920 |  234.919 |              284.051 |              133.899 |            847.383 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3542.3598223099702\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-53\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3494.990128331688\n",
+      "    time_step_min: 3159\n",
+      "  date: 2020-10-12_11-00-26\n",
       "  done: false\n",
-      "  episode_len_mean: 849.3028237585199\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 229.4285552703273\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
+      "  episode_len_mean: 842.626582278481\n",
+      "  episode_reward_max: 287.38383838383817\n",
+      "  episode_reward_mean: 236.53693212553955\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 167\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9663667529821396\n",
+      "        entropy: 0.959399938583374\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00833925325423479\n",
+      "        kl: 0.009050344349816442\n",
       "        model: {}\n",
-      "        policy_loss: -0.01736273110145703\n",
-      "        total_loss: 12.502357721328735\n",
-      "        vf_explained_var: 0.9791706204414368\n",
-      "        vf_loss: 12.51936944325765\n",
+      "        policy_loss: -0.014448691198291877\n",
+      "        total_loss: 14.143741130828857\n",
+      "        vf_explained_var: 0.9704552292823792\n",
+      "        vf_loss: 14.156859795252482\n",
       "    num_steps_sampled: 1779712\n",
       "    num_steps_trained: 1779712\n",
       "  iterations_since_restore: 11\n",
@@ -5322,81 +5146,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.58048780487805\n",
-      "    gpu_util_percent0: 0.3982926829268293\n",
+      "    cpu_util_percent: 23.841935483870966\n",
+      "    gpu_util_percent0: 0.307741935483871\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7804878048780495\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.783870967741935\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1526132408098708\n",
-      "    mean_env_wait_ms: 1.1789611773593984\n",
-      "    mean_inference_ms: 4.671734404012167\n",
-      "    mean_raw_obs_processing_ms: 0.39871998319890184\n",
-      "  time_since_restore: 376.51920080184937\n",
-      "  time_this_iter_s: 33.83079957962036\n",
-      "  time_total_s: 376.51920080184937\n",
+      "    mean_action_processing_ms: 0.1548694538024578\n",
+      "    mean_env_wait_ms: 1.1856497023990709\n",
+      "    mean_inference_ms: 4.812829084442159\n",
+      "    mean_raw_obs_processing_ms: 0.40881206201022163\n",
+      "  time_since_restore: 295.81349515914917\n",
+      "  time_this_iter_s: 26.499248504638672\n",
+      "  time_total_s: 295.81349515914917\n",
       "  timers:\n",
-      "    learn_throughput: 6006.948\n",
-      "    learn_time_ms: 26934.144\n",
-      "    sample_throughput: 22990.875\n",
-      "    sample_time_ms: 7037.227\n",
-      "    update_time_ms: 40.215\n",
-      "  timestamp: 1602449153\n",
+      "    learn_throughput: 8293.203\n",
+      "    learn_time_ms: 19508.988\n",
+      "    sample_throughput: 22780.223\n",
+      "    sample_time_ms: 7102.301\n",
+      "    update_time_ms: 30.482\n",
+      "  timestamp: 1602500426\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
       "  training_iteration: 11\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     11 |          376.519 | 1779712 |  229.429 |              283.747 |              106.778 |            849.303 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     11 |          295.813 | 1779712 |  236.537 |              287.384 |              133.899 |            842.627 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3534.694597069597\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-46-27\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3486.236721611722\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_11-00-53\n",
       "  done: false\n",
-      "  episode_len_mean: 847.131555153707\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 230.50298189855144\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 839.50226039783\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 237.80845069136197\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2212\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9568162461121877\n",
+      "        entropy: 0.9463174144426981\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00814399627658228\n",
+      "        kl: 0.009074758971109986\n",
       "        model: {}\n",
-      "        policy_loss: -0.015694946744285215\n",
-      "        total_loss: 12.548736731211344\n",
-      "        vf_explained_var: 0.9766435623168945\n",
-      "        vf_loss: 12.564095417658487\n",
+      "        policy_loss: -0.014368217787705362\n",
+      "        total_loss: 10.841783205668131\n",
+      "        vf_explained_var: 0.9763579368591309\n",
+      "        vf_loss: 10.854809761047363\n",
       "    num_steps_sampled: 1941504\n",
       "    num_steps_trained: 1941504\n",
       "  iterations_since_restore: 12\n",
@@ -5404,81 +5228,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.81707317073171\n",
-      "    gpu_util_percent0: 0.3797560975609756\n",
+      "    cpu_util_percent: 24.526666666666664\n",
+      "    gpu_util_percent0: 0.3186666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.792682926829269\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7833333333333328\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1523239438594431\n",
-      "    mean_env_wait_ms: 1.1801704441448417\n",
-      "    mean_inference_ms: 4.653173903698042\n",
-      "    mean_raw_obs_processing_ms: 0.3977863822432723\n",
-      "  time_since_restore: 410.4603908061981\n",
-      "  time_this_iter_s: 33.941190004348755\n",
-      "  time_total_s: 410.4603908061981\n",
+      "    mean_action_processing_ms: 0.1545074057078582\n",
+      "    mean_env_wait_ms: 1.1870713770777694\n",
+      "    mean_inference_ms: 4.789291310377852\n",
+      "    mean_raw_obs_processing_ms: 0.40744564222192137\n",
+      "  time_since_restore: 322.13705468177795\n",
+      "  time_this_iter_s: 26.323559522628784\n",
+      "  time_total_s: 322.13705468177795\n",
       "  timers:\n",
-      "    learn_throughput: 6004.841\n",
-      "    learn_time_ms: 26943.593\n",
-      "    sample_throughput: 23202.406\n",
-      "    sample_time_ms: 6973.07\n",
-      "    update_time_ms: 38.84\n",
-      "  timestamp: 1602449187\n",
+      "    learn_throughput: 8300.926\n",
+      "    learn_time_ms: 19490.838\n",
+      "    sample_throughput: 23072.528\n",
+      "    sample_time_ms: 7012.322\n",
+      "    update_time_ms: 28.973\n",
+      "  timestamp: 1602500453\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1941504\n",
       "  training_iteration: 12\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     12 |           410.46 | 1941504 |  230.503 |              283.747 |              106.778 |            847.132 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     12 |          322.137 | 1941504 |  237.808 |              289.202 |              133.899 |            839.502 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3528.8706233988046\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-02\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3477.1867900715188\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_11-01-20\n",
       "  done: false\n",
-      "  episode_len_mean: 845.0793248945148\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 231.55561948599922\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 836.276923076923\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 239.12358512358495\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 193\n",
+      "  episodes_total: 2405\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9341403146584829\n",
+      "        entropy: 0.9069925745328268\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008328795510654649\n",
+      "        kl: 0.009530291194096208\n",
       "        model: {}\n",
-      "        policy_loss: -0.015285106880279878\n",
-      "        total_loss: 11.184300502141317\n",
-      "        vf_explained_var: 0.9784317016601562\n",
-      "        vf_loss: 11.199219783147177\n",
+      "        policy_loss: -0.014515867456793785\n",
+      "        total_loss: 15.319237470626831\n",
+      "        vf_explained_var: 0.9747470021247864\n",
+      "        vf_loss: 15.332300901412964\n",
       "    num_steps_sampled: 2103296\n",
       "    num_steps_trained: 2103296\n",
       "  iterations_since_restore: 13\n",
@@ -5486,81 +5310,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.056097560975612\n",
-      "    gpu_util_percent0: 0.3531707317073171\n",
+      "    cpu_util_percent: 24.29354838709677\n",
+      "    gpu_util_percent0: 0.2983870967741936\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682925\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7645161290322573\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15206707844660014\n",
-      "    mean_env_wait_ms: 1.1812995165783673\n",
-      "    mean_inference_ms: 4.636268107417298\n",
-      "    mean_raw_obs_processing_ms: 0.39691338971294254\n",
-      "  time_since_restore: 444.4848208427429\n",
-      "  time_this_iter_s: 34.0244300365448\n",
-      "  time_total_s: 444.4848208427429\n",
+      "    mean_action_processing_ms: 0.15411688777863225\n",
+      "    mean_env_wait_ms: 1.1888071745009974\n",
+      "    mean_inference_ms: 4.763259120832632\n",
+      "    mean_raw_obs_processing_ms: 0.40591348902537194\n",
+      "  time_since_restore: 348.8731298446655\n",
+      "  time_this_iter_s: 26.736075162887573\n",
+      "  time_total_s: 348.8731298446655\n",
       "  timers:\n",
-      "    learn_throughput: 5995.984\n",
-      "    learn_time_ms: 26983.393\n",
-      "    sample_throughput: 23304.966\n",
-      "    sample_time_ms: 6942.383\n",
-      "    update_time_ms: 32.03\n",
-      "  timestamp: 1602449222\n",
+      "    learn_throughput: 8295.844\n",
+      "    learn_time_ms: 19502.778\n",
+      "    sample_throughput: 23098.117\n",
+      "    sample_time_ms: 7004.554\n",
+      "    update_time_ms: 30.571\n",
+      "  timestamp: 1602500480\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2103296\n",
       "  training_iteration: 13\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     13 |          444.485 | 2103296 |  231.556 |              283.747 |              106.778 |            845.079 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     13 |          348.873 | 2103296 |  239.124 |              289.202 |              133.899 |            836.277 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3517.263601532567\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-35\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3465.9672686230247\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_11-01-46\n",
       "  done: false\n",
-      "  episode_len_mean: 841.8491281273692\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 233.18196368537525\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 2638\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 832.3082650781831\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 240.80178553968565\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 281\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9020447830359141\n",
+      "        entropy: 0.9011691262324651\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008081968214052418\n",
+      "        kl: 0.010886709050585827\n",
       "        model: {}\n",
-      "        policy_loss: -0.015293826969961325\n",
-      "        total_loss: 12.724741299947103\n",
-      "        vf_explained_var: 0.9831693172454834\n",
-      "        vf_loss: 12.739677826563517\n",
+      "        policy_loss: -0.01605825025762897\n",
+      "        total_loss: 13.799258867899576\n",
+      "        vf_explained_var: 0.9779562950134277\n",
+      "        vf_loss: 13.813590288162231\n",
       "    num_steps_sampled: 2265088\n",
       "    num_steps_trained: 2265088\n",
       "  iterations_since_restore: 14\n",
@@ -5568,81 +5392,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 20.178048780487803\n",
-      "    gpu_util_percent0: 0.34682926829268296\n",
+      "    cpu_util_percent: 23.783870967741933\n",
+      "    gpu_util_percent0: 0.22258064516129034\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.775609756097561\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7709677419354835\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15168397874215378\n",
-      "    mean_env_wait_ms: 1.1831688977197714\n",
-      "    mean_inference_ms: 4.610931204965214\n",
-      "    mean_raw_obs_processing_ms: 0.39561206070844984\n",
-      "  time_since_restore: 478.23622155189514\n",
-      "  time_this_iter_s: 33.75140070915222\n",
-      "  time_total_s: 478.23622155189514\n",
+      "    mean_action_processing_ms: 0.15360998507930224\n",
+      "    mean_env_wait_ms: 1.191015474262433\n",
+      "    mean_inference_ms: 4.731020836732773\n",
+      "    mean_raw_obs_processing_ms: 0.40406295374842327\n",
+      "  time_since_restore: 375.4877142906189\n",
+      "  time_this_iter_s: 26.61458444595337\n",
+      "  time_total_s: 375.4877142906189\n",
       "  timers:\n",
-      "    learn_throughput: 5998.158\n",
-      "    learn_time_ms: 26973.613\n",
-      "    sample_throughput: 23414.5\n",
-      "    sample_time_ms: 6909.906\n",
-      "    update_time_ms: 33.132\n",
-      "  timestamp: 1602449255\n",
+      "    learn_throughput: 8289.533\n",
+      "    learn_time_ms: 19517.625\n",
+      "    sample_throughput: 23119.834\n",
+      "    sample_time_ms: 6997.974\n",
+      "    update_time_ms: 30.585\n",
+      "  timestamp: 1602500506\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2265088\n",
       "  training_iteration: 14\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     14 |          478.236 | 2265088 |  233.182 |              283.747 |              106.778 |            841.849 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     14 |          375.488 | 2265088 |  240.802 |              289.202 |              133.899 |            832.308 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3509.4779829545455\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-09\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3459.754971590909\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_11-02-13\n",
       "  done: false\n",
-      "  episode_len_mean: 839.5295358649789\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 234.39397135916116\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
+      "  episode_len_mean: 830.3291139240506\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 241.694508374888\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 2844\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8862918565670649\n",
+      "        entropy: 0.8705271085103353\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007904120022431016\n",
+      "        kl: 0.010132285223032037\n",
       "        model: {}\n",
-      "        policy_loss: -0.014935656054755478\n",
-      "        total_loss: 9.06860645612081\n",
-      "        vf_explained_var: 0.984200656414032\n",
-      "        vf_loss: 9.083194653193155\n",
+      "        policy_loss: -0.01209646585630253\n",
+      "        total_loss: 9.354986588160196\n",
+      "        vf_explained_var: 0.9806396961212158\n",
+      "        vf_loss: 9.36549154917399\n",
       "    num_steps_sampled: 2426880\n",
       "    num_steps_trained: 2426880\n",
       "  iterations_since_restore: 15\n",
@@ -5650,81 +5474,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.682926829268297\n",
-      "    gpu_util_percent0: 0.38243902439024396\n",
+      "    cpu_util_percent: 24.34516129032258\n",
+      "    gpu_util_percent0: 0.3393548387096775\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7878048780487807\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.7838709677419353\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15143390810491775\n",
-      "    mean_env_wait_ms: 1.1844643908633714\n",
-      "    mean_inference_ms: 4.594233582997575\n",
-      "    mean_raw_obs_processing_ms: 0.3947809594728215\n",
-      "  time_since_restore: 512.1841127872467\n",
-      "  time_this_iter_s: 33.94789123535156\n",
-      "  time_total_s: 512.1841127872467\n",
+      "    mean_action_processing_ms: 0.15336340446248875\n",
+      "    mean_env_wait_ms: 1.192160805414192\n",
+      "    mean_inference_ms: 4.71496093314174\n",
+      "    mean_raw_obs_processing_ms: 0.40314242716245324\n",
+      "  time_since_restore: 402.0596549510956\n",
+      "  time_this_iter_s: 26.571940660476685\n",
+      "  time_total_s: 402.0596549510956\n",
       "  timers:\n",
-      "    learn_throughput: 5994.585\n",
-      "    learn_time_ms: 26989.692\n",
-      "    sample_throughput: 23481.767\n",
-      "    sample_time_ms: 6890.112\n",
-      "    update_time_ms: 32.925\n",
-      "  timestamp: 1602449289\n",
+      "    learn_throughput: 8287.414\n",
+      "    learn_time_ms: 19522.615\n",
+      "    sample_throughput: 23073.317\n",
+      "    sample_time_ms: 7012.082\n",
+      "    update_time_ms: 29.135\n",
+      "  timestamp: 1602500533\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2426880\n",
       "  training_iteration: 15\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     15 |          512.184 | 2426880 |  234.394 |              283.747 |              106.778 |             839.53 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     15 |           402.06 | 2426880 |  241.695 |              289.202 |              133.899 |            830.329 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3504.0221923335575\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-44\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3454.032279757902\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_11-02-40\n",
       "  done: false\n",
-      "  episode_len_mean: 837.8334443704197\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 235.28937610616484\n",
-      "  episode_reward_min: 106.77777777777801\n",
+      "  episode_len_mean: 828.5073284477015\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 242.50461645098542\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 3002\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8804336041212082\n",
+      "        entropy: 0.8471738596757253\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00791139566960434\n",
+      "        kl: 0.009305963292717934\n",
       "        model: {}\n",
-      "        policy_loss: -0.017682172047595184\n",
-      "        total_loss: 8.313085556030273\n",
-      "        vf_explained_var: 0.9836888313293457\n",
-      "        vf_loss: 8.330416997273764\n",
+      "        policy_loss: -0.01094130908313673\n",
+      "        total_loss: 10.646601835886637\n",
+      "        vf_explained_var: 0.9784726500511169\n",
+      "        vf_loss: 10.656105756759644\n",
       "    num_steps_sampled: 2588672\n",
       "    num_steps_trained: 2588672\n",
       "  iterations_since_restore: 16\n",
@@ -5732,81 +5556,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.829268292682926\n",
-      "    gpu_util_percent0: 0.4309756097560975\n",
+      "    cpu_util_percent: 24.512903225806454\n",
+      "    gpu_util_percent0: 0.23612903225806453\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7853658536585377\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.793548387096774\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15125642659333643\n",
-      "    mean_env_wait_ms: 1.1853858835587299\n",
-      "    mean_inference_ms: 4.5824743389127525\n",
-      "    mean_raw_obs_processing_ms: 0.39418437084622066\n",
-      "  time_since_restore: 546.3757491111755\n",
-      "  time_this_iter_s: 34.19163632392883\n",
-      "  time_total_s: 546.3757491111755\n",
+      "    mean_action_processing_ms: 0.15313484688014142\n",
+      "    mean_env_wait_ms: 1.1932362942460533\n",
+      "    mean_inference_ms: 4.700063028477268\n",
+      "    mean_raw_obs_processing_ms: 0.40227414635633235\n",
+      "  time_since_restore: 428.6733150482178\n",
+      "  time_this_iter_s: 26.613660097122192\n",
+      "  time_total_s: 428.6733150482178\n",
       "  timers:\n",
-      "    learn_throughput: 5991.373\n",
-      "    learn_time_ms: 27004.162\n",
-      "    sample_throughput: 23569.806\n",
-      "    sample_time_ms: 6864.376\n",
-      "    update_time_ms: 32.942\n",
-      "  timestamp: 1602449324\n",
+      "    learn_throughput: 8291.51\n",
+      "    learn_time_ms: 19512.972\n",
+      "    sample_throughput: 23070.439\n",
+      "    sample_time_ms: 7012.957\n",
+      "    update_time_ms: 26.747\n",
+      "  timestamp: 1602500560\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2588672\n",
       "  training_iteration: 16\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     16 |          546.376 | 2588672 |  235.289 |              283.747 |              106.778 |            837.833 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     16 |          428.673 | 2588672 |  242.505 |              289.202 |              133.899 |            828.507 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3498.312918660287\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-49-18\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3446.2361408882084\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_11-03-07\n",
       "  done: false\n",
-      "  episode_len_mean: 836.1346822636738\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 236.18048330283543\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 161\n",
-      "  episodes_total: 3163\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "  episode_len_mean: 825.9881566960219\n",
+      "  episode_reward_max: 289.9595959595964\n",
+      "  episode_reward_mean: 243.72948433622582\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 291\n",
+      "  episodes_total: 3293\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8537542670965195\n",
+      "        entropy: 0.8250234176715215\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008198376706180474\n",
+      "        kl: 0.008491925351942578\n",
       "        model: {}\n",
-      "        policy_loss: -0.015993841225281358\n",
-      "        total_loss: 9.6584951877594\n",
-      "        vf_explained_var: 0.9823360443115234\n",
-      "        vf_loss: 9.67409602801005\n",
+      "        policy_loss: -0.014777651784243062\n",
+      "        total_loss: 15.209494908650717\n",
+      "        vf_explained_var: 0.9786728024482727\n",
+      "        vf_loss: 15.222986777623495\n",
       "    num_steps_sampled: 2750464\n",
       "    num_steps_trained: 2750464\n",
       "  iterations_since_restore: 17\n",
@@ -5814,81 +5638,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.716666666666665\n",
-      "    gpu_util_percent0: 0.3614285714285715\n",
+      "    cpu_util_percent: 24.87096774193549\n",
+      "    gpu_util_percent0: 0.27645161290322584\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.764516129032258\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15108549071824215\n",
-      "    mean_env_wait_ms: 1.186299740621708\n",
-      "    mean_inference_ms: 4.571266181106936\n",
-      "    mean_raw_obs_processing_ms: 0.3935990755523057\n",
-      "  time_since_restore: 580.5327708721161\n",
-      "  time_this_iter_s: 34.15702176094055\n",
-      "  time_total_s: 580.5327708721161\n",
+      "    mean_action_processing_ms: 0.1527630716566746\n",
+      "    mean_env_wait_ms: 1.1950387108952798\n",
+      "    mean_inference_ms: 4.675569550209842\n",
+      "    mean_raw_obs_processing_ms: 0.40087135530926965\n",
+      "  time_since_restore: 455.30483841896057\n",
+      "  time_this_iter_s: 26.631523370742798\n",
+      "  time_total_s: 455.30483841896057\n",
       "  timers:\n",
-      "    learn_throughput: 5980.848\n",
-      "    learn_time_ms: 27051.68\n",
-      "    sample_throughput: 23599.526\n",
-      "    sample_time_ms: 6855.731\n",
-      "    update_time_ms: 34.302\n",
-      "  timestamp: 1602449358\n",
+      "    learn_throughput: 8300.637\n",
+      "    learn_time_ms: 19491.515\n",
+      "    sample_throughput: 23025.116\n",
+      "    sample_time_ms: 7026.762\n",
+      "    update_time_ms: 24.775\n",
+      "  timestamp: 1602500587\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2750464\n",
       "  training_iteration: 17\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     17 |          580.533 | 2750464 |   236.18 |              283.747 |              106.778 |            836.135 |\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     17 |          455.305 | 2750464 |  243.729 |               289.96 |              133.899 |            825.988 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3488.101369064958\n",
-      "    time_step_min: 3158\n",
-      "  date: 2020-10-11_20-49-52\n",
-      "  done: true\n",
-      "  episode_len_mean: 833.3886160069344\n",
-      "  episode_reward_max: 287.53535353535375\n",
-      "  episode_reward_mean: 237.6940920327224\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 298\n",
-      "  episodes_total: 3461\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3440.9040023201856\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_11-03-33\n",
+      "  done: false\n",
+      "  episode_len_mean: 824.563003452244\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 244.5732671943833\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 183\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8270254284143448\n",
+      "        entropy: 0.8241499215364456\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007853905437514186\n",
+      "        kl: 0.007864817045629025\n",
       "        model: {}\n",
-      "        policy_loss: -0.014354762931664785\n",
-      "        total_loss: 12.10600503285726\n",
-      "        vf_explained_var: 0.9836263060569763\n",
-      "        vf_loss: 12.119987805684408\n",
+      "        policy_loss: -0.01140341673938868\n",
+      "        total_loss: 8.79675587018331\n",
+      "        vf_explained_var: 0.9828992486000061\n",
+      "        vf_loss: 8.806998491287231\n",
       "    num_steps_sampled: 2912256\n",
       "    num_steps_trained: 2912256\n",
       "  iterations_since_restore: 18\n",
@@ -5896,82 +5720,492 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 19.90487804878049\n",
-      "    gpu_util_percent0: 0.37609756097560976\n",
+      "    cpu_util_percent: 24.39354838709677\n",
+      "    gpu_util_percent0: 0.34419354838709676\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
+      "    ram_util_percent: 3.783870967741935\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
+      "  pid: 52163\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15081126315046797\n",
-      "    mean_env_wait_ms: 1.1879326543189301\n",
-      "    mean_inference_ms: 4.552816786571983\n",
-      "    mean_raw_obs_processing_ms: 0.39263685907469736\n",
-      "  time_since_restore: 614.4084322452545\n",
-      "  time_this_iter_s: 33.87566137313843\n",
-      "  time_total_s: 614.4084322452545\n",
+      "    mean_action_processing_ms: 0.15254898746596612\n",
+      "    mean_env_wait_ms: 1.1961064700696495\n",
+      "    mean_inference_ms: 4.661854285209326\n",
+      "    mean_raw_obs_processing_ms: 0.400080847959462\n",
+      "  time_since_restore: 481.973614692688\n",
+      "  time_this_iter_s: 26.668776273727417\n",
+      "  time_total_s: 481.973614692688\n",
       "  timers:\n",
-      "    learn_throughput: 5980.24\n",
-      "    learn_time_ms: 27054.431\n",
-      "    sample_throughput: 23642.693\n",
-      "    sample_time_ms: 6843.214\n",
-      "    update_time_ms: 32.784\n",
-      "  timestamp: 1602449392\n",
+      "    learn_throughput: 8301.255\n",
+      "    learn_time_ms: 19490.065\n",
+      "    sample_throughput: 23019.881\n",
+      "    sample_time_ms: 7028.359\n",
+      "    update_time_ms: 26.892\n",
+      "  timestamp: 1602500613\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2912256\n",
       "  training_iteration: 18\n",
-      "  trial_id: dc7e0_00000\n",
+      "  trial_id: 6dc57_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     18 |          481.974 | 2912256 |  244.573 |              296.626 |              133.899 |            824.563 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3436.840266222962\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_11-04-00\n",
+      "  done: false\n",
+      "  episode_len_mean: 823.8428728673638\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 245.09397497262097\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 3634\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8113949745893478\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008743428780386845\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012751462903300611\n",
+      "        total_loss: 8.8964794476827\n",
+      "        vf_explained_var: 0.9816879630088806\n",
+      "        vf_loss: 8.907887935638428\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.96774193548387\n",
+      "    gpu_util_percent0: 0.2393548387096774\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7935483870967746\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52163\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1523788747405599\n",
+      "    mean_env_wait_ms: 1.1969151479156113\n",
+      "    mean_inference_ms: 4.650815710239755\n",
+      "    mean_raw_obs_processing_ms: 0.3994453254229546\n",
+      "  time_since_restore: 508.44709849357605\n",
+      "  time_this_iter_s: 26.47348380088806\n",
+      "  time_total_s: 508.44709849357605\n",
+      "  timers:\n",
+      "    learn_throughput: 8297.503\n",
+      "    learn_time_ms: 19498.877\n",
+      "    sample_throughput: 23113.225\n",
+      "    sample_time_ms: 6999.975\n",
+      "    update_time_ms: 25.659\n",
+      "  timestamp: 1602500640\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: 6dc57_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     19 |          508.447 | 3074048 |  245.094 |              296.626 |              133.899 |            823.843 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3432.525217850541\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_11-04-26\n",
+      "  done: false\n",
+      "  episode_len_mean: 823.0579292267365\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 245.79004990931585\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 181\n",
+      "  episodes_total: 3815\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7609985868136088\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.00916624628007412\n",
+      "        model: {}\n",
+      "        policy_loss: -0.012107667707217237\n",
+      "        total_loss: 10.657151778539022\n",
+      "        vf_explained_var: 0.9814252257347107\n",
+      "        vf_loss: 10.66780686378479\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 24.62\n",
+      "    gpu_util_percent0: 0.3993333333333334\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.769999999999999\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52163\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1521991805884218\n",
+      "    mean_env_wait_ms: 1.1977767451158385\n",
+      "    mean_inference_ms: 4.638926391821517\n",
+      "    mean_raw_obs_processing_ms: 0.3987586788662761\n",
+      "  time_since_restore: 534.712043762207\n",
+      "  time_this_iter_s: 26.26494526863098\n",
+      "  time_total_s: 534.712043762207\n",
+      "  timers:\n",
+      "    learn_throughput: 8310.527\n",
+      "    learn_time_ms: 19468.32\n",
+      "    sample_throughput: 23165.882\n",
+      "    sample_time_ms: 6984.064\n",
+      "    update_time_ms: 25.726\n",
+      "  timestamp: 1602500666\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: 6dc57_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     20 |          534.712 | 3235840 |   245.79 |              296.626 |              133.899 |            823.058 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3425.473593711619\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_11-04-53\n",
+      "  done: false\n",
+      "  episode_len_mean: 821.8972920224445\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 246.80025184758034\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 284\n",
+      "  episodes_total: 4099\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7578712403774261\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.0086368964985013\n",
+      "        model: {}\n",
+      "        policy_loss: -0.011422600480727851\n",
+      "        total_loss: 10.725571791330973\n",
+      "        vf_explained_var: 0.9839944839477539\n",
+      "        vf_loss: 10.735645691553751\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.761290322580646\n",
+      "    gpu_util_percent0: 0.33645161290322584\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7774193548387096\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52163\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15193798695622557\n",
+      "    mean_env_wait_ms: 1.1989676300864034\n",
+      "    mean_inference_ms: 4.622008917330003\n",
+      "    mean_raw_obs_processing_ms: 0.3977947303873345\n",
+      "  time_since_restore: 561.3735568523407\n",
+      "  time_this_iter_s: 26.661513090133667\n",
+      "  time_total_s: 561.3735568523407\n",
+      "  timers:\n",
+      "    learn_throughput: 8302.137\n",
+      "    learn_time_ms: 19487.995\n",
+      "    sample_throughput: 23182.502\n",
+      "    sample_time_ms: 6979.057\n",
+      "    update_time_ms: 25.283\n",
+      "  timestamp: 1602500693\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: 6dc57_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     21 |          561.374 | 3397632 |    246.8 |              296.626 |              133.899 |            821.897 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3421.670599339311\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_11-05-20\n",
+      "  done: false\n",
+      "  episode_len_mean: 821.5065635255509\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 247.35105627299706\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 167\n",
+      "  episodes_total: 4266\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7521579414606094\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.007824398732433716\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01322558480508936\n",
+      "        total_loss: 7.959930698076884\n",
+      "        vf_explained_var: 0.9843184947967529\n",
+      "        vf_loss: 7.971967538197835\n",
+      "    num_steps_sampled: 3559424\n",
+      "    num_steps_trained: 3559424\n",
+      "  iterations_since_restore: 22\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.929032258064517\n",
+      "    gpu_util_percent0: 0.24225806451612902\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7935483870967746\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52163\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15179522713170052\n",
+      "    mean_env_wait_ms: 1.1995884924415834\n",
+      "    mean_inference_ms: 4.612889760179764\n",
+      "    mean_raw_obs_processing_ms: 0.3972663517974564\n",
+      "  time_since_restore: 587.8923697471619\n",
+      "  time_this_iter_s: 26.518812894821167\n",
+      "  time_total_s: 587.8923697471619\n",
+      "  timers:\n",
+      "    learn_throughput: 8288.691\n",
+      "    learn_time_ms: 19519.608\n",
+      "    sample_throughput: 23235.59\n",
+      "    sample_time_ms: 6963.111\n",
+      "    update_time_ms: 27.54\n",
+      "  timestamp: 1602500720\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3559424\n",
+      "  training_iteration: 22\n",
+      "  trial_id: 6dc57_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_6dc57_00000 | RUNNING  | 172.17.0.4:52163 |     22 |          587.892 | 3559424 |  247.351 |              296.626 |              133.899 |            821.507 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_6dc57_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3418.63762511374\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_11-05-46\n",
+      "  done: true\n",
+      "  episode_len_mean: 821.0913200723327\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 247.84626098233684\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 4424\n",
+      "  experiment_id: eaabf8ddae654dad83878fd4dc55a029\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.739922359585762\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008788479414458076\n",
+      "        model: {}\n",
+      "        policy_loss: -0.013709326779159406\n",
+      "        total_loss: 7.252472162246704\n",
+      "        vf_explained_var: 0.9847645163536072\n",
+      "        vf_loss: 7.264793713887532\n",
+      "    num_steps_sampled: 3721216\n",
+      "    num_steps_trained: 3721216\n",
+      "  iterations_since_restore: 23\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.986666666666665\n",
+      "    gpu_util_percent0: 0.4276666666666666\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7833333333333328\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 52163\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15166941056392566\n",
+      "    mean_env_wait_ms: 1.2001324363843482\n",
+      "    mean_inference_ms: 4.604699596101915\n",
+      "    mean_raw_obs_processing_ms: 0.3967937448701103\n",
+      "  time_since_restore: 614.3653018474579\n",
+      "  time_this_iter_s: 26.47293210029602\n",
+      "  time_total_s: 614.3653018474579\n",
+      "  timers:\n",
+      "    learn_throughput: 8293.393\n",
+      "    learn_time_ms: 19508.542\n",
+      "    sample_throughput: 23285.641\n",
+      "    sample_time_ms: 6948.145\n",
+      "    update_time_ms: 26.961\n",
+      "  timestamp: 1602500746\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3721216\n",
+      "  training_iteration: 23\n",
+      "  trial_id: 6dc57_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_6dc57_00000 | TERMINATED |       |     23 |          614.365 | 3721216 |  247.846 |              296.626 |              133.899 |            821.091 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "== Status ==\n",
       "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 TERMINATED)\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
+      "| PPO_jss_env_6dc57_00000 | TERMINATED |       |     23 |          614.365 | 3721216 |  247.846 |              296.626 |              133.899 |            821.091 |\n",
       "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
       "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 15618\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 51938\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_105518-f0zxmbgr/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_105518-f0zxmbgr/logs/debug-internal.log\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3158\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3098\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 628\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602449392\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4327\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3488.10137\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 287.53535\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 106.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 237.69409\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3461\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 18\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 629\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602500747\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4172\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3418.63763\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 296.62626\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 133.89899\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.84626\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4424\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 23\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
@@ -5987,204 +6221,202 @@
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msplendid-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "2020-10-11 20:49:59,068 - wandb.wandb_agent - INFO - Cleaning up finished run: 4lvdkknr\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.2\n",
-      "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:49:59,357 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.2 --num_sgd_iter=25\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfeasible-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/f0zxmbgr\u001b[0m\n",
+      "2020-10-12 11:05:57,736 - wandb.wandb_agent - INFO - Cleaning up finished run: f0zxmbgr\n",
+      "2020-10-12 11:05:58,037 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 11:05:58,037 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tclip_param: 0.5\n",
+      "\tnum_sgd_iter: 30\n",
+      "2020-10-12 11:05:58,040 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.5 --num_sgd_iter=30\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:50:04,374 - wandb.wandb_agent - INFO - Running runs: ['2n8lexei']\n",
+      "2020-10-12 11:06:03,057 - wandb.wandb_agent - INFO - Running runs: ['r7qhsszi']\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mupbeat-sweep-4\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33micy-sweep-4\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/2n8lexei\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_205001-2n8lexei\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/y2n6znmq\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/r7qhsszi\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_110559-r7qhsszi\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-11 20:50:05,155\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "2020-10-12 11:06:03,732\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
       "Memory usage on this node: 11.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=37257)\u001b[0m 2020-10-11 20:50:07,972\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
+      "\u001b[2m\u001b[36m(pid=79312)\u001b[0m 2020-10-12 11:06:06,528\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=79366)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79366)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79352)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79352)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79294)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79294)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79292)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79292)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79272)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79272)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79331)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79331)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79262)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79262)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79280)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79280)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79328)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79328)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79349)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79349)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79330)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79330)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79341)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79341)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79317)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79317)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79297)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79297)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79309)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79309)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79346)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79346)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79358)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79358)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79360)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79360)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79322)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79322)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79293)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79293)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79290)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79290)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79311)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79311)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79371)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79371)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79344)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79344)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79314)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79314)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79305)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79305)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79271)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79271)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79342)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79342)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79244)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79244)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79333)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79333)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79246)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79246)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79254)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79254)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79324)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79324)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79275)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79275)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79313)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79313)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79338)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79338)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79301)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79301)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79240)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79240)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79326)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79326)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79307)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79307)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79276)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79276)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79239)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79239)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79320)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79320)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=79298)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=79298)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: 4054\n",
       "    time_step_mean: 3615.0923076923077\n",
       "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-50-42\n",
+      "  date: 2020-10-12_11-06-43\n",
       "  done: false\n",
       "  episode_len_mean: 891.1139240506329\n",
       "  episode_reward_max: 258.59595959595964\n",
@@ -6192,7 +6424,7 @@
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
@@ -6201,14 +6433,14 @@
       "        allreduce_latency: 0.0\n",
       "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1851047078768413\n",
+      "        entropy: 1.1810798048973083\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.004071502441850801\n",
+      "        kl: 0.008566662125910321\n",
       "        model: {}\n",
-      "        policy_loss: -0.00785889983914482\n",
-      "        total_loss: 507.07567087809247\n",
-      "        vf_explained_var: 0.540532648563385\n",
-      "        vf_loss: 507.0832926432292\n",
+      "        policy_loss: -0.012310020567383617\n",
+      "        total_loss: 502.2355448404948\n",
+      "        vf_explained_var: 0.5664147734642029\n",
+      "        vf_loss: 502.24672444661456\n",
       "    num_steps_sampled: 161792\n",
       "    num_steps_trained: 161792\n",
       "  iterations_since_restore: 1\n",
@@ -6216,81 +6448,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 27.602941176470587\n",
-      "    gpu_util_percent0: 0.26294117647058823\n",
+      "    cpu_util_percent: 26.134210526315787\n",
+      "    gpu_util_percent0: 0.29500000000000004\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5676470588235296\n",
-      "    vram_util_percent0: 0.08659058900700328\n",
+      "    ram_util_percent: 3.581578947368421\n",
+      "    vram_util_percent0: 0.08828606445599078\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
+      "  pid: 79312\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16776829819945724\n",
-      "    mean_env_wait_ms: 1.1590575435788\n",
-      "    mean_inference_ms: 5.636969428255295\n",
-      "    mean_raw_obs_processing_ms: 0.44418268713107556\n",
-      "  time_since_restore: 28.716503381729126\n",
-      "  time_this_iter_s: 28.716503381729126\n",
-      "  time_total_s: 28.716503381729126\n",
+      "    mean_action_processing_ms: 0.1733017321095197\n",
+      "    mean_env_wait_ms: 1.1909320156454266\n",
+      "    mean_inference_ms: 6.057532432087412\n",
+      "    mean_raw_obs_processing_ms: 0.4641718362429585\n",
+      "  time_since_restore: 32.15226674079895\n",
+      "  time_this_iter_s: 32.15226674079895\n",
+      "  time_total_s: 32.15226674079895\n",
       "  timers:\n",
-      "    learn_throughput: 8268.867\n",
-      "    learn_time_ms: 19566.404\n",
-      "    sample_throughput: 17811.996\n",
-      "    sample_time_ms: 9083.317\n",
-      "    update_time_ms: 25.783\n",
-      "  timestamp: 1602449442\n",
+      "    learn_throughput: 7127.091\n",
+      "    learn_time_ms: 22700.986\n",
+      "    sample_throughput: 17372.094\n",
+      "    sample_time_ms: 9313.328\n",
+      "    update_time_ms: 103.972\n",
+      "  timestamp: 1602500803\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: 57f23_00000\n",
+      "  trial_id: ec062_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 27.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      1 |          28.7165 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      1 |          32.1523 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3614.4305555555557\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-09\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3623.7708333333335\n",
+      "    time_step_min: 3280\n",
+      "  date: 2020-10-12_11-07-14\n",
       "  done: false\n",
-      "  episode_len_mean: 890.8607594936709\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 217.6365234624726\n",
+      "  episode_len_mean: 890.2120253164557\n",
+      "  episode_reward_max: 271.77777777777766\n",
+      "  episode_reward_mean: 216.57352001022863\n",
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1561074058214824\n",
+      "        entropy: 1.1473211546738942\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007923512797181806\n",
+      "        kl: 0.011223212660600742\n",
       "        model: {}\n",
-      "        policy_loss: -0.010965243893830726\n",
-      "        total_loss: 127.46906661987305\n",
-      "        vf_explained_var: 0.8076093792915344\n",
-      "        vf_loss: 127.47981770833333\n",
+      "        policy_loss: -0.013796255535756549\n",
+      "        total_loss: 126.24822680155437\n",
+      "        vf_explained_var: 0.813798725605011\n",
+      "        vf_loss: 126.26034990946452\n",
       "    num_steps_sampled: 323584\n",
       "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 2\n",
@@ -6298,81 +6530,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.793548387096774\n",
-      "    gpu_util_percent0: 0.3754838709677419\n",
+      "    cpu_util_percent: 24.137142857142855\n",
+      "    gpu_util_percent0: 0.3471428571428571\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
+      "    ram_util_percent: 3.765714285714286\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
+      "  pid: 79312\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641719786222011\n",
-      "    mean_env_wait_ms: 1.1571251717808861\n",
-      "    mean_inference_ms: 5.450378231973181\n",
-      "    mean_raw_obs_processing_ms: 0.4348042526165878\n",
-      "  time_since_restore: 55.82824516296387\n",
-      "  time_this_iter_s: 27.11174178123474\n",
-      "  time_total_s: 55.82824516296387\n",
+      "    mean_action_processing_ms: 0.16806359585411593\n",
+      "    mean_env_wait_ms: 1.1841379708651558\n",
+      "    mean_inference_ms: 5.750448117607469\n",
+      "    mean_raw_obs_processing_ms: 0.4512361015597604\n",
+      "  time_since_restore: 62.52883005142212\n",
+      "  time_this_iter_s: 30.37656331062317\n",
+      "  time_total_s: 62.52883005142212\n",
       "  timers:\n",
-      "    learn_throughput: 8314.425\n",
-      "    learn_time_ms: 19459.192\n",
-      "    sample_throughput: 19291.922\n",
-      "    sample_time_ms: 8386.515\n",
-      "    update_time_ms: 22.338\n",
-      "  timestamp: 1602449469\n",
+      "    learn_throughput: 7138.833\n",
+      "    learn_time_ms: 22663.647\n",
+      "    sample_throughput: 19058.946\n",
+      "    sample_time_ms: 8489.032\n",
+      "    update_time_ms: 70.943\n",
+      "  timestamp: 1602500834\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: 57f23_00000\n",
+      "  trial_id: ec062_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      2 |          55.8282 | 323584 |  217.637 |              273.596 |              145.717 |            890.861 |\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      2 |          62.5288 | 323584 |  216.574 |              271.778 |              145.717 |            890.212 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3601.8677130044844\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-35\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3623.7892376681616\n",
+      "    time_step_min: 3280\n",
+      "  date: 2020-10-12_11-07-44\n",
       "  done: false\n",
-      "  episode_len_mean: 885.132911392405\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 219.87009333844756\n",
-      "  episode_reward_min: 145.7171717171716\n",
+      "  episode_len_mean: 886.9367088607595\n",
+      "  episode_reward_max: 271.77777777777766\n",
+      "  episode_reward_mean: 217.08176703746304\n",
+      "  episode_reward_min: 140.7171717171715\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1456398169199626\n",
+      "        entropy: 1.1341195205847423\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008224547879459957\n",
+      "        kl: 0.0113501554975907\n",
       "        model: {}\n",
-      "        policy_loss: -0.013529085864623388\n",
-      "        total_loss: 61.275455474853516\n",
-      "        vf_explained_var: 0.8916645646095276\n",
-      "        vf_loss: 61.28873507181803\n",
+      "        policy_loss: -0.015694307706629235\n",
+      "        total_loss: 56.475844065348305\n",
+      "        vf_explained_var: 0.9051428437232971\n",
+      "        vf_loss: 56.4898354212443\n",
       "    num_steps_sampled: 485376\n",
       "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 3\n",
@@ -6380,56 +6612,1583 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.764516129032263\n",
-      "    gpu_util_percent0: 0.4045161290322581\n",
+      "    cpu_util_percent: 22.238888888888894\n",
+      "    gpu_util_percent0: 0.40555555555555556\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7774193548387096\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
+      "    ram_util_percent: 3.7777777777777786\n",
+      "    vram_util_percent0: 0.1043784847490981\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
+      "  pid: 79312\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16153199701032797\n",
-      "    mean_env_wait_ms: 1.1575292499687186\n",
-      "    mean_inference_ms: 5.28509801236235\n",
-      "    mean_raw_obs_processing_ms: 0.4265118857400026\n",
-      "  time_since_restore: 82.30366969108582\n",
-      "  time_this_iter_s: 26.47542452812195\n",
-      "  time_total_s: 82.30366969108582\n",
+      "    mean_action_processing_ms: 0.16478888845848663\n",
+      "    mean_env_wait_ms: 1.1803292261417089\n",
+      "    mean_inference_ms: 5.533704102533503\n",
+      "    mean_raw_obs_processing_ms: 0.44188504180828364\n",
+      "  time_since_restore: 92.7837405204773\n",
+      "  time_this_iter_s: 30.254910469055176\n",
+      "  time_total_s: 92.7837405204773\n",
       "  timers:\n",
-      "    learn_throughput: 8340.997\n",
-      "    learn_time_ms: 19397.202\n",
-      "    sample_throughput: 20306.88\n",
-      "    sample_time_ms: 7967.349\n",
-      "    update_time_ms: 21.561\n",
-      "  timestamp: 1602449495\n",
+      "    learn_throughput: 7114.123\n",
+      "    learn_time_ms: 22742.368\n",
+      "    sample_throughput: 20022.711\n",
+      "    sample_time_ms: 8080.424\n",
+      "    update_time_ms: 61.025\n",
+      "  timestamp: 1602500864\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: 57f23_00000\n",
+      "  trial_id: ec062_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      3 |          82.3037 | 485376 |   219.87 |              273.596 |              145.717 |            885.133 |\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      3 |          92.7837 | 485376 |  217.082 |              271.778 |              140.717 |            886.937 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
-      "\n"
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3621.864238410596\n",
+      "    time_step_min: 3259\n",
+      "  date: 2020-10-12_11-08-14\n",
+      "  done: false\n",
+      "  episode_len_mean: 884.7626582278481\n",
+      "  episode_reward_max: 272.23232323232315\n",
+      "  episode_reward_mean: 217.0697800792735\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 632\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.1208285590012868\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.011465752497315407\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01761480169564796\n",
+      "        total_loss: 38.10077794392904\n",
+      "        vf_explained_var: 0.9357242584228516\n",
+      "        vf_loss: 38.11666043599447\n",
+      "    num_steps_sampled: 647168\n",
+      "    num_steps_trained: 647168\n",
+      "  iterations_since_restore: 4\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 23.21764705882353\n",
+      "    gpu_util_percent0: 0.2861764705882353\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7794117647058822\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1624482993263691\n",
+      "    mean_env_wait_ms: 1.1785222685194872\n",
+      "    mean_inference_ms: 5.378206156901586\n",
+      "    mean_raw_obs_processing_ms: 0.4347376840177948\n",
+      "  time_since_restore: 122.39383602142334\n",
+      "  time_this_iter_s: 29.610095500946045\n",
+      "  time_total_s: 122.39383602142334\n",
+      "  timers:\n",
+      "    learn_throughput: 7128.507\n",
+      "    learn_time_ms: 22696.477\n",
+      "    sample_throughput: 20739.428\n",
+      "    sample_time_ms: 7801.179\n",
+      "    update_time_ms: 55.395\n",
+      "  timestamp: 1602500894\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 647168\n",
+      "  training_iteration: 4\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      4 |          122.394 | 647168 |   217.07 |              272.232 |              138.899 |            884.763 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3614.723097112861\n",
+      "    time_step_min: 3259\n",
+      "  date: 2020-10-12_11-08-44\n",
+      "  done: false\n",
+      "  episode_len_mean: 880.6405063291139\n",
+      "  episode_reward_max: 272.23232323232315\n",
+      "  episode_reward_mean: 218.68169032093064\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 790\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0919292469819386\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.011500499909743667\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016317931944892432\n",
+      "        total_loss: 29.171505610148113\n",
+      "        vf_explained_var: 0.9493789076805115\n",
+      "        vf_loss: 29.186068852742512\n",
+      "    num_steps_sampled: 808960\n",
+      "    num_steps_trained: 808960\n",
+      "  iterations_since_restore: 5\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.137142857142855\n",
+      "    gpu_util_percent0: 0.3737142857142857\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7714285714285714\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1607412947237584\n",
+      "    mean_env_wait_ms: 1.1779883561216367\n",
+      "    mean_inference_ms: 5.261237598311126\n",
+      "    mean_raw_obs_processing_ms: 0.4290507164599673\n",
+      "  time_since_restore: 152.33566164970398\n",
+      "  time_this_iter_s: 29.94182562828064\n",
+      "  time_total_s: 152.33566164970398\n",
+      "  timers:\n",
+      "    learn_throughput: 7132.281\n",
+      "    learn_time_ms: 22684.467\n",
+      "    sample_throughput: 21058.444\n",
+      "    sample_time_ms: 7682.999\n",
+      "    update_time_ms: 52.788\n",
+      "  timestamp: 1602500924\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 808960\n",
+      "  training_iteration: 5\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      5 |          152.336 | 808960 |  218.682 |              272.232 |              138.899 |            880.641 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3587.817334575955\n",
+      "    time_step_min: 3253\n",
+      "  date: 2020-10-12_11-09-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 869.0708446866485\n",
+      "  episode_reward_max: 281.77777777777794\n",
+      "  episode_reward_mean: 222.88462279470437\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 311\n",
+      "  episodes_total: 1101\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0718796054522197\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.01130249296935896\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017208602143606793\n",
+      "        total_loss: 30.61871035893758\n",
+      "        vf_explained_var: 0.9621255397796631\n",
+      "        vf_loss: 30.63419500986735\n",
+      "    num_steps_sampled: 970752\n",
+      "    num_steps_trained: 970752\n",
+      "  iterations_since_restore: 6\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.258823529411767\n",
+      "    gpu_util_percent0: 0.29911764705882354\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7735294117647062\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15842836598029506\n",
+      "    mean_env_wait_ms: 1.1800898851125674\n",
+      "    mean_inference_ms: 5.103987253229784\n",
+      "    mean_raw_obs_processing_ms: 0.4214483470163353\n",
+      "  time_since_restore: 181.6211371421814\n",
+      "  time_this_iter_s: 29.285475492477417\n",
+      "  time_total_s: 181.6211371421814\n",
+      "  timers:\n",
+      "    learn_throughput: 7149.157\n",
+      "    learn_time_ms: 22630.921\n",
+      "    sample_throughput: 21459.038\n",
+      "    sample_time_ms: 7539.574\n",
+      "    update_time_ms: 50.889\n",
+      "  timestamp: 1602500953\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 970752\n",
+      "  training_iteration: 6\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      6 |          181.621 | 970752 |  222.885 |              281.778 |              138.899 |            869.071 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3574.628640776699\n",
+      "    time_step_min: 3194\n",
+      "  date: 2020-10-12_11-09-43\n",
+      "  done: false\n",
+      "  episode_len_mean: 863.879746835443\n",
+      "  episode_reward_max: 282.08080808080786\n",
+      "  episode_reward_mean: 224.91116864851026\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 163\n",
+      "  episodes_total: 1264\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.060988982518514\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.011702353289971748\n",
+      "        model: {}\n",
+      "        policy_loss: -0.019268650217175793\n",
+      "        total_loss: 18.453628063201904\n",
+      "        vf_explained_var: 0.9659398198127747\n",
+      "        vf_loss: 18.471086502075195\n",
+      "    num_steps_sampled: 1132544\n",
+      "    num_steps_trained: 1132544\n",
+      "  iterations_since_restore: 7\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.845714285714287\n",
+      "    gpu_util_percent0: 0.2934285714285715\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.791428571428572\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1575680302218401\n",
+      "    mean_env_wait_ms: 1.1812803730465038\n",
+      "    mean_inference_ms: 5.044244172096538\n",
+      "    mean_raw_obs_processing_ms: 0.41852570780371284\n",
+      "  time_since_restore: 211.47951650619507\n",
+      "  time_this_iter_s: 29.858379364013672\n",
+      "  time_total_s: 211.47951650619507\n",
+      "  timers:\n",
+      "    learn_throughput: 7132.476\n",
+      "    learn_time_ms: 22683.848\n",
+      "    sample_throughput: 21778.119\n",
+      "    sample_time_ms: 7429.108\n",
+      "    update_time_ms: 49.21\n",
+      "  timestamp: 1602500983\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1132544\n",
+      "  training_iteration: 7\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      7 |           211.48 | 1132544 |  224.911 |              282.081 |              138.899 |             863.88 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3559.687230989957\n",
+      "    time_step_min: 3194\n",
+      "  date: 2020-10-12_11-10-13\n",
+      "  done: false\n",
+      "  episode_len_mean: 858.7841068917019\n",
+      "  episode_reward_max: 282.08080808080786\n",
+      "  episode_reward_mean: 227.159442526531\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1422\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0327277580897014\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.011306605534628034\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0188012203531495\n",
+      "        total_loss: 15.273218075434366\n",
+      "        vf_explained_var: 0.9682538509368896\n",
+      "        vf_loss: 15.290274302164713\n",
+      "    num_steps_sampled: 1294336\n",
+      "    num_steps_trained: 1294336\n",
+      "  iterations_since_restore: 8\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.538235294117644\n",
+      "    gpu_util_percent0: 0.43441176470588233\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7794117647058822\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15685768288033522\n",
+      "    mean_env_wait_ms: 1.1824192503621984\n",
+      "    mean_inference_ms: 4.994578322802786\n",
+      "    mean_raw_obs_processing_ms: 0.41600770103500656\n",
+      "  time_since_restore: 241.07298350334167\n",
+      "  time_this_iter_s: 29.593466997146606\n",
+      "  time_total_s: 241.07298350334167\n",
+      "  timers:\n",
+      "    learn_throughput: 7137.946\n",
+      "    learn_time_ms: 22666.464\n",
+      "    sample_throughput: 21955.807\n",
+      "    sample_time_ms: 7368.984\n",
+      "    update_time_ms: 47.752\n",
+      "  timestamp: 1602501013\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1294336\n",
+      "  training_iteration: 8\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      8 |          241.073 | 1294336 |  227.159 |              282.081 |              138.899 |            858.784 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3548.699742268041\n",
+      "    time_step_min: 3194\n",
+      "  date: 2020-10-12_11-10-42\n",
+      "  done: false\n",
+      "  episode_len_mean: 854.1525316455696\n",
+      "  episode_reward_max: 292.5353535353532\n",
+      "  episode_reward_mean: 228.90723692622413\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 1580\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 1.0014687329530716\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.01150376326404512\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016004978213459253\n",
+      "        total_loss: 19.093974113464355\n",
+      "        vf_explained_var: 0.9633541107177734\n",
+      "        vf_loss: 19.108178933461506\n",
+      "    num_steps_sampled: 1456128\n",
+      "    num_steps_trained: 1456128\n",
+      "  iterations_since_restore: 9\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.191176470588236\n",
+      "    gpu_util_percent0: 0.33617647058823524\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7764705882352945\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1562354407759429\n",
+      "    mean_env_wait_ms: 1.1837066205442477\n",
+      "    mean_inference_ms: 4.9512944069986835\n",
+      "    mean_raw_obs_processing_ms: 0.41377123150621203\n",
+      "  time_since_restore: 270.64611411094666\n",
+      "  time_this_iter_s: 29.57313060760498\n",
+      "  time_total_s: 270.64611411094666\n",
+      "  timers:\n",
+      "    learn_throughput: 7142.357\n",
+      "    learn_time_ms: 22652.468\n",
+      "    sample_throughput: 22095.038\n",
+      "    sample_time_ms: 7322.549\n",
+      "    update_time_ms: 45.674\n",
+      "  timestamp: 1602501042\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1456128\n",
+      "  training_iteration: 9\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |      9 |          270.646 | 1456128 |  228.907 |              292.535 |              138.899 |            854.153 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3527.288317256163\n",
+      "    time_step_min: 3194\n",
+      "  date: 2020-10-12_11-11-12\n",
+      "  done: false\n",
+      "  episode_len_mean: 845.3901795142556\n",
+      "  episode_reward_max: 292.5353535353532\n",
+      "  episode_reward_mean: 232.04648917901278\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 314\n",
+      "  episodes_total: 1894\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9655029277006785\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010109123696262637\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016467383014969528\n",
+      "        total_loss: 19.649176279703777\n",
+      "        vf_explained_var: 0.9746022820472717\n",
+      "        vf_loss: 19.664104143778484\n",
+      "    num_steps_sampled: 1617920\n",
+      "    num_steps_trained: 1617920\n",
+      "  iterations_since_restore: 10\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.870588235294118\n",
+      "    gpu_util_percent0: 0.3364705882352941\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7735294117647062\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1552292831014224\n",
+      "    mean_env_wait_ms: 1.186625595007512\n",
+      "    mean_inference_ms: 4.881686367267097\n",
+      "    mean_raw_obs_processing_ms: 0.41029242161785917\n",
+      "  time_since_restore: 300.233526468277\n",
+      "  time_this_iter_s: 29.587412357330322\n",
+      "  time_total_s: 300.233526468277\n",
+      "  timers:\n",
+      "    learn_throughput: 7143.766\n",
+      "    learn_time_ms: 22647.998\n",
+      "    sample_throughput: 22227.275\n",
+      "    sample_time_ms: 7278.985\n",
+      "    update_time_ms: 45.004\n",
+      "  timestamp: 1602501072\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1617920\n",
+      "  training_iteration: 10\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     10 |          300.234 | 1617920 |  232.046 |              292.535 |              138.899 |             845.39 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3518.6243830207304\n",
+      "    time_step_min: 3194\n",
+      "  date: 2020-10-12_11-11-42\n",
+      "  done: false\n",
+      "  episode_len_mean: 841.65141187926\n",
+      "  episode_reward_max: 292.5353535353532\n",
+      "  episode_reward_mean: 233.41700353092745\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 160\n",
+      "  episodes_total: 2054\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9469701697429022\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010086450492963195\n",
+      "        model: {}\n",
+      "        policy_loss: -0.018124834440338116\n",
+      "        total_loss: 12.415512720743815\n",
+      "        vf_explained_var: 0.9763712286949158\n",
+      "        vf_loss: 12.432093620300293\n",
+      "    num_steps_sampled: 1779712\n",
+      "    num_steps_trained: 1779712\n",
+      "  iterations_since_restore: 11\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 20.873529411764707\n",
+      "    gpu_util_percent0: 0.31470588235294117\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7882352941176474\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1548127093773671\n",
+      "    mean_env_wait_ms: 1.1880107176796835\n",
+      "    mean_inference_ms: 4.852438405198466\n",
+      "    mean_raw_obs_processing_ms: 0.4088344939810243\n",
+      "  time_since_restore: 329.7829658985138\n",
+      "  time_this_iter_s: 29.549439430236816\n",
+      "  time_total_s: 329.7829658985138\n",
+      "  timers:\n",
+      "    learn_throughput: 7150.465\n",
+      "    learn_time_ms: 22626.781\n",
+      "    sample_throughput: 22968.45\n",
+      "    sample_time_ms: 7044.097\n",
+      "    update_time_ms: 38.831\n",
+      "  timestamp: 1602501102\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1779712\n",
+      "  training_iteration: 11\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     11 |          329.783 | 1779712 |  233.417 |              292.535 |              138.899 |            841.651 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3509.8141025641025\n",
+      "    time_step_min: 3194\n",
+      "  date: 2020-10-12_11-12-11\n",
+      "  done: false\n",
+      "  episode_len_mean: 838.3146473779385\n",
+      "  episode_reward_max: 292.5353535353532\n",
+      "  episode_reward_mean: 234.829383345206\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2212\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.9210369984308878\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.010504102567210793\n",
+      "        model: {}\n",
+      "        policy_loss: -0.016645007805588346\n",
+      "        total_loss: 10.698445002237955\n",
+      "        vf_explained_var: 0.9771132469177246\n",
+      "        vf_loss: 10.713449398676554\n",
+      "    num_steps_sampled: 1941504\n",
+      "    num_steps_trained: 1941504\n",
+      "  iterations_since_restore: 12\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 22.38529411764706\n",
+      "    gpu_util_percent0: 0.38\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7882352941176474\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15444011041607467\n",
+      "    mean_env_wait_ms: 1.189267327205493\n",
+      "    mean_inference_ms: 4.826345559128167\n",
+      "    mean_raw_obs_processing_ms: 0.4074932954231811\n",
+      "  time_since_restore: 359.473717212677\n",
+      "  time_this_iter_s: 29.690751314163208\n",
+      "  time_total_s: 359.473717212677\n",
+      "  timers:\n",
+      "    learn_throughput: 7147.549\n",
+      "    learn_time_ms: 22636.012\n",
+      "    sample_throughput: 23224.099\n",
+      "    sample_time_ms: 6966.557\n",
+      "    update_time_ms: 37.882\n",
+      "  timestamp: 1602501131\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 1941504\n",
+      "  training_iteration: 12\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     12 |          359.474 | 1941504 |  234.829 |              292.535 |              138.899 |            838.315 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3496.74555968608\n",
+      "    time_step_min: 3194\n",
+      "  date: 2020-10-12_11-12-41\n",
+      "  done: false\n",
+      "  episode_len_mean: 833.5634953042058\n",
+      "  episode_reward_max: 292.5353535353532\n",
+      "  episode_reward_mean: 236.63003658471183\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2449\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.874845951795578\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009460883758341273\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01588716957970367\n",
+      "        total_loss: 14.987916946411133\n",
+      "        vf_explained_var: 0.9778693318367004\n",
+      "        vf_loss: 15.002349376678467\n",
+      "    num_steps_sampled: 2103296\n",
+      "    num_steps_trained: 2103296\n",
+      "  iterations_since_restore: 13\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.13823529411765\n",
+      "    gpu_util_percent0: 0.37235294117647066\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7764705882352945\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1539508848252292\n",
+      "    mean_env_wait_ms: 1.1912813547915042\n",
+      "    mean_inference_ms: 4.791974394857117\n",
+      "    mean_raw_obs_processing_ms: 0.40572168105096845\n",
+      "  time_since_restore: 388.83686232566833\n",
+      "  time_this_iter_s: 29.363145112991333\n",
+      "  time_total_s: 388.83686232566833\n",
+      "  timers:\n",
+      "    learn_throughput: 7162.416\n",
+      "    learn_time_ms: 22589.025\n",
+      "    sample_throughput: 23368.563\n",
+      "    sample_time_ms: 6923.49\n",
+      "    update_time_ms: 37.6\n",
+      "  timestamp: 1602501161\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2103296\n",
+      "  training_iteration: 13\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     13 |          388.837 | 2103296 |   236.63 |              292.535 |              138.899 |            833.563 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3485.0489089541006\n",
+      "    time_step_min: 3159\n",
+      "  date: 2020-10-12_11-13-10\n",
+      "  done: false\n",
+      "  episode_len_mean: 829.1816827997021\n",
+      "  episode_reward_max: 292.5353535353532\n",
+      "  episode_reward_mean: 238.27470911648115\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 237\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8784356613953909\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008936016277099649\n",
+      "        model: {}\n",
+      "        policy_loss: -0.0144694714108482\n",
+      "        total_loss: 12.34289781252543\n",
+      "        vf_explained_var: 0.9786873459815979\n",
+      "        vf_loss: 12.356019179026285\n",
+      "    num_steps_sampled: 2265088\n",
+      "    num_steps_trained: 2265088\n",
+      "  iterations_since_restore: 14\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.84705882352941\n",
+      "    gpu_util_percent0: 0.4517647058823529\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7735294117647062\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.1535247550740816\n",
+      "    mean_env_wait_ms: 1.1931720837126862\n",
+      "    mean_inference_ms: 4.7620908972039935\n",
+      "    mean_raw_obs_processing_ms: 0.4042169402130369\n",
+      "  time_since_restore: 417.9772484302521\n",
+      "  time_this_iter_s: 29.14038610458374\n",
+      "  time_total_s: 417.9772484302521\n",
+      "  timers:\n",
+      "    learn_throughput: 7171.687\n",
+      "    learn_time_ms: 22559.824\n",
+      "    sample_throughput: 23430.636\n",
+      "    sample_time_ms: 6905.148\n",
+      "    update_time_ms: 37.671\n",
+      "  timestamp: 1602501190\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2265088\n",
+      "  training_iteration: 14\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     14 |          417.977 | 2265088 |  238.275 |              292.535 |              138.899 |            829.182 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3478.615411931818\n",
+      "    time_step_min: 3159\n",
+      "  date: 2020-10-12_11-13-40\n",
+      "  done: false\n",
+      "  episode_len_mean: 826.7542194092827\n",
+      "  episode_reward_max: 292.5353535353532\n",
+      "  episode_reward_mean: 239.19818437539945\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8649471998214722\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.01006123865954578\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017844289424829185\n",
+      "        total_loss: 9.70694867769877\n",
+      "        vf_explained_var: 0.9796954989433289\n",
+      "        vf_loss: 9.723213116327921\n",
+      "    num_steps_sampled: 2426880\n",
+      "    num_steps_trained: 2426880\n",
+      "  iterations_since_restore: 15\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.876470588235296\n",
+      "    gpu_util_percent0: 0.3244117647058823\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7794117647058822\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15327356539218503\n",
+      "    mean_env_wait_ms: 1.194326233850043\n",
+      "    mean_inference_ms: 4.744338916417169\n",
+      "    mean_raw_obs_processing_ms: 0.40329630038774883\n",
+      "  time_since_restore: 447.3988480567932\n",
+      "  time_this_iter_s: 29.421599626541138\n",
+      "  time_total_s: 447.3988480567932\n",
+      "  timers:\n",
+      "    learn_throughput: 7176.041\n",
+      "    learn_time_ms: 22546.137\n",
+      "    sample_throughput: 23560.775\n",
+      "    sample_time_ms: 6867.007\n",
+      "    update_time_ms: 37.136\n",
+      "  timestamp: 1602501220\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2426880\n",
+      "  training_iteration: 15\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     15 |          447.399 | 2426880 |  239.198 |              292.535 |              138.899 |            826.754 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3472.0551311856525\n",
+      "    time_step_min: 3159\n",
+      "  date: 2020-10-12_11-14-09\n",
+      "  done: false\n",
+      "  episode_len_mean: 823.651201052978\n",
+      "  episode_reward_max: 292.5353535353532\n",
+      "  episode_reward_mean: 240.11829050624695\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 195\n",
+      "  episodes_total: 3039\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8254145234823227\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009458012490843734\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01512273036253949\n",
+      "        total_loss: 13.99141558011373\n",
+      "        vf_explained_var: 0.9766866564750671\n",
+      "        vf_loss: 14.005059798558554\n",
+      "    num_steps_sampled: 2588672\n",
+      "    num_steps_trained: 2588672\n",
+      "  iterations_since_restore: 16\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.51176470588235\n",
+      "    gpu_util_percent0: 0.33176470588235296\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7735294117647054\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15298767215998352\n",
+      "    mean_env_wait_ms: 1.1957940587841065\n",
+      "    mean_inference_ms: 4.724218103088548\n",
+      "    mean_raw_obs_processing_ms: 0.40222561069745294\n",
+      "  time_since_restore: 476.6713652610779\n",
+      "  time_this_iter_s: 29.272517204284668\n",
+      "  time_total_s: 476.6713652610779\n",
+      "  timers:\n",
+      "    learn_throughput: 7180.725\n",
+      "    learn_time_ms: 22531.431\n",
+      "    sample_throughput: 23533.661\n",
+      "    sample_time_ms: 6874.918\n",
+      "    update_time_ms: 35.121\n",
+      "  timestamp: 1602501249\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2588672\n",
+      "  training_iteration: 16\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     16 |          476.671 | 2588672 |  240.118 |              292.535 |              138.899 |            823.651 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3463.277591973244\n",
+      "    time_step_min: 3122\n",
+      "  date: 2020-10-12_11-14-38\n",
+      "  done: false\n",
+      "  episode_len_mean: 820.0826047633403\n",
+      "  episode_reward_max: 292.989898989899\n",
+      "  episode_reward_mean: 241.4787671712603\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 278\n",
+      "  episodes_total: 3317\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.8151738196611404\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009590728984524807\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01601108305233841\n",
+      "        total_loss: 10.88164758682251\n",
+      "        vf_explained_var: 0.9833198189735413\n",
+      "        vf_loss: 10.896148045857748\n",
+      "    num_steps_sampled: 2750464\n",
+      "    num_steps_trained: 2750464\n",
+      "  iterations_since_restore: 17\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.66969696969697\n",
+      "    gpu_util_percent0: 0.33909090909090905\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.772727272727273\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15263561454670363\n",
+      "    mean_env_wait_ms: 1.1977706296572646\n",
+      "    mean_inference_ms: 4.698803894164137\n",
+      "    mean_raw_obs_processing_ms: 0.400909170294569\n",
+      "  time_since_restore: 505.8517713546753\n",
+      "  time_this_iter_s: 29.180406093597412\n",
+      "  time_total_s: 505.8517713546753\n",
+      "  timers:\n",
+      "    learn_throughput: 7203.419\n",
+      "    learn_time_ms: 22460.446\n",
+      "    sample_throughput: 23518.9\n",
+      "    sample_time_ms: 6879.233\n",
+      "    update_time_ms: 33.392\n",
+      "  timestamp: 1602501278\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2750464\n",
+      "  training_iteration: 17\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     17 |          505.852 | 2750464 |  241.479 |               292.99 |              138.899 |            820.083 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3459.457366589327\n",
+      "    time_step_min: 3122\n",
+      "  date: 2020-10-12_11-15-08\n",
+      "  done: false\n",
+      "  episode_len_mean: 818.1067318757192\n",
+      "  episode_reward_max: 292.989898989899\n",
+      "  episode_reward_mean: 242.01891178761136\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 159\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7972376495599747\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009708141054337224\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017444406868889928\n",
+      "        total_loss: 9.293004115422567\n",
+      "        vf_explained_var: 0.9813184142112732\n",
+      "        vf_loss: 9.308905283610025\n",
+      "    num_steps_sampled: 2912256\n",
+      "    num_steps_trained: 2912256\n",
+      "  iterations_since_restore: 18\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.91176470588235\n",
+      "    gpu_util_percent0: 0.35205882352941176\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7764705882352945\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15244909410231441\n",
+      "    mean_env_wait_ms: 1.1988208182932776\n",
+      "    mean_inference_ms: 4.685620595286818\n",
+      "    mean_raw_obs_processing_ms: 0.40022293191948377\n",
+      "  time_since_restore: 535.3326375484467\n",
+      "  time_this_iter_s: 29.480866193771362\n",
+      "  time_total_s: 535.3326375484467\n",
+      "  timers:\n",
+      "    learn_throughput: 7203.658\n",
+      "    learn_time_ms: 22459.702\n",
+      "    sample_throughput: 23554.42\n",
+      "    sample_time_ms: 6868.859\n",
+      "    update_time_ms: 33.715\n",
+      "  timestamp: 1602501308\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 2912256\n",
+      "  training_iteration: 18\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     18 |          535.333 | 2912256 |  242.019 |               292.99 |              138.899 |            818.107 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3455.4910146530274\n",
+      "    time_step_min: 3122\n",
+      "  date: 2020-10-12_11-15-38\n",
+      "  done: false\n",
+      "  episode_len_mean: 816.3349794238683\n",
+      "  episode_reward_max: 292.989898989899\n",
+      "  episode_reward_mean: 242.54158872677382\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 169\n",
+      "  episodes_total: 3645\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7739134132862091\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009328874681765834\n",
+      "        model: {}\n",
+      "        policy_loss: -0.01628954194408531\n",
+      "        total_loss: 9.141257365544638\n",
+      "        vf_explained_var: 0.9834416508674622\n",
+      "        vf_loss: 9.156067848205566\n",
+      "    num_steps_sampled: 3074048\n",
+      "    num_steps_trained: 3074048\n",
+      "  iterations_since_restore: 19\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.514285714285716\n",
+      "    gpu_util_percent0: 0.3065714285714286\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7857142857142856\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15226120163607904\n",
+      "    mean_env_wait_ms: 1.1999160371375377\n",
+      "    mean_inference_ms: 4.672479068198147\n",
+      "    mean_raw_obs_processing_ms: 0.39952560571722434\n",
+      "  time_since_restore: 564.7683990001678\n",
+      "  time_this_iter_s: 29.43576145172119\n",
+      "  time_total_s: 564.7683990001678\n",
+      "  timers:\n",
+      "    learn_throughput: 7206.845\n",
+      "    learn_time_ms: 22449.767\n",
+      "    sample_throughput: 23595.931\n",
+      "    sample_time_ms: 6856.776\n",
+      "    update_time_ms: 33.005\n",
+      "  timestamp: 1602501338\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3074048\n",
+      "  training_iteration: 19\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     19 |          564.768 | 3074048 |  242.542 |               292.99 |              138.899 |            816.335 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3450.714504596527\n",
+      "    time_step_min: 3122\n",
+      "  date: 2020-10-12_11-16-07\n",
+      "  done: false\n",
+      "  episode_len_mean: 813.685598377282\n",
+      "  episode_reward_max: 292.989898989899\n",
+      "  episode_reward_mean: 243.27625647960326\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 299\n",
+      "  episodes_total: 3944\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7598459174235662\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.008437203515010575\n",
+      "        model: {}\n",
+      "        policy_loss: -0.014525203267112374\n",
+      "        total_loss: 12.6011643409729\n",
+      "        vf_explained_var: 0.9831928610801697\n",
+      "        vf_loss: 12.614381790161133\n",
+      "    num_steps_sampled: 3235840\n",
+      "    num_steps_trained: 3235840\n",
+      "  iterations_since_restore: 20\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.912121212121217\n",
+      "    gpu_util_percent0: 0.2693939393939394\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.778787878787879\n",
+      "    vram_util_percent0: 0.10437848474909807\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15196848488671325\n",
+      "    mean_env_wait_ms: 1.2018070298209165\n",
+      "    mean_inference_ms: 4.651604684034456\n",
+      "    mean_raw_obs_processing_ms: 0.3984450119874049\n",
+      "  time_since_restore: 593.9878306388855\n",
+      "  time_this_iter_s: 29.21943163871765\n",
+      "  time_total_s: 593.9878306388855\n",
+      "  timers:\n",
+      "    learn_throughput: 7217.754\n",
+      "    learn_time_ms: 22415.837\n",
+      "    sample_throughput: 23604.007\n",
+      "    sample_time_ms: 6854.429\n",
+      "    update_time_ms: 31.065\n",
+      "  timestamp: 1602501367\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3235840\n",
+      "  training_iteration: 20\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 RUNNING)\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | RUNNING  | 172.17.0.4:79312 |     20 |          593.988 | 3235840 |  243.276 |               292.99 |              138.899 |            813.686 |\n",
+      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "Result for PPO_jss_env_ec062_00000:\n",
+      "  custom_metrics:\n",
+      "    time_step_max: 4085\n",
+      "    time_step_mean: 3447.600490196078\n",
+      "    time_step_min: 3122\n",
+      "  date: 2020-10-12_11-16-36\n",
+      "  done: true\n",
+      "  episode_len_mean: 812.2758033106135\n",
+      "  episode_reward_max: 292.989898989899\n",
+      "  episode_reward_mean: 243.7780875945432\n",
+      "  episode_reward_min: 138.8989898989893\n",
+      "  episodes_this_iter: 164\n",
+      "  episodes_total: 4108\n",
+      "  experiment_id: f6da3cea93a14f28a7d05abdc377fac8\n",
+      "  experiment_tag: '0'\n",
+      "  hostname: f85e62b52919\n",
+      "  info:\n",
+      "    learner:\n",
+      "      default_policy:\n",
+      "        allreduce_latency: 0.0\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
+      "        cur_lr: 5.0e-05\n",
+      "        entropy: 0.7564162909984589\n",
+      "        entropy_coeff: 0.0005000000000000001\n",
+      "        kl: 0.009951598476618528\n",
+      "        model: {}\n",
+      "        policy_loss: -0.017080792342312634\n",
+      "        total_loss: 7.360955437024434\n",
+      "        vf_explained_var: 0.9852108955383301\n",
+      "        vf_loss: 7.376423915227254\n",
+      "    num_steps_sampled: 3397632\n",
+      "    num_steps_trained: 3397632\n",
+      "  iterations_since_restore: 21\n",
+      "  node_ip: 172.17.0.4\n",
+      "  num_healthy_workers: 79\n",
+      "  off_policy_estimator: {}\n",
+      "  perf:\n",
+      "    cpu_util_percent: 21.944117647058825\n",
+      "    gpu_util_percent0: 0.3264705882352941\n",
+      "    gpu_util_percent1: 0.0\n",
+      "    gpu_util_percent2: 0.0\n",
+      "    ram_util_percent: 3.7882352941176474\n",
+      "    vram_util_percent0: 0.10437848474909808\n",
+      "    vram_util_percent1: 0.0\n",
+      "    vram_util_percent2: 0.0\n",
+      "  pid: 79312\n",
+      "  policy_reward_max: {}\n",
+      "  policy_reward_mean: {}\n",
+      "  policy_reward_min: {}\n",
+      "  sampler_perf:\n",
+      "    mean_action_processing_ms: 0.15181886518479826\n",
+      "    mean_env_wait_ms: 1.2027377553939933\n",
+      "    mean_inference_ms: 4.641133432730056\n",
+      "    mean_raw_obs_processing_ms: 0.3979022439175898\n",
+      "  time_since_restore: 623.2816741466522\n",
+      "  time_this_iter_s: 29.293843507766724\n",
+      "  time_total_s: 623.2816741466522\n",
+      "  timers:\n",
+      "    learn_throughput: 7220.531\n",
+      "    learn_time_ms: 22407.215\n",
+      "    sample_throughput: 23662.482\n",
+      "    sample_time_ms: 6837.491\n",
+      "    update_time_ms: 30.226\n",
+      "  timestamp: 1602501396\n",
+      "  timesteps_since_restore: 0\n",
+      "  timesteps_total: 3397632\n",
+      "  training_iteration: 21\n",
+      "  trial_id: ec062_00000\n",
+      "  \n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | TERMINATED |       |     21 |          623.282 | 3397632 |  243.778 |               292.99 |              138.899 |            812.276 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "== Status ==\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Using FIFO scheduling algorithm.\n",
+      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.71 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Result logdir: /root/ray_results/ppo-jss\n",
+      "Number of trials: 1 (1 TERMINATED)\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
+      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
+      "| PPO_jss_env_ec062_00000 | TERMINATED |       |     21 |          623.282 | 3397632 |  243.778 |               292.99 |              138.899 |            812.276 |\n",
+      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
+      "\n",
+      "\n",
+      "\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 79123\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201012_110559-r7qhsszi/logs/debug.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201012_110559-r7qhsszi/logs/debug-internal.log\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3122\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 638\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602501397\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4085\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3447.60049\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 292.9899\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 138.89899\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 243.77809\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4108\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 21\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33micy-sweep-4\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/r7qhsszi\u001b[0m\n",
+      "2020-10-12 11:16:49,393 - wandb.wandb_agent - INFO - Cleaning up finished run: r7qhsszi\n",
+      "2020-10-12 11:16:49,730 - wandb.wandb_agent - INFO - Agent received command: exit\n",
+      "2020-10-12 11:16:49,731 - wandb.wandb_agent - INFO - Received exit command. Killing runs and quitting.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Terminating and syncing runs. Press ctrl-c to kill.\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent h0kna0bx"
+    "!wandb agent y2n6znmq"
    ]
   },
   {
diff --git a/JSS/.ipynb_checkpoints/default_config-checkpoint.py b/JSS/.ipynb_checkpoints/default_config-checkpoint.py
index 0786a30..0a91a3d 100644
--- a/JSS/.ipynb_checkpoints/default_config-checkpoint.py
+++ b/JSS/.ipynb_checkpoints/default_config-checkpoint.py
@@ -18,10 +18,10 @@ default_config = {
     'layer_size': 1024,
     'layer_nb': 2,
     'lr': 5e-5,
-    'clip_param': 0.3,
+    'clip_param': 0.5,
     'vf_clip_param': 10.0,
     'kl_target': 0.01,
-    'num_sgd_iter': 30,
+    'num_sgd_iter': 25,
     'lambda': 1.0,
     "use_critic": True,
     "use_gae": True,
@@ -30,7 +30,7 @@ default_config = {
     "lr_schedule": None,
     "vf_share_layers": False,
     "vf_loss_coeff": 1.0,
-    "entropy_coeff": 1e-4,
+    "entropy_coeff": 5e-4,
     "entropy_coeff_schedule": None,
     "grad_clip": None,
     "batch_mode": "truncate_episodes",
diff --git a/JSS/Untitled.ipynb b/JSS/Untitled.ipynb
index d0ca168..966137a 100644
--- a/JSS/Untitled.ipynb
+++ b/JSS/Untitled.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 1,
    "metadata": {},
    "outputs": [
     {
@@ -14,9 +14,8 @@
     }
    ],
    "source": [
-    "##### import os\n",
+    "import os\n",
     "import multiprocessing as mp\n",
-    "\n",
     "import plotly.io as pio\n",
     "import ray\n",
     "from ray import tune\n",
@@ -29,7 +28,7 @@
     "from ray.tune.integration.wandb import WandbLogger\n",
     "\n",
     "from JSS.env_wrapper import BestActionsWrapper\n",
-    "2\n",
+    "\n",
     "from JSS.models import FCMaskedActionsModel\n",
     "\n",
     "pio.orca.config.use_xvfb = True\n",
@@ -64,17 +63,10 @@
     "            'goal': 'minimize',\n",
     "        },\n",
     "        'parameters': {\n",
-    "            'clip_param': {\n",
-    "                'values': [0.3, 0.5]\n",
-    "            },\n",
-    "            'kl_coeff': {\n",
-    "                 'values': [0.1, 0.2, 0.3]\n",
-    "            },\n",
-    "            'entropy_coeff': {\n",
-    "                'values': [5e-4, 1e-4]\n",
-    "            },\n",
-    "            'num_sgd_iter': {\n",
-    "                'values': [25, 30, 35]\n",
+    "            'instance_path': {\n",
+    "                'values': ['/JSS/JSS/env/instances/ta51', '/JSS/JSS/env/instances/ta52', '/JSS/JSS/env/instances/ta53', '/JSS/JSS/env/instances/ta54',\n",
+    "                           '/JSS/JSS/env/instances/ta55', '/JSS/JSS/env/instances/ta56', '/JSS/JSS/env/instances/ta57', '/JSS/JSS/env/instances/ta58',\n",
+    "                           '/JSS/JSS/env/instances/ta59', '/JSS/JSS/env/instances/ta60']\n",
     "            }\n",
     "        }\n",
     "    }"
@@ -82,15 +74,15 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Create sweep with ID: h0kna0bx\n",
-      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\n"
+      "Create sweep with ID: pu0gldb1\n",
+      "Sweep URL: https://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/pu0gldb1\n"
      ]
     }
    ],
@@ -108,203 +100,200 @@
      "output_type": "stream",
      "text": [
       "\u001b[34m\u001b[1mwandb\u001b[0m: Starting wandb agent üïµÔ∏è\n",
-      "2020-10-11 20:17:59,838 - wandb.wandb_agent - INFO - Running runs: []\n",
-      "2020-10-11 20:18:00,194 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:18:00,195 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:18:00,197 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=25\n",
+      "2020-10-12 12:30:07,031 - wandb.wandb_agent - INFO - Running runs: []\n",
+      "2020-10-12 12:30:07,347 - wandb.wandb_agent - INFO - Agent received command: run\n",
+      "2020-10-12 12:30:07,348 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
+      "\tinstance_path: /JSS/JSS/env/instances/ta51\n",
+      "2020-10-12 12:30:07,349 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --instance_path=/JSS/JSS/env/instances/ta51\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgrateful-sweep-1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrich-sweep-1\u001b[0m\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_201802-90w2swxq\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/pu0gldb1\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/otkmv5te\u001b[0m\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201012_123009-otkmv5te\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
       "\n",
-      "2020-10-11 20:18:05,215 - wandb.wandb_agent - INFO - Running runs: ['90w2swxq']\n",
-      "2020-10-11 20:18:05,800\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
+      "2020-10-12 12:30:12,362 - wandb.wandb_agent - INFO - Running runs: ['otkmv5te']\n",
+      "2020-10-12 12:30:12,909\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
       "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
+      "Memory usage on this node: 11.5/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+-------+\n",
       "| Trial name              | status   | loc   |\n",
       "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  |       |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  |       |\n",
       "+-------------------------+----------+-------+\n",
       "\n",
       "\n",
-      "\u001b[2m\u001b[36m(pid=48597)\u001b[0m 2020-10-11 20:18:08,590\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48585)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48600)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48558)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48598)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48595)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48588)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48614)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48535)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48550)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48533)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48613)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48553)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48617)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48568)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48480)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48496)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48590)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48509)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48495)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48539)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48500)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48503)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48487)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48531)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48556)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48486)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48587)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48491)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48610)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48546)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48489)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48549)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48586)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48517)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48545)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48508)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48581)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48484)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48593)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48494)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48605)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48555)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48584)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48483)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48551)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48542)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48554)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48477)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48557)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48552)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48492)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48513)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48475)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48478)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48481)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48485)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48493)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48510)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48497)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48548)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48527)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48479)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48507)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48476)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48534)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48488)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=48516)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "\u001b[2m\u001b[36m(pid=57679)\u001b[0m 2020-10-12 12:30:15,608\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[36m(pid=57592)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57592)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57600)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57600)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57644)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57644)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57666)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57666)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57649)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57649)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57650)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57650)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57596)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57596)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57685)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57685)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57683)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57683)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57637)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57637)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57688)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57688)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57659)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57659)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57672)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57672)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57581)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57581)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57642)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57642)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57577)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57577)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57575)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57575)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57658)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57658)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57651)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57651)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57646)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57646)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57638)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57638)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57624)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57624)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57655)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57655)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57623)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57623)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57641)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57641)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57681)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57681)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57694)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57694)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57647)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57647)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57661)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57661)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57636)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57636)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57640)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57640)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57675)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57675)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57652)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57652)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57631)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57631)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57639)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57639)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57559)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57559)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57663)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57663)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57578)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57578)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57572)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57572)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57561)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57561)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57665)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57665)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57571)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57571)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57593)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57593)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57632)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57632)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57591)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57591)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57645)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57645)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57635)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57635)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57657)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57657)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57599)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57599)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57579)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57579)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57630)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57630)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57573)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57573)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57588)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57588)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57562)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57562)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57597)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57597)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57625)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57625)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57574)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57574)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57699)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57699)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57576)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57576)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57584)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57584)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57633)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57633)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57656)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57656)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57626)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57626)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57628)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57628)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57567)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57567)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57627)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57627)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57629)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57629)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57643)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57643)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57566)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57566)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57585)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57585)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57569)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57569)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57674)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57674)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57560)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57560)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57570)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57570)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57563)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57563)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57565)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57565)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57670)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57670)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57634)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57634)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "\u001b[2m\u001b[36m(pid=57654)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
+      "\u001b[2m\u001b[36m(pid=57654)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
       "    time_step_max: 4054\n",
       "    time_step_mean: 3615.0923076923077\n",
       "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-18-42\n",
+      "  date: 2020-10-12_12-30-49\n",
       "  done: false\n",
       "  episode_len_mean: 891.1139240506329\n",
       "  episode_reward_max: 258.59595959595964\n",
@@ -312,21 +301,21 @@
       "  episode_reward_min: 145.7171717171716\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 158\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1826184193293254\n",
+      "        entropy: 1.1823383669058483\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006616147429061432\n",
+      "        kl: 0.006917016425480445\n",
       "        model: {}\n",
-      "        policy_loss: -0.008133015158819035\n",
-      "        total_loss: 507.07523854573566\n",
+      "        policy_loss: -0.009157503198366612\n",
+      "        total_loss: 507.07493591308594\n",
       "        vf_explained_var: 0.540532648563385\n",
       "        vf_loss: 507.0832926432292\n",
       "    num_steps_sampled: 161792\n",
@@ -336,81 +325,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 29.127272727272725\n",
-      "    gpu_util_percent0: 0.3506060606060606\n",
+      "    cpu_util_percent: 27.593939393939394\n",
+      "    gpu_util_percent0: 0.28818181818181815\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5606060606060606\n",
-      "    vram_util_percent0: 0.08582297226114873\n",
+      "    ram_util_percent: 3.563636363636364\n",
+      "    vram_util_percent0: 0.08736346740610434\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1683247269727301\n",
-      "    mean_env_wait_ms: 1.1628085015989742\n",
-      "    mean_inference_ms: 6.007336148070346\n",
-      "    mean_raw_obs_processing_ms: 0.4543961680719389\n",
-      "  time_since_restore: 28.43995237350464\n",
-      "  time_this_iter_s: 28.43995237350464\n",
-      "  time_total_s: 28.43995237350464\n",
+      "    mean_action_processing_ms: 0.16890503735261111\n",
+      "    mean_env_wait_ms: 1.1702247577230296\n",
+      "    mean_inference_ms: 5.661956237105169\n",
+      "    mean_raw_obs_processing_ms: 0.4499529408392769\n",
+      "  time_since_restore: 28.237815141677856\n",
+      "  time_this_iter_s: 28.237815141677856\n",
+      "  time_total_s: 28.237815141677856\n",
       "  timers:\n",
-      "    learn_throughput: 8628.213\n",
-      "    learn_time_ms: 18751.508\n",
-      "    sample_throughput: 16823.05\n",
-      "    sample_time_ms: 9617.281\n",
-      "    update_time_ms: 31.059\n",
-      "  timestamp: 1602447522\n",
+      "    learn_throughput: 8559.016\n",
+      "    learn_time_ms: 18903.107\n",
+      "    sample_throughput: 17589.407\n",
+      "    sample_time_ms: 9198.263\n",
+      "    update_time_ms: 98.214\n",
+      "  timestamp: 1602505849\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 161792\n",
       "  training_iteration: 1\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 27.7/754.6 GiB\n",
+      "Memory usage on this node: 27.6/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      1 |            28.44 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      1 |          28.2378 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3620.503472222222\n",
-      "    time_step_min: 3313\n",
-      "  date: 2020-10-11_20-19-08\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3614.2256944444443\n",
+      "    time_step_min: 3379\n",
+      "  date: 2020-10-12_12-31-15\n",
       "  done: false\n",
-      "  episode_len_mean: 889.1613924050633\n",
-      "  episode_reward_max: 265.8686868686868\n",
-      "  episode_reward_mean: 217.79810765886694\n",
-      "  episode_reward_min: 145.7171717171716\n",
+      "  episode_len_mean: 892.4873417721519\n",
+      "  episode_reward_max: 264.3535353535352\n",
+      "  episode_reward_mean: 217.54734049354283\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 316\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1493095755577087\n",
+      "        entropy: 1.149937113126119\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008436032105237246\n",
+      "        kl: 0.007523950111741821\n",
       "        model: {}\n",
-      "        policy_loss: -0.010742687620222569\n",
-      "        total_loss: 128.25170707702637\n",
-      "        vf_explained_var: 0.8104302883148193\n",
-      "        vf_loss: 128.26218032836914\n",
+      "        policy_loss: -0.00998671705989788\n",
+      "        total_loss: 126.33550771077473\n",
+      "        vf_explained_var: 0.8110877871513367\n",
+      "        vf_loss: 126.34455998738606\n",
       "    num_steps_sampled: 323584\n",
       "    num_steps_trained: 323584\n",
       "  iterations_since_restore: 2\n",
@@ -418,81 +407,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 26.041935483870965\n",
-      "    gpu_util_percent0: 0.2812903225806452\n",
+      "    cpu_util_percent: 27.38709677419354\n",
+      "    gpu_util_percent0: 0.33709677419354844\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.754838709677419\n",
+      "    ram_util_percent: 3.751612903225806\n",
       "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641174120999257\n",
-      "    mean_env_wait_ms: 1.161537109361996\n",
-      "    mean_inference_ms: 5.692598517415019\n",
-      "    mean_raw_obs_processing_ms: 0.44176304933602323\n",
-      "  time_since_restore: 54.913392305374146\n",
-      "  time_this_iter_s: 26.473439931869507\n",
-      "  time_total_s: 54.913392305374146\n",
+      "    mean_action_processing_ms: 0.16522538421298727\n",
+      "    mean_env_wait_ms: 1.166785318106883\n",
+      "    mean_inference_ms: 5.478239392992289\n",
+      "    mean_raw_obs_processing_ms: 0.44201243673943585\n",
+      "  time_since_restore: 54.568071365356445\n",
+      "  time_this_iter_s: 26.33025622367859\n",
+      "  time_total_s: 54.568071365356445\n",
       "  timers:\n",
-      "    learn_throughput: 8644.657\n",
-      "    learn_time_ms: 18715.839\n",
-      "    sample_throughput: 18672.544\n",
-      "    sample_time_ms: 8664.701\n",
-      "    update_time_ms: 34.541\n",
-      "  timestamp: 1602447548\n",
+      "    learn_throughput: 8650.173\n",
+      "    learn_time_ms: 18703.904\n",
+      "    sample_throughput: 19174.478\n",
+      "    sample_time_ms: 8437.883\n",
+      "    update_time_ms: 65.669\n",
+      "  timestamp: 1602505875\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 323584\n",
       "  training_iteration: 2\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      2 |          54.9134 | 323584 |  217.798 |              265.869 |              145.717 |            889.161 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      2 |          54.5681 | 323584 |  217.547 |              264.354 |              133.899 |            892.487 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4376\n",
-      "    time_step_mean: 3623.385650224215\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-19-34\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3605.479820627803\n",
+      "    time_step_min: 3310\n",
+      "  date: 2020-10-12_12-31-41\n",
       "  done: false\n",
-      "  episode_len_mean: 884.6371308016878\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 217.91957550185379\n",
-      "  episode_reward_min: 102.98989898989872\n",
+      "  episode_len_mean: 888.5801687763714\n",
+      "  episode_reward_max: 264.50505050505006\n",
+      "  episode_reward_mean: 219.20585602864062\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 474\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1392555435498555\n",
+      "        entropy: 1.1411352157592773\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00957879020522038\n",
+      "        kl: 0.010440803055341044\n",
       "        model: {}\n",
-      "        policy_loss: -0.013498059211997315\n",
-      "        total_loss: 65.20246982574463\n",
-      "        vf_explained_var: 0.8920263648033142\n",
-      "        vf_loss: 65.21557839711507\n",
+      "        policy_loss: -0.013970387983135879\n",
+      "        total_loss: 54.93683338165283\n",
+      "        vf_explained_var: 0.8966913819313049\n",
+      "        vf_loss: 54.94928582509359\n",
       "    num_steps_sampled: 485376\n",
       "    num_steps_trained: 485376\n",
       "  iterations_since_restore: 3\n",
@@ -500,81 +489,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.12333333333333\n",
-      "    gpu_util_percent0: 0.29900000000000004\n",
+      "    cpu_util_percent: 25.876666666666665\n",
+      "    gpu_util_percent0: 0.3706666666666666\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
+      "    ram_util_percent: 3.769999999999999\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16137101559306874\n",
-      "    mean_env_wait_ms: 1.1624113133988414\n",
-      "    mean_inference_ms: 5.471956785195863\n",
-      "    mean_raw_obs_processing_ms: 0.4328824318519803\n",
-      "  time_since_restore: 80.61326289176941\n",
-      "  time_this_iter_s: 25.699870586395264\n",
-      "  time_total_s: 80.61326289176941\n",
+      "    mean_action_processing_ms: 0.16260294589169655\n",
+      "    mean_env_wait_ms: 1.1663843852803522\n",
+      "    mean_inference_ms: 5.317580712460233\n",
+      "    mean_raw_obs_processing_ms: 0.4346313705797556\n",
+      "  time_since_restore: 80.45094752311707\n",
+      "  time_this_iter_s: 25.88287615776062\n",
+      "  time_total_s: 80.45094752311707\n",
       "  timers:\n",
-      "    learn_throughput: 8673.855\n",
-      "    learn_time_ms: 18652.836\n",
-      "    sample_throughput: 19886.525\n",
-      "    sample_time_ms: 8135.76\n",
-      "    update_time_ms: 37.024\n",
-      "  timestamp: 1602447574\n",
+      "    learn_throughput: 8664.155\n",
+      "    learn_time_ms: 18673.719\n",
+      "    sample_throughput: 20162.774\n",
+      "    sample_time_ms: 8024.293\n",
+      "    update_time_ms: 51.182\n",
+      "  timestamp: 1602505901\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 485376\n",
       "  training_iteration: 3\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Memory usage on this node: 28.0/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      3 |          80.6133 | 485376 |   217.92 |              280.566 |               102.99 |            884.637 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      3 |          80.4509 | 485376 |  219.206 |              264.505 |              133.899 |             888.58 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3621.849337748344\n",
-      "    time_step_min: 3285\n",
-      "  date: 2020-10-11_20-20-00\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3591.1639072847684\n",
+      "    time_step_min: 3227\n",
+      "  date: 2020-10-12_12-32-07\n",
       "  done: false\n",
-      "  episode_len_mean: 881.6772151898734\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 218.88892085411052\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 885.4873417721519\n",
+      "  episode_reward_max: 277.0808080808083\n",
+      "  episode_reward_mean: 221.420326684567\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 632\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1236704488595326\n",
+      "        entropy: 1.1191200812657673\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007535708253271878\n",
+      "        kl: 0.011468215147033334\n",
       "        model: {}\n",
-      "        policy_loss: -0.013356986630242318\n",
-      "        total_loss: 48.56767304738363\n",
-      "        vf_explained_var: 0.9157173037528992\n",
-      "        vf_loss: 48.58083724975586\n",
+      "        policy_loss: -0.013862663588952273\n",
+      "        total_loss: 39.326786041259766\n",
+      "        vf_explained_var: 0.9241357445716858\n",
+      "        vf_loss: 39.33891359965006\n",
       "    num_steps_sampled: 647168\n",
       "    num_steps_trained: 647168\n",
       "  iterations_since_restore: 4\n",
@@ -582,81 +571,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.296666666666663\n",
-      "    gpu_util_percent0: 0.4023333333333333\n",
+      "    cpu_util_percent: 25.43333333333333\n",
+      "    gpu_util_percent0: 0.37566666666666665\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
+      "    ram_util_percent: 3.77\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1593975281871441\n",
-      "    mean_env_wait_ms: 1.1630363827485917\n",
-      "    mean_inference_ms: 5.315944442746125\n",
-      "    mean_raw_obs_processing_ms: 0.42613695533758145\n",
-      "  time_since_restore: 106.19969916343689\n",
-      "  time_this_iter_s: 25.58643627166748\n",
-      "  time_total_s: 106.19969916343689\n",
+      "    mean_action_processing_ms: 0.1607462757833792\n",
+      "    mean_env_wait_ms: 1.1666065594299164\n",
+      "    mean_inference_ms: 5.19759320615125\n",
+      "    mean_raw_obs_processing_ms: 0.42884899221182987\n",
+      "  time_since_restore: 106.41191577911377\n",
+      "  time_this_iter_s: 25.960968255996704\n",
+      "  time_total_s: 106.41191577911377\n",
       "  timers:\n",
-      "    learn_throughput: 8681.107\n",
-      "    learn_time_ms: 18637.255\n",
-      "    sample_throughput: 20668.006\n",
-      "    sample_time_ms: 7828.138\n",
-      "    update_time_ms: 38.696\n",
-      "  timestamp: 1602447600\n",
+      "    learn_throughput: 8645.902\n",
+      "    learn_time_ms: 18713.143\n",
+      "    sample_throughput: 20794.811\n",
+      "    sample_time_ms: 7780.403\n",
+      "    update_time_ms: 46.964\n",
+      "  timestamp: 1602505927\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 647168\n",
       "  training_iteration: 4\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      4 |            106.2 | 647168 |  218.889 |              280.566 |              75.8687 |            881.677 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      4 |          106.412 | 647168 |   221.42 |              277.081 |              133.899 |            885.487 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3610.6456692913384\n",
-      "    time_step_min: 3278\n",
-      "  date: 2020-10-11_20-20-26\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3577.469816272966\n",
+      "    time_step_min: 3227\n",
+      "  date: 2020-10-12_12-32-33\n",
       "  done: false\n",
-      "  episode_len_mean: 878.0367088607595\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 220.18495077355817\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 882.6164556962025\n",
+      "  episode_reward_max: 277.0808080808083\n",
+      "  episode_reward_mean: 223.37348165196246\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 790\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.090914100408554\n",
+      "        entropy: 1.0904998779296875\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0074959762472038465\n",
+      "        kl: 0.010465693194419146\n",
       "        model: {}\n",
-      "        policy_loss: -0.012363930135810127\n",
-      "        total_loss: 36.32484753926595\n",
-      "        vf_explained_var: 0.9411559104919434\n",
-      "        vf_loss: 36.33700720469157\n",
+      "        policy_loss: -0.013936646308138734\n",
+      "        total_loss: 29.070746898651123\n",
+      "        vf_explained_var: 0.9454066157341003\n",
+      "        vf_loss: 29.0831356048584\n",
       "    num_steps_sampled: 808960\n",
       "    num_steps_trained: 808960\n",
       "  iterations_since_restore: 5\n",
@@ -664,81 +653,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.69\n",
-      "    gpu_util_percent0: 0.27466666666666667\n",
+      "    cpu_util_percent: 25.55333333333333\n",
+      "    gpu_util_percent0: 0.4026666666666666\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7733333333333334\n",
+      "    ram_util_percent: 3.7633333333333328\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15796218411921265\n",
-      "    mean_env_wait_ms: 1.1639934756279489\n",
-      "    mean_inference_ms: 5.2000617098190585\n",
-      "    mean_raw_obs_processing_ms: 0.4209348049282861\n",
-      "  time_since_restore: 131.93419408798218\n",
-      "  time_this_iter_s: 25.734494924545288\n",
-      "  time_total_s: 131.93419408798218\n",
+      "    mean_action_processing_ms: 0.15932651553390745\n",
+      "    mean_env_wait_ms: 1.167247236922676\n",
+      "    mean_inference_ms: 5.105156955761531\n",
+      "    mean_raw_obs_processing_ms: 0.4241619853874412\n",
+      "  time_since_restore: 132.39279627799988\n",
+      "  time_this_iter_s: 25.98088049888611\n",
+      "  time_total_s: 132.39279627799988\n",
       "  timers:\n",
-      "    learn_throughput: 8680.33\n",
-      "    learn_time_ms: 18638.923\n",
-      "    sample_throughput: 21108.552\n",
-      "    sample_time_ms: 7664.761\n",
-      "    update_time_ms: 36.284\n",
-      "  timestamp: 1602447626\n",
+      "    learn_throughput: 8644.99\n",
+      "    learn_time_ms: 18715.117\n",
+      "    sample_throughput: 21124.511\n",
+      "    sample_time_ms: 7658.97\n",
+      "    update_time_ms: 44.841\n",
+      "  timestamp: 1602505953\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 808960\n",
       "  training_iteration: 5\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      5 |          131.934 | 808960 |  220.185 |              280.566 |              75.8687 |            878.037 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      5 |          132.393 | 808960 |  223.373 |              277.081 |              133.899 |            882.616 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3584.0131208997186\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-20-51\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3562.2380487804876\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_12-32-59\n",
       "  done: false\n",
-      "  episode_len_mean: 870.7881278538813\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 224.09796596097948\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 305\n",
-      "  episodes_total: 1095\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 875.4055080721747\n",
+      "  episode_reward_max: 278.89898989898927\n",
+      "  episode_reward_mean: 225.90998302109395\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 263\n",
+      "  episodes_total: 1053\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0736289421717327\n",
+      "        entropy: 1.0669801433881123\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.0076567893071721\n",
+      "        kl: 0.010119187956055006\n",
       "        model: {}\n",
-      "        policy_loss: -0.012293024260240296\n",
-      "        total_loss: 33.63621966044108\n",
-      "        vf_explained_var: 0.9586592316627502\n",
-      "        vf_loss: 33.64828300476074\n",
+      "        policy_loss: -0.014624884177464992\n",
+      "        total_loss: 30.67037757237752\n",
+      "        vf_explained_var: 0.9617660641670227\n",
+      "        vf_loss: 30.683512210845947\n",
       "    num_steps_sampled: 970752\n",
       "    num_steps_trained: 970752\n",
       "  iterations_since_restore: 6\n",
@@ -746,81 +735,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.536666666666672\n",
-      "    gpu_util_percent0: 0.28833333333333333\n",
+      "    cpu_util_percent: 24.896774193548392\n",
+      "    gpu_util_percent0: 0.4380645161290322\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.766666666666666\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
+      "    ram_util_percent: 3.7645161290322577\n",
+      "    vram_util_percent0: 0.10437848474909812\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15607596891536865\n",
-      "    mean_env_wait_ms: 1.1671366247994843\n",
-      "    mean_inference_ms: 5.0500729045139465\n",
-      "    mean_raw_obs_processing_ms: 0.4143215108904387\n",
-      "  time_since_restore: 157.5549192428589\n",
-      "  time_this_iter_s: 25.62072515487671\n",
-      "  time_total_s: 157.5549192428589\n",
+      "    mean_action_processing_ms: 0.15758373732759218\n",
+      "    mean_env_wait_ms: 1.1697938862862185\n",
+      "    mean_inference_ms: 4.993265760954177\n",
+      "    mean_raw_obs_processing_ms: 0.41869440795286283\n",
+      "  time_since_restore: 158.20772171020508\n",
+      "  time_this_iter_s: 25.8149254322052\n",
+      "  time_total_s: 158.20772171020508\n",
       "  timers:\n",
-      "    learn_throughput: 8674.401\n",
-      "    learn_time_ms: 18651.663\n",
-      "    sample_throughput: 21499.526\n",
-      "    sample_time_ms: 7525.375\n",
-      "    update_time_ms: 33.988\n",
-      "  timestamp: 1602447651\n",
+      "    learn_throughput: 8650.438\n",
+      "    learn_time_ms: 18703.33\n",
+      "    sample_throughput: 21428.196\n",
+      "    sample_time_ms: 7550.426\n",
+      "    update_time_ms: 54.438\n",
+      "  timestamp: 1602505979\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 970752\n",
       "  training_iteration: 6\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      6 |          157.555 | 970752 |  224.098 |              280.566 |              75.8687 |            870.788 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      6 |          158.208 | 970752 |   225.91 |              278.899 |              133.899 |            875.406 |\n",
       "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3570.73786407767\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-17\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3547.7540453074434\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_12-33-25\n",
       "  done: false\n",
-      "  episode_len_mean: 867.189082278481\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 226.04501502365406\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 169\n",
+      "  episode_len_mean: 868.5514240506329\n",
+      "  episode_reward_max: 278.89898989898927\n",
+      "  episode_reward_mean: 228.15807601329732\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 211\n",
       "  episodes_total: 1264\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0686622162659962\n",
+      "        entropy: 1.0668786863485973\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007437769207172096\n",
+      "        kl: 0.012256689059237639\n",
       "        model: {}\n",
-      "        policy_loss: -0.012086212953969758\n",
-      "        total_loss: 20.895000457763672\n",
-      "        vf_explained_var: 0.9618611931800842\n",
-      "        vf_loss: 20.906877199808758\n",
+      "        policy_loss: -0.01610318278350557\n",
+      "        total_loss: 20.370780150095623\n",
+      "        vf_explained_var: 0.963979959487915\n",
+      "        vf_loss: 20.384966214497883\n",
       "    num_steps_sampled: 1132544\n",
       "    num_steps_trained: 1132544\n",
       "  iterations_since_restore: 7\n",
@@ -828,81 +817,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.313\n",
+      "    cpu_util_percent: 24.853333333333335\n",
+      "    gpu_util_percent0: 0.34933333333333333\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
+      "    ram_util_percent: 3.766666666666666\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1553269146624884\n",
-      "    mean_env_wait_ms: 1.1685347068037049\n",
-      "    mean_inference_ms: 4.989185923698291\n",
-      "    mean_raw_obs_processing_ms: 0.41171449184267606\n",
-      "  time_since_restore: 183.35250997543335\n",
-      "  time_this_iter_s: 25.797590732574463\n",
-      "  time_total_s: 183.35250997543335\n",
+      "    mean_action_processing_ms: 0.15657329873395373\n",
+      "    mean_env_wait_ms: 1.1718041449096683\n",
+      "    mean_inference_ms: 4.928618743314384\n",
+      "    mean_raw_obs_processing_ms: 0.4154075703104024\n",
+      "  time_since_restore: 184.31369256973267\n",
+      "  time_this_iter_s: 26.105970859527588\n",
+      "  time_total_s: 184.31369256973267\n",
       "  timers:\n",
-      "    learn_throughput: 8659.305\n",
-      "    learn_time_ms: 18684.179\n",
-      "    sample_throughput: 21782.079\n",
-      "    sample_time_ms: 7427.757\n",
-      "    update_time_ms: 32.583\n",
-      "  timestamp: 1602447677\n",
+      "    learn_throughput: 8635.087\n",
+      "    learn_time_ms: 18736.58\n",
+      "    sample_throughput: 21626.365\n",
+      "    sample_time_ms: 7481.239\n",
+      "    update_time_ms: 52.288\n",
+      "  timestamp: 1602506005\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1132544\n",
       "  training_iteration: 7\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      7 |          183.353 | 1132544 |  226.045 |              280.566 |              75.8687 |            867.189 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      7 |          184.314 | 1132544 |  228.158 |              278.899 |              133.899 |            868.551 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3558.4670014347203\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-21-43\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3536.647776183644\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_12-33-51\n",
       "  done: false\n",
-      "  episode_len_mean: 863.3881856540085\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 227.5396155649319\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 862.704641350211\n",
+      "  episode_reward_max: 278.89898989898927\n",
+      "  episode_reward_mean: 229.98016025231198\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1422\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0467442870140076\n",
+      "        entropy: 1.0334690809249878\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00735667875657479\n",
+      "        kl: 0.010793289790550867\n",
       "        model: {}\n",
-      "        policy_loss: -0.012476529033544162\n",
-      "        total_loss: 16.631463209788006\n",
-      "        vf_explained_var: 0.9689691066741943\n",
-      "        vf_loss: 16.643727620442707\n",
+      "        policy_loss: -0.015747709141578525\n",
+      "        total_loss: 15.715624650319418\n",
+      "        vf_explained_var: 0.969296395778656\n",
+      "        vf_loss: 15.729730685551962\n",
       "    num_steps_sampled: 1294336\n",
       "    num_steps_trained: 1294336\n",
       "  iterations_since_restore: 8\n",
@@ -910,81 +899,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666667\n",
-      "    gpu_util_percent0: 0.3546666666666667\n",
+      "    cpu_util_percent: 25.253333333333334\n",
+      "    gpu_util_percent0: 0.391\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7866666666666666\n",
+      "    ram_util_percent: 3.776666666666666\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547256264044939\n",
-      "    mean_env_wait_ms: 1.1697889323469424\n",
-      "    mean_inference_ms: 4.941149080036455\n",
-      "    mean_raw_obs_processing_ms: 0.4095648767577179\n",
-      "  time_since_restore: 208.95958399772644\n",
-      "  time_this_iter_s: 25.60707402229309\n",
-      "  time_total_s: 208.95958399772644\n",
+      "    mean_action_processing_ms: 0.1559479711492542\n",
+      "    mean_env_wait_ms: 1.1733561902991976\n",
+      "    mean_inference_ms: 4.888176842818723\n",
+      "    mean_raw_obs_processing_ms: 0.4133021243199457\n",
+      "  time_since_restore: 210.29469919204712\n",
+      "  time_this_iter_s: 25.981006622314453\n",
+      "  time_total_s: 210.29469919204712\n",
       "  timers:\n",
-      "    learn_throughput: 8657.699\n",
-      "    learn_time_ms: 18687.644\n",
-      "    sample_throughput: 22008.019\n",
-      "    sample_time_ms: 7351.502\n",
-      "    update_time_ms: 31.768\n",
-      "  timestamp: 1602447703\n",
+      "    learn_throughput: 8632.364\n",
+      "    learn_time_ms: 18742.491\n",
+      "    sample_throughput: 21765.348\n",
+      "    sample_time_ms: 7433.467\n",
+      "    update_time_ms: 49.493\n",
+      "  timestamp: 1602506031\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1294336\n",
       "  training_iteration: 8\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      8 |           208.96 | 1294336 |   227.54 |              280.566 |              75.8687 |            863.388 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      8 |          210.295 | 1294336 |   229.98 |              278.899 |              133.899 |            862.705 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3548.3775773195875\n",
-      "    time_step_min: 3238\n",
-      "  date: 2020-10-11_20-22-08\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3525.568943298969\n",
+      "    time_step_min: 3215\n",
+      "  date: 2020-10-12_12-34-17\n",
       "  done: false\n",
-      "  episode_len_mean: 859.5791139240506\n",
-      "  episode_reward_max: 280.5656565656561\n",
-      "  episode_reward_mean: 229.39314026339326\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 857.1208860759493\n",
+      "  episode_reward_max: 279.3535353535359\n",
+      "  episode_reward_mean: 231.70662319396482\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 1580\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0254518787066143\n",
+      "        entropy: 1.0033017992973328\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007505126879550517\n",
+      "        kl: 0.010770521514738599\n",
       "        model: {}\n",
-      "        policy_loss: -0.013200220981768021\n",
-      "        total_loss: 16.60719045003255\n",
-      "        vf_explained_var: 0.9654716849327087\n",
-      "        vf_loss: 16.620153188705444\n",
+      "        policy_loss: -0.015525121105990062\n",
+      "        total_loss: 16.273523728052776\n",
+      "        vf_explained_var: 0.9674468040466309\n",
+      "        vf_loss: 16.28739635149638\n",
       "    num_steps_sampled: 1456128\n",
       "    num_steps_trained: 1456128\n",
       "  iterations_since_restore: 9\n",
@@ -992,81 +981,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.97586206896552\n",
-      "    gpu_util_percent0: 0.373103448275862\n",
+      "    cpu_util_percent: 24.610000000000003\n",
+      "    gpu_util_percent0: 0.27566666666666667\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7689655172413787\n",
+      "    ram_util_percent: 3.77\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15420505835699988\n",
-      "    mean_env_wait_ms: 1.1709664764376828\n",
-      "    mean_inference_ms: 4.899308239449433\n",
-      "    mean_raw_obs_processing_ms: 0.4076704455336656\n",
-      "  time_since_restore: 234.6318006515503\n",
-      "  time_this_iter_s: 25.672216653823853\n",
-      "  time_total_s: 234.6318006515503\n",
+      "    mean_action_processing_ms: 0.15539724462957527\n",
+      "    mean_env_wait_ms: 1.175024142163589\n",
+      "    mean_inference_ms: 4.852607294414321\n",
+      "    mean_raw_obs_processing_ms: 0.41139122673210116\n",
+      "  time_since_restore: 236.31488513946533\n",
+      "  time_this_iter_s: 26.020185947418213\n",
+      "  time_total_s: 236.31488513946533\n",
       "  timers:\n",
-      "    learn_throughput: 8657.476\n",
-      "    learn_time_ms: 18688.125\n",
-      "    sample_throughput: 22163.621\n",
-      "    sample_time_ms: 7299.89\n",
-      "    update_time_ms: 32.627\n",
-      "  timestamp: 1602447728\n",
+      "    learn_throughput: 8625.483\n",
+      "    learn_time_ms: 18757.443\n",
+      "    sample_throughput: 21885.114\n",
+      "    sample_time_ms: 7392.787\n",
+      "    update_time_ms: 46.251\n",
+      "  timestamp: 1602506057\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1456128\n",
       "  training_iteration: 9\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |      9 |          234.632 | 1456128 |  229.393 |              280.566 |              75.8687 |            859.579 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |      9 |          236.315 | 1456128 |  231.707 |              279.354 |              133.899 |            857.121 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3530.453984287318\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-22-34\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3504.7218934911243\n",
+      "    time_step_min: 3186\n",
+      "  date: 2020-10-12_12-34-43\n",
       "  done: false\n",
-      "  episode_len_mean: 855.0779005524862\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 231.6610859981024\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 230\n",
-      "  episodes_total: 1810\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 847.3826179120297\n",
+      "  episode_reward_max: 284.0505050505049\n",
+      "  episode_reward_mean: 234.9192882722293\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 307\n",
+      "  episodes_total: 1887\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9783310542503992\n",
+      "        entropy: 0.9698180854320526\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007558321657901009\n",
+      "        kl: 0.008762541770314177\n",
       "        model: {}\n",
-      "        policy_loss: -0.012323003092509074\n",
-      "        total_loss: 21.252121289571125\n",
-      "        vf_explained_var: 0.9696983695030212\n",
-      "        vf_loss: 21.264177322387695\n",
+      "        policy_loss: -0.011754670903125467\n",
+      "        total_loss: 22.15676514307658\n",
+      "        vf_explained_var: 0.9699413776397705\n",
+      "        vf_loss: 22.167253017425537\n",
       "    num_steps_sampled: 1617920\n",
       "    num_steps_trained: 1617920\n",
       "  iterations_since_restore: 10\n",
@@ -1074,81 +1063,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.10322580645162\n",
-      "    gpu_util_percent0: 0.44322580645161286\n",
+      "    cpu_util_percent: 24.686666666666667\n",
+      "    gpu_util_percent0: 0.25466666666666665\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
+      "    ram_util_percent: 3.763333333333333\n",
+      "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15357945616241028\n",
-      "    mean_env_wait_ms: 1.1729293401628718\n",
-      "    mean_inference_ms: 4.848476154423788\n",
-      "    mean_raw_obs_processing_ms: 0.4053396875096163\n",
-      "  time_since_restore: 260.496376991272\n",
-      "  time_this_iter_s: 25.86457633972168\n",
-      "  time_total_s: 260.496376991272\n",
+      "    mean_action_processing_ms: 0.15453766769147795\n",
+      "    mean_env_wait_ms: 1.1787124191264264\n",
+      "    mean_inference_ms: 4.796413184950241\n",
+      "    mean_raw_obs_processing_ms: 0.40843775652716663\n",
+      "  time_since_restore: 262.18814992904663\n",
+      "  time_this_iter_s: 25.8732647895813\n",
+      "  time_total_s: 262.18814992904663\n",
       "  timers:\n",
-      "    learn_throughput: 8649.232\n",
-      "    learn_time_ms: 18705.938\n",
-      "    sample_throughput: 22309.364\n",
-      "    sample_time_ms: 7252.201\n",
-      "    update_time_ms: 32.981\n",
-      "  timestamp: 1602447754\n",
+      "    learn_throughput: 8627.415\n",
+      "    learn_time_ms: 18753.242\n",
+      "    sample_throughput: 21977.845\n",
+      "    sample_time_ms: 7361.595\n",
+      "    update_time_ms: 44.093\n",
+      "  timestamp: 1602506083\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1617920\n",
       "  training_iteration: 10\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     10 |          260.496 | 1617920 |  231.661 |              282.838 |              75.8687 |            855.078 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     10 |          262.188 | 1617920 |  234.919 |              284.051 |              133.899 |            847.383 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3515.8815399802565\n",
-      "    time_step_min: 3189\n",
-      "  date: 2020-10-11_20-23-00\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3494.990128331688\n",
+      "    time_step_min: 3159\n",
+      "  date: 2020-10-12_12-35-09\n",
       "  done: false\n",
-      "  episode_len_mean: 851.3515092502435\n",
-      "  episode_reward_max: 282.83838383838395\n",
-      "  episode_reward_mean: 233.5874027519596\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 244\n",
+      "  episode_len_mean: 842.626582278481\n",
+      "  episode_reward_max: 287.38383838383817\n",
+      "  episode_reward_mean: 236.53693212553955\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 167\n",
       "  episodes_total: 2054\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9831370264291763\n",
+      "        entropy: 0.959399938583374\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007093390799127519\n",
+      "        kl: 0.009050344349816442\n",
       "        model: {}\n",
-      "        policy_loss: -0.012145887061099833\n",
-      "        total_loss: 15.38879140218099\n",
-      "        vf_explained_var: 0.9745174050331116\n",
-      "        vf_loss: 15.400719245274862\n",
+      "        policy_loss: -0.014448691198291877\n",
+      "        total_loss: 14.143741130828857\n",
+      "        vf_explained_var: 0.9704552292823792\n",
+      "        vf_loss: 14.156859795252482\n",
       "    num_steps_sampled: 1779712\n",
       "    num_steps_trained: 1779712\n",
       "  iterations_since_restore: 11\n",
@@ -1156,81 +1145,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.058620689655175\n",
-      "    gpu_util_percent0: 0.34068965517241384\n",
+      "    cpu_util_percent: 24.470000000000006\n",
+      "    gpu_util_percent0: 0.31033333333333335\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.772413793103448\n",
+      "    ram_util_percent: 3.7766666666666664\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15299769941749414\n",
-      "    mean_env_wait_ms: 1.174449037632307\n",
-      "    mean_inference_ms: 4.802499299001492\n",
-      "    mean_raw_obs_processing_ms: 0.40323562982226707\n",
-      "  time_since_restore: 285.89834547042847\n",
-      "  time_this_iter_s: 25.401968479156494\n",
-      "  time_total_s: 285.89834547042847\n",
+      "    mean_action_processing_ms: 0.1541531067576189\n",
+      "    mean_env_wait_ms: 1.180539782661793\n",
+      "    mean_inference_ms: 4.7710904173214255\n",
+      "    mean_raw_obs_processing_ms: 0.40708730490687545\n",
+      "  time_since_restore: 288.0478582382202\n",
+      "  time_this_iter_s: 25.859708309173584\n",
+      "  time_total_s: 288.0478582382202\n",
       "  timers:\n",
-      "    learn_throughput: 8657.708\n",
-      "    learn_time_ms: 18687.626\n",
-      "    sample_throughput: 23227.447\n",
-      "    sample_time_ms: 6965.552\n",
-      "    update_time_ms: 32.734\n",
-      "  timestamp: 1602447780\n",
+      "    learn_throughput: 8633.513\n",
+      "    learn_time_ms: 18739.996\n",
+      "    sample_throughput: 22654.324\n",
+      "    sample_time_ms: 7141.771\n",
+      "    update_time_ms: 37.934\n",
+      "  timestamp: 1602506109\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1779712\n",
       "  training_iteration: 11\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.1/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     11 |          285.898 | 1779712 |  233.587 |              282.838 |              75.8687 |            851.352 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     11 |          288.048 | 1779712 |  236.537 |              287.384 |              133.899 |            842.627 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3507.2843406593406\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-26\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3486.236721611722\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_12-35-35\n",
       "  done: false\n",
-      "  episode_len_mean: 849.3214285714286\n",
-      "  episode_reward_max: 283.1414141414142\n",
-      "  episode_reward_mean: 234.8278764133193\n",
-      "  episode_reward_min: 75.86868686868725\n",
+      "  episode_len_mean: 839.50226039783\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 237.80845069136197\n",
+      "  episode_reward_min: 133.89898989898964\n",
       "  episodes_this_iter: 158\n",
       "  episodes_total: 2212\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9695532222588857\n",
+      "        entropy: 0.9463174144426981\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006893695720161001\n",
+      "        kl: 0.009074758971109986\n",
       "        model: {}\n",
-      "        policy_loss: -0.013366622074196735\n",
-      "        total_loss: 11.94997787475586\n",
-      "        vf_explained_var: 0.9762477278709412\n",
-      "        vf_loss: 11.963139851888021\n",
+      "        policy_loss: -0.014368217787705362\n",
+      "        total_loss: 10.841783205668131\n",
+      "        vf_explained_var: 0.9763579368591309\n",
+      "        vf_loss: 10.854809761047363\n",
       "    num_steps_sampled: 1941504\n",
       "    num_steps_trained: 1941504\n",
       "  iterations_since_restore: 12\n",
@@ -1238,81 +1227,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.98\n",
-      "    gpu_util_percent0: 0.39133333333333326\n",
+      "    cpu_util_percent: 24.709999999999997\n",
+      "    gpu_util_percent0: 0.304\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7833333333333328\n",
+      "    ram_util_percent: 3.7766666666666664\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15267911592020442\n",
-      "    mean_env_wait_ms: 1.1754082858107124\n",
-      "    mean_inference_ms: 4.7771672423033875\n",
-      "    mean_raw_obs_processing_ms: 0.40206413935896457\n",
-      "  time_since_restore: 311.4134485721588\n",
-      "  time_this_iter_s: 25.515103101730347\n",
-      "  time_total_s: 311.4134485721588\n",
+      "    mean_action_processing_ms: 0.15382456786108878\n",
+      "    mean_env_wait_ms: 1.1821934851322788\n",
+      "    mean_inference_ms: 4.749452794942857\n",
+      "    mean_raw_obs_processing_ms: 0.40591959145529394\n",
+      "  time_since_restore: 314.2713918685913\n",
+      "  time_this_iter_s: 26.223533630371094\n",
+      "  time_total_s: 314.2713918685913\n",
       "  timers:\n",
-      "    learn_throughput: 8665.219\n",
-      "    learn_time_ms: 18671.427\n",
-      "    sample_throughput: 23495.398\n",
-      "    sample_time_ms: 6886.115\n",
-      "    update_time_ms: 31.361\n",
-      "  timestamp: 1602447806\n",
+      "    learn_throughput: 8608.293\n",
+      "    learn_time_ms: 18794.898\n",
+      "    sample_throughput: 22846.513\n",
+      "    sample_time_ms: 7081.693\n",
+      "    update_time_ms: 38.592\n",
+      "  timestamp: 1602506135\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 1941504\n",
       "  training_iteration: 12\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     12 |          311.413 | 1941504 |  234.828 |              283.141 |              75.8687 |            849.321 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     12 |          314.271 | 1941504 |  237.808 |              289.202 |              133.899 |            839.502 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3499.359948761742\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-23-51\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3477.1867900715188\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_12-36-01\n",
       "  done: false\n",
-      "  episode_len_mean: 847.2481012658228\n",
-      "  episode_reward_max: 284.2020202020199\n",
-      "  episode_reward_mean: 236.03087840429595\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 836.276923076923\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 239.12358512358495\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 193\n",
+      "  episodes_total: 2405\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9525636037190756\n",
+      "        entropy: 0.9069925745328268\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007253999511400859\n",
+      "        kl: 0.009530291194096208\n",
       "        model: {}\n",
-      "        policy_loss: -0.011778777848424701\n",
-      "        total_loss: 12.683573007583618\n",
-      "        vf_explained_var: 0.9729364514350891\n",
-      "        vf_loss: 12.695102532704672\n",
+      "        policy_loss: -0.014515867456793785\n",
+      "        total_loss: 15.319237470626831\n",
+      "        vf_explained_var: 0.9747470021247864\n",
+      "        vf_loss: 15.332300901412964\n",
       "    num_steps_sampled: 2103296\n",
       "    num_steps_trained: 2103296\n",
       "  iterations_since_restore: 13\n",
@@ -1320,81 +1309,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.848275862068967\n",
-      "    gpu_util_percent0: 0.4362068965517242\n",
+      "    cpu_util_percent: 24.57333333333333\n",
+      "    gpu_util_percent0: 0.26733333333333337\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7758620689655173\n",
+      "    ram_util_percent: 3.766666666666666\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15238677910288023\n",
-      "    mean_env_wait_ms: 1.1762651426265218\n",
-      "    mean_inference_ms: 4.754077360657\n",
-      "    mean_raw_obs_processing_ms: 0.40096428130312095\n",
-      "  time_since_restore: 336.9129900932312\n",
-      "  time_this_iter_s: 25.499541521072388\n",
-      "  time_total_s: 336.9129900932312\n",
+      "    mean_action_processing_ms: 0.15346836889333854\n",
+      "    mean_env_wait_ms: 1.184240944593027\n",
+      "    mean_inference_ms: 4.725537933532759\n",
+      "    mean_raw_obs_processing_ms: 0.40463245423111577\n",
+      "  time_since_restore: 340.12329864501953\n",
+      "  time_this_iter_s: 25.851906776428223\n",
+      "  time_total_s: 340.12329864501953\n",
       "  timers:\n",
-      "    learn_throughput: 8658.975\n",
-      "    learn_time_ms: 18684.892\n",
-      "    sample_throughput: 23608.495\n",
-      "    sample_time_ms: 6853.126\n",
-      "    update_time_ms: 29.201\n",
-      "  timestamp: 1602447831\n",
+      "    learn_throughput: 8602.467\n",
+      "    learn_time_ms: 18807.627\n",
+      "    sample_throughput: 22905.641\n",
+      "    sample_time_ms: 7063.413\n",
+      "    update_time_ms: 40.411\n",
+      "  timestamp: 1602506161\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2103296\n",
       "  training_iteration: 13\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     13 |          336.913 | 2103296 |  236.031 |              284.202 |              75.8687 |            847.248 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     13 |          340.123 | 2103296 |  239.124 |              289.202 |              133.899 |            836.277 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3489.3022256930885\n",
-      "    time_step_min: 3187\n",
-      "  date: 2020-10-11_20-24-17\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3465.9672686230247\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_12-36-27\n",
       "  done: false\n",
-      "  episode_len_mean: 845.1205098493626\n",
-      "  episode_reward_max: 285.111111111111\n",
-      "  episode_reward_mean: 237.57315916991453\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 219\n",
-      "  episodes_total: 2589\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 832.3082650781831\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 240.80178553968565\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 281\n",
+      "  episodes_total: 2686\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9141986866792043\n",
+      "        entropy: 0.9011691262324651\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006633194202246766\n",
+      "        kl: 0.010886709050585827\n",
       "        model: {}\n",
-      "        policy_loss: -0.011397288045069823\n",
-      "        total_loss: 14.408097267150879\n",
-      "        vf_explained_var: 0.9782162308692932\n",
-      "        vf_loss: 14.419288237889608\n",
+      "        policy_loss: -0.01605825025762897\n",
+      "        total_loss: 13.799258867899576\n",
+      "        vf_explained_var: 0.9779562950134277\n",
+      "        vf_loss: 13.813590288162231\n",
       "    num_steps_sampled: 2265088\n",
       "    num_steps_trained: 2265088\n",
       "  iterations_since_restore: 14\n",
@@ -1402,81 +1391,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 23.483333333333338\n",
-      "    gpu_util_percent0: 0.38299999999999995\n",
+      "    cpu_util_percent: 25.203333333333333\n",
+      "    gpu_util_percent0: 0.39166666666666666\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.77\n",
+      "    ram_util_percent: 3.769999999999999\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15203612506882044\n",
-      "    mean_env_wait_ms: 1.177434403681755\n",
-      "    mean_inference_ms: 4.725975916232662\n",
-      "    mean_raw_obs_processing_ms: 0.3996285154228699\n",
-      "  time_since_restore: 362.68629479408264\n",
-      "  time_this_iter_s: 25.77330470085144\n",
-      "  time_total_s: 362.68629479408264\n",
+      "    mean_action_processing_ms: 0.15301494054162276\n",
+      "    mean_env_wait_ms: 1.1868015832357257\n",
+      "    mean_inference_ms: 4.695915855449172\n",
+      "    mean_raw_obs_processing_ms: 0.4030395525153571\n",
+      "  time_since_restore: 365.95724272727966\n",
+      "  time_this_iter_s: 25.833944082260132\n",
+      "  time_total_s: 365.95724272727966\n",
       "  timers:\n",
-      "    learn_throughput: 8642.561\n",
-      "    learn_time_ms: 18720.378\n",
-      "    sample_throughput: 23665.671\n",
-      "    sample_time_ms: 6836.569\n",
-      "    update_time_ms: 27.867\n",
-      "  timestamp: 1602447857\n",
+      "    learn_throughput: 8610.589\n",
+      "    learn_time_ms: 18789.887\n",
+      "    sample_throughput: 22889.673\n",
+      "    sample_time_ms: 7068.34\n",
+      "    update_time_ms: 39.225\n",
+      "  timestamp: 1602506187\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2265088\n",
       "  training_iteration: 14\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     14 |          362.686 | 2265088 |  237.573 |              285.111 |              75.8687 |            845.121 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     14 |          365.957 | 2265088 |  240.802 |              289.202 |              133.899 |            832.308 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3478.2078152753106\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-24-43\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3459.754971590909\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_12-36-53\n",
       "  done: false\n",
-      "  episode_len_mean: 843.0049243756595\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 239.0910085732455\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 254\n",
-      "  episodes_total: 2843\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 830.3291139240506\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 241.694508374888\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
+      "  episodes_total: 2844\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.906439483165741\n",
+      "        entropy: 0.8705271085103353\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00629633719411989\n",
+      "        kl: 0.010132285223032037\n",
       "        model: {}\n",
-      "        policy_loss: -0.008484600538698336\n",
-      "        total_loss: 13.794315973917643\n",
-      "        vf_explained_var: 0.977971076965332\n",
-      "        vf_loss: 13.802624225616455\n",
+      "        policy_loss: -0.01209646585630253\n",
+      "        total_loss: 9.354986588160196\n",
+      "        vf_explained_var: 0.9806396961212158\n",
+      "        vf_loss: 9.36549154917399\n",
       "    num_steps_sampled: 2426880\n",
       "    num_steps_trained: 2426880\n",
       "  iterations_since_restore: 15\n",
@@ -1484,81 +1473,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.4\n",
-      "    gpu_util_percent0: 0.2956666666666666\n",
+      "    cpu_util_percent: 24.339999999999996\n",
+      "    gpu_util_percent0: 0.354\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769999999999999\n",
+      "    ram_util_percent: 3.7733333333333334\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15166958436902533\n",
-      "    mean_env_wait_ms: 1.1785378851431692\n",
-      "    mean_inference_ms: 4.696807133847539\n",
-      "    mean_raw_obs_processing_ms: 0.39823878821593045\n",
-      "  time_since_restore: 388.19724225997925\n",
-      "  time_this_iter_s: 25.510947465896606\n",
-      "  time_total_s: 388.19724225997925\n",
+      "    mean_action_processing_ms: 0.15279157288304182\n",
+      "    mean_env_wait_ms: 1.188104613473158\n",
+      "    mean_inference_ms: 4.681133757261421\n",
+      "    mean_raw_obs_processing_ms: 0.4022444482464537\n",
+      "  time_since_restore: 391.6302752494812\n",
+      "  time_this_iter_s: 25.673032522201538\n",
+      "  time_total_s: 391.6302752494812\n",
       "  timers:\n",
-      "    learn_throughput: 8641.51\n",
-      "    learn_time_ms: 18722.653\n",
-      "    sample_throughput: 23758.911\n",
-      "    sample_time_ms: 6809.74\n",
-      "    update_time_ms: 28.865\n",
-      "  timestamp: 1602447883\n",
+      "    learn_throughput: 8614.25\n",
+      "    learn_time_ms: 18781.902\n",
+      "    sample_throughput: 22961.178\n",
+      "    sample_time_ms: 7046.328\n",
+      "    update_time_ms: 37.541\n",
+      "  timestamp: 1602506213\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2426880\n",
       "  training_iteration: 15\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     15 |          388.197 | 2426880 |  239.091 |              294.202 |              75.8687 |            843.005 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     15 |           391.63 | 2426880 |  241.695 |              289.202 |              133.899 |            830.329 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3471.2484868863485\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-08\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3454.032279757902\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_12-37-19\n",
       "  done: false\n",
-      "  episode_len_mean: 841.4696868754164\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.07658867152526\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 159\n",
+      "  episode_len_mean: 828.5073284477015\n",
+      "  episode_reward_max: 289.20202020202026\n",
+      "  episode_reward_mean: 242.50461645098542\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 3002\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8939206699530283\n",
+      "        entropy: 0.8471738596757253\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007120410058026512\n",
+      "        kl: 0.009305963292717934\n",
       "        model: {}\n",
-      "        policy_loss: -0.013225489509447167\n",
-      "        total_loss: 11.056419531504313\n",
-      "        vf_explained_var: 0.977925717830658\n",
-      "        vf_loss: 11.069379409154257\n",
+      "        policy_loss: -0.01094130908313673\n",
+      "        total_loss: 10.646601835886637\n",
+      "        vf_explained_var: 0.9784726500511169\n",
+      "        vf_loss: 10.656105756759644\n",
       "    num_steps_sampled: 2588672\n",
       "    num_steps_trained: 2588672\n",
       "  iterations_since_restore: 16\n",
@@ -1566,81 +1555,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.989655172413798\n",
-      "    gpu_util_percent0: 0.32172413793103455\n",
+      "    cpu_util_percent: 25.168965517241375\n",
+      "    gpu_util_percent0: 0.37931034482758613\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
+      "    ram_util_percent: 3.772413793103448\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15146700941909105\n",
-      "    mean_env_wait_ms: 1.1791897641952667\n",
-      "    mean_inference_ms: 4.6806621211616175\n",
-      "    mean_raw_obs_processing_ms: 0.3974652038101286\n",
-      "  time_since_restore: 413.7767312526703\n",
-      "  time_this_iter_s: 25.57948899269104\n",
-      "  time_total_s: 413.7767312526703\n",
+      "    mean_action_processing_ms: 0.15258489228875483\n",
+      "    mean_env_wait_ms: 1.189348100743969\n",
+      "    mean_inference_ms: 4.667388374821382\n",
+      "    mean_raw_obs_processing_ms: 0.4014845687165312\n",
+      "  time_since_restore: 417.28298902511597\n",
+      "  time_this_iter_s: 25.652713775634766\n",
+      "  time_total_s: 417.28298902511597\n",
       "  timers:\n",
-      "    learn_throughput: 8641.857\n",
-      "    learn_time_ms: 18721.903\n",
-      "    sample_throughput: 23771.571\n",
-      "    sample_time_ms: 6806.113\n",
-      "    update_time_ms: 28.84\n",
-      "  timestamp: 1602447908\n",
+      "    learn_throughput: 8611.392\n",
+      "    learn_time_ms: 18788.135\n",
+      "    sample_throughput: 23005.777\n",
+      "    sample_time_ms: 7032.669\n",
+      "    update_time_ms: 29.153\n",
+      "  timestamp: 1602506239\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2588672\n",
       "  training_iteration: 16\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
+      "Memory usage on this node: 28.3/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     16 |          413.777 | 2588672 |  240.077 |              294.202 |              75.8687 |             841.47 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     16 |          417.283 | 2588672 |  242.505 |              289.202 |              133.899 |            828.507 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3464.836845466156\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-34\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3446.2361408882084\n",
+      "    time_step_min: 3147\n",
+      "  date: 2020-10-12_12-37-45\n",
       "  done: false\n",
-      "  episode_len_mean: 839.8240506329114\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 240.94871180155977\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3160\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 825.9881566960219\n",
+      "  episode_reward_max: 289.9595959595964\n",
+      "  episode_reward_mean: 243.72948433622582\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 291\n",
+      "  episodes_total: 3293\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823149502277374\n",
+      "        entropy: 0.8250234176715215\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006691928138025105\n",
+      "        kl: 0.008491925351942578\n",
       "        model: {}\n",
-      "        policy_loss: -0.011884851943856726\n",
-      "        total_loss: 10.509639422098795\n",
-      "        vf_explained_var: 0.9782719612121582\n",
-      "        vf_loss: 10.521296262741089\n",
+      "        policy_loss: -0.014777651784243062\n",
+      "        total_loss: 15.209494908650717\n",
+      "        vf_explained_var: 0.9786728024482727\n",
+      "        vf_loss: 15.222986777623495\n",
       "    num_steps_sampled: 2750464\n",
       "    num_steps_trained: 2750464\n",
       "  iterations_since_restore: 17\n",
@@ -1648,81 +1637,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.383333333333336\n",
-      "    gpu_util_percent0: 0.266\n",
+      "    cpu_util_percent: 23.81666666666667\n",
+      "    gpu_util_percent0: 0.405\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
+      "    ram_util_percent: 3.7599999999999993\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1512813004386509\n",
-      "    mean_env_wait_ms: 1.179821308066897\n",
-      "    mean_inference_ms: 4.665766796337426\n",
-      "    mean_raw_obs_processing_ms: 0.3967421105344154\n",
-      "  time_since_restore: 439.20659351348877\n",
-      "  time_this_iter_s: 25.42986226081848\n",
-      "  time_total_s: 439.20659351348877\n",
+      "    mean_action_processing_ms: 0.15225128410563682\n",
+      "    mean_env_wait_ms: 1.191534804694793\n",
+      "    mean_inference_ms: 4.644749359521727\n",
+      "    mean_raw_obs_processing_ms: 0.4002669504773126\n",
+      "  time_since_restore: 442.85631251335144\n",
+      "  time_this_iter_s: 25.573323488235474\n",
+      "  time_total_s: 442.85631251335144\n",
       "  timers:\n",
-      "    learn_throughput: 8657.028\n",
-      "    learn_time_ms: 18689.092\n",
-      "    sample_throughput: 23787.343\n",
-      "    sample_time_ms: 6801.6\n",
-      "    update_time_ms: 28.419\n",
-      "  timestamp: 1602447934\n",
+      "    learn_throughput: 8621.52\n",
+      "    learn_time_ms: 18766.065\n",
+      "    sample_throughput: 23099.783\n",
+      "    sample_time_ms: 7004.049\n",
+      "    update_time_ms: 27.27\n",
+      "  timestamp: 1602506265\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2750464\n",
       "  training_iteration: 17\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     17 |          439.207 | 2750464 |  240.949 |              294.202 |              75.8687 |            839.824 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     17 |          442.856 | 2750464 |  243.729 |               289.96 |              133.899 |            825.988 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3454.8194444444443\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-25-59\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3440.9040023201856\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_12-38-10\n",
       "  done: false\n",
-      "  episode_len_mean: 837.3622508792497\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 242.37695536845584\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 252\n",
-      "  episodes_total: 3412\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 824.563003452244\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 244.5732671943833\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 183\n",
+      "  episodes_total: 3476\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.851616899172465\n",
+      "        entropy: 0.8241499215364456\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006081323605030775\n",
+      "        kl: 0.007864817045629025\n",
       "        model: {}\n",
-      "        policy_loss: -0.010536718415096402\n",
-      "        total_loss: 13.626426935195923\n",
-      "        vf_explained_var: 0.9793136715888977\n",
-      "        vf_loss: 13.636781613032023\n",
+      "        policy_loss: -0.01140341673938868\n",
+      "        total_loss: 8.79675587018331\n",
+      "        vf_explained_var: 0.9828992486000061\n",
+      "        vf_loss: 8.806998491287231\n",
       "    num_steps_sampled: 2912256\n",
       "    num_steps_trained: 2912256\n",
       "  iterations_since_restore: 18\n",
@@ -1730,81 +1719,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.706666666666663\n",
-      "    gpu_util_percent0: 0.302\n",
+      "    cpu_util_percent: 25.268965517241377\n",
+      "    gpu_util_percent0: 0.32137931034482753\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7633333333333328\n",
+      "    ram_util_percent: 3.772413793103448\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.151021285653716\n",
-      "    mean_env_wait_ms: 1.1808787240074101\n",
-      "    mean_inference_ms: 4.644646637518742\n",
-      "    mean_raw_obs_processing_ms: 0.395716154310957\n",
-      "  time_since_restore: 464.71025347709656\n",
-      "  time_this_iter_s: 25.503659963607788\n",
-      "  time_total_s: 464.71025347709656\n",
+      "    mean_action_processing_ms: 0.152057784099256\n",
+      "    mean_env_wait_ms: 1.1927444276404982\n",
+      "    mean_inference_ms: 4.631954197589499\n",
+      "    mean_raw_obs_processing_ms: 0.3995722632347076\n",
+      "  time_since_restore: 468.4573698043823\n",
+      "  time_this_iter_s: 25.601057291030884\n",
+      "  time_total_s: 468.4573698043823\n",
       "  timers:\n",
-      "    learn_throughput: 8660.443\n",
-      "    learn_time_ms: 18681.723\n",
-      "    sample_throughput: 23804.094\n",
-      "    sample_time_ms: 6796.814\n",
-      "    update_time_ms: 29.145\n",
-      "  timestamp: 1602447959\n",
+      "    learn_throughput: 8625.27\n",
+      "    learn_time_ms: 18757.906\n",
+      "    sample_throughput: 23193.06\n",
+      "    sample_time_ms: 6975.88\n",
+      "    update_time_ms: 26.475\n",
+      "  timestamp: 1602506290\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 2912256\n",
       "  training_iteration: 18\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     18 |           464.71 | 2912256 |  242.377 |              294.202 |              75.8687 |            837.362 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     18 |          468.457 | 2912256 |  244.573 |              296.626 |              133.899 |            824.563 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3447.6802551303385\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-25\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3436.840266222962\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_12-38-36\n",
       "  done: false\n",
-      "  episode_len_mean: 835.4837644468905\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 243.5167414374898\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 222\n",
+      "  episode_len_mean: 823.8428728673638\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 245.09397497262097\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 158\n",
       "  episodes_total: 3634\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8403268406788508\n",
+      "        entropy: 0.8113949745893478\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006061406301644941\n",
+      "        kl: 0.008743428780386845\n",
       "        model: {}\n",
-      "        policy_loss: -0.008233758644716241\n",
-      "        total_loss: 10.79630970954895\n",
-      "        vf_explained_var: 0.9808487892150879\n",
-      "        vf_loss: 10.804357449213663\n",
+      "        policy_loss: -0.012751462903300611\n",
+      "        total_loss: 8.8964794476827\n",
+      "        vf_explained_var: 0.9816879630088806\n",
+      "        vf_loss: 8.907887935638428\n",
       "    num_steps_sampled: 3074048\n",
       "    num_steps_trained: 3074048\n",
       "  iterations_since_restore: 19\n",
@@ -1812,81 +1801,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.273333333333333\n",
-      "    gpu_util_percent0: 0.40166666666666667\n",
+      "    cpu_util_percent: 24.160000000000004\n",
+      "    gpu_util_percent0: 0.31700000000000006\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7766666666666664\n",
+      "    ram_util_percent: 3.773333333333333\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15079811866017936\n",
-      "    mean_env_wait_ms: 1.1816707724435114\n",
-      "    mean_inference_ms: 4.627169590964196\n",
-      "    mean_raw_obs_processing_ms: 0.3948970998715084\n",
-      "  time_since_restore: 490.4313905239105\n",
-      "  time_this_iter_s: 25.721137046813965\n",
-      "  time_total_s: 490.4313905239105\n",
+      "    mean_action_processing_ms: 0.15190300447660146\n",
+      "    mean_env_wait_ms: 1.1937104261191516\n",
+      "    mean_inference_ms: 4.621606530580184\n",
+      "    mean_raw_obs_processing_ms: 0.3990076443002664\n",
+      "  time_since_restore: 494.1212737560272\n",
+      "  time_this_iter_s: 25.663903951644897\n",
+      "  time_total_s: 494.1212737560272\n",
       "  timers:\n",
-      "    learn_throughput: 8653.987\n",
-      "    learn_time_ms: 18695.661\n",
-      "    sample_throughput: 23843.805\n",
-      "    sample_time_ms: 6785.494\n",
-      "    update_time_ms: 30.641\n",
-      "  timestamp: 1602447985\n",
+      "    learn_throughput: 8633.094\n",
+      "    learn_time_ms: 18740.905\n",
+      "    sample_throughput: 23256.792\n",
+      "    sample_time_ms: 6956.763\n",
+      "    update_time_ms: 26.349\n",
+      "  timestamp: 1602506316\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3074048\n",
       "  training_iteration: 19\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     19 |          490.431 | 3074048 |  243.517 |              294.202 |              75.8687 |            835.484 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     19 |          494.121 | 3074048 |  245.094 |              296.626 |              133.899 |            823.843 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3442.4577577045698\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-26-51\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3432.525217850541\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_12-39-02\n",
       "  done: false\n",
-      "  episode_len_mean: 833.8357067510549\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 244.24585251246634\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 823.0579292267365\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 245.79004990931585\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 181\n",
+      "  episodes_total: 3815\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8331598043441772\n",
+      "        entropy: 0.7609985868136088\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006495586984480421\n",
+      "        kl: 0.00916624628007412\n",
       "        model: {}\n",
-      "        policy_loss: -0.011495542149835577\n",
-      "        total_loss: 9.008565505345663\n",
-      "        vf_explained_var: 0.9805734753608704\n",
-      "        vf_loss: 9.019828001658121\n",
+      "        policy_loss: -0.012107667707217237\n",
+      "        total_loss: 10.657151778539022\n",
+      "        vf_explained_var: 0.9814252257347107\n",
+      "        vf_loss: 10.66780686378479\n",
       "    num_steps_sampled: 3235840\n",
       "    num_steps_trained: 3235840\n",
       "  iterations_since_restore: 20\n",
@@ -1894,81 +1883,81 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 25.196551724137933\n",
-      "    gpu_util_percent0: 0.44793103448275867\n",
+      "    cpu_util_percent: 25.175862068965515\n",
+      "    gpu_util_percent0: 0.36344827586206896\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7827586206896546\n",
+      "    ram_util_percent: 3.76551724137931\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1506571880081456\n",
-      "    mean_env_wait_ms: 1.1822421411112307\n",
-      "    mean_inference_ms: 4.615975210350845\n",
-      "    mean_raw_obs_processing_ms: 0.39436020417931467\n",
-      "  time_since_restore: 515.9194169044495\n",
-      "  time_this_iter_s: 25.48802638053894\n",
-      "  time_total_s: 515.9194169044495\n",
+      "    mean_action_processing_ms: 0.15173262102728452\n",
+      "    mean_env_wait_ms: 1.194739519238314\n",
+      "    mean_inference_ms: 4.6104790880218705\n",
+      "    mean_raw_obs_processing_ms: 0.3983916300855253\n",
+      "  time_since_restore: 519.5943777561188\n",
+      "  time_this_iter_s: 25.473104000091553\n",
+      "  time_total_s: 519.5943777561188\n",
       "  timers:\n",
-      "    learn_throughput: 8662.909\n",
-      "    learn_time_ms: 18676.405\n",
-      "    sample_throughput: 23887.718\n",
-      "    sample_time_ms: 6773.02\n",
-      "    update_time_ms: 31.114\n",
-      "  timestamp: 1602448011\n",
+      "    learn_throughput: 8634.98\n",
+      "    learn_time_ms: 18736.812\n",
+      "    sample_throughput: 23382.066\n",
+      "    sample_time_ms: 6919.491\n",
+      "    update_time_ms: 26.922\n",
+      "  timestamp: 1602506342\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3235840\n",
       "  training_iteration: 20\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
+      "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     20 |          515.919 | 3235840 |  244.246 |              294.202 |              75.8687 |            833.836 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     20 |          519.594 | 3235840 |   245.79 |              296.626 |              133.899 |            823.058 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
       "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
+      "Result for PPO_jss_env_ad858_00000:\n",
       "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3437.3735398679532\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-17\n",
+      "    time_step_max: 4172\n",
+      "    time_step_mean: 3425.473593711619\n",
+      "    time_step_min: 3098\n",
+      "  date: 2020-10-12_12-39-28\n",
       "  done: false\n",
-      "  episode_len_mean: 832.0063035804337\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 245.05460810831454\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 174\n",
-      "  episodes_total: 3966\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
+      "  episode_len_mean: 821.8972920224445\n",
+      "  episode_reward_max: 296.62626262626276\n",
+      "  episode_reward_mean: 246.80025184758034\n",
+      "  episode_reward_min: 133.89898989898964\n",
+      "  episodes_this_iter: 284\n",
+      "  episodes_total: 4099\n",
+      "  experiment_id: d2d95ffef53c4f8ba545f23c7d900134\n",
       "  experiment_tag: '0'\n",
       "  hostname: f85e62b52919\n",
       "  info:\n",
       "    learner:\n",
       "      default_policy:\n",
       "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
+      "        cur_kl_coeff: 0.20000000000000004\n",
       "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8113537778457006\n",
+      "        entropy: 0.7578712403774261\n",
       "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00662113749422133\n",
+      "        kl: 0.0086368964985013\n",
       "        model: {}\n",
-      "        policy_loss: -0.010862251704869172\n",
-      "        total_loss: 9.200959205627441\n",
-      "        vf_explained_var: 0.9829750061035156\n",
-      "        vf_loss: 9.211564620335897\n",
+      "        policy_loss: -0.011422600480727851\n",
+      "        total_loss: 10.725571791330973\n",
+      "        vf_explained_var: 0.9839944839477539\n",
+      "        vf_loss: 10.735645691553751\n",
       "    num_steps_sampled: 3397632\n",
       "    num_steps_trained: 3397632\n",
       "  iterations_since_restore: 21\n",
@@ -1976,4460 +1965,56 @@
       "  num_healthy_workers: 79\n",
       "  off_policy_estimator: {}\n",
       "  perf:\n",
-      "    cpu_util_percent: 24.746666666666666\n",
-      "    gpu_util_percent0: 0.43233333333333335\n",
+      "    cpu_util_percent: 24.413333333333338\n",
+      "    gpu_util_percent0: 0.36233333333333334\n",
       "    gpu_util_percent1: 0.0\n",
       "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.783333333333333\n",
+      "    ram_util_percent: 3.763333333333333\n",
       "    vram_util_percent0: 0.10437848474909811\n",
       "    vram_util_percent1: 0.0\n",
       "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
+      "  pid: 57679\n",
       "  policy_reward_max: {}\n",
       "  policy_reward_mean: {}\n",
       "  policy_reward_min: {}\n",
       "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1505154580684014\n",
-      "    mean_env_wait_ms: 1.1829182364579118\n",
-      "    mean_inference_ms: 4.604545436836301\n",
-      "    mean_raw_obs_processing_ms: 0.393806888186482\n",
-      "  time_since_restore: 541.447582244873\n",
-      "  time_this_iter_s: 25.528165340423584\n",
-      "  time_total_s: 541.447582244873\n",
+      "    mean_action_processing_ms: 0.15149336115425896\n",
+      "    mean_env_wait_ms: 1.196135945498552\n",
+      "    mean_inference_ms: 4.5943737192150405\n",
+      "    mean_raw_obs_processing_ms: 0.39750761177887367\n",
+      "  time_since_restore: 545.1678259372711\n",
+      "  time_this_iter_s: 25.573448181152344\n",
+      "  time_total_s: 545.1678259372711\n",
       "  timers:\n",
-      "    learn_throughput: 8659.833\n",
-      "    learn_time_ms: 18683.039\n",
-      "    sample_throughput: 23874.125\n",
-      "    sample_time_ms: 6776.877\n",
-      "    update_time_ms: 32.246\n",
-      "  timestamp: 1602448037\n",
+      "    learn_throughput: 8638.164\n",
+      "    learn_time_ms: 18729.907\n",
+      "    sample_throughput: 23454.768\n",
+      "    sample_time_ms: 6898.043\n",
+      "    update_time_ms: 25.122\n",
+      "  timestamp: 1602506368\n",
       "  timesteps_since_restore: 0\n",
       "  timesteps_total: 3397632\n",
       "  training_iteration: 21\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     21 |          541.448 | 3397632 |  245.055 |              294.202 |              75.8687 |            832.006 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3429.0718336483933\n",
-      "    time_step_min: 3114\n",
-      "  date: 2020-10-11_20-27-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 829.4262910798122\n",
-      "  episode_reward_max: 294.20202020201987\n",
-      "  episode_reward_mean: 246.28809218950053\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 294\n",
-      "  episodes_total: 4260\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7864142805337906\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006753043349211414\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010421635362339051\n",
-      "        total_loss: 12.085295756657919\n",
-      "        vf_explained_var: 0.9821670055389404\n",
-      "        vf_loss: 12.095435539881388\n",
-      "    num_steps_sampled: 3559424\n",
-      "    num_steps_trained: 3559424\n",
-      "  iterations_since_restore: 22\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.77666666666666\n",
-      "    gpu_util_percent0: 0.35666666666666663\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.773333333333333\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15028690275812004\n",
-      "    mean_env_wait_ms: 1.1839689693172888\n",
-      "    mean_inference_ms: 4.58657535166017\n",
-      "    mean_raw_obs_processing_ms: 0.39294259805891246\n",
-      "  time_since_restore: 567.0153458118439\n",
-      "  time_this_iter_s: 25.567763566970825\n",
-      "  time_total_s: 567.0153458118439\n",
-      "  timers:\n",
-      "    learn_throughput: 8657.11\n",
-      "    learn_time_ms: 18688.916\n",
-      "    sample_throughput: 23884.796\n",
-      "    sample_time_ms: 6773.849\n",
-      "    update_time_ms: 33.756\n",
-      "  timestamp: 1602448062\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3559424\n",
-      "  training_iteration: 22\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     22 |          567.015 | 3559424 |  246.288 |              294.202 |              75.8687 |            829.426 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3424.5079617834394\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-08\n",
-      "  done: false\n",
-      "  episode_len_mean: 828.3363471971066\n",
-      "  episode_reward_max: 296.9292929292926\n",
-      "  episode_reward_mean: 246.92703253146288\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 164\n",
-      "  episodes_total: 4424\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7751223593950272\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006270660436712205\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012993110887085399\n",
-      "        total_loss: 9.126743952433268\n",
-      "        vf_explained_var: 0.9815302491188049\n",
-      "        vf_loss: 9.13949735959371\n",
-      "    num_steps_sampled: 3721216\n",
-      "    num_steps_trained: 3721216\n",
-      "  iterations_since_restore: 23\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.034482758620694\n",
-      "    gpu_util_percent0: 0.37655172413793103\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7793103448275853\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15016941325618596\n",
-      "    mean_env_wait_ms: 1.1844954628333266\n",
-      "    mean_inference_ms: 4.577346269372596\n",
-      "    mean_raw_obs_processing_ms: 0.3924992256454737\n",
-      "  time_since_restore: 592.4772689342499\n",
-      "  time_this_iter_s: 25.461923122406006\n",
-      "  time_total_s: 592.4772689342499\n",
-      "  timers:\n",
-      "    learn_throughput: 8658.163\n",
-      "    learn_time_ms: 18686.643\n",
-      "    sample_throughput: 23893.516\n",
-      "    sample_time_ms: 6771.377\n",
-      "    update_time_ms: 35.505\n",
-      "  timestamp: 1602448088\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3721216\n",
-      "  training_iteration: 23\n",
-      "  trial_id: dfeb0_00000\n",
+      "  trial_id: ad858_00000\n",
       "  \n",
       "== Status ==\n",
       "Memory usage on this node: 28.2/754.6 GiB\n",
       "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
+      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
       "Result logdir: /root/ray_results/ppo-jss\n",
       "Number of trials: 1 (1 RUNNING)\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
       "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | RUNNING  | 172.17.0.4:48597 |     23 |          592.477 | 3721216 |  246.927 |              296.929 |              75.8687 |            828.336 |\n",
+      "| PPO_jss_env_ad858_00000 | RUNNING  | 172.17.0.4:57679 |     21 |          545.168 | 3397632 |    246.8 |              296.626 |              133.899 |            821.897 |\n",
       "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
       "\n",
-      "\n",
-      "Result for PPO_jss_env_dfeb0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4555\n",
-      "    time_step_mean: 3420.217391304348\n",
-      "    time_step_min: 3096\n",
-      "  date: 2020-10-11_20-28-34\n",
-      "  done: true\n",
-      "  episode_len_mean: 827.2712789175033\n",
-      "  episode_reward_max: 298.59595959595964\n",
-      "  episode_reward_mean: 247.62179190420122\n",
-      "  episode_reward_min: 75.86868686868725\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 4582\n",
-      "  experiment_id: 486c986d2ff845b0b26d77aba5b4b507\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7690570255120596\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006819716926353673\n",
-      "        model: {}\n",
-      "        policy_loss: -0.011298634965593616\n",
-      "        total_loss: 7.405012885729472\n",
-      "        vf_explained_var: 0.9835589528083801\n",
-      "        vf_loss: 7.416013916333516\n",
-      "    num_steps_sampled: 3883008\n",
-      "    num_steps_trained: 3883008\n",
-      "  iterations_since_restore: 24\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.09666666666667\n",
-      "    gpu_util_percent0: 0.37433333333333335\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7899999999999996\n",
-      "    vram_util_percent0: 0.10437848474909811\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 48597\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1500637869801008\n",
-      "    mean_env_wait_ms: 1.1850024778129549\n",
-      "    mean_inference_ms: 4.568983072556478\n",
-      "    mean_raw_obs_processing_ms: 0.3920924925269654\n",
-      "  time_since_restore: 618.0373919010162\n",
-      "  time_this_iter_s: 25.560122966766357\n",
-      "  time_total_s: 618.0373919010162\n",
-      "  timers:\n",
-      "    learn_throughput: 8670.217\n",
-      "    learn_time_ms: 18660.662\n",
-      "    sample_throughput: 23876.765\n",
-      "    sample_time_ms: 6776.127\n",
-      "    update_time_ms: 34.493\n",
-      "  timestamp: 1602448114\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3883008\n",
-      "  training_iteration: 24\n",
-      "  trial_id: dfeb0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.2 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dfeb0_00000 | TERMINATED |       |     24 |          618.037 | 3883008 |  247.622 |              298.596 |              75.8687 |            827.271 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 48369\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_201802-90w2swxq/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3096\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 632\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448114\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4555\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3420.21739\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 298.59596\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 75.86869\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 247.62179\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 4582\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 24\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mgrateful-sweep-1\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/90w2swxq\u001b[0m\n",
-      "2020-10-11 20:28:41,103 - wandb.wandb_agent - INFO - Cleaning up finished run: 90w2swxq\n",
-      "2020-10-11 20:28:41,455 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:28:41,456 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 30\n",
-      "2020-10-11 20:28:41,460 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=30\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:28:46,478 - wandb.wandb_agent - INFO - Running runs: ['4ndtcjlt']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mpolar-sweep-2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_202843-4ndtcjlt\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:28:47,317\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=74346)\u001b[0m 2020-10-11 20:28:50,076\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74354)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74369)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74323)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74315)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74353)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74322)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74332)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74304)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74326)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74372)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74317)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74320)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74337)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74254)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74309)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74351)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74272)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74253)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74340)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74314)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74308)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74240)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74269)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74321)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74327)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74325)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74361)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74364)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74324)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74257)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74244)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74359)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74335)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74274)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74350)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74243)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74355)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74239)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74279)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74343)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74277)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74301)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74348)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74256)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74316)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74299)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74306)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74362)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74258)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74252)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74265)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74347)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74300)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74357)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74255)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74312)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74370)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74310)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74298)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74319)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74313)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74366)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74318)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74345)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74373)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74249)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=74311)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-29-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1820389827092488\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007561812836987277\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01091390458168462\n",
-      "        total_loss: 502.23597717285156\n",
-      "        vf_explained_var: 0.5664147734642029\n",
-      "        vf_loss: 502.24672444661456\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 27.674358974358974\n",
-      "    gpu_util_percent0: 0.37230769230769234\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5717948717948715\n",
-      "    vram_util_percent0: 0.08725223065990534\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.17197728193847803\n",
-      "    mean_env_wait_ms: 1.178965817339886\n",
-      "    mean_inference_ms: 6.060176406535295\n",
-      "    mean_raw_obs_processing_ms: 0.4615727896011697\n",
-      "  time_since_restore: 31.85646414756775\n",
-      "  time_this_iter_s: 31.85646414756775\n",
-      "  time_total_s: 31.85646414756775\n",
-      "  timers:\n",
-      "    learn_throughput: 7259.825\n",
-      "    learn_time_ms: 22285.937\n",
-      "    sample_throughput: 17058.896\n",
-      "    sample_time_ms: 9484.318\n",
-      "    update_time_ms: 45.763\n",
-      "  timestamp: 1602448167\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 27.7/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      1 |          31.8565 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4081\n",
-      "    time_step_mean: 3626.375\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-29-57\n",
-      "  done: false\n",
-      "  episode_len_mean: 889.8101265822785\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 216.46036312491984\n",
-      "  episode_reward_min: 139.20202020202004\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1471269528071086\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010032878257334232\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01112406033401688\n",
-      "        total_loss: 125.25241088867188\n",
-      "        vf_explained_var: 0.815872848033905\n",
-      "        vf_loss: 125.26310539245605\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 24.586486486486486\n",
-      "    gpu_util_percent0: 0.37729729729729733\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7567567567567575\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16762130233769734\n",
-      "    mean_env_wait_ms: 1.173220641390085\n",
-      "    mean_inference_ms: 5.799851321192781\n",
-      "    mean_raw_obs_processing_ms: 0.45053682537598116\n",
-      "  time_since_restore: 61.79887557029724\n",
-      "  time_this_iter_s: 29.942411422729492\n",
-      "  time_total_s: 61.79887557029724\n",
-      "  timers:\n",
-      "    learn_throughput: 7317.922\n",
-      "    learn_time_ms: 22109.009\n",
-      "    sample_throughput: 18578.114\n",
-      "    sample_time_ms: 8708.742\n",
-      "    update_time_ms: 34.225\n",
-      "  timestamp: 1602448197\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      2 |          61.7989 | 323584 |   216.46 |              269.505 |              139.202 |             889.81 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3622.3206278026905\n",
-      "    time_step_min: 3314\n",
-      "  date: 2020-10-11_20-30-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 885.367088607595\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 217.77988748241893\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.138877511024475\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010077035520225763\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014173034539756676\n",
-      "        total_loss: 56.67084821065267\n",
-      "        vf_explained_var: 0.9027066826820374\n",
-      "        vf_loss: 56.68458398183187\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.597222222222225\n",
-      "    gpu_util_percent0: 0.36972222222222223\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7777777777777786\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16479804064831216\n",
-      "    mean_env_wait_ms: 1.1720182606622203\n",
-      "    mean_inference_ms: 5.603008625003064\n",
-      "    mean_raw_obs_processing_ms: 0.4426390955890892\n",
-      "  time_since_restore: 91.3730297088623\n",
-      "  time_this_iter_s: 29.574154138565063\n",
-      "  time_total_s: 91.3730297088623\n",
-      "  timers:\n",
-      "    learn_throughput: 7328.404\n",
-      "    learn_time_ms: 22077.385\n",
-      "    sample_throughput: 19490.783\n",
-      "    sample_time_ms: 8300.949\n",
-      "    update_time_ms: 32.102\n",
-      "  timestamp: 1602448227\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      3 |           91.373 | 485376 |   217.78 |              269.505 |              121.929 |            885.367 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3609.298013245033\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-30-56\n",
-      "  done: false\n",
-      "  episode_len_mean: 880.4335443037975\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 219.6016653880576\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1205872495969136\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008317627167950073\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014852196210995317\n",
-      "        total_loss: 35.135284423828125\n",
-      "        vf_explained_var: 0.9348650574684143\n",
-      "        vf_loss: 35.149864196777344\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.81142857142857\n",
-      "    gpu_util_percent0: 0.38428571428571434\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7800000000000002\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16266713864790658\n",
-      "    mean_env_wait_ms: 1.1719507465280838\n",
-      "    mean_inference_ms: 5.452768291637971\n",
-      "    mean_raw_obs_processing_ms: 0.436093704889682\n",
-      "  time_since_restore: 120.51979207992554\n",
-      "  time_this_iter_s: 29.146762371063232\n",
-      "  time_total_s: 120.51979207992554\n",
-      "  timers:\n",
-      "    learn_throughput: 7340.701\n",
-      "    learn_time_ms: 22040.402\n",
-      "    sample_throughput: 20214.027\n",
-      "    sample_time_ms: 8003.947\n",
-      "    update_time_ms: 33.725\n",
-      "  timestamp: 1602448256\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      4 |           120.52 | 647168 |  219.602 |              269.505 |              121.929 |            880.434 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3595.94750656168\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-31-25\n",
-      "  done: false\n",
-      "  episode_len_mean: 875.0151898734177\n",
-      "  episode_reward_max: 269.5050505050499\n",
-      "  episode_reward_mean: 221.3562204321696\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 790\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0882032910982768\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008978756920744976\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014062516507692635\n",
-      "        total_loss: 24.341053009033203\n",
-      "        vf_explained_var: 0.9578109383583069\n",
-      "        vf_loss: 24.354761441548664\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.808333333333337\n",
-      "    gpu_util_percent0: 0.41361111111111115\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16103095813233778\n",
-      "    mean_env_wait_ms: 1.172911624714945\n",
-      "    mean_inference_ms: 5.334074757563843\n",
-      "    mean_raw_obs_processing_ms: 0.4305471554597205\n",
-      "  time_since_restore: 149.58945155143738\n",
-      "  time_this_iter_s: 29.06965947151184\n",
-      "  time_total_s: 149.58945155143738\n",
-      "  timers:\n",
-      "    learn_throughput: 7347.418\n",
-      "    learn_time_ms: 22020.252\n",
-      "    sample_throughput: 20703.622\n",
-      "    sample_time_ms: 7814.671\n",
-      "    update_time_ms: 31.711\n",
-      "  timestamp: 1602448285\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      5 |          149.589 | 808960 |  221.356 |              269.505 |              121.929 |            875.015 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3570.9396471680593\n",
-      "    time_step_min: 3272\n",
-      "  date: 2020-10-11_20-31-54\n",
-      "  done: false\n",
-      "  episode_len_mean: 865.3411764705883\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 225.14456785045004\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 315\n",
-      "  episodes_total: 1105\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.081368327140808\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008393583974490562\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01229041333620747\n",
-      "        total_loss: 30.566396554311115\n",
-      "        vf_explained_var: 0.9602224230766296\n",
-      "        vf_loss: 30.578388055165608\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3971428571428571\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.765714285714286\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1587676819904807\n",
-      "    mean_env_wait_ms: 1.1762866754320034\n",
-      "    mean_inference_ms: 5.169591608338926\n",
-      "    mean_raw_obs_processing_ms: 0.42300377666355576\n",
-      "  time_since_restore: 178.9720721244812\n",
-      "  time_this_iter_s: 29.382620573043823\n",
-      "  time_total_s: 178.9720721244812\n",
-      "  timers:\n",
-      "    learn_throughput: 7334.048\n",
-      "    learn_time_ms: 22060.394\n",
-      "    sample_throughput: 21058.022\n",
-      "    sample_time_ms: 7683.153\n",
-      "    update_time_ms: 33.041\n",
-      "  timestamp: 1602448314\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      6 |          178.972 | 970752 |  225.145 |              276.778 |              121.929 |            865.341 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3559.6480582524273\n",
-      "    time_step_min: 3259\n",
-      "  date: 2020-10-11_20-32-24\n",
-      "  done: false\n",
-      "  episode_len_mean: 861.2610759493671\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 226.75584164429083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 159\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0704743762811024\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008557675794387857\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01505787695835655\n",
-      "        total_loss: 16.039914925893147\n",
-      "        vf_explained_var: 0.9693781733512878\n",
-      "        vf_loss: 16.054652611414593\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.458333333333332\n",
-      "    gpu_util_percent0: 0.3652777777777778\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7861111111111123\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15792926470213106\n",
-      "    mean_env_wait_ms: 1.1776823803388836\n",
-      "    mean_inference_ms: 5.108482278862465\n",
-      "    mean_raw_obs_processing_ms: 0.4201292178903985\n",
-      "  time_since_restore: 208.08675360679626\n",
-      "  time_this_iter_s: 29.114681482315063\n",
-      "  time_total_s: 208.08675360679626\n",
-      "  timers:\n",
-      "    learn_throughput: 7335.151\n",
-      "    learn_time_ms: 22057.079\n",
-      "    sample_throughput: 21336.833\n",
-      "    sample_time_ms: 7582.756\n",
-      "    update_time_ms: 32.936\n",
-      "  timestamp: 1602448344\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      7 |          208.087 | 1132544 |  226.756 |              276.778 |              121.929 |            861.261 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3547.9497847919656\n",
-      "    time_step_min: 3243\n",
-      "  date: 2020-10-11_20-32-53\n",
-      "  done: false\n",
-      "  episode_len_mean: 858.2039381153305\n",
-      "  episode_reward_max: 276.7777777777776\n",
-      "  episode_reward_mean: 228.44124792226046\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0472288727760315\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008639561710879207\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015043328690808266\n",
-      "        total_loss: 14.895620028177897\n",
-      "        vf_explained_var: 0.9694356322288513\n",
-      "        vf_loss: 14.910322825113932\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.274285714285718\n",
-      "    gpu_util_percent0: 0.3857142857142858\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15720379894543632\n",
-      "    mean_env_wait_ms: 1.1788712271360022\n",
-      "    mean_inference_ms: 5.055485147389075\n",
-      "    mean_raw_obs_processing_ms: 0.41757554097071403\n",
-      "  time_since_restore: 237.2246127128601\n",
-      "  time_this_iter_s: 29.137859106063843\n",
-      "  time_total_s: 237.2246127128601\n",
-      "  timers:\n",
-      "    learn_throughput: 7334.405\n",
-      "    learn_time_ms: 22059.322\n",
-      "    sample_throughput: 21547.818\n",
-      "    sample_time_ms: 7508.51\n",
-      "    update_time_ms: 31.659\n",
-      "  timestamp: 1602448373\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      8 |          237.225 | 1294336 |  228.441 |              276.778 |              121.929 |            858.204 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3537.53543814433\n",
-      "    time_step_min: 3226\n",
-      "  date: 2020-10-11_20-33-22\n",
-      "  done: false\n",
-      "  episode_len_mean: 855.6518987341772\n",
-      "  episode_reward_max: 281.17171717171726\n",
-      "  episode_reward_mean: 229.99124152921607\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.015722543001175\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008050314267165959\n",
-      "        model: {}\n",
-      "        policy_loss: -0.016199174404998\n",
-      "        total_loss: 14.030672391255697\n",
-      "        vf_explained_var: 0.9713940024375916\n",
-      "        vf_loss: 14.046574354171753\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.55\n",
-      "    gpu_util_percent0: 0.3569444444444445\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7750000000000004\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1565664082884177\n",
-      "    mean_env_wait_ms: 1.179921473586243\n",
-      "    mean_inference_ms: 5.008992086650131\n",
-      "    mean_raw_obs_processing_ms: 0.4152688863683933\n",
-      "  time_since_restore: 266.55099987983704\n",
-      "  time_this_iter_s: 29.32638716697693\n",
-      "  time_total_s: 266.55099987983704\n",
-      "  timers:\n",
-      "    learn_throughput: 7326.864\n",
-      "    learn_time_ms: 22082.026\n",
-      "    sample_throughput: 21714.677\n",
-      "    sample_time_ms: 7450.813\n",
-      "    update_time_ms: 30.511\n",
-      "  timestamp: 1602448402\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |      9 |          266.551 | 1456128 |  229.991 |              281.172 |              121.929 |            855.652 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3520.743295019157\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-33-52\n",
-      "  done: false\n",
-      "  episode_len_mean: 850.9762803234502\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 232.5573252743063\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 275\n",
-      "  episodes_total: 1855\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9801995704571406\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008376963630629083\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013380672792360807\n",
-      "        total_loss: 17.90494426091512\n",
-      "        vf_explained_var: 0.9745662212371826\n",
-      "        vf_loss: 17.91797685623169\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.352777777777774\n",
-      "    gpu_util_percent0: 0.4316666666666667\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.761111111111111\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1556438503127995\n",
-      "    mean_env_wait_ms: 1.1818997761514678\n",
-      "    mean_inference_ms: 4.942037577056882\n",
-      "    mean_raw_obs_processing_ms: 0.4119487772103422\n",
-      "  time_since_restore: 295.92345571517944\n",
-      "  time_this_iter_s: 29.372455835342407\n",
-      "  time_total_s: 295.92345571517944\n",
-      "  timers:\n",
-      "    learn_throughput: 7317.051\n",
-      "    learn_time_ms: 22111.64\n",
-      "    sample_throughput: 21890.999\n",
-      "    sample_time_ms: 7390.8\n",
-      "    update_time_ms: 31.144\n",
-      "  timestamp: 1602448432\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     10 |          295.923 | 1617920 |  232.557 |              286.929 |              121.929 |            850.976 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3511.523692003949\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-21\n",
-      "  done: false\n",
-      "  episode_len_mean: 848.3286270691334\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 233.83599382333549\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 199\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9715732336044312\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007677830173633993\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01453752441254134\n",
-      "        total_loss: 11.66528328259786\n",
-      "        vf_explained_var: 0.9783375859260559\n",
-      "        vf_loss: 11.679538249969482\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.15714285714286\n",
-      "    gpu_util_percent0: 0.39285714285714285\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.782857142857143\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15509423026677763\n",
-      "    mean_env_wait_ms: 1.1832091255108494\n",
-      "    mean_inference_ms: 4.901368530769214\n",
-      "    mean_raw_obs_processing_ms: 0.41003195858099223\n",
-      "  time_since_restore: 325.0179567337036\n",
-      "  time_this_iter_s: 29.09450101852417\n",
-      "  time_total_s: 325.0179567337036\n",
-      "  timers:\n",
-      "    learn_throughput: 7322.545\n",
-      "    learn_time_ms: 22095.051\n",
-      "    sample_throughput: 22691.255\n",
-      "    sample_time_ms: 7130.148\n",
-      "    update_time_ms: 30.79\n",
-      "  timestamp: 1602448461\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     11 |          325.018 | 1779712 |  233.836 |              286.929 |              121.929 |            848.329 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3504.3699633699634\n",
-      "    time_step_min: 3178\n",
-      "  date: 2020-10-11_20-34-50\n",
-      "  done: false\n",
-      "  episode_len_mean: 846.2716998191681\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 235.09083602754478\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9553611228863398\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007482029924479623\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014144674564401308\n",
-      "        total_loss: 11.647562901178995\n",
-      "        vf_explained_var: 0.9759584069252014\n",
-      "        vf_loss: 11.661436955134073\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.317142857142855\n",
-      "    gpu_util_percent0: 0.39085714285714285\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.782857142857143\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15470167612416874\n",
-      "    mean_env_wait_ms: 1.184108459453786\n",
-      "    mean_inference_ms: 4.872707948353993\n",
-      "    mean_raw_obs_processing_ms: 0.40860797230340906\n",
-      "  time_since_restore: 354.16708421707153\n",
-      "  time_this_iter_s: 29.14912748336792\n",
-      "  time_total_s: 354.16708421707153\n",
-      "  timers:\n",
-      "    learn_throughput: 7315.174\n",
-      "    learn_time_ms: 22117.314\n",
-      "    sample_throughput: 23025.185\n",
-      "    sample_time_ms: 7026.74\n",
-      "    update_time_ms: 32.609\n",
-      "  timestamp: 1602448490\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     12 |          354.167 | 1941504 |  235.091 |              286.929 |              121.929 |            846.272 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3497.5670367207513\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-20\n",
-      "  done: false\n",
-      "  episode_len_mean: 844.135864978903\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 236.12517580872006\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9278469234704971\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007884405087679625\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015948789776302874\n",
-      "        total_loss: 10.545268694559732\n",
-      "        vf_explained_var: 0.9787933826446533\n",
-      "        vf_loss: 10.560892899831137\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.094444444444445\n",
-      "    gpu_util_percent0: 0.4186111111111111\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7722222222222235\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15434316168002962\n",
-      "    mean_env_wait_ms: 1.184977046153128\n",
-      "    mean_inference_ms: 4.846469455238201\n",
-      "    mean_raw_obs_processing_ms: 0.40728119664442336\n",
-      "  time_since_restore: 383.4679665565491\n",
-      "  time_this_iter_s: 29.30088233947754\n",
-      "  time_total_s: 383.4679665565491\n",
-      "  timers:\n",
-      "    learn_throughput: 7300.976\n",
-      "    learn_time_ms: 22160.325\n",
-      "    sample_throughput: 23265.469\n",
-      "    sample_time_ms: 6954.169\n",
-      "    update_time_ms: 33.753\n",
-      "  timestamp: 1602448520\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     13 |          383.468 | 2103296 |  236.125 |              286.929 |              121.929 |            844.136 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3485.74210726512\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-35-49\n",
-      "  done: false\n",
-      "  episode_len_mean: 840.0508091832894\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.07121649312083\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 287\n",
-      "  episodes_total: 2657\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9033511777718862\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006811460247263312\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013252816175130041\n",
-      "        total_loss: 14.124323924382528\n",
-      "        vf_explained_var: 0.9795716404914856\n",
-      "        vf_loss: 14.137347300847372\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.24\n",
-      "    gpu_util_percent0: 0.37342857142857144\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7714285714285714\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15377376909228957\n",
-      "    mean_env_wait_ms: 1.1865557477384137\n",
-      "    mean_inference_ms: 4.804878489409233\n",
-      "    mean_raw_obs_processing_ms: 0.4051869038850363\n",
-      "  time_since_restore: 412.62345147132874\n",
-      "  time_this_iter_s: 29.155484914779663\n",
-      "  time_total_s: 412.62345147132874\n",
-      "  timers:\n",
-      "    learn_throughput: 7291.538\n",
-      "    learn_time_ms: 22189.008\n",
-      "    sample_throughput: 23355.346\n",
-      "    sample_time_ms: 6927.408\n",
-      "    update_time_ms: 33.737\n",
-      "  timestamp: 1602448549\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     14 |          412.623 | 2265088 |  238.071 |              286.929 |              121.929 |            840.051 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3479.8014914772725\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-18\n",
-      "  done: false\n",
-      "  episode_len_mean: 838.0256680731364\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 238.9295166858457\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 187\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8823518455028534\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007345292794828613\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014912535432207127\n",
-      "        total_loss: 9.4028111298879\n",
-      "        vf_explained_var: 0.9823583960533142\n",
-      "        vf_loss: 9.41743008295695\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.594285714285714\n",
-      "    gpu_util_percent0: 0.4091428571428571\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7885714285714283\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1534524084488191\n",
-      "    mean_env_wait_ms: 1.1875469379038355\n",
-      "    mean_inference_ms: 4.781234687782602\n",
-      "    mean_raw_obs_processing_ms: 0.4040137555262904\n",
-      "  time_since_restore: 441.5714144706726\n",
-      "  time_this_iter_s: 28.947962999343872\n",
-      "  time_total_s: 441.5714144706726\n",
-      "  timers:\n",
-      "    learn_throughput: 7287.175\n",
-      "    learn_time_ms: 22202.292\n",
-      "    sample_throughput: 23451.507\n",
-      "    sample_time_ms: 6899.002\n",
-      "    update_time_ms: 35.815\n",
-      "  timestamp: 1602448578\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     15 |          441.571 | 2426880 |   238.93 |              286.929 |              121.929 |            838.026 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3475.086751849361\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-36-47\n",
-      "  done: false\n",
-      "  episode_len_mean: 836.580946035976\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 239.68230607204615\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3002\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8759780476490656\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007468625747909148\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012898257254467657\n",
-      "        total_loss: 10.490220069885254\n",
-      "        vf_explained_var: 0.9782711863517761\n",
-      "        vf_loss: 10.502809524536133\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.662857142857145\n",
-      "    gpu_util_percent0: 0.42\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.788571428571429\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1532049529621475\n",
-      "    mean_env_wait_ms: 1.1882989106782562\n",
-      "    mean_inference_ms: 4.7629533971774105\n",
-      "    mean_raw_obs_processing_ms: 0.40308729415103295\n",
-      "  time_since_restore: 470.55639243125916\n",
-      "  time_this_iter_s: 28.984977960586548\n",
-      "  time_total_s: 470.55639243125916\n",
-      "  timers:\n",
-      "    learn_throughput: 7291.648\n",
-      "    learn_time_ms: 22188.674\n",
-      "    sample_throughput: 23534.563\n",
-      "    sample_time_ms: 6874.655\n",
-      "    update_time_ms: 34.0\n",
-      "  timestamp: 1602448607\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     16 |          470.556 | 2588672 |  239.682 |              286.929 |              121.929 |            836.581 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3469.9057024530107\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-16\n",
-      "  done: false\n",
-      "  episode_len_mean: 835.2096621408273\n",
-      "  episode_reward_max: 286.92929292929296\n",
-      "  episode_reward_mean: 240.46451888636915\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 165\n",
-      "  episodes_total: 3167\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.852495531241099\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00796507477449874\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014005369856022298\n",
-      "        total_loss: 12.690512498219809\n",
-      "        vf_explained_var: 0.977016270160675\n",
-      "        vf_loss: 12.704147736231485\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.3897142857142857\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7771428571428576\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1529640052308357\n",
-      "    mean_env_wait_ms: 1.1890237117333837\n",
-      "    mean_inference_ms: 4.74519824859565\n",
-      "    mean_raw_obs_processing_ms: 0.4021687288610967\n",
-      "  time_since_restore: 499.5002360343933\n",
-      "  time_this_iter_s: 28.943843603134155\n",
-      "  time_total_s: 499.5002360343933\n",
-      "  timers:\n",
-      "    learn_throughput: 7290.38\n",
-      "    learn_time_ms: 22192.533\n",
-      "    sample_throughput: 23605.312\n",
-      "    sample_time_ms: 6854.051\n",
-      "    update_time_ms: 34.588\n",
-      "  timestamp: 1602448636\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     17 |            499.5 | 2750464 |  240.465 |              286.929 |              121.929 |             835.21 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3460.8975254730713\n",
-      "    time_step_min: 3172\n",
-      "  date: 2020-10-11_20-37-45\n",
-      "  done: false\n",
-      "  episode_len_mean: 833.2304360381172\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 241.8702269591671\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 296\n",
-      "  episodes_total: 3463\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8307255059480667\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007045873751242955\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01215925798896933\n",
-      "        total_loss: 12.891058842341105\n",
-      "        vf_explained_var: 0.9813470840454102\n",
-      "        vf_loss: 12.902929147084555\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.39444444444444\n",
-      "    gpu_util_percent0: 0.37611111111111106\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.769444444444445\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15257348075562227\n",
-      "    mean_env_wait_ms: 1.190223232808066\n",
-      "    mean_inference_ms: 4.716765364778451\n",
-      "    mean_raw_obs_processing_ms: 0.4007276342320052\n",
-      "  time_since_restore: 528.7100386619568\n",
-      "  time_this_iter_s: 29.209802627563477\n",
-      "  time_total_s: 528.7100386619568\n",
-      "  timers:\n",
-      "    learn_throughput: 7282.324\n",
-      "    learn_time_ms: 22217.084\n",
-      "    sample_throughput: 23670.713\n",
-      "    sample_time_ms: 6835.113\n",
-      "    update_time_ms: 35.605\n",
-      "  timestamp: 1602448665\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     18 |           528.71 | 2912256 |   241.87 |              291.778 |              121.929 |             833.23 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3454.902384914032\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-15\n",
-      "  done: false\n",
-      "  episode_len_mean: 831.9851403412218\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 242.68078139679676\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 171\n",
-      "  episodes_total: 3634\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259735157092413\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.006872209099431832\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013244140621585151\n",
-      "        total_loss: 8.755500555038452\n",
-      "        vf_explained_var: 0.9823317527770996\n",
-      "        vf_loss: 8.768470366795858\n",
-      "    num_steps_sampled: 3074048\n",
-      "    num_steps_trained: 3074048\n",
-      "  iterations_since_restore: 19\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.642857142857142\n",
-      "    gpu_util_percent0: 0.4\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15237407849355733\n",
-      "    mean_env_wait_ms: 1.1908777392592924\n",
-      "    mean_inference_ms: 4.701934814500055\n",
-      "    mean_raw_obs_processing_ms: 0.3999776278068825\n",
-      "  time_since_restore: 557.9314706325531\n",
-      "  time_this_iter_s: 29.221431970596313\n",
-      "  time_total_s: 557.9314706325531\n",
-      "  timers:\n",
-      "    learn_throughput: 7280.232\n",
-      "    learn_time_ms: 22223.467\n",
-      "    sample_throughput: 23734.777\n",
-      "    sample_time_ms: 6816.664\n",
-      "    update_time_ms: 36.199\n",
-      "  timestamp: 1602448695\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3074048\n",
-      "  training_iteration: 19\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     19 |          557.931 | 3074048 |  242.681 |              291.778 |              121.929 |            831.985 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3450.175345377258\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-38-44\n",
-      "  done: false\n",
-      "  episode_len_mean: 830.9298523206751\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 243.33396464646458\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3792\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8259675403436025\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007086256169714034\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014026373353165885\n",
-      "        total_loss: 8.932533502578735\n",
-      "        vf_explained_var: 0.9804465770721436\n",
-      "        vf_loss: 8.946264505386353\n",
-      "    num_steps_sampled: 3235840\n",
-      "    num_steps_trained: 3235840\n",
-      "  iterations_since_restore: 20\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.333333333333332\n",
-      "    gpu_util_percent0: 0.34388888888888886\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7888888888888896\n",
-      "    vram_util_percent0: 0.1043784847490981\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1521992790788445\n",
-      "    mean_env_wait_ms: 1.1914171815739172\n",
-      "    mean_inference_ms: 4.6890953823501\n",
-      "    mean_raw_obs_processing_ms: 0.39931785266421166\n",
-      "  time_since_restore: 587.2469084262848\n",
-      "  time_this_iter_s: 29.31543779373169\n",
-      "  time_total_s: 587.2469084262848\n",
-      "  timers:\n",
-      "    learn_throughput: 7277.52\n",
-      "    learn_time_ms: 22231.749\n",
-      "    sample_throughput: 23771.576\n",
-      "    sample_time_ms: 6806.112\n",
-      "    update_time_ms: 35.896\n",
-      "  timestamp: 1602448724\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3235840\n",
-      "  training_iteration: 20\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | RUNNING  | 172.17.0.4:74346 |     20 |          587.247 | 3235840 |  243.334 |              291.778 |              121.929 |             830.93 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_5e4a4_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4251\n",
-      "    time_step_mean: 3444.209372637944\n",
-      "    time_step_min: 3135\n",
-      "  date: 2020-10-11_20-39-13\n",
-      "  done: true\n",
-      "  episode_len_mean: 829.7485614210658\n",
-      "  episode_reward_max: 291.7777777777776\n",
-      "  episode_reward_mean: 244.23336947154803\n",
-      "  episode_reward_min: 121.92929292929249\n",
-      "  episodes_this_iter: 205\n",
-      "  episodes_total: 3997\n",
-      "  experiment_id: 7ed96af8337946e88ad3be2393f93a7c\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.7932304640611013\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007863614863405624\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013052704744040966\n",
-      "        total_loss: 8.696449995040894\n",
-      "        vf_explained_var: 0.9847684502601624\n",
-      "        vf_loss: 8.709113121032715\n",
-      "    num_steps_sampled: 3397632\n",
-      "    num_steps_trained: 3397632\n",
-      "  iterations_since_restore: 21\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 22.822857142857142\n",
-      "    gpu_util_percent0: 0.41600000000000004\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7714285714285722\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 74346\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15199085982895233\n",
-      "    mean_env_wait_ms: 1.1921048958466818\n",
-      "    mean_inference_ms: 4.67351707422206\n",
-      "    mean_raw_obs_processing_ms: 0.3985042407825798\n",
-      "  time_since_restore: 616.376526594162\n",
-      "  time_this_iter_s: 29.129618167877197\n",
-      "  time_total_s: 616.376526594162\n",
-      "  timers:\n",
-      "    learn_throughput: 7273.12\n",
-      "    learn_time_ms: 22245.198\n",
-      "    sample_throughput: 23807.886\n",
-      "    sample_time_ms: 6795.731\n",
-      "    update_time_ms: 35.623\n",
-      "  timestamp: 1602448753\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 3397632\n",
-      "  training_iteration: 21\n",
-      "  trial_id: 5e4a4_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_5e4a4_00000 | TERMINATED |       |     21 |          616.377 | 3397632 |  244.233 |              291.778 |              121.929 |            829.749 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 74132\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_202843-4ndtcjlt/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3135\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 631\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602448754\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4251\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3444.20937\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 291.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 121.92929\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 244.23337\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3997\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 21\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mpolar-sweep-2\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4ndtcjlt\u001b[0m\n",
-      "2020-10-11 20:39:22,411 - wandb.wandb_agent - INFO - Cleaning up finished run: 4ndtcjlt\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:39:22,752 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.1\n",
-      "\tnum_sgd_iter: 35\n",
-      "2020-10-11 20:39:22,755 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.1 --num_sgd_iter=35\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:39:27,770 - wandb.wandb_agent - INFO - Running runs: ['4lvdkknr']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msplendid-sweep-3\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_203924-4lvdkknr\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:39:28,572\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=15842)\u001b[0m 2020-10-11 20:39:31,348\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15826)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15799)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15838)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15744)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15865)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15866)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15792)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15820)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15816)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15832)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15812)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15830)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15813)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15775)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15825)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15860)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15868)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15876)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15877)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15800)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15765)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15818)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15739)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15766)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15737)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15819)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15853)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15810)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15758)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15869)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15808)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15755)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15828)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15811)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15757)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15741)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15858)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15847)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15753)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15859)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15795)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15846)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15762)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15749)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15738)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15872)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15802)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15746)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15852)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15833)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15748)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15840)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15740)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15751)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15862)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15774)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15760)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15743)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15805)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15767)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15814)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15807)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15817)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15844)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15835)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15736)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15750)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15854)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15849)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15759)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15834)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15773)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15809)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15806)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15769)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15752)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15747)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15764)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=15827)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-40-12\n",
-      "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1813993354638417\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007591694826260209\n",
-      "        model: {}\n",
-      "        policy_loss: -0.012553695759076314\n",
-      "        total_loss: 500.41192626953125\n",
-      "        vf_explained_var: 0.5819632411003113\n",
-      "        vf_loss: 500.42430623372394\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.811363636363637\n",
-      "    gpu_util_percent0: 0.31227272727272726\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5909090909090895\n",
-      "    vram_util_percent0: 0.08942201616029101\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16739492248554\n",
-      "    mean_env_wait_ms: 1.1652346855698266\n",
-      "    mean_inference_ms: 5.5060321204858855\n",
-      "    mean_raw_obs_processing_ms: 0.44000907090020136\n",
-      "  time_since_restore: 35.872936725616455\n",
-      "  time_this_iter_s: 35.872936725616455\n",
-      "  time_total_s: 35.872936725616455\n",
-      "  timers:\n",
-      "    learn_throughput: 6001.037\n",
-      "    learn_time_ms: 26960.675\n",
-      "    sample_throughput: 18322.175\n",
-      "    sample_time_ms: 8830.393\n",
-      "    update_time_ms: 41.968\n",
-      "  timestamp: 1602448812\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 27.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      1 |          35.8729 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3613.684027777778\n",
-      "    time_step_min: 3358\n",
-      "  date: 2020-10-11_20-40-47\n",
-      "  done: false\n",
-      "  episode_len_mean: 888.5917721518987\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 217.0985487789283\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.149230072895686\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00951601347575585\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01619932148605585\n",
-      "        total_loss: 120.9416898091634\n",
-      "        vf_explained_var: 0.8221778273582458\n",
-      "        vf_loss: 120.95751126607259\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 21.199999999999996\n",
-      "    gpu_util_percent0: 0.32047619047619047\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.76904761904762\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16326572534453276\n",
-      "    mean_env_wait_ms: 1.1632587587181373\n",
-      "    mean_inference_ms: 5.312069869064258\n",
-      "    mean_raw_obs_processing_ms: 0.43039064260126914\n",
-      "  time_since_restore: 70.36755323410034\n",
-      "  time_this_iter_s: 34.49461650848389\n",
-      "  time_total_s: 70.36755323410034\n",
-      "  timers:\n",
-      "    learn_throughput: 6017.136\n",
-      "    learn_time_ms: 26888.542\n",
-      "    sample_throughput: 19703.911\n",
-      "    sample_time_ms: 8211.162\n",
-      "    update_time_ms: 40.266\n",
-      "  timestamp: 1602448847\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      2 |          70.3676 | 323584 |  217.099 |              258.596 |              106.778 |            888.592 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3616.4686098654706\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-21\n",
-      "  done: false\n",
-      "  episode_len_mean: 885.3459915611814\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 217.68079529471913\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.137440989414851\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.010796306344370047\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017557858838699758\n",
-      "        total_loss: 47.99287382761637\n",
-      "        vf_explained_var: 0.9169993996620178\n",
-      "        vf_loss: 48.00991948445638\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.892857142857146\n",
-      "    gpu_util_percent0: 0.34785714285714286\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16056212834421194\n",
-      "    mean_env_wait_ms: 1.1634296276589942\n",
-      "    mean_inference_ms: 5.15785089440761\n",
-      "    mean_raw_obs_processing_ms: 0.4230651018633661\n",
-      "  time_since_restore: 104.36089730262756\n",
-      "  time_this_iter_s: 33.99334406852722\n",
-      "  time_total_s: 104.36089730262756\n",
-      "  timers:\n",
-      "    learn_throughput: 6029.227\n",
-      "    learn_time_ms: 26834.618\n",
-      "    sample_throughput: 20609.33\n",
-      "    sample_time_ms: 7850.425\n",
-      "    update_time_ms: 56.456\n",
-      "  timestamp: 1602448881\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      3 |          104.361 | 485376 |  217.681 |              260.414 |              106.778 |            885.346 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3614.6423841059604\n",
-      "    time_step_min: 3337\n",
-      "  date: 2020-10-11_20-41-55\n",
-      "  done: false\n",
-      "  episode_len_mean: 881.8196202531645\n",
-      "  episode_reward_max: 260.41414141414157\n",
-      "  episode_reward_mean: 218.72613796189725\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 632\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1155910591284435\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009656987541044751\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01651762195736713\n",
-      "        total_loss: 28.95356051127116\n",
-      "        vf_explained_var: 0.9477614760398865\n",
-      "        vf_loss: 28.969671090443928\n",
-      "    num_steps_sampled: 647168\n",
-      "    num_steps_trained: 647168\n",
-      "  iterations_since_restore: 4\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.343902439024394\n",
-      "    gpu_util_percent0: 0.35048780487804876\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1586801646218421\n",
-      "    mean_env_wait_ms: 1.164152942958408\n",
-      "    mean_inference_ms: 5.046484781278792\n",
-      "    mean_raw_obs_processing_ms: 0.41745109450024254\n",
-      "  time_since_restore: 138.51990175247192\n",
-      "  time_this_iter_s: 34.15900444984436\n",
-      "  time_total_s: 138.51990175247192\n",
-      "  timers:\n",
-      "    learn_throughput: 6020.605\n",
-      "    learn_time_ms: 26873.045\n",
-      "    sample_throughput: 21117.842\n",
-      "    sample_time_ms: 7661.389\n",
-      "    update_time_ms: 48.665\n",
-      "  timestamp: 1602448915\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 647168\n",
-      "  training_iteration: 4\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      4 |           138.52 | 647168 |  218.726 |              260.414 |              106.778 |             881.82 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3605.250656167979\n",
-      "    time_step_min: 3304\n",
-      "  date: 2020-10-11_20-42-29\n",
-      "  done: false\n",
-      "  episode_len_mean: 877.9139240506329\n",
-      "  episode_reward_max: 265.41414141414134\n",
-      "  episode_reward_mean: 220.00543408771236\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 790\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0832295417785645\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009306296007707715\n",
-      "        model: {}\n",
-      "        policy_loss: -0.018154682746777933\n",
-      "        total_loss: 23.046836853027344\n",
-      "        vf_explained_var: 0.9613752365112305\n",
-      "        vf_loss: 23.06460205713908\n",
-      "    num_steps_sampled: 808960\n",
-      "    num_steps_trained: 808960\n",
-      "  iterations_since_restore: 5\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.524390243902438\n",
-      "    gpu_util_percent0: 0.31585365853658537\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15728991577564908\n",
-      "    mean_env_wait_ms: 1.165519039293983\n",
-      "    mean_inference_ms: 4.9625030190174435\n",
-      "    mean_raw_obs_processing_ms: 0.41304544879908506\n",
-      "  time_since_restore: 172.49350261688232\n",
-      "  time_this_iter_s: 33.9736008644104\n",
-      "  time_total_s: 172.49350261688232\n",
-      "  timers:\n",
-      "    learn_throughput: 6022.129\n",
-      "    learn_time_ms: 26866.247\n",
-      "    sample_throughput: 21465.213\n",
-      "    sample_time_ms: 7537.405\n",
-      "    update_time_ms: 47.824\n",
-      "  timestamp: 1602448949\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 808960\n",
-      "  training_iteration: 5\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      5 |          172.494 | 808960 |  220.005 |              265.414 |              106.778 |            877.914 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3589.0765639589167\n",
-      "    time_step_min: 3289\n",
-      "  date: 2020-10-11_20-43-03\n",
-      "  done: false\n",
-      "  episode_len_mean: 868.1392174704276\n",
-      "  episode_reward_max: 267.6868686868687\n",
-      "  episode_reward_mean: 222.3442707328056\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 309\n",
-      "  episodes_total: 1099\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0729438364505768\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008983297661567727\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014856907461459437\n",
-      "        total_loss: 27.952880541483562\n",
-      "        vf_explained_var: 0.967507541179657\n",
-      "        vf_loss: 27.96737511952718\n",
-      "    num_steps_sampled: 970752\n",
-      "    num_steps_trained: 970752\n",
-      "  iterations_since_restore: 6\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.916666666666668\n",
-      "    gpu_util_percent0: 0.32166666666666666\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7857142857142865\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15544227505819425\n",
-      "    mean_env_wait_ms: 1.1697635491006715\n",
-      "    mean_inference_ms: 4.850780353416123\n",
-      "    mean_raw_obs_processing_ms: 0.4076391069538378\n",
-      "  time_since_restore: 206.787859916687\n",
-      "  time_this_iter_s: 34.29435729980469\n",
-      "  time_total_s: 206.787859916687\n",
-      "  timers:\n",
-      "    learn_throughput: 6012.676\n",
-      "    learn_time_ms: 26908.487\n",
-      "    sample_throughput: 21686.82\n",
-      "    sample_time_ms: 7460.384\n",
-      "    update_time_ms: 46.403\n",
-      "  timestamp: 1602448983\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 970752\n",
-      "  training_iteration: 6\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      6 |          206.788 | 970752 |  222.344 |              267.687 |              106.778 |            868.139 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3580.65857605178\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-43-37\n",
-      "  done: false\n",
-      "  episode_len_mean: 864.2848101265823\n",
-      "  episode_reward_max: 280.2626262626266\n",
-      "  episode_reward_mean: 223.69569108809597\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 165\n",
-      "  episodes_total: 1264\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.058151125907898\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.009279307521258792\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01645077992967951\n",
-      "        total_loss: 15.616268157958984\n",
-      "        vf_explained_var: 0.9726335406303406\n",
-      "        vf_loss: 15.632320404052734\n",
-      "    num_steps_sampled: 1132544\n",
-      "    num_steps_trained: 1132544\n",
-      "  iterations_since_restore: 7\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.31219512195122\n",
-      "    gpu_util_percent0: 0.39048780487804874\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1547533973210653\n",
-      "    mean_env_wait_ms: 1.1714575614665215\n",
-      "    mean_inference_ms: 4.8082734759399735\n",
-      "    mean_raw_obs_processing_ms: 0.4055719972688042\n",
-      "  time_since_restore: 240.5369439125061\n",
-      "  time_this_iter_s: 33.74908399581909\n",
-      "  time_total_s: 240.5369439125061\n",
-      "  timers:\n",
-      "    learn_throughput: 6015.051\n",
-      "    learn_time_ms: 26897.858\n",
-      "    sample_throughput: 21950.814\n",
-      "    sample_time_ms: 7370.661\n",
-      "    update_time_ms: 43.835\n",
-      "  timestamp: 1602449017\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1132544\n",
-      "  training_iteration: 7\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      7 |          240.537 | 1132544 |  223.696 |              280.263 |              106.778 |            864.285 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3572.3407460545195\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-11\n",
-      "  done: false\n",
-      "  episode_len_mean: 860.7060478199719\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 224.74979755359487\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1422\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0435506701469421\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00859822037940224\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017028980733205874\n",
-      "        total_loss: 14.67722193400065\n",
-      "        vf_explained_var: 0.973932683467865\n",
-      "        vf_loss: 14.693913221359253\n",
-      "    num_steps_sampled: 1294336\n",
-      "    num_steps_trained: 1294336\n",
-      "  iterations_since_restore: 8\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.33658536585366\n",
-      "    gpu_util_percent0: 0.3939024390243903\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.790243902439025\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15419709361525985\n",
-      "    mean_env_wait_ms: 1.173051547586474\n",
-      "    mean_inference_ms: 4.773140764750721\n",
-      "    mean_raw_obs_processing_ms: 0.4038527557885323\n",
-      "  time_since_restore: 274.5138940811157\n",
-      "  time_this_iter_s: 33.97695016860962\n",
-      "  time_total_s: 274.5138940811157\n",
-      "  timers:\n",
-      "    learn_throughput: 6015.4\n",
-      "    learn_time_ms: 26896.299\n",
-      "    sample_throughput: 22088.803\n",
-      "    sample_time_ms: 7324.616\n",
-      "    update_time_ms: 42.976\n",
-      "  timestamp: 1602449051\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1294336\n",
-      "  training_iteration: 8\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      8 |          274.514 | 1294336 |   224.75 |              283.747 |              106.778 |            860.706 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3564.5992268041236\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-44-45\n",
-      "  done: false\n",
-      "  episode_len_mean: 857.1246835443038\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 226.1820739035928\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 1580\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.0148475964864094\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008687774262701472\n",
-      "        model: {}\n",
-      "        policy_loss: -0.019221531343646348\n",
-      "        total_loss: 13.16464869181315\n",
-      "        vf_explained_var: 0.974395751953125\n",
-      "        vf_loss: 13.18350887298584\n",
-      "    num_steps_sampled: 1456128\n",
-      "    num_steps_trained: 1456128\n",
-      "  iterations_since_restore: 9\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.164285714285715\n",
-      "    gpu_util_percent0: 0.3242857142857143\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523817\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15371439312164148\n",
-      "    mean_env_wait_ms: 1.1745967344936128\n",
-      "    mean_inference_ms: 4.742392873103581\n",
-      "    mean_raw_obs_processing_ms: 0.40227968154243166\n",
-      "  time_since_restore: 308.6301050186157\n",
-      "  time_this_iter_s: 34.1162109375\n",
-      "  time_total_s: 308.6301050186157\n",
-      "  timers:\n",
-      "    learn_throughput: 6008.991\n",
-      "    learn_time_ms: 26924.987\n",
-      "    sample_throughput: 22237.247\n",
-      "    sample_time_ms: 7275.721\n",
-      "    update_time_ms: 40.494\n",
-      "  timestamp: 1602449085\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1456128\n",
-      "  training_iteration: 9\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |      9 |           308.63 | 1456128 |  226.182 |              283.747 |              106.778 |            857.125 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3552.531868131868\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-20\n",
-      "  done: false\n",
-      "  episode_len_mean: 852.1964285714286\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 228.07582316673216\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 1848\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9734643250703812\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00841127677510182\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015553771576378495\n",
-      "        total_loss: 19.610436121622723\n",
-      "        vf_explained_var: 0.9750833511352539\n",
-      "        vf_loss: 19.625635147094727\n",
-      "    num_steps_sampled: 1617920\n",
-      "    num_steps_trained: 1617920\n",
-      "  iterations_since_restore: 10\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.104878048780492\n",
-      "    gpu_util_percent0: 0.3853658536585366\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7731707317073173\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1530331197150846\n",
-      "    mean_env_wait_ms: 1.1772620710886672\n",
-      "    mean_inference_ms: 4.6989199095298195\n",
-      "    mean_raw_obs_processing_ms: 0.40005810250385193\n",
-      "  time_since_restore: 342.688401222229\n",
-      "  time_this_iter_s: 34.05829620361328\n",
-      "  time_total_s: 342.688401222229\n",
-      "  timers:\n",
-      "    learn_throughput: 6005.184\n",
-      "    learn_time_ms: 26942.055\n",
-      "    sample_throughput: 22362.798\n",
-      "    sample_time_ms: 7234.873\n",
-      "    update_time_ms: 40.393\n",
-      "  timestamp: 1602449120\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1617920\n",
-      "  training_iteration: 10\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     10 |          342.688 | 1617920 |  228.076 |              283.747 |              106.778 |            852.196 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3542.3598223099702\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-45-53\n",
-      "  done: false\n",
-      "  episode_len_mean: 849.3028237585199\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 229.4285552703273\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
-      "  episodes_total: 2054\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9663667529821396\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00833925325423479\n",
-      "        model: {}\n",
-      "        policy_loss: -0.01736273110145703\n",
-      "        total_loss: 12.502357721328735\n",
-      "        vf_explained_var: 0.9791706204414368\n",
-      "        vf_loss: 12.51936944325765\n",
-      "    num_steps_sampled: 1779712\n",
-      "    num_steps_trained: 1779712\n",
-      "  iterations_since_restore: 11\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.58048780487805\n",
-      "    gpu_util_percent0: 0.3982926829268293\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7804878048780495\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1526132408098708\n",
-      "    mean_env_wait_ms: 1.1789611773593984\n",
-      "    mean_inference_ms: 4.671734404012167\n",
-      "    mean_raw_obs_processing_ms: 0.39871998319890184\n",
-      "  time_since_restore: 376.51920080184937\n",
-      "  time_this_iter_s: 33.83079957962036\n",
-      "  time_total_s: 376.51920080184937\n",
-      "  timers:\n",
-      "    learn_throughput: 6006.948\n",
-      "    learn_time_ms: 26934.144\n",
-      "    sample_throughput: 22990.875\n",
-      "    sample_time_ms: 7037.227\n",
-      "    update_time_ms: 40.215\n",
-      "  timestamp: 1602449153\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1779712\n",
-      "  training_iteration: 11\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     11 |          376.519 | 1779712 |  229.429 |              283.747 |              106.778 |            849.303 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3534.694597069597\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-46-27\n",
-      "  done: false\n",
-      "  episode_len_mean: 847.131555153707\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 230.50298189855144\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2212\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9568162461121877\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00814399627658228\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015694946744285215\n",
-      "        total_loss: 12.548736731211344\n",
-      "        vf_explained_var: 0.9766435623168945\n",
-      "        vf_loss: 12.564095417658487\n",
-      "    num_steps_sampled: 1941504\n",
-      "    num_steps_trained: 1941504\n",
-      "  iterations_since_restore: 12\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.81707317073171\n",
-      "    gpu_util_percent0: 0.3797560975609756\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.792682926829269\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1523239438594431\n",
-      "    mean_env_wait_ms: 1.1801704441448417\n",
-      "    mean_inference_ms: 4.653173903698042\n",
-      "    mean_raw_obs_processing_ms: 0.3977863822432723\n",
-      "  time_since_restore: 410.4603908061981\n",
-      "  time_this_iter_s: 33.941190004348755\n",
-      "  time_total_s: 410.4603908061981\n",
-      "  timers:\n",
-      "    learn_throughput: 6004.841\n",
-      "    learn_time_ms: 26943.593\n",
-      "    sample_throughput: 23202.406\n",
-      "    sample_time_ms: 6973.07\n",
-      "    update_time_ms: 38.84\n",
-      "  timestamp: 1602449187\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 1941504\n",
-      "  training_iteration: 12\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     12 |           410.46 | 1941504 |  230.503 |              283.747 |              106.778 |            847.132 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3528.8706233988046\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-02\n",
-      "  done: false\n",
-      "  episode_len_mean: 845.0793248945148\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 231.55561948599922\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 2370\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9341403146584829\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008328795510654649\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015285106880279878\n",
-      "        total_loss: 11.184300502141317\n",
-      "        vf_explained_var: 0.9784317016601562\n",
-      "        vf_loss: 11.199219783147177\n",
-      "    num_steps_sampled: 2103296\n",
-      "    num_steps_trained: 2103296\n",
-      "  iterations_since_restore: 13\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.056097560975612\n",
-      "    gpu_util_percent0: 0.3531707317073171\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682925\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15206707844660014\n",
-      "    mean_env_wait_ms: 1.1812995165783673\n",
-      "    mean_inference_ms: 4.636268107417298\n",
-      "    mean_raw_obs_processing_ms: 0.39691338971294254\n",
-      "  time_since_restore: 444.4848208427429\n",
-      "  time_this_iter_s: 34.0244300365448\n",
-      "  time_total_s: 444.4848208427429\n",
-      "  timers:\n",
-      "    learn_throughput: 5995.984\n",
-      "    learn_time_ms: 26983.393\n",
-      "    sample_throughput: 23304.966\n",
-      "    sample_time_ms: 6942.383\n",
-      "    update_time_ms: 32.03\n",
-      "  timestamp: 1602449222\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2103296\n",
-      "  training_iteration: 13\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     13 |          444.485 | 2103296 |  231.556 |              283.747 |              106.778 |            845.079 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3517.263601532567\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-47-35\n",
-      "  done: false\n",
-      "  episode_len_mean: 841.8491281273692\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 233.18196368537525\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 268\n",
-      "  episodes_total: 2638\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.9020447830359141\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008081968214052418\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015293826969961325\n",
-      "        total_loss: 12.724741299947103\n",
-      "        vf_explained_var: 0.9831693172454834\n",
-      "        vf_loss: 12.739677826563517\n",
-      "    num_steps_sampled: 2265088\n",
-      "    num_steps_trained: 2265088\n",
-      "  iterations_since_restore: 14\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 20.178048780487803\n",
-      "    gpu_util_percent0: 0.34682926829268296\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.775609756097561\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15168397874215378\n",
-      "    mean_env_wait_ms: 1.1831688977197714\n",
-      "    mean_inference_ms: 4.610931204965214\n",
-      "    mean_raw_obs_processing_ms: 0.39561206070844984\n",
-      "  time_since_restore: 478.23622155189514\n",
-      "  time_this_iter_s: 33.75140070915222\n",
-      "  time_total_s: 478.23622155189514\n",
-      "  timers:\n",
-      "    learn_throughput: 5998.158\n",
-      "    learn_time_ms: 26973.613\n",
-      "    sample_throughput: 23414.5\n",
-      "    sample_time_ms: 6909.906\n",
-      "    update_time_ms: 33.132\n",
-      "  timestamp: 1602449255\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2265088\n",
-      "  training_iteration: 14\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     14 |          478.236 | 2265088 |  233.182 |              283.747 |              106.778 |            841.849 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3509.4779829545455\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-09\n",
-      "  done: false\n",
-      "  episode_len_mean: 839.5295358649789\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 234.39397135916116\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 206\n",
-      "  episodes_total: 2844\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8862918565670649\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007904120022431016\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014935656054755478\n",
-      "        total_loss: 9.06860645612081\n",
-      "        vf_explained_var: 0.984200656414032\n",
-      "        vf_loss: 9.083194653193155\n",
-      "    num_steps_sampled: 2426880\n",
-      "    num_steps_trained: 2426880\n",
-      "  iterations_since_restore: 15\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.682926829268297\n",
-      "    gpu_util_percent0: 0.38243902439024396\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7878048780487807\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15143390810491775\n",
-      "    mean_env_wait_ms: 1.1844643908633714\n",
-      "    mean_inference_ms: 4.594233582997575\n",
-      "    mean_raw_obs_processing_ms: 0.3947809594728215\n",
-      "  time_since_restore: 512.1841127872467\n",
-      "  time_this_iter_s: 33.94789123535156\n",
-      "  time_total_s: 512.1841127872467\n",
-      "  timers:\n",
-      "    learn_throughput: 5994.585\n",
-      "    learn_time_ms: 26989.692\n",
-      "    sample_throughput: 23481.767\n",
-      "    sample_time_ms: 6890.112\n",
-      "    update_time_ms: 32.925\n",
-      "  timestamp: 1602449289\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2426880\n",
-      "  training_iteration: 15\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     15 |          512.184 | 2426880 |  234.394 |              283.747 |              106.778 |             839.53 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3504.0221923335575\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-48-44\n",
-      "  done: false\n",
-      "  episode_len_mean: 837.8334443704197\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 235.28937610616484\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 3002\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8804336041212082\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.00791139566960434\n",
-      "        model: {}\n",
-      "        policy_loss: -0.017682172047595184\n",
-      "        total_loss: 8.313085556030273\n",
-      "        vf_explained_var: 0.9836888313293457\n",
-      "        vf_loss: 8.330416997273764\n",
-      "    num_steps_sampled: 2588672\n",
-      "    num_steps_trained: 2588672\n",
-      "  iterations_since_restore: 16\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.829268292682926\n",
-      "    gpu_util_percent0: 0.4309756097560975\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7853658536585377\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15125642659333643\n",
-      "    mean_env_wait_ms: 1.1853858835587299\n",
-      "    mean_inference_ms: 4.5824743389127525\n",
-      "    mean_raw_obs_processing_ms: 0.39418437084622066\n",
-      "  time_since_restore: 546.3757491111755\n",
-      "  time_this_iter_s: 34.19163632392883\n",
-      "  time_total_s: 546.3757491111755\n",
-      "  timers:\n",
-      "    learn_throughput: 5991.373\n",
-      "    learn_time_ms: 27004.162\n",
-      "    sample_throughput: 23569.806\n",
-      "    sample_time_ms: 6864.376\n",
-      "    update_time_ms: 32.942\n",
-      "  timestamp: 1602449324\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2588672\n",
-      "  training_iteration: 16\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     16 |          546.376 | 2588672 |  235.289 |              283.747 |              106.778 |            837.833 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3498.312918660287\n",
-      "    time_step_min: 3206\n",
-      "  date: 2020-10-11_20-49-18\n",
-      "  done: false\n",
-      "  episode_len_mean: 836.1346822636738\n",
-      "  episode_reward_max: 283.7474747474749\n",
-      "  episode_reward_mean: 236.18048330283543\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 161\n",
-      "  episodes_total: 3163\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8537542670965195\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008198376706180474\n",
-      "        model: {}\n",
-      "        policy_loss: -0.015993841225281358\n",
-      "        total_loss: 9.6584951877594\n",
-      "        vf_explained_var: 0.9823360443115234\n",
-      "        vf_loss: 9.67409602801005\n",
-      "    num_steps_sampled: 2750464\n",
-      "    num_steps_trained: 2750464\n",
-      "  iterations_since_restore: 17\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.716666666666665\n",
-      "    gpu_util_percent0: 0.3614285714285715\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7809523809523813\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15108549071824215\n",
-      "    mean_env_wait_ms: 1.186299740621708\n",
-      "    mean_inference_ms: 4.571266181106936\n",
-      "    mean_raw_obs_processing_ms: 0.3935990755523057\n",
-      "  time_since_restore: 580.5327708721161\n",
-      "  time_this_iter_s: 34.15702176094055\n",
-      "  time_total_s: 580.5327708721161\n",
-      "  timers:\n",
-      "    learn_throughput: 5980.848\n",
-      "    learn_time_ms: 27051.68\n",
-      "    sample_throughput: 23599.526\n",
-      "    sample_time_ms: 6855.731\n",
-      "    update_time_ms: 34.302\n",
-      "  timestamp: 1602449358\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2750464\n",
-      "  training_iteration: 17\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | RUNNING  | 172.17.0.4:15842 |     17 |          580.533 | 2750464 |   236.18 |              283.747 |              106.778 |            836.135 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_dc7e0_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4327\n",
-      "    time_step_mean: 3488.101369064958\n",
-      "    time_step_min: 3158\n",
-      "  date: 2020-10-11_20-49-52\n",
-      "  done: true\n",
-      "  episode_len_mean: 833.3886160069344\n",
-      "  episode_reward_max: 287.53535353535375\n",
-      "  episode_reward_mean: 237.6940920327224\n",
-      "  episode_reward_min: 106.77777777777801\n",
-      "  episodes_this_iter: 298\n",
-      "  episodes_total: 3461\n",
-      "  experiment_id: 3eef0fe6cc764e4f81ff922cb0fcaf3b\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 0.8270254284143448\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007853905437514186\n",
-      "        model: {}\n",
-      "        policy_loss: -0.014354762931664785\n",
-      "        total_loss: 12.10600503285726\n",
-      "        vf_explained_var: 0.9836263060569763\n",
-      "        vf_loss: 12.119987805684408\n",
-      "    num_steps_sampled: 2912256\n",
-      "    num_steps_trained: 2912256\n",
-      "  iterations_since_restore: 18\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 19.90487804878049\n",
-      "    gpu_util_percent0: 0.37609756097560976\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7829268292682934\n",
-      "    vram_util_percent0: 0.10437848474909808\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 15842\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.15081126315046797\n",
-      "    mean_env_wait_ms: 1.1879326543189301\n",
-      "    mean_inference_ms: 4.552816786571983\n",
-      "    mean_raw_obs_processing_ms: 0.39263685907469736\n",
-      "  time_since_restore: 614.4084322452545\n",
-      "  time_this_iter_s: 33.87566137313843\n",
-      "  time_total_s: 614.4084322452545\n",
-      "  timers:\n",
-      "    learn_throughput: 5980.24\n",
-      "    learn_time_ms: 27054.431\n",
-      "    sample_throughput: 23642.693\n",
-      "    sample_time_ms: 6843.214\n",
-      "    update_time_ms: 32.784\n",
-      "  timestamp: 1602449392\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 2912256\n",
-      "  training_iteration: 18\n",
-      "  trial_id: dc7e0_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.3/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 TERMINATED)\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_dc7e0_00000 | TERMINATED |       |     18 |          614.408 | 2912256 |  237.694 |              287.535 |              106.778 |            833.389 |\n",
-      "+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 15618\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find user logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Find internal logs for this run at: wandb/run-20201011_203924-4lvdkknr/logs/debug-internal.log\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min 3158\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step 7\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime 628\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp 1602449392\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max 4327\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean 3488.10137\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max 287.53535\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min 106.77778\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean 237.69409\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total 3461\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration 18\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _step ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:              _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:            _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:         time_step_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        time_step_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_max ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    episode_reward_min ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:   episode_reward_mean ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:        episodes_total ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m:    training_iteration ‚ñÅ\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33msplendid-sweep-3\u001b[0m: \u001b[34mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/4lvdkknr\u001b[0m\n",
-      "2020-10-11 20:49:59,068 - wandb.wandb_agent - INFO - Cleaning up finished run: 4lvdkknr\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent received command: run\n",
-      "2020-10-11 20:49:59,354 - wandb.wandb_agent - INFO - Agent starting run with config:\n",
-      "\tclip_param: 0.3\n",
-      "\tentropy_coeff: 0.0005\n",
-      "\tkl_coeff: 0.2\n",
-      "\tnum_sgd_iter: 25\n",
-      "2020-10-11 20:49:59,357 - wandb.wandb_agent - INFO - About to run command: /usr/bin/env python train.py --clip_param=0.3 --entropy_coeff=0.0005 --kl_coeff=0.2 --num_sgd_iter=25\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mingambe\u001b[0m (use `wandb login --relogin` to force relogin)\n",
-      "2020-10-11 20:50:04,374 - wandb.wandb_agent - INFO - Running runs: ['2n8lexei']\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.5\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mupbeat-sweep-4\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üßπ View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/sweeps/h0kna0bx\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/ingambe/RLLIB_SWEEP_2/runs/2n8lexei\u001b[0m\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20201011_205001-2n8lexei\n",
-      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
-      "\n",
-      "2020-10-11 20:50:05,155\tINFO services.py:1164 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
-      "== Status ==\n",
-      "Memory usage on this node: 11.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+-------+\n",
-      "| Trial name              | status   | loc   |\n",
-      "|-------------------------+----------+-------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  |       |\n",
-      "+-------------------------+----------+-------+\n",
-      "\n",
-      "\n",
-      "\u001b[2m\u001b[36m(pid=37257)\u001b[0m 2020-10-11 20:50:07,972\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37232)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37263)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37237)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37160)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37220)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37238)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37219)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37271)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37178)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37201)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37225)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37223)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37213)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37207)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37241)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37259)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37247)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37261)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37234)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37273)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37210)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37157)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37235)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37251)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37166)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37142)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37200)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37149)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37146)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37182)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37282)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37224)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37215)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37214)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37155)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37197)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37177)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37266)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37242)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37141)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37159)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37205)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37162)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37221)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37140)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37170)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37248)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37158)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37245)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37217)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37161)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37204)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37153)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37176)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37143)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37203)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37236)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37278)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37154)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37250)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37222)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37145)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37173)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37226)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37229)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37230)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37228)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37218)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37233)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37150)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37163)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37268)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37144)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37168)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37152)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37260)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37216)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37147)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
-      "\u001b[2m\u001b[36m(pid=37174)\u001b[0m   tensor = torch.from_numpy(np.asarray(item))\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3615.0923076923077\n",
-      "    time_step_min: 3379\n",
-      "  date: 2020-10-11_20-50-42\n",
-      "  done: false\n",
-      "  episode_len_mean: 891.1139240506329\n",
-      "  episode_reward_max: 258.59595959595964\n",
-      "  episode_reward_mean: 216.07678046285614\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 158\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.20000000000000004\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1851047078768413\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.004071502441850801\n",
-      "        model: {}\n",
-      "        policy_loss: -0.00785889983914482\n",
-      "        total_loss: 507.07567087809247\n",
-      "        vf_explained_var: 0.540532648563385\n",
-      "        vf_loss: 507.0832926432292\n",
-      "    num_steps_sampled: 161792\n",
-      "    num_steps_trained: 161792\n",
-      "  iterations_since_restore: 1\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 27.602941176470587\n",
-      "    gpu_util_percent0: 0.26294117647058823\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.5676470588235296\n",
-      "    vram_util_percent0: 0.08659058900700328\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16776829819945724\n",
-      "    mean_env_wait_ms: 1.1590575435788\n",
-      "    mean_inference_ms: 5.636969428255295\n",
-      "    mean_raw_obs_processing_ms: 0.44418268713107556\n",
-      "  time_since_restore: 28.716503381729126\n",
-      "  time_this_iter_s: 28.716503381729126\n",
-      "  time_total_s: 28.716503381729126\n",
-      "  timers:\n",
-      "    learn_throughput: 8268.867\n",
-      "    learn_time_ms: 19566.404\n",
-      "    sample_throughput: 17811.996\n",
-      "    sample_time_ms: 9083.317\n",
-      "    update_time_ms: 25.783\n",
-      "  timestamp: 1602449442\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 161792\n",
-      "  training_iteration: 1\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 27.6/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      1 |          28.7165 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3614.4305555555557\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-09\n",
-      "  done: false\n",
-      "  episode_len_mean: 890.8607594936709\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 217.6365234624726\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 316\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1561074058214824\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.007923512797181806\n",
-      "        model: {}\n",
-      "        policy_loss: -0.010965243893830726\n",
-      "        total_loss: 127.46906661987305\n",
-      "        vf_explained_var: 0.8076093792915344\n",
-      "        vf_loss: 127.47981770833333\n",
-      "    num_steps_sampled: 323584\n",
-      "    num_steps_trained: 323584\n",
-      "  iterations_since_restore: 2\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 25.793548387096774\n",
-      "    gpu_util_percent0: 0.3754838709677419\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7580645161290316\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.1641719786222011\n",
-      "    mean_env_wait_ms: 1.1571251717808861\n",
-      "    mean_inference_ms: 5.450378231973181\n",
-      "    mean_raw_obs_processing_ms: 0.4348042526165878\n",
-      "  time_since_restore: 55.82824516296387\n",
-      "  time_this_iter_s: 27.11174178123474\n",
-      "  time_total_s: 55.82824516296387\n",
-      "  timers:\n",
-      "    learn_throughput: 8314.425\n",
-      "    learn_time_ms: 19459.192\n",
-      "    sample_throughput: 19291.922\n",
-      "    sample_time_ms: 8386.515\n",
-      "    update_time_ms: 22.338\n",
-      "  timestamp: 1602449469\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 323584\n",
-      "  training_iteration: 2\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.2/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      2 |          55.8282 | 323584 |  217.637 |              273.596 |              145.717 |            890.861 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
-      "\n",
-      "Result for PPO_jss_env_57f23_00000:\n",
-      "  custom_metrics:\n",
-      "    time_step_max: 4054\n",
-      "    time_step_mean: 3601.8677130044844\n",
-      "    time_step_min: 3250\n",
-      "  date: 2020-10-11_20-51-35\n",
-      "  done: false\n",
-      "  episode_len_mean: 885.132911392405\n",
-      "  episode_reward_max: 273.5959595959592\n",
-      "  episode_reward_mean: 219.87009333844756\n",
-      "  episode_reward_min: 145.7171717171716\n",
-      "  episodes_this_iter: 158\n",
-      "  episodes_total: 474\n",
-      "  experiment_id: 2c4c9d1a032f4f60b4e49b42a49eb793\n",
-      "  experiment_tag: '0'\n",
-      "  hostname: f85e62b52919\n",
-      "  info:\n",
-      "    learner:\n",
-      "      default_policy:\n",
-      "        allreduce_latency: 0.0\n",
-      "        cur_kl_coeff: 0.10000000000000002\n",
-      "        cur_lr: 5.0e-05\n",
-      "        entropy: 1.1456398169199626\n",
-      "        entropy_coeff: 0.0005000000000000001\n",
-      "        kl: 0.008224547879459957\n",
-      "        model: {}\n",
-      "        policy_loss: -0.013529085864623388\n",
-      "        total_loss: 61.275455474853516\n",
-      "        vf_explained_var: 0.8916645646095276\n",
-      "        vf_loss: 61.28873507181803\n",
-      "    num_steps_sampled: 485376\n",
-      "    num_steps_trained: 485376\n",
-      "  iterations_since_restore: 3\n",
-      "  node_ip: 172.17.0.4\n",
-      "  num_healthy_workers: 79\n",
-      "  off_policy_estimator: {}\n",
-      "  perf:\n",
-      "    cpu_util_percent: 23.764516129032263\n",
-      "    gpu_util_percent0: 0.4045161290322581\n",
-      "    gpu_util_percent1: 0.0\n",
-      "    gpu_util_percent2: 0.0\n",
-      "    ram_util_percent: 3.7774193548387096\n",
-      "    vram_util_percent0: 0.10437848474909812\n",
-      "    vram_util_percent1: 0.0\n",
-      "    vram_util_percent2: 0.0\n",
-      "  pid: 37257\n",
-      "  policy_reward_max: {}\n",
-      "  policy_reward_mean: {}\n",
-      "  policy_reward_min: {}\n",
-      "  sampler_perf:\n",
-      "    mean_action_processing_ms: 0.16153199701032797\n",
-      "    mean_env_wait_ms: 1.1575292499687186\n",
-      "    mean_inference_ms: 5.28509801236235\n",
-      "    mean_raw_obs_processing_ms: 0.4265118857400026\n",
-      "  time_since_restore: 82.30366969108582\n",
-      "  time_this_iter_s: 26.47542452812195\n",
-      "  time_total_s: 82.30366969108582\n",
-      "  timers:\n",
-      "    learn_throughput: 8340.997\n",
-      "    learn_time_ms: 19397.202\n",
-      "    sample_throughput: 20306.88\n",
-      "    sample_time_ms: 7967.349\n",
-      "    update_time_ms: 21.561\n",
-      "  timestamp: 1602449495\n",
-      "  timesteps_since_restore: 0\n",
-      "  timesteps_total: 485376\n",
-      "  training_iteration: 3\n",
-      "  trial_id: 57f23_00000\n",
-      "  \n",
-      "== Status ==\n",
-      "Memory usage on this node: 28.1/754.6 GiB\n",
-      "Using FIFO scheduling algorithm.\n",
-      "Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.15 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)\n",
-      "Result logdir: /root/ray_results/ppo-jss\n",
-      "Number of trials: 1 (1 RUNNING)\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |\n",
-      "|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|\n",
-      "| PPO_jss_env_57f23_00000 | RUNNING  | 172.17.0.4:37257 |      3 |          82.3037 | 485376 |   219.87 |              273.596 |              145.717 |            885.133 |\n",
-      "+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+\n",
-      "\n",
       "\n"
      ]
     }
    ],
    "source": [
-    "!wandb agent h0kna0bx"
+    "!wandb agent pu0gldb1"
    ]
   },
   {
diff --git a/JSS/__pycache__/default_config.cpython-38.pyc b/JSS/__pycache__/default_config.cpython-38.pyc
index ac81b03..b96fa2c 100644
Binary files a/JSS/__pycache__/default_config.cpython-38.pyc and b/JSS/__pycache__/default_config.cpython-38.pyc differ
diff --git a/JSS/default_config.py b/JSS/default_config.py
index 0786a30..0a91a3d 100644
--- a/JSS/default_config.py
+++ b/JSS/default_config.py
@@ -18,10 +18,10 @@ default_config = {
     'layer_size': 1024,
     'layer_nb': 2,
     'lr': 5e-5,
-    'clip_param': 0.3,
+    'clip_param': 0.5,
     'vf_clip_param': 10.0,
     'kl_target': 0.01,
-    'num_sgd_iter': 30,
+    'num_sgd_iter': 25,
     'lambda': 1.0,
     "use_critic": True,
     "use_gae": True,
@@ -30,7 +30,7 @@ default_config = {
     "lr_schedule": None,
     "vf_share_layers": False,
     "vf_loss_coeff": 1.0,
-    "entropy_coeff": 1e-4,
+    "entropy_coeff": 5e-4,
     "entropy_coeff_schedule": None,
     "grad_clip": None,
     "batch_mode": "truncate_episodes",
diff --git a/JSS/wandb/debug-internal.log b/JSS/wandb/debug-internal.log
index 8ee10cb..df835f6 120000
--- a/JSS/wandb/debug-internal.log
+++ b/JSS/wandb/debug-internal.log
@@ -1 +1 @@
-run-20201012_023117-p62mhra8/logs/debug-internal.log
\ No newline at end of file
+run-20201012_124056-y1n2drlw/logs/debug-internal.log
\ No newline at end of file
diff --git a/JSS/wandb/debug.log b/JSS/wandb/debug.log
index 4f3bf3b..dd15033 120000
--- a/JSS/wandb/debug.log
+++ b/JSS/wandb/debug.log
@@ -1 +1 @@
-run-20201012_023117-p62mhra8/logs/debug.log
\ No newline at end of file
+run-20201012_124056-y1n2drlw/logs/debug.log
\ No newline at end of file
diff --git a/JSS/wandb/latest-run b/JSS/wandb/latest-run
index 8be457f..89952fc 120000
--- a/JSS/wandb/latest-run
+++ b/JSS/wandb/latest-run
@@ -1 +1 @@
-run-20201012_023117-p62mhra8
\ No newline at end of file
+run-20201012_124056-y1n2drlw
\ No newline at end of file
