2020-10-12 12:41:00,037	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_2f54c_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=3607)[0m 2020-10-12 12:41:02,820	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=3517)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3517)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3606)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3606)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3571)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3571)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3589)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3589)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3590)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3590)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3557)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3557)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3570)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3570)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3579)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3579)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3575)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3575)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3535)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3535)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3574)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3574)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3549)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3549)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3561)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3561)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3560)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3560)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3604)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3604)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3552)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3552)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3556)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3556)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3585)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3585)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3597)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3597)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3564)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3564)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3586)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3586)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3592)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3592)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3599)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3599)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3478)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3478)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3499)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3499)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3582)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3582)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3481)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3481)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3479)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3479)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3495)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3495)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3578)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3578)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3541)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3541)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3538)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3538)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3532)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3532)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3484)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3484)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3536)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3536)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3486)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3486)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3554)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3554)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3543)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3543)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3539)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3539)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3542)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3542)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3559)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3559)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3483)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3483)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3482)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3482)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3587)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3587)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3516)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3516)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3490)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3490)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3544)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3544)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3487)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3487)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3588)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3588)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3477)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3477)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3547)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3547)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3558)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3558)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3594)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3594)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3551)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3551)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3568)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3568)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=3485)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=3485)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3616.3166666666666
    time_step_min: 3355
  date: 2020-10-12_12-41-36
  done: false
  episode_len_mean: 904.8481012658228
  episode_reward_max: 246.595959595959
  episode_reward_mean: 201.8721391126452
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1660849452018738
        entropy_coeff: 0.0005000000000000001
        kl: 0.007487039663828909
        model: {}
        policy_loss: -0.009705218815118618
        total_loss: 369.24190012613934
        vf_explained_var: 0.588043749332428
        vf_loss: 369.2507044474284
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 30.439999999999998
    gpu_util_percent0: 0.34828571428571425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5514285714285716
    vram_util_percent0: 0.08515906854706463
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16766784587882486
    mean_env_wait_ms: 1.1779018683579277
    mean_inference_ms: 6.1455708986890665
    mean_raw_obs_processing_ms: 0.4561936336374828
  time_since_restore: 28.484970092773438
  time_this_iter_s: 28.484970092773438
  time_total_s: 28.484970092773438
  timers:
    learn_throughput: 8744.933
    learn_time_ms: 18501.228
    sample_throughput: 16339.015
    sample_time_ms: 9902.188
    update_time_ms: 44.878
  timestamp: 1602506496
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      1 |           28.485 | 161792 |  201.872 |              246.596 |              106.747 |            904.848 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3625.2374100719426
    time_step_min: 3339
  date: 2020-10-12_12-42-02
  done: false
  episode_len_mean: 904.4556962025316
  episode_reward_max: 246.595959595959
  episode_reward_mean: 199.3687827643521
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.135809987783432
        entropy_coeff: 0.0005000000000000001
        kl: 0.010140993477155765
        model: {}
        policy_loss: -0.011478722333170785
        total_loss: 95.7723019917806
        vf_explained_var: 0.8307454586029053
        vf_loss: 95.78232320149739
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.345161290322583
    gpu_util_percent0: 0.33032258064516135
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.751612903225806
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1637749172129011
    mean_env_wait_ms: 1.175515161566294
    mean_inference_ms: 5.808114322059557
    mean_raw_obs_processing_ms: 0.44289364338056286
  time_since_restore: 54.45203757286072
  time_this_iter_s: 25.96706748008728
  time_total_s: 54.45203757286072
  timers:
    learn_throughput: 8856.737
    learn_time_ms: 18267.676
    sample_throughput: 18216.5
    sample_time_ms: 8881.618
    update_time_ms: 33.458
  timestamp: 1602506522
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      2 |           54.452 | 323584 |  199.369 |              246.596 |              106.747 |            904.456 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3631.1490825688074
    time_step_min: 3328
  date: 2020-10-12_12-42-28
  done: false
  episode_len_mean: 902.246835443038
  episode_reward_max: 246.595959595959
  episode_reward_mean: 199.6703746323997
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.125467707713445
        entropy_coeff: 0.0005000000000000001
        kl: 0.010452566435560584
        model: {}
        policy_loss: -0.013522157406744858
        total_loss: 49.543551445007324
        vf_explained_var: 0.899634599685669
        vf_loss: 49.555545806884766
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.677419354838705
    gpu_util_percent0: 0.31225806451612903
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1610122614239026
    mean_env_wait_ms: 1.1752129850381983
    mean_inference_ms: 5.566328896160028
    mean_raw_obs_processing_ms: 0.43357261225894383
  time_since_restore: 80.04528307914734
  time_this_iter_s: 25.59324550628662
  time_total_s: 80.04528307914734
  timers:
    learn_throughput: 8834.464
    learn_time_ms: 18313.732
    sample_throughput: 19524.707
    sample_time_ms: 8286.526
    update_time_ms: 35.094
  timestamp: 1602506548
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      3 |          80.0453 | 485376 |   199.67 |              246.596 |              106.747 |            902.247 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3626.96632996633
    time_step_min: 3328
  date: 2020-10-12_12-42-53
  done: false
  episode_len_mean: 897.6582278481013
  episode_reward_max: 253.71717171717134
  episode_reward_mean: 200.85348740570234
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1046620110670726
        entropy_coeff: 0.0005000000000000001
        kl: 0.01121117314323783
        model: {}
        policy_loss: -0.014733990072272718
        total_loss: 36.47766558329264
        vf_explained_var: 0.924907922744751
        vf_loss: 36.49070962270101
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.554838709677416
    gpu_util_percent0: 0.3461290322580645
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15902557874431109
    mean_env_wait_ms: 1.1761492975958119
    mean_inference_ms: 5.3938636303115555
    mean_raw_obs_processing_ms: 0.4266225682217487
  time_since_restore: 105.31522297859192
  time_this_iter_s: 25.26993989944458
  time_total_s: 105.31522297859192
  timers:
    learn_throughput: 8834.02
    learn_time_ms: 18314.652
    sample_throughput: 20391.969
    sample_time_ms: 7934.104
    update_time_ms: 31.737
  timestamp: 1602506573
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      4 |          105.315 | 647168 |  200.853 |              253.717 |              106.747 |            897.658 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3620.130319148936
    time_step_min: 3328
  date: 2020-10-12_12-43-18
  done: false
  episode_len_mean: 894.2341772151899
  episode_reward_max: 253.71717171717134
  episode_reward_mean: 201.7969569108807
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0741320550441742
        entropy_coeff: 0.0005000000000000001
        kl: 0.010659902356564999
        model: {}
        policy_loss: -0.011991073998312155
        total_loss: 29.64512062072754
        vf_explained_var: 0.9406320452690125
        vf_loss: 29.655516147613525
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.776666666666667
    gpu_util_percent0: 0.4046666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15753872962615612
    mean_env_wait_ms: 1.1772916063340257
    mean_inference_ms: 5.2647729361155635
    mean_raw_obs_processing_ms: 0.421179650515422
  time_since_restore: 130.2804799079895
  time_this_iter_s: 24.965256929397583
  time_total_s: 130.2804799079895
  timers:
    learn_throughput: 8863.013
    learn_time_ms: 18254.74
    sample_throughput: 20949.572
    sample_time_ms: 7722.926
    update_time_ms: 29.383
  timestamp: 1602506598
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      5 |           130.28 | 808960 |  201.797 |              253.717 |              106.747 |            894.234 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3613.8930131004367
    time_step_min: 3280
  date: 2020-10-12_12-43-44
  done: false
  episode_len_mean: 890.5723270440252
  episode_reward_max: 258.868686868687
  episode_reward_mean: 202.77139317705334
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 164
  episodes_total: 954
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0176733334859211
        entropy_coeff: 0.0005000000000000001
        kl: 0.01112077998307844
        model: {}
        policy_loss: -0.01367081212811172
        total_loss: 28.44929854075114
        vf_explained_var: 0.9561074376106262
        vf_loss: 28.461254119873047
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.986666666666665
    gpu_util_percent0: 0.394
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7533333333333325
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1563283776266907
    mean_env_wait_ms: 1.1787037140608163
    mean_inference_ms: 5.161306142094558
    mean_raw_obs_processing_ms: 0.4166823689177291
  time_since_restore: 155.60316634178162
  time_this_iter_s: 25.322686433792114
  time_total_s: 155.60316634178162
  timers:
    learn_throughput: 8861.524
    learn_time_ms: 18257.807
    sample_throughput: 21306.62
    sample_time_ms: 7593.509
    update_time_ms: 30.4
  timestamp: 1602506624
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      6 |          155.603 | 970752 |  202.771 |              258.869 |              106.747 |            890.572 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3603.3406862745096
    time_step_min: 3264
  date: 2020-10-12_12-44-09
  done: false
  episode_len_mean: 883.7662440570523
  episode_reward_max: 258.868686868687
  episode_reward_mean: 204.31626886935896
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 308
  episodes_total: 1262
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0213659306367238
        entropy_coeff: 0.0005000000000000001
        kl: 0.009701167543729147
        model: {}
        policy_loss: -0.010542363626882434
        total_loss: 30.853121121724445
        vf_explained_var: 0.9592533111572266
        vf_loss: 30.862233479817707
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.703333333333337
    gpu_util_percent0: 0.3773333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15473377617903775
    mean_env_wait_ms: 1.1810367532901567
    mean_inference_ms: 5.024348698010241
    mean_raw_obs_processing_ms: 0.4108852518846039
  time_since_restore: 180.50350046157837
  time_this_iter_s: 24.900334119796753
  time_total_s: 180.50350046157837
  timers:
    learn_throughput: 8876.571
    learn_time_ms: 18226.857
    sample_throughput: 21638.256
    sample_time_ms: 7477.128
    update_time_ms: 29.74
  timestamp: 1602506649
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      7 |          180.504 | 1132544 |  204.316 |              258.869 |              106.747 |            883.766 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3596.635838150289
    time_step_min: 3264
  date: 2020-10-12_12-44-34
  done: false
  episode_len_mean: 880.6427566807314
  episode_reward_max: 265.98989898989885
  episode_reward_mean: 205.24681413288985
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 160
  episodes_total: 1422
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0055027554432552
        entropy_coeff: 0.0005000000000000001
        kl: 0.009654009947553277
        model: {}
        policy_loss: -0.011977127088660685
        total_loss: 21.057878653208416
        vf_explained_var: 0.9642793536186218
        vf_loss: 21.068427403767902
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.467741935483875
    gpu_util_percent0: 0.2916129032258064
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774193548387097
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15411860827672585
    mean_env_wait_ms: 1.1819827185557858
    mean_inference_ms: 4.97131117082984
    mean_raw_obs_processing_ms: 0.4086455750448838
  time_since_restore: 205.72761225700378
  time_this_iter_s: 25.224111795425415
  time_total_s: 205.72761225700378
  timers:
    learn_throughput: 8870.705
    learn_time_ms: 18238.911
    sample_throughput: 21886.024
    sample_time_ms: 7392.48
    update_time_ms: 30.869
  timestamp: 1602506674
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      8 |          205.728 | 1294336 |  205.247 |               265.99 |              103.869 |            880.643 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3588.064850843061
    time_step_min: 3263
  date: 2020-10-12_12-44-59
  done: false
  episode_len_mean: 876.9892405063291
  episode_reward_max: 265.98989898989885
  episode_reward_mean: 206.43830712185124
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9724004765351614
        entropy_coeff: 0.0005000000000000001
        kl: 0.010166126924256483
        model: {}
        policy_loss: -0.01288065587868914
        total_loss: 18.919014771779377
        vf_explained_var: 0.9656748175621033
        vf_loss: 18.930348714192707
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.136666666666667
    gpu_util_percent0: 0.37
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15360356336808859
    mean_env_wait_ms: 1.1830644993625332
    mean_inference_ms: 4.9263586316318
    mean_raw_obs_processing_ms: 0.4067494007353412
  time_since_restore: 231.01188683509827
  time_this_iter_s: 25.284274578094482
  time_total_s: 231.01188683509827
  timers:
    learn_throughput: 8866.442
    learn_time_ms: 18247.681
    sample_throughput: 22054.375
    sample_time_ms: 7336.05
    update_time_ms: 30.778
  timestamp: 1602506699
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |      9 |          231.012 | 1456128 |  206.438 |               265.99 |              103.869 |            876.989 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3580.165294117647
    time_step_min: 3244
  date: 2020-10-12_12-45-25
  done: false
  episode_len_mean: 874.2485615650172
  episode_reward_max: 265.98989898989885
  episode_reward_mean: 207.6282328462994
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 158
  episodes_total: 1738
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9345782349507014
        entropy_coeff: 0.0005000000000000001
        kl: 0.010406606830656528
        model: {}
        policy_loss: -0.012782466857364247
        total_loss: 15.828081607818604
        vf_explained_var: 0.9704818725585938
        vf_loss: 15.839249928792318
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.05161290322581
    gpu_util_percent0: 0.3235483870967742
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1531620655206913
    mean_env_wait_ms: 1.1841426684940646
    mean_inference_ms: 4.887140248800401
    mean_raw_obs_processing_ms: 0.4050625725290317
  time_since_restore: 256.2793447971344
  time_this_iter_s: 25.267457962036133
  time_total_s: 256.2793447971344
  timers:
    learn_throughput: 8863.693
    learn_time_ms: 18253.339
    sample_throughput: 22190.401
    sample_time_ms: 7291.08
    update_time_ms: 30.06
  timestamp: 1602506725
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |     10 |          256.279 | 1617920 |  207.628 |               265.99 |              103.869 |            874.249 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3567.2398331595414
    time_step_min: 3204
  date: 2020-10-12_12-45-50
  done: false
  episode_len_mean: 869.6589979550102
  episode_reward_max: 265.98989898989885
  episode_reward_mean: 209.6501983020386
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 218
  episodes_total: 1956
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8774597297112147
        entropy_coeff: 0.0005000000000000001
        kl: 0.008312907807218531
        model: {}
        policy_loss: -0.0122647722697972
        total_loss: 18.05313523610433
        vf_explained_var: 0.9744693636894226
        vf_loss: 18.064175605773926
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.416129032258066
    gpu_util_percent0: 0.43387096774193545
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15261507089215343
    mean_env_wait_ms: 1.1855412581728093
    mean_inference_ms: 4.840692025156583
    mean_raw_obs_processing_ms: 0.40302535798065264
  time_since_restore: 281.6960823535919
  time_this_iter_s: 25.41673755645752
  time_total_s: 281.6960823535919
  timers:
    learn_throughput: 8872.789
    learn_time_ms: 18234.628
    sample_throughput: 23124.342
    sample_time_ms: 6996.61
    update_time_ms: 34.77
  timestamp: 1602506750
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |     11 |          281.696 | 1779712 |   209.65 |               265.99 |              103.869 |            869.659 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3549.628334866605
    time_step_min: 3204
  date: 2020-10-12_12-46-16
  done: false
  episode_len_mean: 864.1817359855335
  episode_reward_max: 265.98989898989885
  episode_reward_mean: 212.43381372495276
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 256
  episodes_total: 2212
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8915381878614426
        entropy_coeff: 0.0005000000000000001
        kl: 0.008165694385146102
        model: {}
        policy_loss: -0.011242418205559565
        total_loss: 13.918485085169474
        vf_explained_var: 0.9769068360328674
        vf_loss: 13.928540070851644
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.02
    gpu_util_percent0: 0.38633333333333336
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15210972960233765
    mean_env_wait_ms: 1.1873283764208125
    mean_inference_ms: 4.7954882195614985
    mean_raw_obs_processing_ms: 0.4011316816424087
  time_since_restore: 306.8828868865967
  time_this_iter_s: 25.18680453300476
  time_total_s: 306.8828868865967
  timers:
    learn_throughput: 8866.176
    learn_time_ms: 18248.228
    sample_throughput: 23431.74
    sample_time_ms: 6904.822
    update_time_ms: 34.708
  timestamp: 1602506776
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |     12 |          306.883 | 1941504 |  212.434 |               265.99 |              103.869 |            864.182 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3538.193396226415
    time_step_min: 3181
  date: 2020-10-12_12-46-41
  done: false
  episode_len_mean: 861.0860759493671
  episode_reward_max: 274.32323232323245
  episode_reward_mean: 214.30494821634042
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8875755866368612
        entropy_coeff: 0.0005000000000000001
        kl: 0.008178358897566795
        model: {}
        policy_loss: -0.01203233091897952
        total_loss: 10.249838272730509
        vf_explained_var: 0.9787597060203552
        vf_loss: 10.260678688685099
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.56666666666667
    gpu_util_percent0: 0.3710000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1518314596967917
    mean_env_wait_ms: 1.1882538796145266
    mean_inference_ms: 4.771315277022864
    mean_raw_obs_processing_ms: 0.4000812518671405
  time_since_restore: 332.0176875591278
  time_this_iter_s: 25.134800672531128
  time_total_s: 332.0176875591278
  timers:
    learn_throughput: 8875.196
    learn_time_ms: 18229.681
    sample_throughput: 23525.436
    sample_time_ms: 6877.322
    update_time_ms: 34.71
  timestamp: 1602506801
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |     13 |          332.018 | 2103296 |  214.305 |              274.323 |              103.869 |            861.086 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3528.1875502008033
    time_step_min: 3181
  date: 2020-10-12_12-47-06
  done: false
  episode_len_mean: 858.2674050632911
  episode_reward_max: 274.32323232323245
  episode_reward_mean: 215.77826924306336
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.856998215119044
        entropy_coeff: 0.0005000000000000001
        kl: 0.00969620724208653
        model: {}
        policy_loss: -0.0134882829831137
        total_loss: 13.924917697906494
        vf_explained_var: 0.9716804623603821
        vf_loss: 13.936895052591959
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.700000000000006
    gpu_util_percent0: 0.4358064516129032
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7677419354838704
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1515813407918045
    mean_env_wait_ms: 1.189197447544308
    mean_inference_ms: 4.749326621425944
    mean_raw_obs_processing_ms: 0.39910258833924206
  time_since_restore: 357.32856607437134
  time_this_iter_s: 25.31087851524353
  time_total_s: 357.32856607437134
  timers:
    learn_throughput: 8875.097
    learn_time_ms: 18229.885
    sample_throughput: 23522.194
    sample_time_ms: 6878.27
    update_time_ms: 37.184
  timestamp: 1602506826
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |     14 |          357.329 | 2265088 |  215.778 |              274.323 |              103.869 |            858.267 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3514.6466495789086
    time_step_min: 3140
  date: 2020-10-12_12-47-32
  done: false
  episode_len_mean: 853.8215962441315
  episode_reward_max: 280.8383838383843
  episode_reward_mean: 217.90827013362207
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 241
  episodes_total: 2769
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8127262592315674
        entropy_coeff: 0.0005000000000000001
        kl: 0.008126523694954813
        model: {}
        policy_loss: -0.010932543635135517
        total_loss: 14.474535862604776
        vf_explained_var: 0.977644145488739
        vf_loss: 14.484249750773111
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.063333333333336
    gpu_util_percent0: 0.40133333333333343
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7566666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15123347765611564
    mean_env_wait_ms: 1.1906520362384039
    mean_inference_ms: 4.719627431960467
    mean_raw_obs_processing_ms: 0.39779042001698217
  time_since_restore: 382.6521873474121
  time_this_iter_s: 25.32362127304077
  time_total_s: 382.6521873474121
  timers:
    learn_throughput: 8860.362
    learn_time_ms: 18260.202
    sample_throughput: 23510.812
    sample_time_ms: 6881.6
    update_time_ms: 39.104
  timestamp: 1602506852
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |     15 |          382.652 | 2426880 |  217.908 |              280.838 |              103.869 |            853.822 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3501.6562078272605
    time_step_min: 3140
  date: 2020-10-12_12-47-57
  done: false
  episode_len_mean: 850.0749500333111
  episode_reward_max: 280.8383838383843
  episode_reward_mean: 219.97819971870587
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 233
  episodes_total: 3002
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8265580087900162
        entropy_coeff: 0.0005000000000000001
        kl: 0.0073860930278897285
        model: {}
        policy_loss: -0.01235430066784223
        total_loss: 12.919872283935547
        vf_explained_var: 0.9763839244842529
        vf_loss: 12.931162595748901
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.33225806451613
    gpu_util_percent0: 0.37806451612903225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15095862624685177
    mean_env_wait_ms: 1.191961939984729
    mean_inference_ms: 4.6942695809081
    mean_raw_obs_processing_ms: 0.3966709070166309
  time_since_restore: 407.81439876556396
  time_this_iter_s: 25.162211418151855
  time_total_s: 407.81439876556396
  timers:
    learn_throughput: 8863.467
    learn_time_ms: 18253.805
    sample_throughput: 23546.572
    sample_time_ms: 6871.149
    update_time_ms: 39.317
  timestamp: 1602506877
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |     16 |          407.814 | 2588672 |  219.978 |              280.838 |              103.869 |            850.075 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3492.436258808456
    time_step_min: 3119
  date: 2020-10-12_12-48-22
  done: false
  episode_len_mean: 847.2594936708861
  episode_reward_max: 280.8383838383843
  episode_reward_mean: 221.37885180923143
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8125823885202408
        entropy_coeff: 0.0005000000000000001
        kl: 0.008281391502047578
        model: {}
        policy_loss: -0.011356104048900306
        total_loss: 9.663305759429932
        vf_explained_var: 0.9782115817070007
        vf_loss: 9.673412243525187
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.693333333333335
    gpu_util_percent0: 0.4070000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1507837572186493
    mean_env_wait_ms: 1.1928006997215825
    mean_inference_ms: 4.6788241654043015
    mean_raw_obs_processing_ms: 0.39598572349265476
  time_since_restore: 432.97275257110596
  time_this_iter_s: 25.158353805541992
  time_total_s: 432.97275257110596
  timers:
    learn_throughput: 8859.915
    learn_time_ms: 18261.123
    sample_throughput: 23489.966
    sample_time_ms: 6887.707
    update_time_ms: 40.806
  timestamp: 1602506902
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |     17 |          432.973 | 2750464 |  221.379 |              280.838 |              103.869 |            847.259 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3483.4416489845407
    time_step_min: 3107
  date: 2020-10-12_12-48-48
  done: false
  episode_len_mean: 844.361402457297
  episode_reward_max: 280.8383838383843
  episode_reward_mean: 222.66292230062072
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 177
  episodes_total: 3337
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7774624129136404
        entropy_coeff: 0.0005000000000000001
        kl: 0.007771470583975315
        model: {}
        policy_loss: -0.0106985210198521
        total_loss: 13.568020105361938
        vf_explained_var: 0.9741862416267395
        vf_loss: 13.577553272247314
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.533333333333335
    gpu_util_percent0: 0.35033333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.763333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15059689435383208
    mean_env_wait_ms: 1.1937565633065248
    mean_inference_ms: 4.662767968667752
    mean_raw_obs_processing_ms: 0.3952597096376507
  time_since_restore: 458.26481223106384
  time_this_iter_s: 25.292059659957886
  time_total_s: 458.26481223106384
  timers:
    learn_throughput: 8866.181
    learn_time_ms: 18248.217
    sample_throughput: 23421.429
    sample_time_ms: 6907.862
    update_time_ms: 40.792
  timestamp: 1602506928
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |     18 |          458.265 | 2912256 |  222.663 |              280.838 |              103.869 |            844.361 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3469.0558035714284
    time_step_min: 3103
  date: 2020-10-12_12-49-13
  done: false
  episode_len_mean: 840.6540585311982
  episode_reward_max: 280.8383838383843
  episode_reward_mean: 224.7835505803478
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 285
  episodes_total: 3622
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7639108151197433
        entropy_coeff: 0.0005000000000000001
        kl: 0.007965258749512335
        model: {}
        policy_loss: -0.011703262804076076
        total_loss: 13.452379624048868
        vf_explained_var: 0.9790812134742737
        vf_loss: 13.462871869405111
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.19354838709678
    gpu_util_percent0: 0.38774193548387104
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15033058914564848
    mean_env_wait_ms: 1.1952151938253293
    mean_inference_ms: 4.6397435473809665
    mean_raw_obs_processing_ms: 0.3942438580475177
  time_since_restore: 483.7762076854706
  time_this_iter_s: 25.51139545440674
  time_total_s: 483.7762076854706
  timers:
    learn_throughput: 8864.184
    learn_time_ms: 18252.328
    sample_throughput: 23362.765
    sample_time_ms: 6925.208
    update_time_ms: 41.208
  timestamp: 1602506953
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |     19 |          483.776 | 3074048 |  224.784 |              280.838 |              103.869 |            840.654 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3461.3732019179542
    time_step_min: 3103
  date: 2020-10-12_12-49-39
  done: false
  episode_len_mean: 838.9135021097046
  episode_reward_max: 285.38383838383845
  episode_reward_mean: 225.88976793248932
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 170
  episodes_total: 3792
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.766115223368009
        entropy_coeff: 0.0005000000000000001
        kl: 0.008806192160894474
        model: {}
        policy_loss: -0.011443730986987552
        total_loss: 9.936623414357504
        vf_explained_var: 0.9795882701873779
        vf_loss: 9.946688731511435
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.05483870967742
    gpu_util_percent0: 0.40096774193548396
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1501918110461253
    mean_env_wait_ms: 1.195999963637844
    mean_inference_ms: 4.627335142873465
    mean_raw_obs_processing_ms: 0.3936955816268394
  time_since_restore: 508.9462254047394
  time_this_iter_s: 25.1700177192688
  time_total_s: 508.9462254047394
  timers:
    learn_throughput: 8874.592
    learn_time_ms: 18230.923
    sample_throughput: 23346.289
    sample_time_ms: 6930.095
    update_time_ms: 47.119
  timestamp: 1602506979
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |     20 |          508.946 | 3235840 |   225.89 |              285.384 |              103.869 |            838.914 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3454.1712678936606
    time_step_min: 3055
  date: 2020-10-12_12-50-04
  done: false
  episode_len_mean: 837.6673417721519
  episode_reward_max: 287.50505050505063
  episode_reward_mean: 226.9058943869069
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 158
  episodes_total: 3950
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7407130201657613
        entropy_coeff: 0.0005000000000000001
        kl: 0.008243777633955082
        model: {}
        policy_loss: -0.012428918872804692
        total_loss: 8.967528343200684
        vf_explained_var: 0.9805740714073181
        vf_loss: 8.978678782780966
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.153333333333332
    gpu_util_percent0: 0.3763333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15006646725248415
    mean_env_wait_ms: 1.1966844198960693
    mean_inference_ms: 4.61650700645417
    mean_raw_obs_processing_ms: 0.39321282832754056
  time_since_restore: 534.2988319396973
  time_this_iter_s: 25.352606534957886
  time_total_s: 534.2988319396973
  timers:
    learn_throughput: 8874.418
    learn_time_ms: 18231.281
    sample_throughput: 23349.139
    sample_time_ms: 6929.249
    update_time_ms: 40.065
  timestamp: 1602507004
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |     21 |          534.299 | 3397632 |  226.906 |              287.505 |              103.869 |            837.667 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3445.0468825519574
    time_step_min: 3038
  date: 2020-10-12_12-50-30
  done: false
  episode_len_mean: 835.9090038314176
  episode_reward_max: 290.0808080808085
  episode_reward_mean: 228.28348862185055
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 226
  episodes_total: 4176
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7066819369792938
        entropy_coeff: 0.0005000000000000001
        kl: 0.0072280893024678034
        model: {}
        policy_loss: -0.010945961985271424
        total_loss: 11.130944808324179
        vf_explained_var: 0.9808902144432068
        vf_loss: 11.140798648198446
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.722580645161294
    gpu_util_percent0: 0.34903225806451615
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14989979197496556
    mean_env_wait_ms: 1.1976402522800627
    mean_inference_ms: 4.602214341921051
    mean_raw_obs_processing_ms: 0.3925851846653174
  time_since_restore: 559.6668326854706
  time_this_iter_s: 25.368000745773315
  time_total_s: 559.6668326854706
  timers:
    learn_throughput: 8862.443
    learn_time_ms: 18255.914
    sample_throughput: 23375.045
    sample_time_ms: 6921.57
    update_time_ms: 40.005
  timestamp: 1602507030
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |     22 |          559.667 | 3559424 |  228.283 |              290.081 |              103.869 |            835.909 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3435.8950490531597
    time_step_min: 3038
  date: 2020-10-12_12-50-55
  done: false
  episode_len_mean: 834.2800271431803
  episode_reward_max: 290.0808080808085
  episode_reward_mean: 229.685107121886
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 245
  episodes_total: 4421
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7094381352265676
        entropy_coeff: 0.0005000000000000001
        kl: 0.007193775498308241
        model: {}
        policy_loss: -0.009674939826557724
        total_loss: 11.638227303822836
        vf_explained_var: 0.9800446629524231
        vf_loss: 11.646818240483602
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.433333333333334
    gpu_util_percent0: 0.362
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1497400142185662
    mean_env_wait_ms: 1.1985558213425693
    mean_inference_ms: 4.588117093058339
    mean_raw_obs_processing_ms: 0.39196941573310146
  time_since_restore: 584.7904210090637
  time_this_iter_s: 25.12358832359314
  time_total_s: 584.7904210090637
  timers:
    learn_throughput: 8864.736
    learn_time_ms: 18251.192
    sample_throughput: 23359.588
    sample_time_ms: 6926.149
    update_time_ms: 38.088
  timestamp: 1602507055
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | RUNNING  | 172.17.0.4:3607 |     23 |           584.79 | 3721216 |  229.685 |              290.081 |              103.869 |             834.28 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_2f54c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3430.409991197183
    time_step_min: 3038
  date: 2020-10-12_12-51-20
  done: true
  episode_len_mean: 833.2625491051942
  episode_reward_max: 290.0808080808085
  episode_reward_mean: 230.49811956315654
  episode_reward_min: 103.86868686868668
  episodes_this_iter: 161
  episodes_total: 4582
  experiment_id: 491ef34585e64f54b20fbc09c16bc3ba
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7097810804843903
        entropy_coeff: 0.0005000000000000001
        kl: 0.008278841967694461
        model: {}
        policy_loss: -0.012854809523560107
        total_loss: 9.026721954345703
        vf_explained_var: 0.9808015823364258
        vf_loss: 9.038275957107544
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.696774193548393
    gpu_util_percent0: 0.3629032258064516
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 3607
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14964207197748294
    mean_env_wait_ms: 1.1991136531444715
    mean_inference_ms: 4.579491036798572
    mean_raw_obs_processing_ms: 0.39159067077186765
  time_since_restore: 610.0600578784943
  time_this_iter_s: 25.269636869430542
  time_total_s: 610.0600578784943
  timers:
    learn_throughput: 8873.143
    learn_time_ms: 18233.899
    sample_throughput: 23318.511
    sample_time_ms: 6938.35
    update_time_ms: 37.915
  timestamp: 1602507080
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 2f54c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | TERMINATED |       |     24 |           610.06 | 3883008 |  230.498 |              290.081 |              103.869 |            833.263 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.67 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_2f54c_00000 | TERMINATED |       |     24 |           610.06 | 3883008 |  230.498 |              290.081 |              103.869 |            833.263 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


