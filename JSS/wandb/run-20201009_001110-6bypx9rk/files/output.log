2020-10-09 00:11:12,998	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_f1b77_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=65012)[0m F1009 00:11:15.186262 65012 65012 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:41401
[2m[36m(pid=65012)[0m *** Check failure stack trace: ***
[2m[36m(pid=65012)[0m     @     0x7f88ba7016ed  google::LogMessage::Fail()
[2m[36m(pid=65012)[0m     @     0x7f88ba70284c  google::LogMessage::SendToLog()
[2m[36m(pid=65012)[0m     @     0x7f88ba7013c9  google::LogMessage::Flush()
[2m[36m(pid=65012)[0m     @     0x7f88ba7015e1  google::LogMessage::~LogMessage()
[2m[36m(pid=65012)[0m     @     0x7f88ba6b8789  ray::RayLog::~RayLog()
[2m[36m(pid=65012)[0m     @     0x7f88ba3fc1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=65012)[0m     @     0x7f88ba3fc2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=65012)[0m     @     0x7f88ba3fc491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=65012)[0m     @     0x7f88ba3fe801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=65012)[0m     @     0x7f88ba37fed6  ray::CoreWorker::CoreWorker()
[2m[36m(pid=65012)[0m     @     0x7f88ba383c14  ray::CoreWorkerProcess::CreateWorker()
[2m[36m(pid=65012)[0m     @     0x7f88ba384e82  ray::CoreWorkerProcess::CoreWorkerProcess()
[2m[36m(pid=65012)[0m     @     0x7f88ba38584b  ray::CoreWorkerProcess::Initialize()
[2m[36m(pid=65012)[0m     @     0x7f88ba2c3448  __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()
[2m[36m(pid=65012)[0m     @     0x7f88ba2c4ba5  __pyx_tp_new_3ray_7_raylet_CoreWorker()
[2m[36m(pid=65012)[0m     @     0x556ac03f737d  _PyObject_MakeTpCall
[2m[36m(pid=65012)[0m     @     0x556ac047fd09  _PyEval_EvalFrameDefault
[2m[36m(pid=65012)[0m     @     0x556ac0444baf  _PyEval_EvalCodeWithName
[2m[36m(pid=65012)[0m     @     0x556ac0445643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=65012)[0m     @     0x556ac03bade6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=65012)[0m     @     0x556ac04446a2  _PyEval_EvalCodeWithName
[2m[36m(pid=65012)[0m     @     0x556ac0445454  PyEval_EvalCodeEx
[2m[36m(pid=65012)[0m     @     0x556ac04d3bbc  PyEval_EvalCode
[2m[36m(pid=65012)[0m     @     0x556ac04d3c64  run_eval_code_obj
[2m[36m(pid=65012)[0m     @     0x556ac0505d14  run_mod
[2m[36m(pid=65012)[0m     @     0x556ac03ce625  PyRun_FileExFlags
[2m[36m(pid=65012)[0m     @     0x556ac03cea0a  PyRun_SimpleFileExFlags
[2m[36m(pid=65012)[0m     @     0x556ac03cf8cf  Py_RunMain.cold.2911
[2m[36m(pid=65012)[0m     @     0x556ac0508829  Py_BytesMain
[2m[36m(pid=65012)[0m     @     0x7f88bba06840  __libc_start_main
[2m[36m(pid=65012)[0m     @     0x556ac0498b33  (unknown)
[2m[36m(pid=64997)[0m F1009 00:11:15.186239 64997 64997 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:41401
[2m[36m(pid=64997)[0m *** Check failure stack trace: ***
[2m[36m(pid=64997)[0m     @     0x7f8bf01a56ed  google::LogMessage::Fail()
[2m[36m(pid=64997)[0m     @     0x7f8bf01a684c  google::LogMessage::SendToLog()
[2m[36m(pid=64997)[0m     @     0x7f8bf01a53c9  google::LogMessage::Flush()
[2m[36m(pid=64997)[0m     @     0x7f8bf01a55e1  google::LogMessage::~LogMessage()
[2m[36m(pid=64997)[0m     @     0x7f8bf015c789  ray::RayLog::~RayLog()
[2m[36m(pid=64997)[0m     @     0x7f8befea01ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=64997)[0m     @     0x7f8befea02ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=64997)[0m     @     0x7f8befea0491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=64997)[0m     @     0x7f8befea2801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=64997)[0m     @     0x7f8befdb17a8  ray::gcs::GlobalStateAccessor::Connect()
[2m[36m(pid=64997)[0m     @     0x7f8befd22a2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()
[2m[36m(pid=64997)[0m     @     0x55e3fe97d98a  method_vectorcall_NOARGS
[2m[36m(pid=64997)[0m     @     0x55e3fe90db08  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=64997)[0m     @     0x55e3fe9986a2  _PyEval_EvalCodeWithName
[2m[36m(pid=64997)[0m     @     0x55e3fe999a20  method_vectorcall
[2m[36m(pid=64997)[0m     @     0x55e3fe90ede6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=64997)[0m     @     0x55e3fe998baf  _PyEval_EvalCodeWithName
[2m[36m(pid=64997)[0m     @     0x55e3fe999643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=64997)[0m     @     0x55e3fe90ede6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=64997)[0m     @     0x55e3fe9986a2  _PyEval_EvalCodeWithName
[2m[36m(pid=64997)[0m     @     0x55e3fe999454  PyEval_EvalCodeEx
[2m[36m(pid=64997)[0m     @     0x55e3fea27bbc  PyEval_EvalCode
[2m[36m(pid=64997)[0m     @     0x55e3fea27c64  run_eval_code_obj
[2m[36m(pid=64997)[0m     @     0x55e3fea59d14  run_mod
[2m[36m(pid=64997)[0m     @     0x55e3fe922625  PyRun_FileExFlags
[2m[36m(pid=64997)[0m     @     0x55e3fe922a0a  PyRun_SimpleFileExFlags
[2m[36m(pid=64997)[0m     @     0x55e3fe9238cf  Py_RunMain.cold.2911
[2m[36m(pid=64997)[0m     @     0x55e3fea5c829  Py_BytesMain
[2m[36m(pid=64997)[0m     @     0x7f8bf14aa840  __libc_start_main
[2m[36m(pid=64997)[0m     @     0x55e3fe9ecb33  (unknown)
[2m[36m(pid=64968)[0m F1009 00:11:15.186281 64968 64968 service_based_gcs_client.cc:207] Couldn't reconnect to GCS server. The last attempted GCS server address was 172.17.0.4:41401
[2m[36m(pid=64968)[0m *** Check failure stack trace: ***
[2m[36m(pid=64968)[0m     @     0x7f3a4f4516ed  google::LogMessage::Fail()
[2m[36m(pid=64968)[0m     @     0x7f3a4f45284c  google::LogMessage::SendToLog()
[2m[36m(pid=64968)[0m     @     0x7f3a4f4513c9  google::LogMessage::Flush()
[2m[36m(pid=64968)[0m     @     0x7f3a4f4515e1  google::LogMessage::~LogMessage()
[2m[36m(pid=64968)[0m     @     0x7f3a4f408789  ray::RayLog::~RayLog()
[2m[36m(pid=64968)[0m     @     0x7f3a4f14c1ea  ray::gcs::ServiceBasedGcsClient::ReconnectGcsServer()
[2m[36m(pid=64968)[0m     @     0x7f3a4f14c2ef  ray::gcs::ServiceBasedGcsClient::GcsServiceFailureDetected()
[2m[36m(pid=64968)[0m     @     0x7f3a4f14c491  ray::gcs::ServiceBasedGcsClient::PeriodicallyCheckGcsServerAddress()
[2m[36m(pid=64968)[0m     @     0x7f3a4f14e801  ray::gcs::ServiceBasedGcsClient::Connect()
[2m[36m(pid=64968)[0m     @     0x7f3a4f05d7a8  ray::gcs::GlobalStateAccessor::Connect()
[2m[36m(pid=64968)[0m     @     0x7f3a4efcea2c  __pyx_pw_3ray_7_raylet_19GlobalStateAccessor_3connect()
[2m[36m(pid=64968)[0m     @     0x562afdb7898a  method_vectorcall_NOARGS
[2m[36m(pid=64968)[0m     @     0x562afdb08b08  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=64968)[0m     @     0x562afdb936a2  _PyEval_EvalCodeWithName
[2m[36m(pid=64968)[0m     @     0x562afdb94a20  method_vectorcall
[2m[36m(pid=64968)[0m     @     0x562afdb09de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=64968)[0m     @     0x562afdb93baf  _PyEval_EvalCodeWithName
[2m[36m(pid=64968)[0m     @     0x562afdb94643  _PyFunction_Vectorcall.localalias.353
[2m[36m(pid=64968)[0m     @     0x562afdb09de6  _PyEval_EvalFrameDefault.cold.2792
[2m[36m(pid=64968)[0m     @     0x562afdb936a2  _PyEval_EvalCodeWithName
[2m[36m(pid=64968)[0m     @     0x562afdb94454  PyEval_EvalCodeEx
[2m[36m(pid=64968)[0m     @     0x562afdc22bbc  PyEval_EvalCode
[2m[36m(pid=64968)[0m     @     0x562afdc22c64  run_eval_code_obj
[2m[36m(pid=64968)[0m     @     0x562afdc54d14  run_mod
[2m[36m(pid=64968)[0m     @     0x562afdb1d625  PyRun_FileExFlags
[2m[36m(pid=64968)[0m     @     0x562afdb1da0a  PyRun_SimpleFileExFlags
[2m[36m(pid=64968)[0m     @     0x562afdb1e8cf  Py_RunMain.cold.2911
[2m[36m(pid=64968)[0m     @     0x562afdc57829  Py_BytesMain
[2m[36m(pid=64968)[0m     @     0x7f3a50756840  __libc_start_main
[2m[36m(pid=64968)[0m     @     0x562afdbe7b33  (unknown)
[2m[33m(pid=raylet)[0m E1009 00:11:15.359071 64857 64857 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 14: Socket closed
[2m[36m(pid=65035)[0m 2020-10-09 00:11:16,020	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=64966)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64966)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65025)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65025)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64977)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64977)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65021)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65021)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65043)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65043)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65047)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65047)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64993)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64993)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64922)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64922)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66310)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66310)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=66308)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=66308)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64901)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64901)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64972)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64972)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64929)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64957)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64957)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64917)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64917)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64959)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64959)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64906)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64906)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64910)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64910)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64920)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64920)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64932)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64932)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64903)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65006)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65006)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64908)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64908)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64970)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64970)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64976)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64976)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64927)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64927)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=64987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=64987)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-09_00-12-04
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1628045976161956
        entropy_coeff: 0.0
        kl: 0.004239660990424454
        model: {}
        policy_loss: -0.004714153171516955
        total_loss: 9.456318664550782
        vf_explained_var: 0.7033258080482483
        vf_loss: 9.460185050964355
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.805999999999997
    gpu_util_percent0: 0.32080000000000003
    gpu_util_percent1: 0.0002
    gpu_util_percent2: 0.0
    ram_util_percent: 9.606
    vram_util_percent0: 0.2612397507379468
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1759655661846466
    mean_env_wait_ms: 1.6622204528836861
    mean_inference_ms: 5.842126028962473
    mean_raw_obs_processing_ms: 0.4849467140614673
  time_since_restore: 42.709136962890625
  time_this_iter_s: 42.709136962890625
  time_total_s: 42.709136962890625
  timers:
    learn_throughput: 4909.96
    learn_time_ms: 32951.796
    sample_throughput: 16726.466
    sample_time_ms: 9672.814
    update_time_ms: 49.521
  timestamp: 1602202324
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | RUNNING  | 172.17.0.4:65035 |      1 |          42.7091 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3229.0
  date: 2020-10-09_00-12-46
  done: false
  episode_len_mean: 868.6645569620254
  episode_reward_max: 276.02020202020145
  episode_reward_mean: 227.76617440225016
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1365543842315673
        entropy_coeff: 0.0
        kl: 0.006420647399500013
        model: {}
        policy_loss: -0.006186454044654966
        total_loss: 9.450008010864257
        vf_explained_var: 0.8492267727851868
        vf_loss: 9.455552434921264
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.945999999999998
    gpu_util_percent0: 0.42839999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.764
    vram_util_percent0: 0.26820268940636266
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1719626135179167
    mean_env_wait_ms: 1.6568595224966123
    mean_inference_ms: 5.596785371847416
    mean_raw_obs_processing_ms: 0.4732312684114028
  time_since_restore: 84.6427047252655
  time_this_iter_s: 41.93356776237488
  time_total_s: 84.6427047252655
  timers:
    learn_throughput: 4905.774
    learn_time_ms: 32979.91
    sample_throughput: 17513.241
    sample_time_ms: 9238.267
    update_time_ms: 50.768
  timestamp: 1602202366
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | RUNNING  | 172.17.0.4:65035 |      2 |          84.6427 | 323584 |  227.766 |               276.02 |              115.788 |            868.665 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3229.0
  date: 2020-10-09_00-13-28
  done: false
  episode_len_mean: 860.1455696202531
  episode_reward_max: 276.02020202020145
  episode_reward_mean: 229.9722115671481
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1241052627563477
        entropy_coeff: 0.0
        kl: 0.007269341056235135
        model: {}
        policy_loss: -0.006223427232907852
        total_loss: 10.918299245834351
        vf_explained_var: 0.8974983096122742
        vf_loss: 10.923795747756959
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.03877551020408
    gpu_util_percent0: 0.3197959183673469
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.781632653061225
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16932918467182737
    mean_env_wait_ms: 1.654746898399017
    mean_inference_ms: 5.453665335204041
    mean_raw_obs_processing_ms: 0.46480607780913724
  time_since_restore: 126.49483966827393
  time_this_iter_s: 41.85213494300842
  time_total_s: 126.49483966827393
  timers:
    learn_throughput: 4899.878
    learn_time_ms: 33019.596
    sample_throughput: 17874.548
    sample_time_ms: 9051.53
    update_time_ms: 41.858
  timestamp: 1602202408
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | RUNNING  | 172.17.0.4:65035 |      3 |          126.495 | 485376 |  229.972 |               276.02 |              115.788 |            860.146 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3229.0
  date: 2020-10-09_00-14-09
  done: false
  episode_len_mean: 853.5094936708861
  episode_reward_max: 276.02020202020145
  episode_reward_mean: 229.8946586114306
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0905028462409974
        entropy_coeff: 0.0
        kl: 0.005915813730098307
        model: {}
        policy_loss: -0.005764117499347776
        total_loss: 12.163257503509522
        vf_explained_var: 0.9268477559089661
        vf_loss: 12.168429899215699
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.381250000000005
    gpu_util_percent0: 0.2691666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.797916666666666
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16735682173780037
    mean_env_wait_ms: 1.6560578683778837
    mean_inference_ms: 5.34454344885855
    mean_raw_obs_processing_ms: 0.4584647325920728
  time_since_restore: 167.60762286186218
  time_this_iter_s: 41.11278319358826
  time_total_s: 167.60762286186218
  timers:
    learn_throughput: 4910.134
    learn_time_ms: 32950.631
    sample_throughput: 18269.868
    sample_time_ms: 8855.674
    update_time_ms: 44.05
  timestamp: 1602202449
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | RUNNING  | 172.17.0.4:65035 |      4 |          167.608 | 647168 |  229.895 |               276.02 |              115.788 |            853.509 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3229.0
  date: 2020-10-09_00-14-51
  done: false
  episode_len_mean: 839.717299578059
  episode_reward_max: 277.78787878787887
  episode_reward_mean: 230.043557942292
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 948
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0668568909168243
        entropy_coeff: 0.0
        kl: 0.006043939827941358
        model: {}
        policy_loss: -0.005857846001163125
        total_loss: 16.43660545349121
        vf_explained_var: 0.9565473794937134
        vf_loss: 16.441858530044556
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.426530612244896
    gpu_util_percent0: 0.3357142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.777551020408163
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1648819733382446
    mean_env_wait_ms: 1.6625882664317821
    mean_inference_ms: 5.201216203464679
    mean_raw_obs_processing_ms: 0.45050696691361053
  time_since_restore: 208.6708996295929
  time_this_iter_s: 41.06327676773071
  time_total_s: 208.6708996295929
  timers:
    learn_throughput: 4919.459
    learn_time_ms: 32888.167
    sample_throughput: 18487.7
    sample_time_ms: 8751.332
    update_time_ms: 41.245
  timestamp: 1602202491
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | RUNNING  | 172.17.0.4:65035 |      5 |          208.671 | 808960 |  230.044 |              277.788 |              115.788 |            839.717 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3229.0
  date: 2020-10-09_00-15-32
  done: false
  episode_len_mean: 833.9538878842676
  episode_reward_max: 277.78787878787887
  episode_reward_mean: 230.76249840173878
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1106
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0431653082370758
        entropy_coeff: 0.0
        kl: 0.005221850331872701
        model: {}
        policy_loss: -0.00576116448501125
        total_loss: 8.598921585083009
        vf_explained_var: 0.9699373245239258
        vf_loss: 8.604160499572753
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.695918367346938
    gpu_util_percent0: 0.51
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.781632653061225
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16402721921080277
    mean_env_wait_ms: 1.6655565112005717
    mean_inference_ms: 5.150633792478033
    mean_raw_obs_processing_ms: 0.4477647813453903
  time_since_restore: 250.02689933776855
  time_this_iter_s: 41.35599970817566
  time_total_s: 250.02689933776855
  timers:
    learn_throughput: 4917.024
    learn_time_ms: 32904.453
    sample_throughput: 18650.103
    sample_time_ms: 8675.126
    update_time_ms: 38.031
  timestamp: 1602202532
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | RUNNING  | 172.17.0.4:65035 |      6 |          250.027 | 970752 |  230.762 |              277.788 |              115.788 |            833.954 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3229.0
  date: 2020-10-09_00-16-13
  done: false
  episode_len_mean: 828.8892405063291
  episode_reward_max: 277.78787878787887
  episode_reward_mean: 231.0204018028384
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0170399367809295
        entropy_coeff: 0.0
        kl: 0.005163697362877429
        model: {}
        policy_loss: -0.005776332248933614
        total_loss: 7.376203727722168
        vf_explained_var: 0.9783684015274048
        vf_loss: 7.381463575363159
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.89375
    gpu_util_percent0: 0.3160416666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.783333333333333
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16327990998450112
    mean_env_wait_ms: 1.668543015713501
    mean_inference_ms: 5.106530530373725
    mean_raw_obs_processing_ms: 0.4453346032433937
  time_since_restore: 291.2291383743286
  time_this_iter_s: 41.20223903656006
  time_total_s: 291.2291383743286
  timers:
    learn_throughput: 4920.472
    learn_time_ms: 32881.396
    sample_throughput: 18748.662
    sample_time_ms: 8629.522
    update_time_ms: 39.047
  timestamp: 1602202573
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | RUNNING  | 172.17.0.4:65035 |      7 |          291.229 | 1132544 |   231.02 |              277.788 |              115.788 |            828.889 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_00-16-55
  done: false
  episode_len_mean: 823.405737704918
  episode_reward_max: 280.18181818181773
  episode_reward_mean: 231.09354473698733
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 200
  episodes_total: 1464
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9572030603885651
        entropy_coeff: 0.0
        kl: 0.004545945767313242
        model: {}
        policy_loss: -0.005052770231850445
        total_loss: 7.691865944862366
        vf_explained_var: 0.9867053031921387
        vf_loss: 7.696464085578919
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.87551020408163
    gpu_util_percent0: 0.09693877551020408
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.802040816326532
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16246519359747
    mean_env_wait_ms: 1.673000529309231
    mean_inference_ms: 5.058626958301233
    mean_raw_obs_processing_ms: 0.44259229413412576
  time_since_restore: 332.7390384674072
  time_this_iter_s: 41.50990009307861
  time_total_s: 332.7390384674072
  timers:
    learn_throughput: 4918.941
    learn_time_ms: 32891.631
    sample_throughput: 18800.527
    sample_time_ms: 8605.716
    update_time_ms: 38.904
  timestamp: 1602202615
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | RUNNING  | 172.17.0.4:65035 |      8 |          332.739 | 1294336 |  231.094 |              280.182 |              115.788 |            823.406 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_00-17-36
  done: false
  episode_len_mean: 817.6800920598389
  episode_reward_max: 280.18181818181773
  episode_reward_mean: 231.49821575943548
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 274
  episodes_total: 1738
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.9353442519903183
        entropy_coeff: 0.0
        kl: 0.0056465347064659
        model: {}
        policy_loss: -0.004887169401627034
        total_loss: 6.298691725730896
        vf_explained_var: 0.9877284169197083
        vf_loss: 6.303296661376953
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.170833333333334
    gpu_util_percent0: 0.299375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.781249999999998
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16159257081417872
    mean_env_wait_ms: 1.6780370380276186
    mean_inference_ms: 5.005834822196348
    mean_raw_obs_processing_ms: 0.43961367598294454
  time_since_restore: 374.0010726451874
  time_this_iter_s: 41.26203417778015
  time_total_s: 374.0010726451874
  timers:
    learn_throughput: 4920.144
    learn_time_ms: 32883.593
    sample_throughput: 18867.966
    sample_time_ms: 8574.957
    update_time_ms: 39.402
  timestamp: 1602202656
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | RUNNING  | 172.17.0.4:65035 |      9 |          374.001 | 1456128 |  231.498 |              280.182 |              115.788 |             817.68 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_00-18-18
  done: false
  episode_len_mean: 815.1360759493671
  episode_reward_max: 280.18181818181773
  episode_reward_mean: 231.9729467672505
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.9011976152658463
        entropy_coeff: 0.0
        kl: 0.005353815853595734
        model: {}
        policy_loss: -0.00549195641069673
        total_loss: 4.04140590429306
        vf_explained_var: 0.9917567372322083
        vf_loss: 4.046630144119263
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.083333333333332
    gpu_util_percent0: 0.42041666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.78125
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16117048010140494
    mean_env_wait_ms: 1.6806202080669514
    mean_inference_ms: 4.980081018769075
    mean_raw_obs_processing_ms: 0.43814627561971403
  time_since_restore: 415.1648678779602
  time_this_iter_s: 41.16379523277283
  time_total_s: 415.1648678779602
  timers:
    learn_throughput: 4918.101
    learn_time_ms: 32897.251
    sample_throughput: 18984.173
    sample_time_ms: 8522.468
    update_time_ms: 39.515
  timestamp: 1602202698
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | RUNNING  | 172.17.0.4:65035 |     10 |          415.165 | 1617920 |  231.973 |              280.182 |              115.788 |            815.136 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_00-18-59
  done: false
  episode_len_mean: 812.9839337877313
  episode_reward_max: 280.18181818181773
  episode_reward_mean: 232.49470852635406
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.8679291367530823
        entropy_coeff: 0.0
        kl: 0.00418379814364016
        model: {}
        policy_loss: -0.00505220094928518
        total_loss: 3.719516968727112
        vf_explained_var: 0.9933605194091797
        vf_loss: 3.724359953403473
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.20408163265306
    gpu_util_percent0: 0.31408163265306127
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.783673469387756
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16078821194047
    mean_env_wait_ms: 1.683208187113277
    mean_inference_ms: 4.956687403257201
    mean_raw_obs_processing_ms: 0.4367956229476271
  time_since_restore: 456.07657742500305
  time_this_iter_s: 40.91170954704285
  time_total_s: 456.07657742500305
  timers:
    learn_throughput: 4922.309
    learn_time_ms: 32869.125
    sample_throughput: 19330.242
    sample_time_ms: 8369.89
    update_time_ms: 38.371
  timestamp: 1602202739
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | RUNNING  | 172.17.0.4:65035 |     11 |          456.077 | 1779712 |  232.495 |              280.182 |              115.788 |            812.984 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_00-19-40
  done: false
  episode_len_mean: 809.1286919831224
  episode_reward_max: 280.18181818181773
  episode_reward_mean: 233.61435451562033
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 2370
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 1.0e-05
        entropy: 0.8189219504594802
        entropy_coeff: 0.0
        kl: 0.004730034689418972
        model: {}
        policy_loss: -0.005011124367592856
        total_loss: 4.677055621147156
        vf_explained_var: 0.9933661222457886
        vf_loss: 4.68194854259491
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.172916666666662
    gpu_util_percent0: 0.3989583333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.779166666666667
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16014509139395966
    mean_env_wait_ms: 1.688058552583549
    mean_inference_ms: 4.916701334509862
    mean_raw_obs_processing_ms: 0.43450867110211705
  time_since_restore: 497.62349033355713
  time_this_iter_s: 41.54691290855408
  time_total_s: 497.62349033355713
  timers:
    learn_throughput: 4923.723
    learn_time_ms: 32859.688
    sample_throughput: 19393.421
    sample_time_ms: 8342.623
    update_time_ms: 37.079
  timestamp: 1602202780
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | RUNNING  | 172.17.0.4:65035 |     12 |          497.623 | 1941504 |  233.614 |              280.182 |              115.788 |            809.129 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_00-20-21
  done: false
  episode_len_mean: 807.659414556962
  episode_reward_max: 280.18181818181773
  episode_reward_mean: 234.05011747219027
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 1.0e-05
        entropy: 0.7959087997674942
        entropy_coeff: 0.0
        kl: 0.0039864212856628
        model: {}
        policy_loss: -0.004950319259660318
        total_loss: 3.1522298097610473
        vf_explained_var: 0.9938285946846008
        vf_loss: 3.157130265235901
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.933333333333337
    gpu_util_percent0: 0.3320833333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.7875
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.159864029351603
    mean_env_wait_ms: 1.690159467066224
    mean_inference_ms: 4.899497117911475
    mean_raw_obs_processing_ms: 0.433510906873082
  time_since_restore: 538.5248665809631
  time_this_iter_s: 40.901376247406006
  time_total_s: 538.5248665809631
  timers:
    learn_throughput: 4929.654
    learn_time_ms: 32820.156
    sample_throughput: 19529.363
    sample_time_ms: 8284.551
    update_time_ms: 38.786
  timestamp: 1602202821
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | RUNNING  | 172.17.0.4:65035 |     13 |          538.525 | 2103296 |   234.05 |              280.182 |              115.788 |            807.659 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3201.0
  date: 2020-10-09_00-21-03
  done: false
  episode_len_mean: 806.3339538346985
  episode_reward_max: 280.18181818181773
  episode_reward_mean: 234.77989500364777
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 1.0e-05
        entropy: 0.7839490950107575
        entropy_coeff: 0.0
        kl: 0.0041248679044656456
        model: {}
        policy_loss: -0.004718409001361579
        total_loss: 2.8125744819641114
        vf_explained_var: 0.9941147565841675
        vf_loss: 2.817267096042633
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.287755102040816
    gpu_util_percent0: 0.36122448979591837
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.791836734693877
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15960040064179137
    mean_env_wait_ms: 1.6922018909105057
    mean_inference_ms: 4.8835658913744355
    mean_raw_obs_processing_ms: 0.432562259090755
  time_since_restore: 579.9269604682922
  time_this_iter_s: 41.4020938873291
  time_total_s: 579.9269604682922
  timers:
    learn_throughput: 4925.57
    learn_time_ms: 32847.366
    sample_throughput: 19528.825
    sample_time_ms: 8284.779
    update_time_ms: 37.956
  timestamp: 1602202863
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | RUNNING  | 172.17.0.4:65035 |     14 |          579.927 | 2265088 |   234.78 |              280.182 |              115.788 |            806.334 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_f1b77_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3182.0
  date: 2020-10-09_00-21-44
  done: true
  episode_len_mean: 803.6287904031989
  episode_reward_max: 282.0707070707074
  episode_reward_mean: 236.16680635074508
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 315
  episodes_total: 3001
  experiment_id: 60d63063c23a490cafc475c04f5c8c1a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0031250000000000006
        cur_lr: 1.0e-05
        entropy: 0.7367629140615464
        entropy_coeff: 0.0
        kl: 0.004150136047974229
        model: {}
        policy_loss: -0.00450068045174703
        total_loss: 3.538986313343048
        vf_explained_var: 0.9948498606681824
        vf_loss: 3.54347403049469
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.510204081632654
    gpu_util_percent0: 0.356734693877551
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.779591836734694
    vram_util_percent0: 0.2682026894063627
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 65035
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1591449327951695
    mean_env_wait_ms: 1.6959974117832342
    mean_inference_ms: 4.855619889521321
    mean_raw_obs_processing_ms: 0.43093402812088233
  time_since_restore: 621.3654685020447
  time_this_iter_s: 41.43850803375244
  time_total_s: 621.3654685020447
  timers:
    learn_throughput: 4918.568
    learn_time_ms: 32894.129
    sample_throughput: 19553.782
    sample_time_ms: 8274.205
    update_time_ms: 39.204
  timestamp: 1602202904
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: f1b77_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | TERMINATED |       |     15 |          621.365 | 2426880 |  236.167 |              282.071 |              115.788 |            803.629 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.6 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_f1b77_00000 | TERMINATED |       |     15 |          621.365 | 2426880 |  236.167 |              282.071 |              115.788 |            803.629 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


