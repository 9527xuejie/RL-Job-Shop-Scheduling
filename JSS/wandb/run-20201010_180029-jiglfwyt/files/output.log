2020-10-10 18:00:31,356	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_7d809_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=68505)[0m 2020-10-10 18:00:34,269	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=68411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68442)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68442)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68451)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68451)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68504)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68504)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68463)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68463)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68476)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68476)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68455)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68455)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68457)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68457)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68472)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68472)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68479)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68479)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68517)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68517)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68483)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68483)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68456)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68456)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68398)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68398)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68464)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68464)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68458)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68458)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68450)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68450)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68380)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68380)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68482)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68482)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68460)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68460)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68392)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68392)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68454)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68454)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68524)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68524)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68396)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68396)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68394)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68394)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68417)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68417)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68383)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68439)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68439)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68452)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68452)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68382)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68382)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68467)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68467)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68521)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68521)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68447)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68447)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68408)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68408)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68379)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68379)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68385)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68385)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68403)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68403)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68484)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68484)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68393)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68393)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68465)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68465)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68511)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68511)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68475)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68475)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68402)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68402)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68412)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68412)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68487)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68487)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68410)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68410)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68419)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68419)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68462)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68462)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68443)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68443)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68453)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68453)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68449)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68449)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68415)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68415)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68378)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68378)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68477)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68477)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68445)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68445)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68390)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68390)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68459)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68459)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68381)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68381)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68421)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68421)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68446)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68446)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68406)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68406)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68434)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68434)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68490)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68490)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=68400)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=68400)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_18-01-13
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.186097834791456
        entropy_coeff: 0.0
        kl: 0.0032893326466104816
        model: {}
        policy_loss: -0.01122107180500669
        total_loss: 499.5494188581194
        vf_explained_var: 0.5819914937019348
        vf_loss: 499.55997358049666
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.639999999999997
    gpu_util_percent0: 0.3125
    gpu_util_percent1: 0.00025
    gpu_util_percent2: 0.00025
    ram_util_percent: 6.279999999999999
    vram_util_percent0: 0.19141521810429646
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17395308371788562
    mean_env_wait_ms: 1.2009675343046218
    mean_inference_ms: 5.914540195141209
    mean_raw_obs_processing_ms: 0.46917951265283864
  time_since_restore: 32.96662163734436
  time_this_iter_s: 32.96662163734436
  time_total_s: 32.96662163734436
  timers:
    learn_throughput: 6852.606
    learn_time_ms: 23610.288
    sample_throughput: 17421.626
    sample_time_ms: 9286.848
    update_time_ms: 25.047
  timestamp: 1602352873
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |      1 |          32.9666 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3619.4826388888887
    time_step_min: 3353
  date: 2020-10-10_18-01-44
  done: false
  episode_len_mean: 890.1012658227849
  episode_reward_max: 261.62626262626264
  episode_reward_mean: 217.25006393044345
  episode_reward_min: 134.20202020201987
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.157803441796984
        entropy_coeff: 0.0
        kl: 0.004539551379691277
        model: {}
        policy_loss: -0.011646161770581134
        total_loss: 118.9713521684919
        vf_explained_var: 0.823847770690918
        vf_loss: 118.9825461251395
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.760526315789473
    gpu_util_percent0: 0.3447368421052632
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.463157894736842
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17018869851310336
    mean_env_wait_ms: 1.1966714660317748
    mean_inference_ms: 5.736856962070343
    mean_raw_obs_processing_ms: 0.45935750014329263
  time_since_restore: 64.72463989257812
  time_this_iter_s: 31.758018255233765
  time_total_s: 64.72463989257812
  timers:
    learn_throughput: 6866.316
    learn_time_ms: 23563.145
    sample_throughput: 18555.358
    sample_time_ms: 8719.422
    update_time_ms: 33.938
  timestamp: 1602352904
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |      2 |          64.7246 | 323584 |   217.25 |              261.626 |              134.202 |            890.101 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4170
    time_step_mean: 3622.7174887892374
    time_step_min: 3316
  date: 2020-10-10_18-02-15
  done: false
  episode_len_mean: 887.1708860759494
  episode_reward_max: 269.8080808080809
  episode_reward_mean: 217.62421685206476
  episode_reward_min: 134.20202020201987
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.1534903815814428
        entropy_coeff: 0.0
        kl: 0.00551073532551527
        model: {}
        policy_loss: -0.01395282030612829
        total_loss: 51.47011375427246
        vf_explained_var: 0.9126104712486267
        vf_loss: 51.48379135131836
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.400000000000002
    gpu_util_percent0: 0.2662162162162162
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491891891891892
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16714587339143336
    mean_env_wait_ms: 1.1944384939032104
    mean_inference_ms: 5.554942898202355
    mean_raw_obs_processing_ms: 0.45006819490369987
  time_since_restore: 95.56371188163757
  time_this_iter_s: 30.83907198905945
  time_total_s: 95.56371188163757
  timers:
    learn_throughput: 6881.256
    learn_time_ms: 23511.986
    sample_throughput: 19579.888
    sample_time_ms: 8263.173
    update_time_ms: 32.561
  timestamp: 1602352935
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |      3 |          95.5637 | 485376 |  217.624 |              269.808 |              134.202 |            887.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3622.0066225165565
    time_step_min: 3316
  date: 2020-10-10_18-02-46
  done: false
  episode_len_mean: 884.7879746835443
  episode_reward_max: 269.8080808080809
  episode_reward_mean: 217.7360152154454
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.1425845623016357
        entropy_coeff: 0.0
        kl: 0.005250951774152262
        model: {}
        policy_loss: -0.01425160194048658
        total_loss: 34.05040468488421
        vf_explained_var: 0.9425634741783142
        vf_loss: 34.06439331599644
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.445945945945947
    gpu_util_percent0: 0.4294594594594595
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.481081081081081
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1648684792708395
    mean_env_wait_ms: 1.193461947344577
    mean_inference_ms: 5.41227774067045
    mean_raw_obs_processing_ms: 0.44244926978407795
  time_since_restore: 126.00398349761963
  time_this_iter_s: 30.440271615982056
  time_total_s: 126.00398349761963
  timers:
    learn_throughput: 6899.534
    learn_time_ms: 23449.698
    sample_throughput: 20325.199
    sample_time_ms: 7960.168
    update_time_ms: 43.524
  timestamp: 1602352966
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |      4 |          126.004 | 647168 |  217.736 |              269.808 |              124.202 |            884.788 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3622.6154855643044
    time_step_min: 3316
  date: 2020-10-10_18-03-16
  done: false
  episode_len_mean: 881.8379746835443
  episode_reward_max: 269.8080808080809
  episode_reward_mean: 217.7766270297914
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.120991281100682
        entropy_coeff: 0.0
        kl: 0.005595514983204859
        model: {}
        policy_loss: -0.013975067535024468
        total_loss: 26.310669217790878
        vf_explained_var: 0.9577683210372925
        vf_loss: 26.324365070887975
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.60555555555555
    gpu_util_percent0: 0.3041666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16310833700869073
    mean_env_wait_ms: 1.1933654684824981
    mean_inference_ms: 5.300065576701515
    mean_raw_obs_processing_ms: 0.43630499902616665
  time_since_restore: 156.30104041099548
  time_this_iter_s: 30.297056913375854
  time_total_s: 156.30104041099548
  timers:
    learn_throughput: 6913.311
    learn_time_ms: 23402.968
    sample_throughput: 20829.729
    sample_time_ms: 7767.36
    update_time_ms: 40.557
  timestamp: 1602352996
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |      5 |          156.301 | 808960 |  217.777 |              269.808 |              124.202 |            881.838 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3611.1036821705425
    time_step_min: 3316
  date: 2020-10-10_18-03-47
  done: false
  episode_len_mean: 875.4698113207547
  episode_reward_max: 269.95959595959584
  episode_reward_mean: 219.36382694873245
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 270
  episodes_total: 1060
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.0989515015057154
        entropy_coeff: 0.0
        kl: 0.005502724953527961
        model: {}
        policy_loss: -0.013555938003784311
        total_loss: 27.34231867109026
        vf_explained_var: 0.96973717212677
        vf_loss: 27.355599539620535
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.105405405405406
    gpu_util_percent0: 0.3786486486486486
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.475675675675675
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16097480537949513
    mean_env_wait_ms: 1.1952433828060691
    mean_inference_ms: 5.162544682078923
    mean_raw_obs_processing_ms: 0.42896217786784296
  time_since_restore: 186.87072038650513
  time_this_iter_s: 30.569679975509644
  time_total_s: 186.87072038650513
  timers:
    learn_throughput: 6911.728
    learn_time_ms: 23408.33
    sample_throughput: 21151.275
    sample_time_ms: 7649.279
    update_time_ms: 38.403
  timestamp: 1602353027
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |      6 |          186.871 | 970752 |  219.364 |               269.96 |              124.202 |             875.47 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3599.3454692556634
    time_step_min: 3278
  date: 2020-10-10_18-04-17
  done: false
  episode_len_mean: 870.2824367088608
  episode_reward_max: 269.95959595959584
  episode_reward_mean: 221.0540052422962
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 204
  episodes_total: 1264
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 1.1114654200417655
        entropy_coeff: 0.0
        kl: 0.004992645034300429
        model: {}
        policy_loss: -0.01249541574673328
        total_loss: 16.654271330152238
        vf_explained_var: 0.9730954766273499
        vf_loss: 16.666516712733678
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.569444444444443
    gpu_util_percent0: 0.32833333333333337
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222222
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15985518037801053
    mean_env_wait_ms: 1.1965297911298882
    mean_inference_ms: 5.0874483826220915
    mean_raw_obs_processing_ms: 0.4250869642011084
  time_since_restore: 217.0870225429535
  time_this_iter_s: 30.216302156448364
  time_total_s: 217.0870225429535
  timers:
    learn_throughput: 6918.036
    learn_time_ms: 23386.984
    sample_throughput: 21457.347
    sample_time_ms: 7540.168
    update_time_ms: 36.296
  timestamp: 1602353057
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |      7 |          217.087 | 1132544 |  221.054 |               269.96 |              124.202 |            870.282 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3588.8335724533717
    time_step_min: 3278
  date: 2020-10-10_18-04-48
  done: false
  episode_len_mean: 866.4254571026723
  episode_reward_max: 275.8686868686869
  episode_reward_mean: 222.6162255466051
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.000000000000001e-05
        entropy: 1.088858962059021
        entropy_coeff: 0.0
        kl: 0.0052546054191355196
        model: {}
        policy_loss: -0.013732743915170431
        total_loss: 14.223424979618617
        vf_explained_var: 0.9744275808334351
        vf_loss: 14.237026759556361
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.386486486486483
    gpu_util_percent0: 0.37000000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491891891891892
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1591219240187411
    mean_env_wait_ms: 1.1975691687773855
    mean_inference_ms: 5.038611175825418
    mean_raw_obs_processing_ms: 0.4224898748572166
  time_since_restore: 247.65488743782043
  time_this_iter_s: 30.567864894866943
  time_total_s: 247.65488743782043
  timers:
    learn_throughput: 6915.527
    learn_time_ms: 23395.468
    sample_throughput: 21657.267
    sample_time_ms: 7470.564
    update_time_ms: 40.694
  timestamp: 1602353088
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |      8 |          247.655 | 1294336 |  222.616 |              275.869 |              124.202 |            866.425 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3578.4349226804125
    time_step_min: 3278
  date: 2020-10-10_18-05-18
  done: false
  episode_len_mean: 863.3715189873418
  episode_reward_max: 275.8686868686869
  episode_reward_mean: 224.048299450198
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.000000000000001e-05
        entropy: 1.074735769203731
        entropy_coeff: 0.0
        kl: 0.005275290093517729
        model: {}
        policy_loss: -0.015043947912220444
        total_loss: 12.651826654161725
        vf_explained_var: 0.9761558175086975
        vf_loss: 12.66673823765346
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.625
    gpu_util_percent0: 0.2713888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5055555555555555
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1584816947463252
    mean_env_wait_ms: 1.1984814650528341
    mean_inference_ms: 4.995904183253275
    mean_raw_obs_processing_ms: 0.42019646895617907
  time_since_restore: 278.0872712135315
  time_this_iter_s: 30.43238377571106
  time_total_s: 278.0872712135315
  timers:
    learn_throughput: 6914.022
    learn_time_ms: 23400.561
    sample_throughput: 21838.696
    sample_time_ms: 7408.501
    update_time_ms: 38.705
  timestamp: 1602353118
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |      9 |          278.087 | 1456128 |  224.048 |              275.869 |              124.202 |            863.372 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3569.8109826589593
    time_step_min: 3227
  date: 2020-10-10_18-05-49
  done: false
  episode_len_mean: 860.1296928327645
  episode_reward_max: 277.0808080808082
  episode_reward_mean: 225.64072465266992
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 178
  episodes_total: 1758
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.000000000000001e-05
        entropy: 1.037905182157244
        entropy_coeff: 0.0
        kl: 0.004970576614141464
        model: {}
        policy_loss: -0.013349515086572086
        total_loss: 16.258581502096995
        vf_explained_var: 0.9763450026512146
        vf_loss: 16.271806716918945
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.867567567567566
    gpu_util_percent0: 0.3581081081081082
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.478378378378379
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.157842764498831
    mean_env_wait_ms: 1.1995779614757336
    mean_inference_ms: 4.9538318618923824
    mean_raw_obs_processing_ms: 0.41792062751995324
  time_since_restore: 308.85990047454834
  time_this_iter_s: 30.772629261016846
  time_total_s: 308.85990047454834
  timers:
    learn_throughput: 6908.415
    learn_time_ms: 23419.555
    sample_throughput: 21928.407
    sample_time_ms: 7378.192
    update_time_ms: 36.912
  timestamp: 1602353149
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |     10 |           308.86 | 1617920 |  225.641 |              277.081 |              124.202 |             860.13 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3550.937808489635
    time_step_min: 3227
  date: 2020-10-10_18-06-20
  done: false
  episode_len_mean: 854.7025316455696
  episode_reward_max: 278.4444444444448
  episode_reward_mean: 228.30369911382556
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 296
  episodes_total: 2054
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0420198696000236
        entropy_coeff: 0.0
        kl: 0.005163072042965463
        model: {}
        policy_loss: -0.01357293629553169
        total_loss: 15.155334404536656
        vf_explained_var: 0.9783591032028198
        vf_loss: 15.168842792510986
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.064864864864866
    gpu_util_percent0: 0.3575675675675676
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.475675675675675
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15699143769664747
    mean_env_wait_ms: 1.2013554321117497
    mean_inference_ms: 4.896531147981747
    mean_raw_obs_processing_ms: 0.41485660897305143
  time_since_restore: 339.45431447029114
  time_this_iter_s: 30.594413995742798
  time_total_s: 339.45431447029114
  timers:
    learn_throughput: 6912.779
    learn_time_ms: 23404.768
    sample_throughput: 22631.133
    sample_time_ms: 7149.09
    update_time_ms: 36.293
  timestamp: 1602353180
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |     11 |          339.454 | 1779712 |  228.304 |              278.444 |              124.202 |            854.703 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3543.610347985348
    time_step_min: 3194
  date: 2020-10-10_18-06-51
  done: false
  episode_len_mean: 852.1808318264015
  episode_reward_max: 282.08080808080837
  episode_reward_mean: 229.49135112426242
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0266378351620264
        entropy_coeff: 0.0
        kl: 0.005136326387790697
        model: {}
        policy_loss: -0.013605826334761721
        total_loss: 11.940916470118932
        vf_explained_var: 0.9781644940376282
        vf_loss: 11.954458236694336
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.308333333333334
    gpu_util_percent0: 0.38277777777777783
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15660036309020212
    mean_env_wait_ms: 1.20220736056364
    mean_inference_ms: 4.8707200496876215
    mean_raw_obs_processing_ms: 0.41346970085118406
  time_since_restore: 370.28903460502625
  time_this_iter_s: 30.834720134735107
  time_total_s: 370.28903460502625
  timers:
    learn_throughput: 6918.487
    learn_time_ms: 23385.461
    sample_throughput: 22867.244
    sample_time_ms: 7075.273
    update_time_ms: 36.194
  timestamp: 1602353211
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |     12 |          370.289 | 1941504 |  229.491 |              282.081 |              124.202 |            852.181 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3534.8992314261313
    time_step_min: 3194
  date: 2020-10-10_18-07-21
  done: false
  episode_len_mean: 849.9050632911392
  episode_reward_max: 282.08080808080837
  episode_reward_mean: 230.70700677662688
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.008635061127799
        entropy_coeff: 0.0
        kl: 0.0049113688125674215
        model: {}
        policy_loss: -0.013389415589959494
        total_loss: 13.494732516152519
        vf_explained_var: 0.9735878705978394
        vf_loss: 13.508060795920235
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.77837837837838
    gpu_util_percent0: 0.3205405405405406
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497297297297297
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15624495248728584
    mean_env_wait_ms: 1.2030000905482203
    mean_inference_ms: 4.847311654307621
    mean_raw_obs_processing_ms: 0.4121919927429622
  time_since_restore: 400.62213492393494
  time_this_iter_s: 30.33310031890869
  time_total_s: 400.62213492393494
  timers:
    learn_throughput: 6927.803
    learn_time_ms: 23354.014
    sample_throughput: 22929.298
    sample_time_ms: 7056.125
    update_time_ms: 35.397
  timestamp: 1602353241
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |     13 |          400.622 | 2103296 |  230.707 |              282.081 |              124.202 |            849.905 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3526.3339920948615
    time_step_min: 3194
  date: 2020-10-10_18-07-51
  done: false
  episode_len_mean: 847.5942142298671
  episode_reward_max: 282.08080808080837
  episode_reward_mean: 231.9651282172782
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 188
  episodes_total: 2558
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 0.9691377707890102
        entropy_coeff: 0.0
        kl: 0.005212520881156836
        model: {}
        policy_loss: -0.014132388135684388
        total_loss: 16.05379663194929
        vf_explained_var: 0.9759194254875183
        vf_loss: 16.06789643423898
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.68611111111111
    gpu_util_percent0: 0.43166666666666675
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.475
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15585086183215016
    mean_env_wait_ms: 1.2039125433576048
    mean_inference_ms: 4.821910850728084
    mean_raw_obs_processing_ms: 0.41080877485930745
  time_since_restore: 430.8506450653076
  time_this_iter_s: 30.22851014137268
  time_total_s: 430.8506450653076
  timers:
    learn_throughput: 6931.045
    learn_time_ms: 23343.09
    sample_throughput: 22968.626
    sample_time_ms: 7044.044
    update_time_ms: 30.405
  timestamp: 1602353271
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |     14 |          430.851 | 2265088 |  231.965 |              282.081 |              124.202 |            847.594 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3512.667377398721
    time_step_min: 3158
  date: 2020-10-10_18-08-22
  done: false
  episode_len_mean: 844.4398311048558
  episode_reward_max: 287.53535353535347
  episode_reward_mean: 233.9243668209184
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 284
  episodes_total: 2842
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 0.9696190782955715
        entropy_coeff: 0.0
        kl: 0.005437346840543407
        model: {}
        policy_loss: -0.013310886187744992
        total_loss: 12.95275606427874
        vf_explained_var: 0.9809551239013672
        vf_loss: 12.966032777513776
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.672222222222228
    gpu_util_percent0: 0.3202777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480555555555556
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1553626147627758
    mean_env_wait_ms: 1.2052809895250804
    mean_inference_ms: 4.789055959049009
    mean_raw_obs_processing_ms: 0.4090291531078057
  time_since_restore: 460.8979318141937
  time_this_iter_s: 30.04728674888611
  time_total_s: 460.8979318141937
  timers:
    learn_throughput: 6935.983
    learn_time_ms: 23326.47
    sample_throughput: 22993.65
    sample_time_ms: 7036.378
    update_time_ms: 29.436
  timestamp: 1602353302
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |     15 |          460.898 | 2426880 |  233.924 |              287.535 |              124.202 |             844.44 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3506.3745796906524
    time_step_min: 3158
  date: 2020-10-10_18-08-52
  done: false
  episode_len_mean: 842.4463690872751
  episode_reward_max: 287.53535353535347
  episode_reward_mean: 234.74095384221957
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 160
  episodes_total: 3002
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 0.9515290473188672
        entropy_coeff: 0.0
        kl: 0.0051314189830528835
        model: {}
        policy_loss: -0.011344457693797137
        total_loss: 11.649195739201136
        vf_explained_var: 0.9788883924484253
        vf_loss: 11.660508360181536
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.56111111111111
    gpu_util_percent0: 0.32888888888888895
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222223
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15511459907061853
    mean_env_wait_ms: 1.2059755625643882
    mean_inference_ms: 4.772609938978411
    mean_raw_obs_processing_ms: 0.40814934001712794
  time_since_restore: 490.951149225235
  time_this_iter_s: 30.05321741104126
  time_total_s: 490.951149225235
  timers:
    learn_throughput: 6949.589
    learn_time_ms: 23280.802
    sample_throughput: 23014.676
    sample_time_ms: 7029.949
    update_time_ms: 28.675
  timestamp: 1602353332
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |     16 |          490.951 | 2588672 |  234.741 |              287.535 |              124.202 |            842.446 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3500.19220945083
    time_step_min: 3144
  date: 2020-10-10_18-09-22
  done: false
  episode_len_mean: 840.4224683544304
  episode_reward_max: 289.65656565656525
  episode_reward_mean: 235.6724843370412
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 0.9381523941244397
        entropy_coeff: 0.0
        kl: 0.004868000014019864
        model: {}
        policy_loss: -0.011848786130680569
        total_loss: 12.858907903943743
        vf_explained_var: 0.9750352501869202
        vf_loss: 12.870726449148995
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.419444444444448
    gpu_util_percent0: 0.3483333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15488509092672503
    mean_env_wait_ms: 1.206653993594605
    mean_inference_ms: 4.7575128999202585
    mean_raw_obs_processing_ms: 0.4073310828287075
  time_since_restore: 521.0962805747986
  time_this_iter_s: 30.1451313495636
  time_total_s: 521.0962805747986
  timers:
    learn_throughput: 6959.25
    learn_time_ms: 23248.481
    sample_throughput: 22934.579
    sample_time_ms: 7054.5
    update_time_ms: 28.513
  timestamp: 1602353362
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |     17 |          521.096 | 2750464 |  235.672 |              289.657 |              124.202 |            840.422 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3488.6940276551927
    time_step_min: 3144
  date: 2020-10-10_18-09-52
  done: false
  episode_len_mean: 837.0035016049022
  episode_reward_max: 289.65656565656525
  episode_reward_mean: 237.35717843742347
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 267
  episodes_total: 3427
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0031250000000000006
        cur_lr: 5.000000000000001e-05
        entropy: 0.9079814042363848
        entropy_coeff: 0.0
        kl: 0.00496510965084391
        model: {}
        policy_loss: -0.011718383740766771
        total_loss: 13.596261841910225
        vf_explained_var: 0.9807472229003906
        vf_loss: 13.607964583805629
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.102777777777778
    gpu_util_percent0: 0.3188888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.483333333333333
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15452945481984748
    mean_env_wait_ms: 1.2077925404016467
    mean_inference_ms: 4.7342553188963965
    mean_raw_obs_processing_ms: 0.4060839811324098
  time_since_restore: 551.2987277507782
  time_this_iter_s: 30.202447175979614
  time_total_s: 551.2987277507782
  timers:
    learn_throughput: 6971.837
    learn_time_ms: 23206.508
    sample_throughput: 22905.838
    sample_time_ms: 7063.352
    update_time_ms: 24.809
  timestamp: 1602353392
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |     18 |          551.299 | 2912256 |  237.357 |              289.657 |              124.202 |            837.004 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3481.207986688852
    time_step_min: 3144
  date: 2020-10-10_18-10-23
  done: false
  episode_len_mean: 834.561640066043
  episode_reward_max: 292.0808080808078
  episode_reward_mean: 238.4320613954625
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 207
  episodes_total: 3634
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625000000000003
        cur_lr: 5.000000000000001e-05
        entropy: 0.8964611717632839
        entropy_coeff: 0.0
        kl: 0.0049009422572063545
        model: {}
        policy_loss: -0.013867148616554914
        total_loss: 11.308657169342041
        vf_explained_var: 0.9800779223442078
        vf_loss: 11.322516577584404
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.14864864864865
    gpu_util_percent0: 0.4078378378378379
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489189189189189
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.154290424289635
    mean_env_wait_ms: 1.2087291941393283
    mean_inference_ms: 4.718401471044509
    mean_raw_obs_processing_ms: 0.4052533646740519
  time_since_restore: 581.651552438736
  time_this_iter_s: 30.352824687957764
  time_total_s: 581.651552438736
  timers:
    learn_throughput: 6980.749
    learn_time_ms: 23176.884
    sample_throughput: 22856.364
    sample_time_ms: 7078.641
    update_time_ms: 24.483
  timestamp: 1602353423
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | RUNNING  | 172.17.0.4:68505 |     19 |          581.652 | 3074048 |  238.432 |              292.081 |              124.202 |            834.562 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_7d809_00000:
  custom_metrics:
    time_step_max: 4236
    time_step_mean: 3476.6902231668437
    time_step_min: 3144
  date: 2020-10-10_18-10-53
  done: true
  episode_len_mean: 832.7191455696203
  episode_reward_max: 292.0808080808078
  episode_reward_mean: 239.12038901674967
  episode_reward_min: 124.20202020202025
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: 2a476da3b6df46c5bca28c3eed3cc705
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0007812500000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8951955565384456
        entropy_coeff: 0.0
        kl: 0.00489765325827258
        model: {}
        policy_loss: -0.01453051227976435
        total_loss: 9.820400033678327
        vf_explained_var: 0.9796697497367859
        vf_loss: 9.834926945822579
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.95555555555556
    gpu_util_percent0: 0.31166666666666676
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222223
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 68505
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15411794084241862
    mean_env_wait_ms: 1.2093901367378832
    mean_inference_ms: 4.7070315956761455
    mean_raw_obs_processing_ms: 0.40465124926053586
  time_since_restore: 611.8542745113373
  time_this_iter_s: 30.20272207260132
  time_total_s: 611.8542745113373
  timers:
    learn_throughput: 6994.237
    learn_time_ms: 23132.187
    sample_throughput: 22897.026
    sample_time_ms: 7066.07
    update_time_ms: 24.134
  timestamp: 1602353453
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 7d809_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | TERMINATED |       |     20 |          611.854 | 3235840 |   239.12 |              292.081 |              124.202 |            832.719 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.5 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_7d809_00000 | TERMINATED |       |     20 |          611.854 | 3235840 |   239.12 |              292.081 |              124.202 |            832.719 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


