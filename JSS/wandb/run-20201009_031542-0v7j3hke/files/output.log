2020-10-09 03:15:44,965	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_b9272_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=51017)[0m 2020-10-09 03:15:48,007	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=50998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50972)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50972)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50916)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50916)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50946)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50946)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51032)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51032)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50980)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50980)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50922)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50922)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50956)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50956)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51025)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51025)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50937)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50937)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50981)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50981)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50918)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50918)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50949)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50949)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50886)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50886)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50952)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50952)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50971)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50971)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50970)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50970)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50884)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50884)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50920)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50920)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50934)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50934)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=51014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=51014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50969)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50969)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50894)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50976)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50976)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50942)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50942)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50968)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50968)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50901)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50901)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=50896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=50896)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-09_03-16-19
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1646132230758668
        entropy_coeff: 0.0
        kl: 0.0024959716480225324
        model: {}
        policy_loss: -0.008073807321488857
        total_loss: 579.9676513671875
        vf_explained_var: 0.24308137595653534
        vf_loss: 579.9752319335937
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 40.524137931034495
    gpu_util_percent0: 0.2551724137931034
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0003448275862068966
    ram_util_percent: 9.524137931034481
    vram_util_percent0: 0.30634408115719114
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.18300495459805965
    mean_env_wait_ms: 1.666079403699714
    mean_inference_ms: 6.196813974972306
    mean_raw_obs_processing_ms: 0.49830900735787376
  time_since_restore: 25.18367910385132
  time_this_iter_s: 25.18367910385132
  time_total_s: 25.18367910385132
  timers:
    learn_throughput: 10749.487
    learn_time_ms: 15051.137
    sample_throughput: 16072.958
    sample_time_ms: 10066.1
    update_time_ms: 23.261
  timestamp: 1602213379
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |      1 |          25.1837 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3205.0
  date: 2020-10-09_03-16-42
  done: false
  episode_len_mean: 874.6835443037975
  episode_reward_max: 279.5454545454541
  episode_reward_mean: 227.6390806802197
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.139573884010315
        entropy_coeff: 0.0
        kl: 0.0035176432691514494
        model: {}
        policy_loss: -0.009164061769843102
        total_loss: 208.12246704101562
        vf_explained_var: 0.6740990877151489
        vf_loss: 208.13128662109375
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.68888888888889
    gpu_util_percent0: 0.33037037037037037
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.73703703703704
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17645765491746931
    mean_env_wait_ms: 1.6551984424712658
    mean_inference_ms: 5.809622088663965
    mean_raw_obs_processing_ms: 0.4803630222120272
  time_since_restore: 48.14430570602417
  time_this_iter_s: 22.96062660217285
  time_total_s: 48.14430570602417
  timers:
    learn_throughput: 10926.086
    learn_time_ms: 14807.865
    sample_throughput: 17609.54
    sample_time_ms: 9187.747
    update_time_ms: 31.139
  timestamp: 1602213402
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |      2 |          48.1443 | 323584 |  227.639 |              279.545 |              115.788 |            874.684 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3161.0
  date: 2020-10-09_03-17-05
  done: false
  episode_len_mean: 872.3565400843881
  episode_reward_max: 286.0808080808081
  episode_reward_mean: 226.47076247709137
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 1.1348739624023438
        entropy_coeff: 0.0
        kl: 0.004562308825552463
        model: {}
        policy_loss: -0.010867214272730052
        total_loss: 98.6408920288086
        vf_explained_var: 0.8154574632644653
        vf_loss: 98.65152893066406
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.01153846153846
    gpu_util_percent0: 0.2534615384615385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75769230769231
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1725494231384641
    mean_env_wait_ms: 1.6488053536533291
    mean_inference_ms: 5.6029136329141345
    mean_raw_obs_processing_ms: 0.4683786563148153
  time_since_restore: 71.2376458644867
  time_this_iter_s: 23.093340158462524
  time_total_s: 71.2376458644867
  timers:
    learn_throughput: 10960.832
    learn_time_ms: 14760.923
    sample_throughput: 18172.367
    sample_time_ms: 8903.188
    update_time_ms: 28.758
  timestamp: 1602213425
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |      3 |          71.2376 | 485376 |  226.471 |              286.081 |              115.788 |            872.357 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3161.0
  date: 2020-10-09_03-17-28
  done: false
  episode_len_mean: 869.5775316455696
  episode_reward_max: 286.0808080808081
  episode_reward_mean: 228.08723309039746
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 0.0001
        entropy: 1.1247028827667236
        entropy_coeff: 0.0
        kl: 0.004643470235168934
        model: {}
        policy_loss: -0.011949875019490718
        total_loss: 65.27578277587891
        vf_explained_var: 0.8639154434204102
        vf_loss: 65.28761749267578
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.57777777777777
    gpu_util_percent0: 0.3185185185185186
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.755555555555556
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16996638329664412
    mean_env_wait_ms: 1.646293667986033
    mean_inference_ms: 5.455359581305866
    mean_raw_obs_processing_ms: 0.4604101930675187
  time_since_restore: 94.07562470436096
  time_this_iter_s: 22.837978839874268
  time_total_s: 94.07562470436096
  timers:
    learn_throughput: 10974.694
    learn_time_ms: 14742.279
    sample_throughput: 18615.089
    sample_time_ms: 8691.444
    update_time_ms: 32.675
  timestamp: 1602213448
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |      4 |          94.0756 | 647168 |  228.087 |              286.081 |              115.788 |            869.578 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3161.0
  date: 2020-10-09_03-17-51
  done: false
  episode_len_mean: 865.6042713567839
  episode_reward_max: 286.0808080808081
  episode_reward_mean: 229.71616922998814
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 164
  episodes_total: 796
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 0.0001
        entropy: 1.0890195846557618
        entropy_coeff: 0.0
        kl: 0.004554770514369011
        model: {}
        policy_loss: -0.011642836593091488
        total_loss: 55.87821273803711
        vf_explained_var: 0.9090856313705444
        vf_loss: 55.88979721069336
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.32
    gpu_util_percent0: 0.2964
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.748000000000001
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16799538743141268
    mean_env_wait_ms: 1.6463866317197524
    mean_inference_ms: 5.341260771506637
    mean_raw_obs_processing_ms: 0.4541843959227987
  time_since_restore: 116.75583863258362
  time_this_iter_s: 22.680213928222656
  time_total_s: 116.75583863258362
  timers:
    learn_throughput: 11004.342
    learn_time_ms: 14702.56
    sample_throughput: 18895.51
    sample_time_ms: 8562.457
    update_time_ms: 32.182
  timestamp: 1602213471
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |      5 |          116.756 | 808960 |  229.716 |              286.081 |              115.788 |            865.604 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3161.0
  date: 2020-10-09_03-18-14
  done: false
  episode_len_mean: 857.6672694394214
  episode_reward_max: 286.0808080808081
  episode_reward_mean: 231.04695234442053
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 310
  episodes_total: 1106
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00625
        cur_lr: 0.0001
        entropy: 1.1144234180450439
        entropy_coeff: 0.0
        kl: 0.0047482728958129885
        model: {}
        policy_loss: -0.011521663796156646
        total_loss: 52.29216079711914
        vf_explained_var: 0.9247733354568481
        vf_loss: 52.303652954101565
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.41481481481482
    gpu_util_percent0: 0.3185185185185185
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16544991275003446
    mean_env_wait_ms: 1.648245522649472
    mean_inference_ms: 5.197977430618005
    mean_raw_obs_processing_ms: 0.44679213455792915
  time_since_restore: 139.9032108783722
  time_this_iter_s: 23.147372245788574
  time_total_s: 139.9032108783722
  timers:
    learn_throughput: 10998.843
    learn_time_ms: 14709.911
    sample_throughput: 18983.632
    sample_time_ms: 8522.71
    update_time_ms: 30.936
  timestamp: 1602213494
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |      6 |          139.903 | 970752 |  231.047 |              286.081 |              115.788 |            857.667 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3161.0
  date: 2020-10-09_03-18-37
  done: false
  episode_len_mean: 853.7587025316456
  episode_reward_max: 286.0808080808081
  episode_reward_mean: 232.42488172867903
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.003125
        cur_lr: 0.0001
        entropy: 1.1020848035812378
        entropy_coeff: 0.0
        kl: 0.004608931578695774
        model: {}
        policy_loss: -0.012220757268369197
        total_loss: 31.313700866699218
        vf_explained_var: 0.9361206293106079
        vf_loss: 31.32590675354004
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.669230769230765
    gpu_util_percent0: 0.32807692307692304
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765384615384617
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16451418214490415
    mean_env_wait_ms: 1.649418032105227
    mean_inference_ms: 5.14538794606778
    mean_raw_obs_processing_ms: 0.44405616233683426
  time_since_restore: 162.7167239189148
  time_this_iter_s: 22.813513040542603
  time_total_s: 162.7167239189148
  timers:
    learn_throughput: 11007.982
    learn_time_ms: 14697.699
    sample_throughput: 19115.298
    sample_time_ms: 8464.006
    update_time_ms: 29.787
  timestamp: 1602213517
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |      7 |          162.717 | 1132544 |  232.425 |              286.081 |              115.788 |            853.759 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3161.0
  date: 2020-10-09_03-19-00
  done: false
  episode_len_mean: 850.5597749648383
  episode_reward_max: 286.0808080808081
  episode_reward_mean: 233.7435181633492
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625
        cur_lr: 0.0001
        entropy: 1.084244704246521
        entropy_coeff: 0.0
        kl: 0.004794697929173708
        model: {}
        policy_loss: -0.01299494355916977
        total_loss: 25.940602493286132
        vf_explained_var: 0.9441471099853516
        vf_loss: 25.953589630126952
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.47307692307693
    gpu_util_percent0: 0.27807692307692305
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.76923076923077
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16370609471826958
    mean_env_wait_ms: 1.6506100035630848
    mean_inference_ms: 5.099822180661067
    mean_raw_obs_processing_ms: 0.4416316095835322
  time_since_restore: 185.545893907547
  time_this_iter_s: 22.829169988632202
  time_total_s: 185.545893907547
  timers:
    learn_throughput: 11004.519
    learn_time_ms: 14702.323
    sample_throughput: 19243.269
    sample_time_ms: 8407.719
    update_time_ms: 28.894
  timestamp: 1602213540
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |      8 |          185.546 | 1294336 |  233.744 |              286.081 |              115.788 |             850.56 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3161.0
  date: 2020-10-09_03-19-23
  done: false
  episode_len_mean: 847.6382575757576
  episode_reward_max: 286.0808080808081
  episode_reward_mean: 234.89723625140277
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 162
  episodes_total: 1584
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00078125
        cur_lr: 0.0001
        entropy: 1.0479911327362061
        entropy_coeff: 0.0
        kl: 0.004709825105965138
        model: {}
        policy_loss: -0.012447661068290473
        total_loss: 26.798345947265624
        vf_explained_var: 0.9513479471206665
        vf_loss: 26.810789108276367
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.503846153846155
    gpu_util_percent0: 0.32499999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765384615384615
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1629826982153957
    mean_env_wait_ms: 1.6521647676231728
    mean_inference_ms: 5.059244230243261
    mean_raw_obs_processing_ms: 0.4394274947509713
  time_since_restore: 208.5243363380432
  time_this_iter_s: 22.978442430496216
  time_total_s: 208.5243363380432
  timers:
    learn_throughput: 10996.842
    learn_time_ms: 14712.588
    sample_throughput: 19324.559
    sample_time_ms: 8372.351
    update_time_ms: 29.973
  timestamp: 1602213563
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |      9 |          208.524 | 1456128 |  234.897 |              286.081 |              115.788 |            847.638 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3113.0
  date: 2020-10-09_03-19-46
  done: false
  episode_len_mean: 842.0036919831224
  episode_reward_max: 292.040404040404
  episode_reward_mean: 237.16358735029607
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 312
  episodes_total: 1896
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.000390625
        cur_lr: 0.0001
        entropy: 1.052963662147522
        entropy_coeff: 0.0
        kl: 0.004501621425151825
        model: {}
        policy_loss: -0.011033773142844438
        total_loss: 28.23277587890625
        vf_explained_var: 0.9573712348937988
        vf_loss: 28.24380760192871
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.47692307692307
    gpu_util_percent0: 0.3584615384615385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746153846153847
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16187549870079426
    mean_env_wait_ms: 1.6551680293830222
    mean_inference_ms: 4.996229560163292
    mean_raw_obs_processing_ms: 0.4360854013229174
  time_since_restore: 231.5252342224121
  time_this_iter_s: 23.000897884368896
  time_total_s: 231.5252342224121
  timers:
    learn_throughput: 10984.15
    learn_time_ms: 14729.588
    sample_throughput: 19408.074
    sample_time_ms: 8336.324
    update_time_ms: 31.328
  timestamp: 1602213586
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     10 |          231.525 | 1617920 |  237.164 |               292.04 |              115.788 |            842.004 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3113.0
  date: 2020-10-09_03-20-09
  done: false
  episode_len_mean: 839.3904576436222
  episode_reward_max: 292.040404040404
  episode_reward_mean: 238.47024775505773
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0001953125
        cur_lr: 0.0001
        entropy: 1.0414965391159057
        entropy_coeff: 0.0
        kl: 0.004531228821724654
        model: {}
        policy_loss: -0.012431620713323354
        total_loss: 15.679171371459962
        vf_explained_var: 0.9653902053833008
        vf_loss: 15.69160213470459
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.866666666666674
    gpu_util_percent0: 0.3618518518518519
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.766666666666667
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1614119882611636
    mean_env_wait_ms: 1.6566364483936415
    mean_inference_ms: 4.969876132227768
    mean_raw_obs_processing_ms: 0.4346685704377788
  time_since_restore: 254.71158146858215
  time_this_iter_s: 23.186347246170044
  time_total_s: 254.71158146858215
  timers:
    learn_throughput: 11002.949
    learn_time_ms: 14704.421
    sample_throughput: 19830.569
    sample_time_ms: 8158.717
    update_time_ms: 32.273
  timestamp: 1602213609
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     11 |          254.712 | 1779712 |   238.47 |               292.04 |              115.788 |             839.39 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3111.0
  date: 2020-10-09_03-20-32
  done: false
  episode_len_mean: 836.8856238698011
  episode_reward_max: 293.88888888888926
  episode_reward_mean: 239.53141724660702
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625e-05
        cur_lr: 0.0001
        entropy: 1.0256999731063843
        entropy_coeff: 0.0
        kl: 0.0046826832927763466
        model: {}
        policy_loss: -0.012546256929636002
        total_loss: 16.875491333007812
        vf_explained_var: 0.9607393145561218
        vf_loss: 16.88803825378418
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.6
    gpu_util_percent0: 0.36346153846153845
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765384615384617
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16099290886318474
    mean_env_wait_ms: 1.658051117400074
    mean_inference_ms: 4.945962370146584
    mean_raw_obs_processing_ms: 0.43332903883899127
  time_since_restore: 277.5406069755554
  time_this_iter_s: 22.829025506973267
  time_total_s: 277.5406069755554
  timers:
    learn_throughput: 10995.727
    learn_time_ms: 14714.079
    sample_throughput: 19885.897
    sample_time_ms: 8136.017
    update_time_ms: 31.146
  timestamp: 1602213632
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     12 |          277.541 | 1941504 |  239.531 |              293.889 |              115.788 |            836.886 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3111.0
  date: 2020-10-09_03-20-55
  done: false
  episode_len_mean: 833.7011494252873
  episode_reward_max: 293.88888888888926
  episode_reward_mean: 240.9597701149424
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 224
  episodes_total: 2436
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.8828125e-05
        cur_lr: 0.0001
        entropy: 0.9878423690795899
        entropy_coeff: 0.0
        kl: 0.005221346486359834
        model: {}
        policy_loss: -0.01074263323098421
        total_loss: 22.35823211669922
        vf_explained_var: 0.9641415476799011
        vf_loss: 22.3689754486084
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.426923076923075
    gpu_util_percent0: 0.2146153846153846
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16047164701324904
    mean_env_wait_ms: 1.66038382359584
    mean_inference_ms: 4.9158355504657205
    mean_raw_obs_processing_ms: 0.43164044150428266
  time_since_restore: 300.5047821998596
  time_this_iter_s: 22.9641752243042
  time_total_s: 300.5047821998596
  timers:
    learn_throughput: 10996.134
    learn_time_ms: 14713.534
    sample_throughput: 19914.312
    sample_time_ms: 8124.408
    update_time_ms: 31.426
  timestamp: 1602213655
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     13 |          300.505 | 2103296 |   240.96 |              293.889 |              115.788 |            833.701 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3111.0
  date: 2020-10-09_03-21-18
  done: false
  episode_len_mean: 830.6716306775875
  episode_reward_max: 293.88888888888926
  episode_reward_mean: 242.1503042336995
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 250
  episodes_total: 2686
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.8828125e-05
        cur_lr: 0.0001
        entropy: 0.9968238830566406
        entropy_coeff: 0.0
        kl: 0.004777842853218317
        model: {}
        policy_loss: -0.011325714271515607
        total_loss: 17.97556838989258
        vf_explained_var: 0.9664093852043152
        vf_loss: 17.986892318725587
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.48888888888889
    gpu_util_percent0: 0.2877777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15998007441814077
    mean_env_wait_ms: 1.6624468067590097
    mean_inference_ms: 4.887165179204717
    mean_raw_obs_processing_ms: 0.4300512226074341
  time_since_restore: 323.72106313705444
  time_this_iter_s: 23.216280937194824
  time_total_s: 323.72106313705444
  timers:
    learn_throughput: 10989.644
    learn_time_ms: 14722.224
    sample_throughput: 19844.682
    sample_time_ms: 8152.915
    update_time_ms: 31.122
  timestamp: 1602213678
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     14 |          323.721 | 2265088 |   242.15 |              293.889 |              115.788 |            830.672 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3111.0
  date: 2020-10-09_03-21-41
  done: false
  episode_len_mean: 829.1993670886076
  episode_reward_max: 293.88888888888926
  episode_reward_mean: 242.93689710039908
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.44140625e-05
        cur_lr: 0.0001
        entropy: 0.9964828372001648
        entropy_coeff: 0.0
        kl: 0.0046570182777941225
        model: {}
        policy_loss: -0.012620258517563343
        total_loss: 14.19004421234131
        vf_explained_var: 0.9679697155952454
        vf_loss: 14.202664566040038
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.01923076923077
    gpu_util_percent0: 0.2653846153846154
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.76923076923077
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15970292906489253
    mean_env_wait_ms: 1.663735910741401
    mean_inference_ms: 4.870958640637879
    mean_raw_obs_processing_ms: 0.42915631881703703
  time_since_restore: 346.5212993621826
  time_this_iter_s: 22.800236225128174
  time_total_s: 346.5212993621826
  timers:
    learn_throughput: 10980.895
    learn_time_ms: 14733.954
    sample_throughput: 19845.176
    sample_time_ms: 8152.712
    update_time_ms: 31.397
  timestamp: 1602213701
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     15 |          346.521 | 2426880 |  242.937 |              293.889 |              115.788 |            829.199 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3111.0
  date: 2020-10-09_03-22-04
  done: false
  episode_len_mean: 827.7485009993338
  episode_reward_max: 293.88888888888926
  episode_reward_mean: 243.61723497466323
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.220703125e-05
        cur_lr: 0.0001
        entropy: 0.9716984629631042
        entropy_coeff: 0.0
        kl: 0.004797522723674774
        model: {}
        policy_loss: -0.012094723293557763
        total_loss: 15.364163970947265
        vf_explained_var: 0.9658077955245972
        vf_loss: 15.376258277893067
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.06923076923077
    gpu_util_percent0: 0.3226923076923077
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765384615384615
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15944797819885118
    mean_env_wait_ms: 1.6649690592605086
    mean_inference_ms: 4.8559857046103065
    mean_raw_obs_processing_ms: 0.42833658699934
  time_since_restore: 369.37456822395325
  time_this_iter_s: 22.85326886177063
  time_total_s: 369.37456822395325
  timers:
    learn_throughput: 10978.238
    learn_time_ms: 14737.52
    sample_throughput: 19931.628
    sample_time_ms: 8117.35
    update_time_ms: 32.985
  timestamp: 1602213724
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     16 |          369.375 | 2588672 |  243.617 |              293.889 |              115.788 |            827.749 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3111.0
  date: 2020-10-09_03-22-27
  done: false
  episode_len_mean: 825.6991230722709
  episode_reward_max: 293.88888888888926
  episode_reward_mean: 244.93255811822476
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 305
  episodes_total: 3307
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 6.103515625e-06
        cur_lr: 0.0001
        entropy: 0.9474871039390564
        entropy_coeff: 0.0
        kl: 0.004751697462052107
        model: {}
        policy_loss: -0.010407716780900956
        total_loss: 22.666028594970705
        vf_explained_var: 0.9659603238105774
        vf_loss: 22.67643585205078
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.892307692307696
    gpu_util_percent0: 0.3103846153846153
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746153846153847
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1590147353741996
    mean_env_wait_ms: 1.667286166264757
    mean_inference_ms: 4.830434554774848
    mean_raw_obs_processing_ms: 0.42697806070658084
  time_since_restore: 392.153293132782
  time_this_iter_s: 22.778724908828735
  time_total_s: 392.153293132782
  timers:
    learn_throughput: 10976.47
    learn_time_ms: 14739.893
    sample_throughput: 19954.96
    sample_time_ms: 8107.859
    update_time_ms: 34.255
  timestamp: 1602213747
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     17 |          392.153 | 2750464 |  244.933 |              293.889 |              115.788 |            825.699 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3111.0
  date: 2020-10-09_03-22-50
  done: false
  episode_len_mean: 824.7876869965478
  episode_reward_max: 293.88888888888926
  episode_reward_mean: 245.61351431460744
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 169
  episodes_total: 3476
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.0517578125e-06
        cur_lr: 0.0001
        entropy: 0.9434128046035767
        entropy_coeff: 0.0
        kl: 0.004225034732371569
        model: {}
        policy_loss: -0.011341851484030486
        total_loss: 14.039760780334472
        vf_explained_var: 0.970009982585907
        vf_loss: 14.051102828979491
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.75
    gpu_util_percent0: 0.2907692307692308
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.773076923076925
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1587948579570496
    mean_env_wait_ms: 1.6683536873773408
    mean_inference_ms: 4.817764681490805
    mean_raw_obs_processing_ms: 0.4263145980710082
  time_since_restore: 414.800411939621
  time_this_iter_s: 22.64711880683899
  time_total_s: 414.800411939621
  timers:
    learn_throughput: 10985.126
    learn_time_ms: 14728.279
    sample_throughput: 19973.564
    sample_time_ms: 8100.307
    update_time_ms: 35.02
  timestamp: 1602213770
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     18 |            414.8 | 2912256 |  245.614 |              293.889 |              115.788 |            824.788 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3111.0
  date: 2020-10-09_03-23-13
  done: false
  episode_len_mean: 823.9512933406714
  episode_reward_max: 293.88888888888926
  episode_reward_mean: 246.2274089269135
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.52587890625e-06
        cur_lr: 0.0001
        entropy: 0.9482764840126038
        entropy_coeff: 0.0
        kl: 0.00443124296143651
        model: {}
        policy_loss: -0.01153549924492836
        total_loss: 14.898041915893554
        vf_explained_var: 0.9653136134147644
        vf_loss: 14.909577941894531
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.82692307692308
    gpu_util_percent0: 0.2588461538461539
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.77692307692308
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15860760051887618
    mean_env_wait_ms: 1.6693334469435752
    mean_inference_ms: 4.806729869907263
    mean_raw_obs_processing_ms: 0.4257356216104913
  time_since_restore: 437.798953294754
  time_this_iter_s: 22.998541355133057
  time_total_s: 437.798953294754
  timers:
    learn_throughput: 10998.597
    learn_time_ms: 14710.239
    sample_throughput: 19922.758
    sample_time_ms: 8120.964
    update_time_ms: 33.496
  timestamp: 1602213793
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     19 |          437.799 | 3074048 |  246.227 |              293.889 |              115.788 |            823.951 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3111.0
  date: 2020-10-09_03-23-36
  done: false
  episode_len_mean: 822.9660794109914
  episode_reward_max: 293.88888888888926
  episode_reward_mean: 246.8800787257268
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 169
  episodes_total: 3803
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 7.62939453125e-07
        cur_lr: 0.0001
        entropy: 0.9118903756141663
        entropy_coeff: 0.0
        kl: 0.0044347413815557955
        model: {}
        policy_loss: -0.011680699698626996
        total_loss: 13.052145767211915
        vf_explained_var: 0.9740586280822754
        vf_loss: 13.063826560974121
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.11538461538462
    gpu_util_percent0: 0.30115384615384616
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15842217429419309
    mean_env_wait_ms: 1.6703842563260665
    mean_inference_ms: 4.795765804789799
    mean_raw_obs_processing_ms: 0.425151662797024
  time_since_restore: 460.61356806755066
  time_this_iter_s: 22.81461477279663
  time_total_s: 460.61356806755066
  timers:
    learn_throughput: 11019.672
    learn_time_ms: 14682.107
    sample_throughput: 19896.986
    sample_time_ms: 8131.483
    update_time_ms: 31.599
  timestamp: 1602213816
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     20 |          460.614 | 3235840 |   246.88 |              293.889 |              115.788 |            822.966 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3111.0
  date: 2020-10-09_03-23-59
  done: false
  episode_len_mean: 821.3611787627862
  episode_reward_max: 295.74747474747426
  episode_reward_mean: 247.90177222788023
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 303
  episodes_total: 4106
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 3.814697265625e-07
        cur_lr: 0.0001
        entropy: 0.9006095051765441
        entropy_coeff: 0.0
        kl: 0.0044069703668355945
        model: {}
        policy_loss: -0.0105011697858572
        total_loss: 18.003569412231446
        vf_explained_var: 0.9713605046272278
        vf_loss: 18.01407127380371
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.833333333333336
    gpu_util_percent0: 0.2940740740740741
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.74074074074074
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15810753580883236
    mean_env_wait_ms: 1.67205733459522
    mean_inference_ms: 4.777549215663382
    mean_raw_obs_processing_ms: 0.4241804935034048
  time_since_restore: 483.49096965789795
  time_this_iter_s: 22.87740159034729
  time_total_s: 483.49096965789795
  timers:
    learn_throughput: 11034.055
    learn_time_ms: 14662.968
    sample_throughput: 19928.299
    sample_time_ms: 8118.706
    update_time_ms: 31.789
  timestamp: 1602213839
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     21 |          483.491 | 3397632 |  247.902 |              295.747 |              115.788 |            821.361 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3111.0
  date: 2020-10-09_03-24-22
  done: false
  episode_len_mean: 820.658462259728
  episode_reward_max: 295.74747474747426
  episode_reward_mean: 248.33848802132897
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 160
  episodes_total: 4266
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.9073486328125e-07
        cur_lr: 0.0001
        entropy: 0.8948758244514465
        entropy_coeff: 0.0
        kl: 0.004278976190835238
        model: {}
        policy_loss: -0.011763215996325016
        total_loss: 12.470299339294433
        vf_explained_var: 0.973299503326416
        vf_loss: 12.482062339782715
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.61538461538461
    gpu_util_percent0: 0.33538461538461534
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.77692307692308
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15796286780627017
    mean_env_wait_ms: 1.6729073122364446
    mean_inference_ms: 4.768948947475137
    mean_raw_obs_processing_ms: 0.42374120732523335
  time_since_restore: 506.3930199146271
  time_this_iter_s: 22.902050256729126
  time_total_s: 506.3930199146271
  timers:
    learn_throughput: 11028.431
    learn_time_ms: 14670.446
    sample_throughput: 19930.826
    sample_time_ms: 8117.677
    update_time_ms: 31.691
  timestamp: 1602213862
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     22 |          506.393 | 3559424 |  248.338 |              295.747 |              115.788 |            820.658 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3111.0
  date: 2020-10-09_03-24-46
  done: false
  episode_len_mean: 819.9520795660036
  episode_reward_max: 295.74747474747426
  episode_reward_mean: 248.8497634573583
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.5367431640625e-08
        cur_lr: 0.0001
        entropy: 0.8916106343269348
        entropy_coeff: 0.0
        kl: 0.004524402879178524
        model: {}
        policy_loss: -0.011376874893903733
        total_loss: 11.01026611328125
        vf_explained_var: 0.9735782742500305
        vf_loss: 11.021643257141113
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.25769230769231
    gpu_util_percent0: 0.22423076923076923
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765384615384615
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15782480333409207
    mean_env_wait_ms: 1.6736898985750612
    mean_inference_ms: 4.760837614145504
    mean_raw_obs_processing_ms: 0.42331413706532434
  time_since_restore: 529.3967671394348
  time_this_iter_s: 23.00374722480774
  time_total_s: 529.3967671394348
  timers:
    learn_throughput: 11020.448
    learn_time_ms: 14681.073
    sample_throughput: 19949.916
    sample_time_ms: 8109.909
    update_time_ms: 31.54
  timestamp: 1602213886
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     23 |          529.397 | 3721216 |   248.85 |              295.747 |              115.788 |            819.952 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3094.0
  date: 2020-10-09_03-25-09
  done: false
  episode_len_mean: 818.6877799104286
  episode_reward_max: 295.74747474747426
  episode_reward_mean: 249.60878781416199
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 265
  episodes_total: 4689
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.76837158203125e-08
        cur_lr: 0.0001
        entropy: 0.8577644467353821
        entropy_coeff: 0.0
        kl: 0.004245135746896267
        model: {}
        policy_loss: -0.010577398538589477
        total_loss: 16.279094696044922
        vf_explained_var: 0.9737876057624817
        vf_loss: 16.28967151641846
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.522222222222226
    gpu_util_percent0: 0.3422222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1576184058410679
    mean_env_wait_ms: 1.6750129947957557
    mean_inference_ms: 4.748210868457836
    mean_raw_obs_processing_ms: 0.4226435707981779
  time_since_restore: 552.4868867397308
  time_this_iter_s: 23.09011960029602
  time_total_s: 552.4868867397308
  timers:
    learn_throughput: 11033.583
    learn_time_ms: 14663.595
    sample_throughput: 19955.311
    sample_time_ms: 8107.716
    update_time_ms: 36.858
  timestamp: 1602213909
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     24 |          552.487 | 3883008 |  249.609 |              295.747 |              115.788 |            818.688 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3094.0
  date: 2020-10-09_03-25-32
  done: false
  episode_len_mean: 817.7868517762352
  episode_reward_max: 295.74747474747426
  episode_reward_mean: 250.1794568799468
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 209
  episodes_total: 4898
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.384185791015625e-08
        cur_lr: 0.0001
        entropy: 0.8494078516960144
        entropy_coeff: 0.0
        kl: 0.0042180360294878485
        model: {}
        policy_loss: -0.010974284028634429
        total_loss: 11.602952575683593
        vf_explained_var: 0.9770470857620239
        vf_loss: 11.61392650604248
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.49230769230769
    gpu_util_percent0: 0.3269230769230769
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1574609605934605
    mean_env_wait_ms: 1.6759151368108676
    mean_inference_ms: 4.739022810787354
    mean_raw_obs_processing_ms: 0.42217420823206775
  time_since_restore: 575.5073418617249
  time_this_iter_s: 23.02045512199402
  time_total_s: 575.5073418617249
  timers:
    learn_throughput: 11033.285
    learn_time_ms: 14663.991
    sample_throughput: 19924.544
    sample_time_ms: 8120.236
    update_time_ms: 42.444
  timestamp: 1602213932
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     25 |          575.507 | 4044800 |  250.179 |              295.747 |              115.788 |            817.787 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3094.0
  date: 2020-10-09_03-25-55
  done: false
  episode_len_mean: 817.2070806962025
  episode_reward_max: 295.74747474747426
  episode_reward_mean: 250.59631920470522
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 5056
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.1920928955078126e-08
        cur_lr: 0.0001
        entropy: 0.8610100269317627
        entropy_coeff: 0.0
        kl: 0.004082049522548914
        model: {}
        policy_loss: -0.011690744198858738
        total_loss: 10.228339576721192
        vf_explained_var: 0.9761525392532349
        vf_loss: 10.240030670166016
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.28076923076923
    gpu_util_percent0: 0.3103846153846153
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765384615384615
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15735098474775672
    mean_env_wait_ms: 1.6765881259107398
    mean_inference_ms: 4.732458389612443
    mean_raw_obs_processing_ms: 0.4218323088906285
  time_since_restore: 598.2048797607422
  time_this_iter_s: 22.697537899017334
  time_total_s: 598.2048797607422
  timers:
    learn_throughput: 11045.099
    learn_time_ms: 14648.306
    sample_throughput: 19938.916
    sample_time_ms: 8114.383
    update_time_ms: 40.613
  timestamp: 1602213955
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | RUNNING  | 172.17.0.4:51017 |     26 |          598.205 | 4206592 |  250.596 |              295.747 |              115.788 |            817.207 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_b9272_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3094.0
  date: 2020-10-09_03-26-18
  done: true
  episode_len_mean: 816.5672156261969
  episode_reward_max: 295.8383838383833
  episode_reward_mean: 250.9618107540359
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 166
  episodes_total: 5222
  experiment_id: 99da21fbe9b0427fb1ecb27b850b60dd
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 5.960464477539063e-09
        cur_lr: 0.0001
        entropy: 0.847122585773468
        entropy_coeff: 0.0
        kl: 0.004283256363123655
        model: {}
        policy_loss: -0.011017254437319934
        total_loss: 12.918401908874511
        vf_explained_var: 0.9739933013916016
        vf_loss: 12.92941951751709
    num_steps_sampled: 4368384
    num_steps_trained: 4368384
  iterations_since_restore: 27
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.87307692307692
    gpu_util_percent0: 0.2673076923076923
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.761538461538462
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 51017
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15723756925623406
    mean_env_wait_ms: 1.677266765411485
    mean_inference_ms: 4.725830502891452
    mean_raw_obs_processing_ms: 0.4214715528265037
  time_since_restore: 621.0284881591797
  time_this_iter_s: 22.8236083984375
  time_total_s: 621.0284881591797
  timers:
    learn_throughput: 11048.269
    learn_time_ms: 14644.104
    sample_throughput: 19913.121
    sample_time_ms: 8124.894
    update_time_ms: 39.168
  timestamp: 1602213978
  timesteps_since_restore: 0
  timesteps_total: 4368384
  training_iteration: 27
  trial_id: b9272_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | TERMINATED |       |     27 |          621.028 | 4368384 |  250.962 |              295.838 |              115.788 |            816.567 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.55 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_b9272_00000 | TERMINATED |       |     27 |          621.028 | 4368384 |  250.962 |              295.838 |              115.788 |            816.567 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


