2020-10-11 23:19:48,837	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_429ba_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=29215)[0m 2020-10-11 23:19:51,604	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=29205)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29205)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29163)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29163)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29202)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29202)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29210)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29210)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29203)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29203)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29108)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29117)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29117)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29098)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29098)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29208)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29208)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29101)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29101)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29160)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29160)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29175)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29175)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29218)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29218)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29196)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29196)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29164)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29164)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29158)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29158)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29213)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29213)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29172)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29172)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29216)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29216)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29133)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29133)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29187)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29111)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29111)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29131)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29131)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=29189)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=29189)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_23-20-33
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.29999999999999993
        cur_lr: 5.0e-05
        entropy: 1.184471885363261
        entropy_coeff: 0.0001
        kl: 0.004436286670776705
        model: {}
        policy_loss: -0.012187958707727375
        total_loss: 500.41333770751953
        vf_explained_var: 0.5819632411003113
        vf_loss: 500.42430623372394
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.793333333333333
    gpu_util_percent0: 0.356
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5888888888888877
    vram_util_percent0: 0.0895539521154477
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1690343295618795
    mean_env_wait_ms: 1.1699197026600472
    mean_inference_ms: 5.844398762348737
    mean_raw_obs_processing_ms: 0.45414668757741045
  time_since_restore: 36.222580909729004
  time_this_iter_s: 36.222580909729004
  time_total_s: 36.222580909729004
  timers:
    learn_throughput: 6020.382
    learn_time_ms: 26874.04
    sample_throughput: 17551.321
    sample_time_ms: 9218.224
    update_time_ms: 50.393
  timestamp: 1602458433
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |      1 |          36.2226 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3623.1979166666665
    time_step_min: 3379
  date: 2020-10-11_23-21-08
  done: false
  episode_len_mean: 889.8417721518987
  episode_reward_max: 259.20202020201987
  episode_reward_mean: 216.61091931977984
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1534875929355621
        entropy_coeff: 0.0001
        kl: 0.007247027397776644
        model: {}
        policy_loss: -0.016684174149607617
        total_loss: 120.84751637776692
        vf_explained_var: 0.8236787915229797
        vf_loss: 120.86322784423828
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.826190476190476
    gpu_util_percent0: 0.2928571428571428
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7761904761904765
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16404149397282972
    mean_env_wait_ms: 1.1653806611093884
    mean_inference_ms: 5.55155448886634
    mean_raw_obs_processing_ms: 0.4394792674333427
  time_since_restore: 70.9866075515747
  time_this_iter_s: 34.7640266418457
  time_total_s: 70.9866075515747
  timers:
    learn_throughput: 5980.428
    learn_time_ms: 27053.581
    sample_throughput: 19402.606
    sample_time_ms: 8338.673
    update_time_ms: 38.087
  timestamp: 1602458468
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |      2 |          70.9866 | 323584 |  216.611 |              259.202 |              145.717 |            889.842 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3620.92600896861
    time_step_min: 3314
  date: 2020-10-11_23-21-42
  done: false
  episode_len_mean: 889.457805907173
  episode_reward_max: 272.08080808080786
  episode_reward_mean: 217.7920342667176
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1428222755591075
        entropy_coeff: 0.0001
        kl: 0.008524477714672685
        model: {}
        policy_loss: -0.016711332912867267
        total_loss: 48.362962086995445
        vf_explained_var: 0.9160447120666504
        vf_loss: 48.378509203592934
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.275609756097563
    gpu_util_percent0: 0.37341463414634146
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7829268292682934
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16110012769722998
    mean_env_wait_ms: 1.1631204076772548
    mean_inference_ms: 5.348544956046692
    mean_raw_obs_processing_ms: 0.4297734520318146
  time_since_restore: 104.85482931137085
  time_this_iter_s: 33.86822175979614
  time_total_s: 104.85482931137085
  timers:
    learn_throughput: 5995.24
    learn_time_ms: 26986.743
    sample_throughput: 20567.116
    sample_time_ms: 7866.538
    update_time_ms: 39.49
  timestamp: 1602458502
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |      3 |          104.855 | 485376 |  217.792 |              272.081 |               109.96 |            889.458 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3615.066225165563
    time_step_min: 3274
  date: 2020-10-11_23-22-16
  done: false
  episode_len_mean: 889.4050632911392
  episode_reward_max: 272.08080808080786
  episode_reward_mean: 218.31690320930804
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.1215758124987285
        entropy_coeff: 0.0001
        kl: 0.009388032291705409
        model: {}
        policy_loss: -0.01995697299328943
        total_loss: 33.57533311843872
        vf_explained_var: 0.9426862597465515
        vf_loss: 33.593993186950684
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.078048780487805
    gpu_util_percent0: 0.4073170731707318
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7804878048780495
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15908992122195528
    mean_env_wait_ms: 1.161775834591839
    mean_inference_ms: 5.206135388582775
    mean_raw_obs_processing_ms: 0.4229043915207052
  time_since_restore: 138.6759798526764
  time_this_iter_s: 33.82115054130554
  time_total_s: 138.6759798526764
  timers:
    learn_throughput: 5999.07
    learn_time_ms: 26969.514
    sample_throughput: 21266.424
    sample_time_ms: 7607.861
    update_time_ms: 35.966
  timestamp: 1602458536
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |      4 |          138.676 | 647168 |  218.317 |              272.081 |               109.96 |            889.405 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3603.211286089239
    time_step_min: 3247
  date: 2020-10-11_23-22-50
  done: false
  episode_len_mean: 887.3025316455696
  episode_reward_max: 274.0505050505049
  episode_reward_mean: 219.98241912798855
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0983635981877644
        entropy_coeff: 0.0001
        kl: 0.008348640791761378
        model: {}
        policy_loss: -0.017825614428147674
        total_loss: 22.6289381980896
        vf_explained_var: 0.9583442807197571
        vf_loss: 22.64562114079793
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.75714285714286
    gpu_util_percent0: 0.36666666666666664
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77857142857143
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15760126921376377
    mean_env_wait_ms: 1.1613587854708025
    mean_inference_ms: 5.099985077489108
    mean_raw_obs_processing_ms: 0.417715240741064
  time_since_restore: 172.6720151901245
  time_this_iter_s: 33.99603533744812
  time_total_s: 172.6720151901245
  timers:
    learn_throughput: 6000.065
    learn_time_ms: 26965.039
    sample_throughput: 21663.233
    sample_time_ms: 7468.507
    update_time_ms: 47.13
  timestamp: 1602458570
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |      5 |          172.672 | 808960 |  219.982 |              274.051 |               109.96 |            887.303 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3589.106339468303
    time_step_min: 3244
  date: 2020-10-11_23-23-24
  done: false
  episode_len_mean: 881.4125248508947
  episode_reward_max: 274.50505050505046
  episode_reward_mean: 222.2226840974354
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 216
  episodes_total: 1006
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0668284197648366
        entropy_coeff: 0.0001
        kl: 0.008734627704446515
        model: {}
        policy_loss: -0.014155974650445083
        total_loss: 28.392080148061115
        vf_explained_var: 0.9643754363059998
        vf_loss: 28.405032634735107
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.197560975609758
    gpu_util_percent0: 0.3570731707317073
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7731707317073173
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15614771036997163
    mean_env_wait_ms: 1.1626689489115456
    mean_inference_ms: 4.993800184840323
    mean_raw_obs_processing_ms: 0.41260855026243304
  time_since_restore: 206.86062598228455
  time_this_iter_s: 34.188610792160034
  time_total_s: 206.86062598228455
  timers:
    learn_throughput: 5995.174
    learn_time_ms: 26987.041
    sample_throughput: 21895.693
    sample_time_ms: 7389.216
    update_time_ms: 45.95
  timestamp: 1602458604
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |      6 |          206.861 | 970752 |  222.223 |              274.505 |               109.96 |            881.413 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3579.089805825243
    time_step_min: 3244
  date: 2020-10-11_23-23-58
  done: false
  episode_len_mean: 874.8757911392405
  episode_reward_max: 274.8080808080806
  episode_reward_mean: 224.01466404551832
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 258
  episodes_total: 1264
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0796265403429668
        entropy_coeff: 0.0001
        kl: 0.007877287998174628
        model: {}
        policy_loss: -0.015921933721983805
        total_loss: 18.916932582855225
        vf_explained_var: 0.971172571182251
        vf_loss: 18.93178113301595
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.688095238095237
    gpu_util_percent0: 0.3142857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783333333333334
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15486971045362238
    mean_env_wait_ms: 1.1641749035391151
    mean_inference_ms: 4.903302548928694
    mean_raw_obs_processing_ms: 0.4083644933087705
  time_since_restore: 241.39743733406067
  time_this_iter_s: 34.53681135177612
  time_total_s: 241.39743733406067
  timers:
    learn_throughput: 5979.321
    learn_time_ms: 27058.593
    sample_throughput: 22083.608
    sample_time_ms: 7326.339
    update_time_ms: 44.687
  timestamp: 1602458638
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |      7 |          241.397 | 1132544 |  224.015 |              274.808 |               109.96 |            874.876 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3573.090387374462
    time_step_min: 3244
  date: 2020-10-11_23-24-33
  done: false
  episode_len_mean: 871.1722925457103
  episode_reward_max: 274.8080808080806
  episode_reward_mean: 225.0589012487745
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.0497520565986633
        entropy_coeff: 0.0001
        kl: 0.00786250263142089
        model: {}
        policy_loss: -0.016586801075997453
        total_loss: 15.961147228876749
        vf_explained_var: 0.9726879000663757
        vf_loss: 15.976659536361694
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.530952380952378
    gpu_util_percent0: 0.35333333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142865
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1542668180555801
    mean_env_wait_ms: 1.1652062256534839
    mean_inference_ms: 4.85996057409543
    mean_raw_obs_processing_ms: 0.40638381249302197
  time_since_restore: 275.45378375053406
  time_this_iter_s: 34.05634641647339
  time_total_s: 275.45378375053406
  timers:
    learn_throughput: 5981.185
    learn_time_ms: 27050.158
    sample_throughput: 22215.98
    sample_time_ms: 7282.686
    update_time_ms: 43.899
  timestamp: 1602458673
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |      8 |          275.454 | 1294336 |  225.059 |              274.808 |               109.96 |            871.172 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3567.456829896907
    time_step_min: 3244
  date: 2020-10-11_23-25-07
  done: false
  episode_len_mean: 868.1158227848101
  episode_reward_max: 274.8080808080806
  episode_reward_mean: 225.8314793504665
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 1.029351790746053
        entropy_coeff: 0.0001
        kl: 0.0077440734797467785
        model: {}
        policy_loss: -0.016327598869490128
        total_loss: 17.769489765167236
        vf_explained_var: 0.969449520111084
        vf_loss: 17.784758408864338
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.740476190476187
    gpu_util_percent0: 0.3938095238095239
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.783333333333334
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15374442728467308
    mean_env_wait_ms: 1.1661856731743563
    mean_inference_ms: 4.822314636509746
    mean_raw_obs_processing_ms: 0.40465411914386173
  time_since_restore: 309.9779760837555
  time_this_iter_s: 34.524192333221436
  time_total_s: 309.9779760837555
  timers:
    learn_throughput: 5973.858
    learn_time_ms: 27083.335
    sample_throughput: 22301.502
    sample_time_ms: 7254.758
    update_time_ms: 48.838
  timestamp: 1602458707
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |      9 |          309.978 | 1456128 |  225.831 |              274.808 |               109.96 |            868.116 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3560.2962099125366
    time_step_min: 3244
  date: 2020-10-11_23-25-41
  done: false
  episode_len_mean: 865.0814687320711
  episode_reward_max: 274.8080808080806
  episode_reward_mean: 227.08019958622353
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 163
  episodes_total: 1743
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.989854762951533
        entropy_coeff: 0.0001
        kl: 0.007641173743953307
        model: {}
        policy_loss: -0.01585044778767042
        total_loss: 16.144983212153118
        vf_explained_var: 0.9741546511650085
        vf_loss: 16.159786621729534
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.89268292682927
    gpu_util_percent0: 0.3921951219512196
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.785365853658537
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1532746099899737
    mean_env_wait_ms: 1.1672693778462284
    mean_inference_ms: 4.788309381864179
    mean_raw_obs_processing_ms: 0.403078467199566
  time_since_restore: 343.82972502708435
  time_this_iter_s: 33.85174894332886
  time_total_s: 343.82972502708435
  timers:
    learn_throughput: 5978.697
    learn_time_ms: 27061.415
    sample_throughput: 22407.876
    sample_time_ms: 7220.319
    update_time_ms: 46.142
  timestamp: 1602458741
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |     10 |           343.83 | 1617920 |   227.08 |              274.808 |               109.96 |            865.081 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3542.8610973801287
    time_step_min: 3224
  date: 2020-10-11_23-26-15
  done: false
  episode_len_mean: 858.5933690882497
  episode_reward_max: 277.5353535353535
  episode_reward_mean: 229.46988657910146
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 308
  episodes_total: 2051
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9857913305362066
        entropy_coeff: 0.0001
        kl: 0.0072292360321929055
        model: {}
        policy_loss: -0.017585868408787064
        total_loss: 18.77361249923706
        vf_explained_var: 0.9756621718406677
        vf_loss: 18.790212631225586
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.224390243902437
    gpu_util_percent0: 0.3695121951219512
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775609756097561
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15254932682626982
    mean_env_wait_ms: 1.169487636156996
    mean_inference_ms: 4.735902869006732
    mean_raw_obs_processing_ms: 0.4006921299835691
  time_since_restore: 377.821816444397
  time_this_iter_s: 33.99209141731262
  time_total_s: 377.821816444397
  timers:
    learn_throughput: 5977.454
    learn_time_ms: 27067.043
    sample_throughput: 23122.73
    sample_time_ms: 6997.098
    update_time_ms: 43.473
  timestamp: 1602458775
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |     11 |          377.822 | 1779712 |   229.47 |              277.535 |               109.96 |            858.593 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3533.8411172161173
    time_step_min: 3213
  date: 2020-10-11_23-26-49
  done: false
  episode_len_mean: 855.0474683544304
  episode_reward_max: 283.14141414141403
  episode_reward_mean: 230.82669826657155
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 161
  episodes_total: 2212
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9714688062667847
        entropy_coeff: 0.0001
        kl: 0.00782435693933318
        model: {}
        policy_loss: -0.01601176185067743
        total_loss: 10.585988442103067
        vf_explained_var: 0.9798522591590881
        vf_loss: 10.60092306137085
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.690243902439022
    gpu_util_percent0: 0.35292682926829266
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.792682926829269
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15223125806875235
    mean_env_wait_ms: 1.1705748188201568
    mean_inference_ms: 4.712952641109797
    mean_raw_obs_processing_ms: 0.39964513878301133
  time_since_restore: 411.95282220840454
  time_this_iter_s: 34.13100576400757
  time_total_s: 411.95282220840454
  timers:
    learn_throughput: 5982.33
    learn_time_ms: 27044.981
    sample_throughput: 23268.872
    sample_time_ms: 6953.152
    update_time_ms: 44.984
  timestamp: 1602458809
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |     12 |          411.953 | 1941504 |  230.827 |              283.141 |               109.96 |            855.047 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3524.6524338172503
    time_step_min: 3213
  date: 2020-10-11_23-27-24
  done: false
  episode_len_mean: 852.3603375527426
  episode_reward_max: 285.56565656565635
  episode_reward_mean: 232.18149852959968
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9551965246597925
        entropy_coeff: 0.0001
        kl: 0.007747883947255711
        model: {}
        policy_loss: -0.01706781630249073
        total_loss: 9.645657777786255
        vf_explained_var: 0.9797250628471375
        vf_loss: 9.661659161249796
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.807142857142857
    gpu_util_percent0: 0.3533333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7904761904761917
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1519480428067991
    mean_env_wait_ms: 1.1716145349758227
    mean_inference_ms: 4.6926012079126265
    mean_raw_obs_processing_ms: 0.39870145069057816
  time_since_restore: 445.94863653182983
  time_this_iter_s: 33.99581432342529
  time_total_s: 445.94863653182983
  timers:
    learn_throughput: 5982.205
    learn_time_ms: 27045.545
    sample_throughput: 23228.97
    sample_time_ms: 6965.096
    update_time_ms: 44.665
  timestamp: 1602458844
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |     13 |          445.949 | 2103296 |  232.181 |              285.566 |               109.96 |             852.36 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3515.0444974175607
    time_step_min: 3165
  date: 2020-10-11_23-27-58
  done: false
  episode_len_mean: 849.860510805501
  episode_reward_max: 286.4747474747471
  episode_reward_mean: 233.53833025738712
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 175
  episodes_total: 2545
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.918505072593689
        entropy_coeff: 0.0001
        kl: 0.008027533418498933
        model: {}
        policy_loss: -0.017281677496309083
        total_loss: 12.071628252665201
        vf_explained_var: 0.9792194366455078
        vf_loss: 12.08779780069987
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.0
    gpu_util_percent0: 0.3375609756097561
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7853658536585364
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15166834527998138
    mean_env_wait_ms: 1.172834349922338
    mean_inference_ms: 4.672171408699876
    mean_raw_obs_processing_ms: 0.39774629558490804
  time_since_restore: 479.9764382839203
  time_this_iter_s: 34.027801752090454
  time_total_s: 479.9764382839203
  timers:
    learn_throughput: 5979.328
    learn_time_ms: 27058.56
    sample_throughput: 23210.766
    sample_time_ms: 6970.558
    update_time_ms: 45.931
  timestamp: 1602458878
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |     14 |          479.976 | 2265088 |  233.538 |              286.475 |               109.96 |            849.861 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3502.6094527363184
    time_step_min: 3165
  date: 2020-10-11_23-28-32
  done: false
  episode_len_mean: 846.0809289232934
  episode_reward_max: 286.4747474747471
  episode_reward_mean: 235.3697318007662
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 297
  episodes_total: 2842
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.9135314673185349
        entropy_coeff: 0.0001
        kl: 0.00709421094506979
        model: {}
        policy_loss: -0.01534730609273538
        total_loss: 16.48606236775716
        vf_explained_var: 0.977409839630127
        vf_loss: 16.500436623891193
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.333333333333336
    gpu_util_percent0: 0.429047619047619
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7738095238095246
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15125419718421507
    mean_env_wait_ms: 1.1745675980314356
    mean_inference_ms: 4.642178954778537
    mean_raw_obs_processing_ms: 0.39635128039839657
  time_since_restore: 514.368403673172
  time_this_iter_s: 34.39196538925171
  time_total_s: 514.368403673172
  timers:
    learn_throughput: 5974.903
    learn_time_ms: 27078.601
    sample_throughput: 23150.09
    sample_time_ms: 6988.828
    update_time_ms: 45.526
  timestamp: 1602458912
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |     15 |          514.368 | 2426880 |   235.37 |              286.475 |               109.96 |            846.081 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3496.892400806994
    time_step_min: 3165
  date: 2020-10-11_23-29-07
  done: false
  episode_len_mean: 843.9686875416389
  episode_reward_max: 286.4747474747471
  episode_reward_mean: 236.34347135579637
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 160
  episodes_total: 3002
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8947641452153524
        entropy_coeff: 0.0001
        kl: 0.007218999283698698
        model: {}
        policy_loss: -0.016975217460033793
        total_loss: 9.831872383753458
        vf_explained_var: 0.9811124801635742
        vf_loss: 9.847853978474935
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.97073170731707
    gpu_util_percent0: 0.3985365853658537
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7878048780487807
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15105942512579745
    mean_env_wait_ms: 1.1754548213385807
    mean_inference_ms: 4.627961476901226
    mean_raw_obs_processing_ms: 0.39569553624055576
  time_since_restore: 548.8439099788666
  time_this_iter_s: 34.47550630569458
  time_total_s: 548.8439099788666
  timers:
    learn_throughput: 5969.746
    learn_time_ms: 27101.989
    sample_throughput: 23128.931
    sample_time_ms: 6995.222
    update_time_ms: 44.524
  timestamp: 1602458947
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |     16 |          548.844 | 2588672 |  236.343 |              286.475 |               109.96 |            843.969 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3490.816091954023
    time_step_min: 3165
  date: 2020-10-11_23-29-41
  done: false
  episode_len_mean: 842.2620253164557
  episode_reward_max: 286.4747474747471
  episode_reward_mean: 237.16826492775854
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8865708311398824
        entropy_coeff: 0.0001
        kl: 0.00784701066246877
        model: {}
        policy_loss: -0.019675907319954906
        total_loss: 10.207090775171915
        vf_explained_var: 0.9793717861175537
        vf_loss: 10.225678443908691
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.89047619047619
    gpu_util_percent0: 0.4052380952380953
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7904761904761908
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1508806527023755
    mean_env_wait_ms: 1.1762866718787202
    mean_inference_ms: 4.615012242529609
    mean_raw_obs_processing_ms: 0.3950857053124105
  time_since_restore: 583.0203921794891
  time_this_iter_s: 34.17648220062256
  time_total_s: 583.0203921794891
  timers:
    learn_throughput: 5982.66
    learn_time_ms: 27043.49
    sample_throughput: 23054.822
    sample_time_ms: 7017.707
    update_time_ms: 45.029
  timestamp: 1602458981
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | RUNNING  | 172.17.0.4:29215 |     17 |           583.02 | 2750464 |  237.168 |              286.475 |               109.96 |            842.262 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_429ba_00000:
  custom_metrics:
    time_step_max: 4330
    time_step_mean: 3482.912107623318
    time_step_min: 3165
  date: 2020-10-11_23-30-15
  done: true
  episode_len_mean: 840.2537800177884
  episode_reward_max: 286.4747474747471
  episode_reward_mean: 238.1957224183728
  episode_reward_min: 109.95959595959587
  episodes_this_iter: 213
  episodes_total: 3373
  experiment_id: 96cdff9e31a5487e95a46772e529db0b
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.14999999999999997
        cur_lr: 5.0e-05
        entropy: 0.8533652673165003
        entropy_coeff: 0.0001
        kl: 0.007678817453173299
        model: {}
        policy_loss: -0.01582063998406132
        total_loss: 12.075001875559488
        vf_explained_var: 0.9814364910125732
        vf_loss: 12.089756091435751
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.809756097560978
    gpu_util_percent0: 0.37219512195121945
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7780487804878056
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 29215
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15065609967277724
    mean_env_wait_ms: 1.1774207488787056
    mean_inference_ms: 4.598879569773722
    mean_raw_obs_processing_ms: 0.39432512493985017
  time_since_restore: 616.9592678546906
  time_this_iter_s: 33.938875675201416
  time_total_s: 616.9592678546906
  timers:
    learn_throughput: 5982.053
    learn_time_ms: 27046.232
    sample_throughput: 23108.506
    sample_time_ms: 7001.405
    update_time_ms: 45.794
  timestamp: 1602459015
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 429ba_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | TERMINATED |       |     18 |          616.959 | 2912256 |  238.196 |              286.475 |               109.96 |            840.254 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_429ba_00000 | TERMINATED |       |     18 |          616.959 | 2912256 |  238.196 |              286.475 |               109.96 |            840.254 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


