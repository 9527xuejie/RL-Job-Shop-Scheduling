2020-10-09 21:25:42,049	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_fcccf_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=73216)[0m 2020-10-09 21:25:44,801	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=73104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73195)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73195)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73227)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73227)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73188)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73188)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73213)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73213)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73110)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73219)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73219)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73111)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73111)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73127)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73127)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73175)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73175)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73197)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73197)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73208)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73208)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73189)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73189)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73138)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73138)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73186)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73186)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73095)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73095)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73202)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73202)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73218)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73218)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73169)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73169)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73190)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73190)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73194)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73167)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73167)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73135)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73135)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73173)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73173)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73108)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73168)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73168)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73125)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73125)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73172)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73172)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=73134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=73134)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_fcccf_00000:
  custom_metrics:
    time_step_max: 4249
    time_step_mean: 3606.536231884058
    time_step_min: 3277
  date: 2020-10-09_21-26-47
  done: false
  episode_len_mean: 890.3196202531645
  episode_reward_max: 269.5050505050508
  episode_reward_mean: 220.52154455951901
  episode_reward_min: 122.23232323232297
  episodes_this_iter: 316
  episodes_total: 316
  experiment_id: 04105dba9dec4bb2a5c3d55d9578b4ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1849677307265145
        entropy_coeff: 0.0
        kl: 0.004723370341317994
        model: {}
        policy_loss: -0.008612766770446407
        total_loss: 496.76798139299666
        vf_explained_var: 0.577113687992096
        vf_loss: 496.77565002441406
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.54925373134328
    gpu_util_percent0: 0.4243283582089552
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7746268656716415
    vram_util_percent0: 0.11730662854961009
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73216
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22743799245515772
    mean_env_wait_ms: 2.2123632728409417
    mean_inference_ms: 8.75208423917181
    mean_raw_obs_processing_ms: 0.7682937411254996
  time_since_restore: 57.52699136734009
  time_this_iter_s: 57.52699136734009
  time_total_s: 57.52699136734009
  timers:
    learn_throughput: 7442.787
    learn_time_ms: 43476.187
    sample_throughput: 23175.157
    sample_time_ms: 13962.538
    update_time_ms: 48.416
  timestamp: 1602278807
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 1
  trial_id: fcccf_00000
  
== Status ==
Memory usage on this node: 29.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fcccf_00000 | RUNNING  | 172.17.0.4:73216 |      1 |           57.527 | 323584 |  220.522 |              269.505 |              122.232 |             890.32 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fcccf_00000:
  custom_metrics:
    time_step_max: 4249
    time_step_mean: 3614.4856596558316
    time_step_min: 3277
  date: 2020-10-09_21-27-43
  done: false
  episode_len_mean: 885.2278481012659
  episode_reward_max: 269.5050505050508
  episode_reward_mean: 219.10013105740936
  episode_reward_min: 112.83838383838373
  episodes_this_iter: 316
  episodes_total: 632
  experiment_id: 04105dba9dec4bb2a5c3d55d9578b4ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1541960324559892
        entropy_coeff: 0.0
        kl: 0.008637720319841589
        model: {}
        policy_loss: -0.009568923255886017
        total_loss: 128.58022580827986
        vf_explained_var: 0.8098640441894531
        vf_loss: 128.5889276776995
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.143749999999997
    gpu_util_percent0: 0.36296875
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.15625
    vram_util_percent0: 0.13881600524762217
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73216
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.22328094090841696
    mean_env_wait_ms: 2.2089906801656127
    mean_inference_ms: 8.418752664552139
    mean_raw_obs_processing_ms: 0.7576157899245999
  time_since_restore: 113.46481847763062
  time_this_iter_s: 55.93782711029053
  time_total_s: 113.46481847763062
  timers:
    learn_throughput: 7456.647
    learn_time_ms: 43395.377
    sample_throughput: 24457.058
    sample_time_ms: 13230.7
    update_time_ms: 41.864
  timestamp: 1602278863
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 2
  trial_id: fcccf_00000
  
== Status ==
Memory usage on this node: 30.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fcccf_00000 | RUNNING  | 172.17.0.4:73216 |      2 |          113.465 | 647168 |    219.1 |              269.505 |              112.838 |            885.228 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fcccf_00000:
  custom_metrics:
    time_step_max: 4249
    time_step_mean: 3621.2097735399284
    time_step_min: 3277
  date: 2020-10-09_21-28-39
  done: false
  episode_len_mean: 884.204641350211
  episode_reward_max: 271.6262626262628
  episode_reward_mean: 218.02234369006504
  episode_reward_min: 112.83838383838373
  episodes_this_iter: 316
  episodes_total: 948
  experiment_id: 04105dba9dec4bb2a5c3d55d9578b4ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1367694905826025
        entropy_coeff: 0.0
        kl: 0.009814104397914239
        model: {}
        policy_loss: -0.009392478415975347
        total_loss: 56.715634209769114
        vf_explained_var: 0.9093261361122131
        vf_loss: 56.72404561723982
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.743076923076924
    gpu_util_percent0: 0.3490769230769231
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.1753846153846155
    vram_util_percent0: 0.13881600524762217
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73216
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2209388891544223
    mean_env_wait_ms: 2.2072864608234224
    mean_inference_ms: 8.212270944579755
    mean_raw_obs_processing_ms: 0.7509411491422914
  time_since_restore: 169.45731401443481
  time_this_iter_s: 55.9924955368042
  time_total_s: 169.45731401443481
  timers:
    learn_throughput: 7441.672
    learn_time_ms: 43482.702
    sample_throughput: 25115.862
    sample_time_ms: 12883.651
    update_time_ms: 41.536
  timestamp: 1602278919
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 3
  trial_id: fcccf_00000
  
== Status ==
Memory usage on this node: 30.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fcccf_00000 | RUNNING  | 172.17.0.4:73216 |      3 |          169.457 | 970752 |  218.022 |              271.626 |              112.838 |            884.205 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fcccf_00000:
  custom_metrics:
    time_step_max: 4249
    time_step_mean: 3619.9445887445886
    time_step_min: 3277
  date: 2020-10-09_21-29-35
  done: false
  episode_len_mean: 881.8465189873418
  episode_reward_max: 271.6262626262628
  episode_reward_mean: 218.7751646208923
  episode_reward_min: 101.92929292929271
  episodes_this_iter: 316
  episodes_total: 1264
  experiment_id: 04105dba9dec4bb2a5c3d55d9578b4ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.117723754474095
        entropy_coeff: 0.0
        kl: 0.00838863364021693
        model: {}
        policy_loss: -0.010310693835240923
        total_loss: 35.431003025599885
        vf_explained_var: 0.9411176443099976
        vf_loss: 35.440474373953684
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.60158730158731
    gpu_util_percent0: 0.39444444444444443
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.169841269841268
    vram_util_percent0: 0.13881600524762222
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73216
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.21942543562641167
    mean_env_wait_ms: 2.20675823025662
    mean_inference_ms: 8.068033097045088
    mean_raw_obs_processing_ms: 0.7457182814901342
  time_since_restore: 224.84860920906067
  time_this_iter_s: 55.391295194625854
  time_total_s: 224.84860920906067
  timers:
    learn_throughput: 7455.447
    learn_time_ms: 43402.363
    sample_throughput: 25496.588
    sample_time_ms: 12691.267
    update_time_ms: 41.413
  timestamp: 1602278975
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 4
  trial_id: fcccf_00000
  
== Status ==
Memory usage on this node: 30.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fcccf_00000 | RUNNING  | 172.17.0.4:73216 |      4 |          224.849 | 1294336 |  218.775 |              271.626 |              101.929 |            881.847 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fcccf_00000:
  custom_metrics:
    time_step_max: 4249
    time_step_mean: 3612.2963970088376
    time_step_min: 3277
  date: 2020-10-09_21-30-30
  done: false
  episode_len_mean: 879.2088607594936
  episode_reward_max: 271.6262626262628
  episode_reward_mean: 220.40436005625864
  episode_reward_min: 101.92929292929271
  episodes_this_iter: 316
  episodes_total: 1580
  experiment_id: 04105dba9dec4bb2a5c3d55d9578b4ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0820847153663635
        entropy_coeff: 0.0
        kl: 0.00781538081355393
        model: {}
        policy_loss: -0.00901993714433047
        total_loss: 28.14945806775774
        vf_explained_var: 0.9545435905456543
        vf_loss: 28.157695770263672
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.3734375
    gpu_util_percent0: 0.39234375
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.16875
    vram_util_percent0: 0.13881600524762217
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73216
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2183626939411538
    mean_env_wait_ms: 2.206843395228797
    mean_inference_ms: 7.961476072354632
    mean_raw_obs_processing_ms: 0.7412201492166582
  time_since_restore: 280.2076840400696
  time_this_iter_s: 55.35907483100891
  time_total_s: 280.2076840400696
  timers:
    learn_throughput: 7452.851
    learn_time_ms: 43417.478
    sample_throughput: 25904.682
    sample_time_ms: 12491.333
    update_time_ms: 43.577
  timestamp: 1602279030
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 5
  trial_id: fcccf_00000
  
== Status ==
Memory usage on this node: 30.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fcccf_00000 | RUNNING  | 172.17.0.4:73216 |      5 |          280.208 | 1617920 |  220.404 |              271.626 |              101.929 |            879.209 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fcccf_00000:
  custom_metrics:
    time_step_max: 4249
    time_step_mean: 3584.576607056549
    time_step_min: 3266
  date: 2020-10-09_21-31-26
  done: false
  episode_len_mean: 871.8792470156106
  episode_reward_max: 276.92929292929284
  episode_reward_mean: 224.38261401897748
  episode_reward_min: 101.92929292929271
  episodes_this_iter: 598
  episodes_total: 2178
  experiment_id: 04105dba9dec4bb2a5c3d55d9578b4ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.064732653754098
        entropy_coeff: 0.0
        kl: 0.007807594923568624
        model: {}
        policy_loss: -0.011261867508957428
        total_loss: 31.93278271811349
        vf_explained_var: 0.9620145559310913
        vf_loss: 31.94326455252511
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.6968253968254
    gpu_util_percent0: 0.4174603174603174
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.174603174603174
    vram_util_percent0: 0.13881600524762222
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73216
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.21702667957391783
    mean_env_wait_ms: 2.2105428870330734
    mean_inference_ms: 7.823214882914323
    mean_raw_obs_processing_ms: 0.7357971452196232
  time_since_restore: 335.396183013916
  time_this_iter_s: 55.188498973846436
  time_total_s: 335.396183013916
  timers:
    learn_throughput: 7453.807
    learn_time_ms: 43411.908
    sample_throughput: 26186.484
    sample_time_ms: 12356.909
    update_time_ms: 42.58
  timestamp: 1602279086
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 6
  trial_id: fcccf_00000
  
== Status ==
Memory usage on this node: 30.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fcccf_00000 | RUNNING  | 172.17.0.4:73216 |      6 |          335.396 | 1941504 |  224.383 |              276.929 |              101.929 |            871.879 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fcccf_00000:
  custom_metrics:
    time_step_max: 4249
    time_step_mean: 3572.433236874742
    time_step_min: 3249
  date: 2020-10-09_21-32-21
  done: false
  episode_len_mean: 867.4972310126582
  episode_reward_max: 282.98989898989925
  episode_reward_mean: 226.0739635276817
  episode_reward_min: 101.92929292929271
  episodes_this_iter: 350
  episodes_total: 2528
  experiment_id: 04105dba9dec4bb2a5c3d55d9578b4ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0606098430497306
        entropy_coeff: 0.0
        kl: 0.00757208200437682
        model: {}
        policy_loss: -0.011291875038295984
        total_loss: 18.432099887302943
        vf_explained_var: 0.9685453772544861
        vf_loss: 18.44263458251953
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.050793650793647
    gpu_util_percent0: 0.3788888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.187301587301587
    vram_util_percent0: 0.13881600524762222
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73216
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.21645794400008814
    mean_env_wait_ms: 2.212731973893361
    mean_inference_ms: 7.764455378859042
    mean_raw_obs_processing_ms: 0.7336107791023253
  time_since_restore: 390.8066840171814
  time_this_iter_s: 55.41050100326538
  time_total_s: 390.8066840171814
  timers:
    learn_throughput: 7450.228
    learn_time_ms: 43432.762
    sample_throughput: 26375.966
    sample_time_ms: 12268.138
    update_time_ms: 41.674
  timestamp: 1602279141
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 7
  trial_id: fcccf_00000
  
== Status ==
Memory usage on this node: 30.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fcccf_00000 | RUNNING  | 172.17.0.4:73216 |      7 |          390.807 | 2265088 |  226.074 |               282.99 |              101.929 |            867.497 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fcccf_00000:
  custom_metrics:
    time_step_max: 4249
    time_step_mean: 3559.7751371115173
    time_step_min: 3248
  date: 2020-10-09_21-33-15
  done: false
  episode_len_mean: 863.9651898734177
  episode_reward_max: 282.98989898989925
  episode_reward_mean: 227.7900630780376
  episode_reward_min: 101.92929292929271
  episodes_this_iter: 316
  episodes_total: 2844
  experiment_id: 04105dba9dec4bb2a5c3d55d9578b4ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0411277753966195
        entropy_coeff: 0.0
        kl: 0.0073146945464291745
        model: {}
        policy_loss: -0.010260522288652802
        total_loss: 17.397767748151505
        vf_explained_var: 0.9686874747276306
        vf_loss: 17.40729672568185
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.220967741935482
    gpu_util_percent0: 0.4369354838709678
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.1903225806451605
    vram_util_percent0: 0.1388160052476222
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73216
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.21604619692383908
    mean_env_wait_ms: 2.2147469435327367
    mean_inference_ms: 7.720108017215557
    mean_raw_obs_processing_ms: 0.7319096167364941
  time_since_restore: 445.1128158569336
  time_this_iter_s: 54.3061318397522
  time_total_s: 445.1128158569336
  timers:
    learn_throughput: 7472.38
    learn_time_ms: 43304.005
    sample_throughput: 26503.533
    sample_time_ms: 12209.089
    update_time_ms: 39.079
  timestamp: 1602279195
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 8
  trial_id: fcccf_00000
  
== Status ==
Memory usage on this node: 30.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fcccf_00000 | RUNNING  | 172.17.0.4:73216 |      8 |          445.113 | 2588672 |   227.79 |               282.99 |              101.929 |            863.965 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fcccf_00000:
  custom_metrics:
    time_step_max: 4249
    time_step_mean: 3549.868895444117
    time_step_min: 3193
  date: 2020-10-09_21-34-11
  done: false
  episode_len_mean: 860.4433544303797
  episode_reward_max: 282.98989898989925
  episode_reward_mean: 229.14510612453634
  episode_reward_min: 101.92929292929271
  episodes_this_iter: 316
  episodes_total: 3160
  experiment_id: 04105dba9dec4bb2a5c3d55d9578b4ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0131980691637312
        entropy_coeff: 0.0
        kl: 0.0075678295522396055
        model: {}
        policy_loss: -0.010305832539285933
        total_loss: 16.719011579241073
        vf_explained_var: 0.969113826751709
        vf_loss: 16.72856072017125
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.982812499999998
    gpu_util_percent0: 0.41140625000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.1890625
    vram_util_percent0: 0.13881600524762217
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73216
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.21569412187572692
    mean_env_wait_ms: 2.216782090663566
    mean_inference_ms: 7.681386347059446
    mean_raw_obs_processing_ms: 0.7303225455063391
  time_since_restore: 500.7474482059479
  time_this_iter_s: 55.63463234901428
  time_total_s: 500.7474482059479
  timers:
    learn_throughput: 7463.439
    learn_time_ms: 43355.885
    sample_throughput: 26635.765
    sample_time_ms: 12148.478
    update_time_ms: 46.541
  timestamp: 1602279251
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 9
  trial_id: fcccf_00000
  
== Status ==
Memory usage on this node: 30.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fcccf_00000 | RUNNING  | 172.17.0.4:73216 |      9 |          500.747 | 2912256 |  229.145 |               282.99 |              101.929 |            860.443 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fcccf_00000:
  custom_metrics:
    time_step_max: 4249
    time_step_mean: 3534.211731044349
    time_step_min: 3165
  date: 2020-10-09_21-35-06
  done: false
  episode_len_mean: 855.7339067702553
  episode_reward_max: 286.4747474747474
  episode_reward_mean: 231.25991883317064
  episode_reward_min: 101.92929292929271
  episodes_this_iter: 444
  episodes_total: 3604
  experiment_id: 04105dba9dec4bb2a5c3d55d9578b4ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9687805005482265
        entropy_coeff: 0.0
        kl: 0.006649907877934831
        model: {}
        policy_loss: -0.010618219351662057
        total_loss: 19.604169573102677
        vf_explained_var: 0.9738057255744934
        vf_loss: 19.614122663225448
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.562903225806448
    gpu_util_percent0: 0.3953225806451613
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.170967741935483
    vram_util_percent0: 0.1388160052476222
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73216
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.2152999945122458
    mean_env_wait_ms: 2.2202146078506924
    mean_inference_ms: 7.63549907135702
    mean_raw_obs_processing_ms: 0.7284855490932268
  time_since_restore: 555.8514347076416
  time_this_iter_s: 55.103986501693726
  time_total_s: 555.8514347076416
  timers:
    learn_throughput: 7466.255
    learn_time_ms: 43339.531
    sample_throughput: 26723.94
    sample_time_ms: 12108.394
    update_time_ms: 45.812
  timestamp: 1602279306
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 10
  trial_id: fcccf_00000
  
== Status ==
Memory usage on this node: 30.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fcccf_00000 | RUNNING  | 172.17.0.4:73216 |     10 |          555.851 | 3235840 |   231.26 |              286.475 |              101.929 |            855.734 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_fcccf_00000:
  custom_metrics:
    time_step_max: 4249
    time_step_mean: 3521.0332583145787
    time_step_min: 3165
  date: 2020-10-09_21-36-02
  done: true
  episode_len_mean: 851.5542843232716
  episode_reward_max: 287.6868686868686
  episode_reward_mean: 233.27677456158457
  episode_reward_min: 101.92929292929271
  episodes_this_iter: 504
  episodes_total: 4108
  experiment_id: 04105dba9dec4bb2a5c3d55d9578b4ae
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9651731976440975
        entropy_coeff: 0.0
        kl: 0.006858057475515774
        model: {}
        policy_loss: -0.008435985763623779
        total_loss: 14.92973266329084
        vf_explained_var: 0.9765583276748657
        vf_loss: 14.937482970101494
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.446875
    gpu_util_percent0: 0.36453125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 4.171875
    vram_util_percent0: 0.13881600524762217
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 73216
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.21489755830188537
    mean_env_wait_ms: 2.223308834808616
    mean_inference_ms: 7.591292742444794
    mean_raw_obs_processing_ms: 0.726722590182892
  time_since_restore: 611.3708024024963
  time_this_iter_s: 55.519367694854736
  time_total_s: 611.3708024024963
  timers:
    learn_throughput: 7461.825
    learn_time_ms: 43365.262
    sample_throughput: 27245.236
    sample_time_ms: 11876.719
    update_time_ms: 45.488
  timestamp: 1602279362
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 11
  trial_id: fcccf_00000
  
== Status ==
Memory usage on this node: 30.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fcccf_00000 | TERMINATED |       |     11 |          611.371 | 3559424 |  233.277 |              287.687 |              101.929 |            851.554 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 30.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.25 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_fcccf_00000 | TERMINATED |       |     11 |          611.371 | 3559424 |  233.277 |              287.687 |              101.929 |            851.554 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


