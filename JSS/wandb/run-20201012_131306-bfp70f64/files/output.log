2020-10-12 13:13:09,996	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_ada08_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=984)[0m 2020-10-12 13:13:12,743	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=1014)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1014)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1035)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1035)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1027)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1027)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=979)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=979)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=980)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=980)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=975)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=975)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=972)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=972)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1022)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1022)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=971)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=971)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1025)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1025)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=985)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=985)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=977)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=977)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=903)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=894)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=968)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=968)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=973)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=973)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=895)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=895)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=906)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=906)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1031)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1031)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=923)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=923)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=993)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=993)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=910)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=910)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=901)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=901)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=900)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=900)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=953)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=953)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=917)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=917)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=911)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=911)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=899)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=899)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=915)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=915)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=928)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=928)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1006)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1006)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=955)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=955)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=967)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=967)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=969)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=969)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=999)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=999)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=924)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=924)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=925)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=925)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=959)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=959)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=916)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=916)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=932)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=932)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=970)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=970)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=920)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=920)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1011)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1011)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=976)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=976)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=927)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=927)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 3941
    time_step_mean: 3510.563025210084
    time_step_min: 3241
  date: 2020-10-12_13-13-46
  done: false
  episode_len_mean: 895.2911392405064
  episode_reward_max: 255.28282828282772
  episode_reward_mean: 213.63438179260947
  episode_reward_min: 147.70707070707059
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1695472796758015
        entropy_coeff: 0.0005000000000000001
        kl: 0.008918385487049818
        model: {}
        policy_loss: -0.011033496926150596
        total_loss: 415.62353515625
        vf_explained_var: 0.5660186409950256
        vf_loss: 415.63336181640625
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.99705882352941
    gpu_util_percent0: 0.3464705882352941
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.5558823529411767
    vram_util_percent0: 0.08636872262844136
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1654686799716272
    mean_env_wait_ms: 1.1624538166061453
    mean_inference_ms: 5.47014673685873
    mean_raw_obs_processing_ms: 0.4388955714857921
  time_since_restore: 27.739327669143677
  time_this_iter_s: 27.739327669143677
  time_total_s: 27.739327669143677
  timers:
    learn_throughput: 8559.128
    learn_time_ms: 18902.859
    sample_throughput: 18448.588
    sample_time_ms: 8769.885
    update_time_ms: 27.831
  timestamp: 1602508426
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |      1 |          27.7393 | 161792 |  213.634 |              255.283 |              147.707 |            895.291 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3520.2779783393503
    time_step_min: 3241
  date: 2020-10-12_13-14-11
  done: false
  episode_len_mean: 899.4145569620254
  episode_reward_max: 255.28282828282772
  episode_reward_mean: 211.10944891957533
  episode_reward_min: 137.40404040404047
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1412788331508636
        entropy_coeff: 0.0005000000000000001
        kl: 0.008170056467254957
        model: {}
        policy_loss: -0.010739226680016145
        total_loss: 98.03919537862141
        vf_explained_var: 0.8379969000816345
        vf_loss: 98.04887135823567
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.990322580645156
    gpu_util_percent0: 0.34193548387096767
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7548387096774185
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1609611687316561
    mean_env_wait_ms: 1.159167943042173
    mean_inference_ms: 5.23097374532696
    mean_raw_obs_processing_ms: 0.4265583582320572
  time_since_restore: 53.53063750267029
  time_this_iter_s: 25.79130983352661
  time_total_s: 53.53063750267029
  timers:
    learn_throughput: 8622.009
    learn_time_ms: 18765.001
    sample_throughput: 20425.438
    sample_time_ms: 7921.103
    update_time_ms: 35.452
  timestamp: 1602508451
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |      2 |          53.5306 | 323584 |  211.109 |              255.283 |              137.404 |            899.415 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3528.3379310344826
    time_step_min: 3225
  date: 2020-10-12_13-14-37
  done: false
  episode_len_mean: 898.6350210970464
  episode_reward_max: 256.19191919191843
  episode_reward_mean: 209.84490474363878
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1322798530260723
        entropy_coeff: 0.0005000000000000001
        kl: 0.010767004685476422
        model: {}
        policy_loss: -0.012665366327079633
        total_loss: 43.89692052205404
        vf_explained_var: 0.9133307933807373
        vf_loss: 43.90800031026205
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.316129032258072
    gpu_util_percent0: 0.36870967741935484
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15830101423335372
    mean_env_wait_ms: 1.1585371208474247
    mean_inference_ms: 5.0716236319304695
    mean_raw_obs_processing_ms: 0.4188533356669978
  time_since_restore: 79.10382580757141
  time_this_iter_s: 25.573188304901123
  time_total_s: 79.10382580757141
  timers:
    learn_throughput: 8633.054
    learn_time_ms: 18740.993
    sample_throughput: 21438.51
    sample_time_ms: 7546.793
    update_time_ms: 34.338
  timestamp: 1602508477
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |      3 |          79.1038 | 485376 |  209.845 |              256.192 |              121.495 |            898.635 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3529.460370994941
    time_step_min: 3225
  date: 2020-10-12_13-15-02
  done: false
  episode_len_mean: 893.7879746835443
  episode_reward_max: 256.19191919191843
  episode_reward_mean: 210.4055747346885
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.11337806781133
        entropy_coeff: 0.0005000000000000001
        kl: 0.010417933110147715
        model: {}
        policy_loss: -0.012520392735799154
        total_loss: 33.9288527170817
        vf_explained_var: 0.930683434009552
        vf_loss: 33.93984572092692
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.4741935483871
    gpu_util_percent0: 0.3241935483870968
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15652433078240555
    mean_env_wait_ms: 1.1595657664548331
    mean_inference_ms: 4.96086188000214
    mean_raw_obs_processing_ms: 0.41336019341070473
  time_since_restore: 104.4432921409607
  time_this_iter_s: 25.339466333389282
  time_total_s: 104.4432921409607
  timers:
    learn_throughput: 8676.602
    learn_time_ms: 18646.931
    sample_throughput: 21904.008
    sample_time_ms: 7386.411
    update_time_ms: 30.843
  timestamp: 1602508502
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |      4 |          104.443 | 647168 |  210.406 |              256.192 |              121.495 |            893.788 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3521.659121171771
    time_step_min: 3225
  date: 2020-10-12_13-15-28
  done: false
  episode_len_mean: 888.5582278481013
  episode_reward_max: 256.19191919191843
  episode_reward_mean: 211.43242552103297
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.078717718521754
        entropy_coeff: 0.0005000000000000001
        kl: 0.012644899543374777
        model: {}
        policy_loss: -0.015359613966817657
        total_loss: 25.78201134999593
        vf_explained_var: 0.947361171245575
        vf_loss: 25.795381546020508
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.406451612903222
    gpu_util_percent0: 0.395483870967742
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15521464676357713
    mean_env_wait_ms: 1.1612388286862831
    mean_inference_ms: 4.8790944869985555
    mean_raw_obs_processing_ms: 0.4091257298725149
  time_since_restore: 130.00773286819458
  time_this_iter_s: 25.564440727233887
  time_total_s: 130.00773286819458
  timers:
    learn_throughput: 8688.409
    learn_time_ms: 18621.591
    sample_throughput: 22194.842
    sample_time_ms: 7289.622
    update_time_ms: 42.972
  timestamp: 1602508528
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |      5 |          130.008 | 808960 |  211.432 |              256.192 |              121.495 |            888.558 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3508.678137651822
    time_step_min: 3165
  date: 2020-10-12_13-15-54
  done: false
  episode_len_mean: 879.7702044790652
  episode_reward_max: 265.2828282828283
  episode_reward_mean: 212.92468010189515
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 237
  episodes_total: 1027
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.030537764231364
        entropy_coeff: 0.0005000000000000001
        kl: 0.011042173486202955
        model: {}
        policy_loss: -0.014260276167381866
        total_loss: 25.060717741648357
        vf_explained_var: 0.965539276599884
        vf_loss: 25.073285420735676
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.0741935483871
    gpu_util_percent0: 0.34096774193548385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7612903225806447
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15386036664928418
    mean_env_wait_ms: 1.1650331493394692
    mean_inference_ms: 4.791230070858989
    mean_raw_obs_processing_ms: 0.40464393777041424
  time_since_restore: 155.7492527961731
  time_this_iter_s: 25.741519927978516
  time_total_s: 155.7492527961731
  timers:
    learn_throughput: 8688.071
    learn_time_ms: 18622.316
    sample_throughput: 22322.562
    sample_time_ms: 7247.914
    update_time_ms: 39.768
  timestamp: 1602508554
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |      6 |          155.749 | 970752 |  212.925 |              265.283 |              121.495 |             879.77 |
+-------------------------+----------+----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3497.530612244898
    time_step_min: 3165
  date: 2020-10-12_13-16-19
  done: false
  episode_len_mean: 870.7357594936709
  episode_reward_max: 274.2222222222218
  episode_reward_mean: 215.23967523334608
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 237
  episodes_total: 1264
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0390752255916595
        entropy_coeff: 0.0005000000000000001
        kl: 0.008950663963332772
        model: {}
        policy_loss: -0.012979783758055419
        total_loss: 17.63845729827881
        vf_explained_var: 0.9667128920555115
        vf_loss: 17.650166829427082
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.819999999999997
    gpu_util_percent0: 0.3156666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.763333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15286554168158484
    mean_env_wait_ms: 1.16817197428278
    mean_inference_ms: 4.729411884719929
    mean_raw_obs_processing_ms: 0.40151336002938526
  time_since_restore: 181.0323395729065
  time_this_iter_s: 25.2830867767334
  time_total_s: 181.0323395729065
  timers:
    learn_throughput: 8711.178
    learn_time_ms: 18572.919
    sample_throughput: 22468.001
    sample_time_ms: 7200.997
    update_time_ms: 39.415
  timestamp: 1602508579
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |      7 |          181.032 | 1132544 |   215.24 |              274.222 |              121.495 |            870.736 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3485.5090383224874
    time_step_min: 3165
  date: 2020-10-12_13-16-45
  done: false
  episode_len_mean: 864.0893108298171
  episode_reward_max: 274.2222222222218
  episode_reward_mean: 216.8130034522439
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0153801242510478
        entropy_coeff: 0.0005000000000000001
        kl: 0.009843991370871663
        model: {}
        policy_loss: -0.013797902094665915
        total_loss: 15.153997739156088
        vf_explained_var: 0.9670274257659912
        vf_loss: 15.16633423169454
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.970967741935485
    gpu_util_percent0: 0.4048387096774193
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15234609199987278
    mean_env_wait_ms: 1.170314328133891
    mean_inference_ms: 4.6963970107161925
    mean_raw_obs_processing_ms: 0.3998303844212603
  time_since_restore: 206.35286259651184
  time_this_iter_s: 25.320523023605347
  time_total_s: 206.35286259651184
  timers:
    learn_throughput: 8717.679
    learn_time_ms: 18559.069
    sample_throughput: 22636.593
    sample_time_ms: 7147.365
    update_time_ms: 39.013
  timestamp: 1602508605
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |      8 |          206.353 | 1294336 |  216.813 |              274.222 |              121.495 |            864.089 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3475.097988319273
    time_step_min: 3165
  date: 2020-10-12_13-17-10
  done: false
  episode_len_mean: 858.7050632911393
  episode_reward_max: 274.2222222222218
  episode_reward_mean: 218.34544815241014
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9808233429988226
        entropy_coeff: 0.0005000000000000001
        kl: 0.010888603903974095
        model: {}
        policy_loss: -0.01424153451807797
        total_loss: 12.326210180918375
        vf_explained_var: 0.9723730087280273
        vf_loss: 12.338764508565268
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.083333333333332
    gpu_util_percent0: 0.3953333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1518962557749775
    mean_env_wait_ms: 1.172473266274207
    mean_inference_ms: 4.6678085121318444
    mean_raw_obs_processing_ms: 0.3983376470146021
  time_since_restore: 231.73970580101013
  time_this_iter_s: 25.38684320449829
  time_total_s: 231.73970580101013
  timers:
    learn_throughput: 8728.149
    learn_time_ms: 18536.806
    sample_throughput: 22706.843
    sample_time_ms: 7125.253
    update_time_ms: 37.736
  timestamp: 1602508630
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |      9 |           231.74 | 1456128 |  218.345 |              274.222 |              121.495 |            858.705 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3456.0323110624317
    time_step_min: 3121
  date: 2020-10-12_13-17-36
  done: false
  episode_len_mean: 850.2605898123325
  episode_reward_max: 274.2222222222218
  episode_reward_mean: 221.2334335310206
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 285
  episodes_total: 1865
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9398987740278244
        entropy_coeff: 0.0005000000000000001
        kl: 0.009501839056611061
        model: {}
        policy_loss: -0.012655374244786799
        total_loss: 16.177312692006428
        vf_explained_var: 0.9759433269500732
        vf_loss: 16.188537041346233
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.212903225806457
    gpu_util_percent0: 0.3254838709677419
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15123061180979347
    mean_env_wait_ms: 1.1763477610027673
    mean_inference_ms: 4.625377076801003
    mean_raw_obs_processing_ms: 0.3961567031694136
  time_since_restore: 257.18270111083984
  time_this_iter_s: 25.442995309829712
  time_total_s: 257.18270111083984
  timers:
    learn_throughput: 8730.917
    learn_time_ms: 18530.929
    sample_throughput: 22784.538
    sample_time_ms: 7100.956
    update_time_ms: 36.627
  timestamp: 1602508656
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |     10 |          257.183 | 1617920 |  221.233 |              274.222 |              121.495 |            850.261 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3444.1017369727047
    time_step_min: 3121
  date: 2020-10-12_13-18-01
  done: false
  episode_len_mean: 846.269717624148
  episode_reward_max: 274.2222222222218
  episode_reward_mean: 223.0387959438592
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 189
  episodes_total: 2054
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9336913575728735
        entropy_coeff: 0.0005000000000000001
        kl: 0.010904871858656406
        model: {}
        policy_loss: -0.01296268259951224
        total_loss: 11.209124247233072
        vf_explained_var: 0.977226197719574
        vf_loss: 11.220372756322226
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.135483870967743
    gpu_util_percent0: 0.355483870967742
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15087142776167956
    mean_env_wait_ms: 1.1784343725257342
    mean_inference_ms: 4.602809263805374
    mean_raw_obs_processing_ms: 0.39501344957202694
  time_since_restore: 282.89694237709045
  time_this_iter_s: 25.71424126625061
  time_total_s: 282.89694237709045
  timers:
    learn_throughput: 8738.416
    learn_time_ms: 18515.025
    sample_throughput: 23406.768
    sample_time_ms: 6912.189
    update_time_ms: 36.209
  timestamp: 1602508681
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |     11 |          282.897 | 1779712 |  223.039 |              274.222 |              121.495 |             846.27 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3433.8877128393924
    time_step_min: 3121
  date: 2020-10-12_13-18-27
  done: false
  episode_len_mean: 843.0773056057866
  episode_reward_max: 274.52525252525254
  episode_reward_mean: 224.5506648766142
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.92471211651961
        entropy_coeff: 0.0005000000000000001
        kl: 0.010187809355556965
        model: {}
        policy_loss: -0.014768260831867034
        total_loss: 10.398540019989014
        vf_explained_var: 0.9753820896148682
        vf_loss: 10.411733071009317
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.496774193548386
    gpu_util_percent0: 0.3770967741935483
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.150602034837233
    mean_env_wait_ms: 1.180044631522846
    mean_inference_ms: 4.585915076883349
    mean_raw_obs_processing_ms: 0.3941238410275384
  time_since_restore: 308.49336338043213
  time_this_iter_s: 25.596421003341675
  time_total_s: 308.49336338043213
  timers:
    learn_throughput: 8736.301
    learn_time_ms: 18519.508
    sample_throughput: 23488.68
    sample_time_ms: 6888.084
    update_time_ms: 35.915
  timestamp: 1602508707
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |     12 |          308.493 | 1941504 |  224.551 |              274.525 |              121.495 |            843.077 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3424.4236853356133
    time_step_min: 3100
  date: 2020-10-12_13-18-53
  done: false
  episode_len_mean: 840.2094196804037
  episode_reward_max: 282.25252525252546
  episode_reward_mean: 225.92227574313358
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 166
  episodes_total: 2378
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8893729994694392
        entropy_coeff: 0.0005000000000000001
        kl: 0.00908448228922983
        model: {}
        policy_loss: -0.012357292202068493
        total_loss: 12.14861257870992
        vf_explained_var: 0.9755513668060303
        vf_loss: 12.159597158432007
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.367741935483878
    gpu_util_percent0: 0.36741935483870963
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15034536979125834
    mean_env_wait_ms: 1.18166412373556
    mean_inference_ms: 4.569764712127753
    mean_raw_obs_processing_ms: 0.3932526145950369
  time_since_restore: 333.9657666683197
  time_this_iter_s: 25.472403287887573
  time_total_s: 333.9657666683197
  timers:
    learn_throughput: 8742.469
    learn_time_ms: 18506.443
    sample_throughput: 23478.653
    sample_time_ms: 6891.026
    update_time_ms: 34.866
  timestamp: 1602508733
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |     13 |          333.966 | 2103296 |  225.922 |              282.253 |              121.495 |            840.209 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3407.4765506807867
    time_step_min: 3057
  date: 2020-10-12_13-19-18
  done: false
  episode_len_mean: 835.5564666418188
  episode_reward_max: 282.25252525252546
  episode_reward_mean: 228.2698735397207
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 305
  episodes_total: 2683
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8532486607631048
        entropy_coeff: 0.0005000000000000001
        kl: 0.009016360621899366
        model: {}
        policy_loss: -0.01283824277925305
        total_loss: 15.463050127029419
        vf_explained_var: 0.9766743183135986
        vf_loss: 15.474511941274008
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.190322580645162
    gpu_util_percent0: 0.3832258064516129
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14993902337535023
    mean_env_wait_ms: 1.1843446349152766
    mean_inference_ms: 4.5444064244555005
    mean_raw_obs_processing_ms: 0.3919347843467722
  time_since_restore: 359.37025690078735
  time_this_iter_s: 25.40449023246765
  time_total_s: 359.37025690078735
  timers:
    learn_throughput: 8742.481
    learn_time_ms: 18506.418
    sample_throughput: 23480.326
    sample_time_ms: 6890.535
    update_time_ms: 39.617
  timestamp: 1602508758
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |     14 |           359.37 | 2265088 |   228.27 |              282.253 |              121.495 |            835.556 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3400.564705882353
    time_step_min: 3057
  date: 2020-10-12_13-19-44
  done: false
  episode_len_mean: 833.6536568213784
  episode_reward_max: 283.01010101010144
  episode_reward_mean: 229.32861313557518
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 161
  episodes_total: 2844
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8508899509906769
        entropy_coeff: 0.0005000000000000001
        kl: 0.009069444534058372
        model: {}
        policy_loss: -0.011304805482116839
        total_loss: 10.248993555704752
        vf_explained_var: 0.9778319001197815
        vf_loss: 10.258909940719604
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.189999999999994
    gpu_util_percent0: 0.3463333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1497545059604681
    mean_env_wait_ms: 1.1855623393926709
    mean_inference_ms: 4.532787028107307
    mean_raw_obs_processing_ms: 0.3913296495413931
  time_since_restore: 384.69905614852905
  time_this_iter_s: 25.3287992477417
  time_total_s: 384.69905614852905
  timers:
    learn_throughput: 8752.002
    learn_time_ms: 18486.285
    sample_throughput: 23473.818
    sample_time_ms: 6892.445
    update_time_ms: 33.023
  timestamp: 1602508784
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |     15 |          384.699 | 2426880 |  229.329 |               283.01 |              121.495 |            833.654 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3394.0401619979752
    time_step_min: 3049
  date: 2020-10-12_13-20-09
  done: false
  episode_len_mean: 831.7961359093937
  episode_reward_max: 283.01010101010144
  episode_reward_mean: 230.36272451362396
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8350291202465693
        entropy_coeff: 0.0005000000000000001
        kl: 0.008423286063286165
        model: {}
        policy_loss: -0.013151350537858283
        total_loss: 10.261669158935547
        vf_explained_var: 0.9754757881164551
        vf_loss: 10.273553053538004
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.225806451612904
    gpu_util_percent0: 0.3048387096774194
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419353
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14958384533019653
    mean_env_wait_ms: 1.1866691008426602
    mean_inference_ms: 4.522259491242597
    mean_raw_obs_processing_ms: 0.390770014070992
  time_since_restore: 409.8559265136719
  time_this_iter_s: 25.156870365142822
  time_total_s: 409.8559265136719
  timers:
    learn_throughput: 8772.911
    learn_time_ms: 18442.225
    sample_throughput: 23529.06
    sample_time_ms: 6876.263
    update_time_ms: 33.307
  timestamp: 1602508809
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |     16 |          409.856 | 2588672 |  230.363 |               283.01 |              121.495 |            831.796 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3384.0923845193506
    time_step_min: 3049
  date: 2020-10-12_13-20-34
  done: false
  episode_len_mean: 829.4196731421523
  episode_reward_max: 283.01010101010144
  episode_reward_mean: 231.755277100328
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 241
  episodes_total: 3243
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7941412776708603
        entropy_coeff: 0.0005000000000000001
        kl: 0.007831045077182353
        model: {}
        policy_loss: -0.011214571937064951
        total_loss: 12.558861096700033
        vf_explained_var: 0.9791995882987976
        vf_loss: 12.56890638669332
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.813333333333333
    gpu_util_percent0: 0.3296666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1493511129281221
    mean_env_wait_ms: 1.18836039587014
    mean_inference_ms: 4.507843205404144
    mean_raw_obs_processing_ms: 0.3900279143537348
  time_since_restore: 435.0468645095825
  time_this_iter_s: 25.190937995910645
  time_total_s: 435.0468645095825
  timers:
    learn_throughput: 8776.225
    learn_time_ms: 18435.261
    sample_throughput: 23538.727
    sample_time_ms: 6873.439
    update_time_ms: 31.914
  timestamp: 1602508834
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |     17 |          435.047 | 2750464 |  231.755 |               283.01 |              121.495 |             829.42 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3375.5573341094296
    time_step_min: 3043
  date: 2020-10-12_13-21-00
  done: false
  episode_len_mean: 827.7430215827338
  episode_reward_max: 283.76767676767685
  episode_reward_mean: 233.1279558171645
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 232
  episodes_total: 3475
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7775030036767324
        entropy_coeff: 0.0005000000000000001
        kl: 0.009208389169846972
        model: {}
        policy_loss: -0.013305067919039478
        total_loss: 9.972206036249796
        vf_explained_var: 0.9811418056488037
        vf_loss: 9.984058380126953
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.119354838709683
    gpu_util_percent0: 0.3838709677419355
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14914887227837353
    mean_env_wait_ms: 1.1895773988084628
    mean_inference_ms: 4.49537274982109
    mean_raw_obs_processing_ms: 0.3893721395148053
  time_since_restore: 460.54497480392456
  time_this_iter_s: 25.49811029434204
  time_total_s: 460.54497480392456
  timers:
    learn_throughput: 8779.349
    learn_time_ms: 18428.701
    sample_throughput: 23458.108
    sample_time_ms: 6897.061
    update_time_ms: 31.78
  timestamp: 1602508860
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |     18 |          460.545 | 2912256 |  233.128 |              283.768 |              121.495 |            827.743 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3369.139360222531
    time_step_min: 3043
  date: 2020-10-12_13-21-25
  done: false
  episode_len_mean: 826.7760044028619
  episode_reward_max: 285.58585858585906
  episode_reward_mean: 234.05803216535196
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 159
  episodes_total: 3634
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7807081788778305
        entropy_coeff: 0.0005000000000000001
        kl: 0.009336601942777634
        model: {}
        policy_loss: -0.01237989262881456
        total_loss: 9.13566509882609
        vf_explained_var: 0.9783623218536377
        vf_loss: 9.146568139394125
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.653333333333332
    gpu_util_percent0: 0.39566666666666683
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14902705507754505
    mean_env_wait_ms: 1.190391644876372
    mean_inference_ms: 4.487675474338713
    mean_raw_obs_processing_ms: 0.3889768629839905
  time_since_restore: 485.60069012641907
  time_this_iter_s: 25.055715322494507
  time_total_s: 485.60069012641907
  timers:
    learn_throughput: 8790.637
    learn_time_ms: 18405.038
    sample_throughput: 23491.611
    sample_time_ms: 6887.224
    update_time_ms: 31.115
  timestamp: 1602508885
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |     19 |          485.601 | 3074048 |  234.058 |              285.586 |              121.495 |            826.776 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3363.7053500133084
    time_step_min: 3032
  date: 2020-10-12_13-21-50
  done: false
  episode_len_mean: 826.1087987355111
  episode_reward_max: 286.1919191919197
  episode_reward_mean: 234.93980372747498
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 162
  episodes_total: 3796
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7429781158765157
        entropy_coeff: 0.0005000000000000001
        kl: 0.009349981866156062
        model: {}
        policy_loss: -0.013361311527357126
        total_loss: 9.10965379079183
        vf_explained_var: 0.9795462489128113
        vf_loss: 9.121516386667887
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.78333333333334
    gpu_util_percent0: 0.364
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666657
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1489115552856999
    mean_env_wait_ms: 1.191176957921576
    mean_inference_ms: 4.4803595481529594
    mean_raw_obs_processing_ms: 0.38859953564998534
  time_since_restore: 510.6083676815033
  time_this_iter_s: 25.00767755508423
  time_total_s: 510.6083676815033
  timers:
    learn_throughput: 8814.504
    learn_time_ms: 18355.203
    sample_throughput: 23468.996
    sample_time_ms: 6893.861
    update_time_ms: 30.448
  timestamp: 1602508910
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |     20 |          510.608 | 3235840 |   234.94 |              286.192 |              121.495 |            826.109 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3354.6508172362555
    time_step_min: 3032
  date: 2020-10-12_13-22-16
  done: false
  episode_len_mean: 824.5339710571499
  episode_reward_max: 286.1919191919197
  episode_reward_mean: 236.27929032785548
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 281
  episodes_total: 4077
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7142210404078165
        entropy_coeff: 0.0005000000000000001
        kl: 0.008245780870007971
        model: {}
        policy_loss: -0.009262117419135999
        total_loss: 13.05993421872457
        vf_explained_var: 0.9789599776268005
        vf_loss: 13.067903518676758
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.345161290322586
    gpu_util_percent0: 0.3483870967741936
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14871882929718494
    mean_env_wait_ms: 1.1923795168400448
    mean_inference_ms: 4.4685243476726955
    mean_raw_obs_processing_ms: 0.387991984450712
  time_since_restore: 535.9011969566345
  time_this_iter_s: 25.292829275131226
  time_total_s: 535.9011969566345
  timers:
    learn_throughput: 8841.868
    learn_time_ms: 18298.395
    sample_throughput: 23417.774
    sample_time_ms: 6908.94
    update_time_ms: 30.281
  timestamp: 1602508936
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |     21 |          535.901 | 3397632 |  236.279 |              286.192 |              121.495 |            824.534 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3349.3562810503904
    time_step_min: 3032
  date: 2020-10-12_13-22-41
  done: false
  episode_len_mean: 823.4624941397093
  episode_reward_max: 286.1919191919197
  episode_reward_mean: 237.10186250692584
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 189
  episodes_total: 4266
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7203580538431803
        entropy_coeff: 0.0005000000000000001
        kl: 0.007941971455390254
        model: {}
        policy_loss: -0.013164400860356787
        total_loss: 8.039840499560038
        vf_explained_var: 0.9827823638916016
        vf_loss: 8.05177652835846
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.290000000000003
    gpu_util_percent0: 0.3319999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14861110832074215
    mean_env_wait_ms: 1.1930919795055774
    mean_inference_ms: 4.4615342156341375
    mean_raw_obs_processing_ms: 0.3876486290475501
  time_since_restore: 561.1088273525238
  time_this_iter_s: 25.207630395889282
  time_total_s: 561.1088273525238
  timers:
    learn_throughput: 8859.164
    learn_time_ms: 18262.671
    sample_throughput: 23429.842
    sample_time_ms: 6905.382
    update_time_ms: 29.619
  timestamp: 1602508961
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |     22 |          561.109 | 3559424 |  237.102 |              286.192 |              121.495 |            823.462 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3345.0405929304447
    time_step_min: 3032
  date: 2020-10-12_13-23-06
  done: false
  episode_len_mean: 822.6620705244123
  episode_reward_max: 286.1919191919197
  episode_reward_mean: 237.75289513580657
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7312988787889481
        entropy_coeff: 0.0005000000000000001
        kl: 0.008627945246795813
        model: {}
        policy_loss: -0.010504904401993068
        total_loss: 7.065648317337036
        vf_explained_var: 0.9828181266784668
        vf_loss: 7.0747930606206255
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.006451612903223
    gpu_util_percent0: 0.3783870967741936
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1485229974162005
    mean_env_wait_ms: 1.1936602824184575
    mean_inference_ms: 4.455903565988392
    mean_raw_obs_processing_ms: 0.38736226096607634
  time_since_restore: 586.1680197715759
  time_this_iter_s: 25.059192419052124
  time_total_s: 586.1680197715759
  timers:
    learn_throughput: 8879.096
    learn_time_ms: 18221.674
    sample_throughput: 23456.511
    sample_time_ms: 6897.53
    update_time_ms: 29.867
  timestamp: 1602508986
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc            |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | RUNNING  | 172.17.0.4:984 |     23 |          586.168 | 3721216 |  237.753 |              286.192 |              121.495 |            822.662 |
+-------------------------+----------+----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ada08_00000:
  custom_metrics:
    time_step_max: 4009
    time_step_mean: 3340.55448787945
    time_step_min: 3032
  date: 2020-10-12_13-23-31
  done: true
  episode_len_mean: 821.8300129926375
  episode_reward_max: 286.1919191919197
  episode_reward_mean: 238.4608077308381
  episode_reward_min: 121.49494949494925
  episodes_this_iter: 194
  episodes_total: 4618
  experiment_id: b21da84cff414e2e81a0baeadd18988c
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.6872272938489914
        entropy_coeff: 0.0005000000000000001
        kl: 0.009218541672453284
        model: {}
        policy_loss: -0.014350513558990011
        total_loss: 9.473631223042807
        vf_explained_var: 0.9823441505432129
        vf_loss: 9.486481666564941
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.833333333333332
    gpu_util_percent0: 0.3953333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1484230924951972
    mean_env_wait_ms: 1.1943576339703978
    mean_inference_ms: 4.449402962333426
    mean_raw_obs_processing_ms: 0.38703784241811273
  time_since_restore: 611.1163921356201
  time_this_iter_s: 24.94837236404419
  time_total_s: 611.1163921356201
  timers:
    learn_throughput: 8894.879
    learn_time_ms: 18189.342
    sample_throughput: 23485.45
    sample_time_ms: 6889.031
    update_time_ms: 25.398
  timestamp: 1602509011
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: ada08_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | TERMINATED |       |     24 |          611.116 | 3883008 |  238.461 |              286.192 |              121.495 |             821.83 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.62 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ada08_00000 | TERMINATED |       |     24 |          611.116 | 3883008 |  238.461 |              286.192 |              121.495 |             821.83 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


