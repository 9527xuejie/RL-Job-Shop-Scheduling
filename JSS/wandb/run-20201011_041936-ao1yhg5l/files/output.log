2020-10-11 04:19:38,081	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_faab2_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=65626)[0m 2020-10-11 04:19:40,989	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=65486)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65486)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65611)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65611)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65521)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65521)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65617)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65617)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65595)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65595)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65607)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65607)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65560)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65560)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65619)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65619)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65526)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65526)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65609)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65609)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65589)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65589)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65566)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65566)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65572)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65572)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65570)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65570)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65599)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65599)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65505)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65505)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65602)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65602)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65598)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65598)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65515)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65515)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65528)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65528)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65557)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65557)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65580)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65580)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65621)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65621)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65613)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65613)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65606)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65606)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65490)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65490)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65574)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65574)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65571)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65571)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65592)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65592)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65578)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65578)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65605)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65605)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65559)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65559)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65610)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65610)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65556)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65556)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65517)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65517)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65489)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65489)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65552)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65552)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65596)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65596)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65549)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65549)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65495)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65495)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65554)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65554)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65519)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65519)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65564)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65564)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65568)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65568)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65569)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65569)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65548)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65548)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65503)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65503)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65620)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65620)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65582)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65582)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65558)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65558)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65507)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65507)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65550)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65550)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65547)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65547)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65492)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65492)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65588)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65588)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65581)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65581)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65493)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65493)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65488)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65488)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65523)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65523)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65499)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65499)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65487)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65487)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65527)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65527)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65514)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65514)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65561)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65561)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=65512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=65512)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_04-20-22
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1804919583456857
        entropy_coeff: 0.00010000000000000002
        kl: 0.0085143099672028
        model: {}
        policy_loss: -0.0053389975468495065
        total_loss: 16.359797886439733
        vf_explained_var: 0.5462602972984314
        vf_loss: 16.36355229786464
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.54186046511628
    gpu_util_percent0: 0.37139534883720926
    gpu_util_percent1: 0.00023255813953488373
    gpu_util_percent2: 0.0
    ram_util_percent: 6.288372093023254
    vram_util_percent0: 0.19188144035024826
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17217563677437697
    mean_env_wait_ms: 1.189628228908632
    mean_inference_ms: 6.076312696687156
    mean_raw_obs_processing_ms: 0.4666870160763851
  time_since_restore: 36.140496492385864
  time_this_iter_s: 36.140496492385864
  time_total_s: 36.140496492385864
  timers:
    learn_throughput: 6115.228
    learn_time_ms: 26457.232
    sample_throughput: 16837.572
    sample_time_ms: 9608.987
    update_time_ms: 43.339
  timestamp: 1602390022
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |      1 |          36.1405 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3598.7604166666665
    time_step_min: 3288
  date: 2020-10-11_04-20-57
  done: false
  episode_len_mean: 880.1803797468355
  episode_reward_max: 267.8383838383835
  episode_reward_mean: 219.13105740953822
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1463408470153809
        entropy_coeff: 0.00010000000000000002
        kl: 0.011348377181483167
        model: {}
        policy_loss: -0.008286168358089136
        total_loss: 10.8593350819179
        vf_explained_var: 0.8144732713699341
        vf_loss: 10.865465913500104
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.419512195121953
    gpu_util_percent0: 0.37365853658536585
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.468292682926828
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16722760206185855
    mean_env_wait_ms: 1.1913006499625305
    mean_inference_ms: 5.745654269521274
    mean_raw_obs_processing_ms: 0.45089832945649927
  time_since_restore: 70.47019743919373
  time_this_iter_s: 34.32970094680786
  time_total_s: 70.47019743919373
  timers:
    learn_throughput: 6133.622
    learn_time_ms: 26377.888
    sample_throughput: 18430.599
    sample_time_ms: 8778.445
    update_time_ms: 39.368
  timestamp: 1602390057
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |      2 |          70.4702 | 323584 |  219.131 |              267.838 |              145.717 |             880.18 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3592.4663677130043
    time_step_min: 3270
  date: 2020-10-11_04-21-31
  done: false
  episode_len_mean: 869.0949367088608
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 220.44706559263503
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1223562785557337
        entropy_coeff: 0.00010000000000000002
        kl: 0.010300276601420981
        model: {}
        policy_loss: -0.008124663793881024
        total_loss: 13.333167212350029
        vf_explained_var: 0.8752042055130005
        vf_loss: 13.339344092777797
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.712195121951222
    gpu_util_percent0: 0.3836585365853658
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.487804878048781
    vram_util_percent0: 0.20465726467694323
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1642445293736771
    mean_env_wait_ms: 1.1946959923386362
    mean_inference_ms: 5.5202637764798075
    mean_raw_obs_processing_ms: 0.4405263379347787
  time_since_restore: 104.26282691955566
  time_this_iter_s: 33.79262948036194
  time_total_s: 104.26282691955566
  timers:
    learn_throughput: 6144.596
    learn_time_ms: 26330.778
    sample_throughput: 19395.245
    sample_time_ms: 8341.839
    update_time_ms: 38.504
  timestamp: 1602390091
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |      3 |          104.263 | 485376 |  220.447 |              275.717 |              115.414 |            869.095 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3577.706953642384
    time_step_min: 3270
  date: 2020-10-11_04-22-04
  done: false
  episode_len_mean: 859.0158227848101
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 222.9366768955375
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0862220525741577
        entropy_coeff: 0.00010000000000000002
        kl: 0.008876325429550238
        model: {}
        policy_loss: -0.00693573263041409
        total_loss: 14.144111497061592
        vf_explained_var: 0.9058113694190979
        vf_loss: 14.149380343300956
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.965
    gpu_util_percent0: 0.3825
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4925
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16215581877950952
    mean_env_wait_ms: 1.1985741081825505
    mean_inference_ms: 5.361794516365517
    mean_raw_obs_processing_ms: 0.4329761645500151
  time_since_restore: 137.5379421710968
  time_this_iter_s: 33.27511525154114
  time_total_s: 137.5379421710968
  timers:
    learn_throughput: 6157.037
    learn_time_ms: 26277.576
    sample_throughput: 20153.999
    sample_time_ms: 8027.787
    update_time_ms: 34.314
  timestamp: 1602390124
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |      4 |          137.538 | 647168 |  222.937 |              275.717 |              115.414 |            859.016 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3572.86289445049
    time_step_min: 3270
  date: 2020-10-11_04-22-37
  done: false
  episode_len_mean: 841.8225976768744
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 223.61211907885604
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 315
  episodes_total: 947
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0585944397108895
        entropy_coeff: 0.00010000000000000002
        kl: 0.0077687113745404145
        model: {}
        policy_loss: -0.006936300684174057
        total_loss: 20.514549936567033
        vf_explained_var: 0.9429968595504761
        vf_loss: 20.520038196018763
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.83846153846154
    gpu_util_percent0: 0.3441025641025641
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.48974358974359
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15954112564627973
    mean_env_wait_ms: 1.2081349284888414
    mean_inference_ms: 5.163281733130662
    mean_raw_obs_processing_ms: 0.42408896426969983
  time_since_restore: 170.73357129096985
  time_this_iter_s: 33.19562911987305
  time_total_s: 170.73357129096985
  timers:
    learn_throughput: 6164.131
    learn_time_ms: 26247.331
    sample_throughput: 20683.977
    sample_time_ms: 7822.093
    update_time_ms: 31.739
  timestamp: 1602390157
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |      5 |          170.734 | 808960 |  223.612 |              275.717 |              115.414 |            841.823 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3573.1892393320963
    time_step_min: 3270
  date: 2020-10-11_04-23-10
  done: false
  episode_len_mean: 835.4168173598554
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 223.64431841014104
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 159
  episodes_total: 1106
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0412485003471375
        entropy_coeff: 0.00010000000000000002
        kl: 0.010357945425701993
        model: {}
        policy_loss: -0.008060624806343444
        total_loss: 13.442375319344658
        vf_explained_var: 0.9524129629135132
        vf_loss: 13.448468685150146
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.307499999999997
    gpu_util_percent0: 0.32799999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15863322219127968
    mean_env_wait_ms: 1.2119279168116464
    mean_inference_ms: 5.094774579728615
    mean_raw_obs_processing_ms: 0.4209930507308999
  time_since_restore: 203.91927289962769
  time_this_iter_s: 33.18570160865784
  time_total_s: 203.91927289962769
  timers:
    learn_throughput: 6167.156
    learn_time_ms: 26234.46
    sample_throughput: 21080.293
    sample_time_ms: 7675.036
    update_time_ms: 30.97
  timestamp: 1602390190
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |      6 |          203.919 | 970752 |  223.644 |              275.717 |              115.414 |            835.417 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3570.690129449838
    time_step_min: 3270
  date: 2020-10-11_04-23-44
  done: false
  episode_len_mean: 830.5245253164557
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 223.776722925457
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.0034892814499992
        entropy_coeff: 0.00010000000000000002
        kl: 0.00814351046990071
        model: {}
        policy_loss: -0.005383553804546993
        total_loss: 11.712424142020089
        vf_explained_var: 0.9670271277427673
        vf_loss: 11.716279097965785
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.6625
    gpu_util_percent0: 0.3785
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.49
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15784873160690271
    mean_env_wait_ms: 1.2152125125020106
    mean_inference_ms: 5.036655377719177
    mean_raw_obs_processing_ms: 0.4182388133734258
  time_since_restore: 237.4191529750824
  time_this_iter_s: 33.49988007545471
  time_total_s: 237.4191529750824
  timers:
    learn_throughput: 6167.531
    learn_time_ms: 26232.863
    sample_throughput: 21269.264
    sample_time_ms: 7606.845
    update_time_ms: 30.674
  timestamp: 1602390224
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |      7 |          237.419 | 1132544 |  223.777 |              275.717 |              115.414 |            830.525 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3573.271499644634
    time_step_min: 3270
  date: 2020-10-11_04-24-18
  done: false
  episode_len_mean: 826.6383275261325
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 223.59110266427334
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 171
  episodes_total: 1435
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.9433567481381553
        entropy_coeff: 0.00010000000000000002
        kl: 0.008974639432770866
        model: {}
        policy_loss: -0.007207899899055649
        total_loss: 11.240974698747907
        vf_explained_var: 0.9797438979148865
        vf_loss: 11.24648196356637
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.96
    gpu_util_percent0: 0.36575
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4875
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15713713535254342
    mean_env_wait_ms: 1.2187106416215747
    mean_inference_ms: 4.98330714386515
    mean_raw_obs_processing_ms: 0.41564906556095743
  time_since_restore: 270.7856402397156
  time_this_iter_s: 33.36648726463318
  time_total_s: 270.7856402397156
  timers:
    learn_throughput: 6168.147
    learn_time_ms: 26230.243
    sample_throughput: 21454.125
    sample_time_ms: 7541.3
    update_time_ms: 29.85
  timestamp: 1602390258
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |      8 |          270.786 | 1294336 |  223.591 |              275.717 |              115.414 |            826.638 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3578.920467836257
    time_step_min: 3270
  date: 2020-10-11_04-24-51
  done: false
  episode_len_mean: 820.9309551208286
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 223.44662389138793
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 303
  episodes_total: 1738
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.9047172495297023
        entropy_coeff: 0.00010000000000000002
        kl: 0.007263596967927047
        model: {}
        policy_loss: -0.005842094683820116
        total_loss: 10.8244982446943
        vf_explained_var: 0.9832080602645874
        vf_loss: 10.828977857317243
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.08974358974359
    gpu_util_percent0: 0.3328205128205129
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.484615384615385
    vram_util_percent0: 0.2046572646769433
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15611722892508306
    mean_env_wait_ms: 1.2240034002484863
    mean_inference_ms: 4.9079395322492045
    mean_raw_obs_processing_ms: 0.4121040067707636
  time_since_restore: 303.9745440483093
  time_this_iter_s: 33.18890380859375
  time_total_s: 303.9745440483093
  timers:
    learn_throughput: 6170.017
    learn_time_ms: 26222.295
    sample_throughput: 21640.986
    sample_time_ms: 7476.184
    update_time_ms: 29.09
  timestamp: 1602390291
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |      9 |          303.975 | 1456128 |  223.447 |              275.717 |              115.414 |            820.931 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3578.2200214132763
    time_step_min: 3270
  date: 2020-10-11_04-25-24
  done: false
  episode_len_mean: 818.6086497890295
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 223.64047116736987
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.8495498257023948
        entropy_coeff: 0.00010000000000000002
        kl: 0.008640707337430545
        model: {}
        policy_loss: -0.0066340716439299285
        total_loss: 5.734183243342808
        vf_explained_var: 0.9895483255386353
        vf_loss: 5.739173991339547
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.55
    gpu_util_percent0: 0.37525
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15568617880598073
    mean_env_wait_ms: 1.2262958135251367
    mean_inference_ms: 4.875931412162082
    mean_raw_obs_processing_ms: 0.41059676763811376
  time_since_restore: 337.35760855674744
  time_this_iter_s: 33.38306450843811
  time_total_s: 337.35760855674744
  timers:
    learn_throughput: 6167.894
    learn_time_ms: 26231.322
    sample_throughput: 21781.705
    sample_time_ms: 7427.885
    update_time_ms: 28.727
  timestamp: 1602390324
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |     10 |          337.358 | 1617920 |   223.64 |              275.717 |              115.414 |            818.609 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3576.4881539980256
    time_step_min: 3270
  date: 2020-10-11_04-25-58
  done: false
  episode_len_mean: 816.5301850048686
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 223.95578963933391
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.8197436801024846
        entropy_coeff: 0.00010000000000000002
        kl: 0.005348405335098505
        model: {}
        policy_loss: -0.006687246737003859
        total_loss: 5.301506996154785
        vf_explained_var: 0.9907737970352173
        vf_loss: 5.30720659664699
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.18
    gpu_util_percent0: 0.36974999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15530244777164906
    mean_env_wait_ms: 1.2285329015744992
    mean_inference_ms: 4.847137832626545
    mean_raw_obs_processing_ms: 0.409202453676572
  time_since_restore: 370.739675283432
  time_this_iter_s: 33.38206672668457
  time_total_s: 370.739675283432
  timers:
    learn_throughput: 6175.539
    learn_time_ms: 26198.846
    sample_throughput: 22519.608
    sample_time_ms: 7184.495
    update_time_ms: 26.817
  timestamp: 1602390358
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |     11 |           370.74 | 1779712 |  223.956 |              275.717 |              115.414 |             816.53 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3575.3266438941077
    time_step_min: 3270
  date: 2020-10-11_04-26-31
  done: false
  episode_len_mean: 812.7160337552742
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 224.06616800920597
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 316
  episodes_total: 2370
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.7788919380732945
        entropy_coeff: 0.00010000000000000002
        kl: 0.0059645292016544515
        model: {}
        policy_loss: -0.006024691076683146
        total_loss: 7.5099272046770364
        vf_explained_var: 0.9912603497505188
        vf_loss: 7.514836822237287
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.78
    gpu_util_percent0: 0.3125
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4925
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1546492025412908
    mean_env_wait_ms: 1.2327314883435485
    mean_inference_ms: 4.79864388022991
    mean_raw_obs_processing_ms: 0.4069149160398113
  time_since_restore: 404.3427894115448
  time_this_iter_s: 33.60311412811279
  time_total_s: 404.3427894115448
  timers:
    learn_throughput: 6176.837
    learn_time_ms: 26193.343
    sample_throughput: 22730.58
    sample_time_ms: 7117.812
    update_time_ms: 25.676
  timestamp: 1602390391
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |     12 |          404.343 | 1941504 |  224.066 |              275.717 |              115.414 |            812.716 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3573.7932
    time_step_min: 3270
  date: 2020-10-11_04-27-05
  done: false
  episode_len_mean: 811.1799841772151
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 224.41442910113796
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.7316497223717826
        entropy_coeff: 0.00010000000000000002
        kl: 0.006847755185195378
        model: {}
        policy_loss: -0.004600141342962161
        total_loss: 4.0212849378585815
        vf_explained_var: 0.9932011961936951
        vf_loss: 4.024588584899902
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.78
    gpu_util_percent0: 0.41400000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.495
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15437192712506262
    mean_env_wait_ms: 1.2345577968832995
    mean_inference_ms: 4.777940518356862
    mean_raw_obs_processing_ms: 0.4059366516438152
  time_since_restore: 437.81683444976807
  time_this_iter_s: 33.47404503822327
  time_total_s: 437.81683444976807
  timers:
    learn_throughput: 6175.318
    learn_time_ms: 26199.782
    sample_throughput: 22852.704
    sample_time_ms: 7079.775
    update_time_ms: 24.386
  timestamp: 1602390425
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |     13 |          437.817 | 2103296 |  224.414 |              275.717 |              115.414 |             811.18 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3570.6012039127163
    time_step_min: 3270
  date: 2020-10-11_04-27-39
  done: false
  episode_len_mean: 809.6749813849591
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 224.81067563197124
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.711552062204906
        entropy_coeff: 0.00010000000000000002
        kl: 0.006347174323829157
        model: {}
        policy_loss: -0.0038324560903544936
        total_loss: 3.3239152942384993
        vf_explained_var: 0.9939002990722656
        vf_loss: 3.3265494448798045
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.402499999999996
    gpu_util_percent0: 0.34199999999999997
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5025
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15411553117198634
    mean_env_wait_ms: 1.2363069937230418
    mean_inference_ms: 4.758912933840017
    mean_raw_obs_processing_ms: 0.4050229040895587
  time_since_restore: 471.65987253189087
  time_this_iter_s: 33.8430380821228
  time_total_s: 471.65987253189087
  timers:
    learn_throughput: 6164.716
    learn_time_ms: 26244.843
    sample_throughput: 22822.807
    sample_time_ms: 7089.049
    update_time_ms: 26.266
  timestamp: 1602390459
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |     14 |           471.66 | 2265088 |  224.811 |              275.717 |              115.414 |            809.675 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3564.0
    time_step_min: 3270
  date: 2020-10-11_04-28-12
  done: false
  episode_len_mean: 807.2820945945946
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 225.7156360906361
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 274
  episodes_total: 2960
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 0.691635936498642
        entropy_coeff: 0.00010000000000000002
        kl: 0.004467136825301817
        model: {}
        policy_loss: -0.0033729740950678077
        total_loss: 4.242420843669346
        vf_explained_var: 0.9944854378700256
        vf_loss: 4.244969572339739
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.802500000000002
    gpu_util_percent0: 0.364
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.484999999999999
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1537300551960561
    mean_env_wait_ms: 1.2392623170137855
    mean_inference_ms: 4.729772054108741
    mean_raw_obs_processing_ms: 0.40362557226674267
  time_since_restore: 504.9590983390808
  time_this_iter_s: 33.29922580718994
  time_total_s: 504.9590983390808
  timers:
    learn_throughput: 6164.617
    learn_time_ms: 26245.266
    sample_throughput: 22795.579
    sample_time_ms: 7097.517
    update_time_ms: 26.403
  timestamp: 1602390492
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |     15 |          504.959 | 2426880 |  225.716 |              275.717 |              115.414 |            807.282 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3560.20466155811
    time_step_min: 3270
  date: 2020-10-11_04-28-46
  done: false
  episode_len_mean: 805.7759493670886
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 226.30477240762056
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 200
  episodes_total: 3160
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.6319396708692823
        entropy_coeff: 0.00010000000000000002
        kl: 0.007903699297457933
        model: {}
        policy_loss: -0.0049378665114220765
        total_loss: 3.4120043345860074
        vf_explained_var: 0.9940549731254578
        vf_loss: 3.4162150621414185
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.2875
    gpu_util_percent0: 0.36025
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4975
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15346496328825976
    mean_env_wait_ms: 1.2411142884097561
    mean_inference_ms: 4.710855236980388
    mean_raw_obs_processing_ms: 0.40273539663250524
  time_since_restore: 538.3377730846405
  time_this_iter_s: 33.37867474555969
  time_total_s: 538.3377730846405
  timers:
    learn_throughput: 6164.231
    learn_time_ms: 26246.908
    sample_throughput: 22748.006
    sample_time_ms: 7112.36
    update_time_ms: 27.697
  timestamp: 1602390526
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |     16 |          538.338 | 2588672 |  226.305 |              275.717 |              115.414 |            805.776 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3556.4589665653493
    time_step_min: 3246
  date: 2020-10-11_04-29-20
  done: false
  episode_len_mean: 804.6305003013864
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 226.86061336694254
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.6105902748448508
        entropy_coeff: 0.00010000000000000002
        kl: 0.008127264212816954
        model: {}
        policy_loss: -0.003576582430728844
        total_loss: 3.091127003942217
        vf_explained_var: 0.9937660098075867
        vf_loss: 3.0939518213272095
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.87
    gpu_util_percent0: 0.3405
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.5
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15328030531913422
    mean_env_wait_ms: 1.2425162425727068
    mean_inference_ms: 4.697157442229631
    mean_raw_obs_processing_ms: 0.40207933055660067
  time_since_restore: 572.0020213127136
  time_this_iter_s: 33.66424822807312
  time_total_s: 572.0020213127136
  timers:
    learn_throughput: 6161.929
    learn_time_ms: 26256.714
    sample_throughput: 22732.654
    sample_time_ms: 7117.163
    update_time_ms: 29.019
  timestamp: 1602390560
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | RUNNING  | 172.17.0.4:65626 |     17 |          572.002 | 2750464 |  226.861 |              275.717 |              115.414 |            804.631 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_faab2_00000:
  custom_metrics:
    time_step_max: 4294
    time_step_mean: 3551.308861485518
    time_step_min: 3246
  date: 2020-10-11_04-29-53
  done: true
  episode_len_mean: 803.2640113798009
  episode_reward_max: 275.7171717171716
  episode_reward_mean: 227.5864333232755
  episode_reward_min: 115.41414141414135
  episodes_this_iter: 197
  episodes_total: 3515
  experiment_id: d12177054fa84aa792e1f89dbc1e4fa2
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.5852166541985103
        entropy_coeff: 0.00010000000000000002
        kl: 0.007693530060350895
        model: {}
        policy_loss: -0.005799248199244695
        total_loss: 3.272842083658491
        vf_explained_var: 0.9947790503501892
        vf_loss: 3.2779303959437778
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.6875
    gpu_util_percent0: 0.4015000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489999999999999
    vram_util_percent0: 0.20465726467694326
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 65626
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15307102975189316
    mean_env_wait_ms: 1.2442943236548805
    mean_inference_ms: 4.6813028776587124
    mean_raw_obs_processing_ms: 0.40131786529116037
  time_since_restore: 605.4929049015045
  time_this_iter_s: 33.490883588790894
  time_total_s: 605.4929049015045
  timers:
    learn_throughput: 6160.787
    learn_time_ms: 26261.581
    sample_throughput: 22712.397
    sample_time_ms: 7123.511
    update_time_ms: 28.809
  timestamp: 1602390593
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: faab2_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | TERMINATED |       |     18 |          605.493 | 2912256 |  227.586 |              275.717 |              115.414 |            803.264 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.01 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_faab2_00000 | TERMINATED |       |     18 |          605.493 | 2912256 |  227.586 |              275.717 |              115.414 |            803.264 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


