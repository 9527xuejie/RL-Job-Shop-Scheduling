2020-10-08 13:13:57,407	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8269[39m[22m
== Status ==
Memory usage on this node: 37.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_20482_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=72926)[0m 2020-10-08 13:14:00,378	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=72917)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72917)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72923)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72923)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72877)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72877)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72902)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72902)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72910)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72910)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72884)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72884)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72897)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72897)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72932)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72932)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72889)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72889)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72894)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72894)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72924)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72924)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72921)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72921)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72882)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72882)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72803)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72803)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72891)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72891)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72835)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72835)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72868)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72868)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72795)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72795)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72912)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72912)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72893)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72893)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72827)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72827)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72896)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72896)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72796)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72796)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72801)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72801)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72866)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72866)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72832)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72832)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72887)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72887)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72864)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72864)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72874)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72874)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72834)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72834)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72802)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72802)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72807)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72807)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72870)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72870)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72799)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72799)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72863)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72863)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72901)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72901)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72939)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72939)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72905)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72905)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72821)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72821)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72812)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72812)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72797)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72811)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72811)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72873)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72873)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=72930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=72930)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-08_13-14-32
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1611746549606323
        entropy_coeff: 0.0
        kl: 0.005718740075826645
        model: {}
        policy_loss: -0.013096390827558934
        total_loss: 7.403090405464172
        vf_explained_var: 0.7892305254936218
        vf_loss: 7.415043115615845
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.854838709677416
    gpu_util_percent0: 0.40387096774193554
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0003225806451612903
    ram_util_percent: 6.858064516129033
    vram_util_percent0: 0.14882192998233162
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17311963301891525
    mean_env_wait_ms: 1.619766967905344
    mean_inference_ms: 5.664909503532803
    mean_raw_obs_processing_ms: 0.4645348331301843
  time_since_restore: 26.242305755615234
  time_this_iter_s: 26.242305755615234
  time_total_s: 26.242305755615234
  timers:
    learn_throughput: 9691.785
    learn_time_ms: 16693.726
    sample_throughput: 17069.205
    sample_time_ms: 9478.59
    update_time_ms: 32.62
  timestamp: 1602162872
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 52.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      1 |          26.2423 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3265.0
  date: 2020-10-08_13-14-57
  done: false
  episode_len_mean: 873.4715189873418
  episode_reward_max: 274.85858585858557
  episode_reward_mean: 227.3690384861269
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.132627922296524
        entropy_coeff: 0.0
        kl: 0.006706285546533764
        model: {}
        policy_loss: -0.016248987091239543
        total_loss: 5.631959009170532
        vf_explained_var: 0.9176143407821655
        vf_loss: 5.646866726875305
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.272413793103446
    gpu_util_percent0: 0.1520689655172414
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.065517241379309
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1687145306260058
    mean_env_wait_ms: 1.6153583995147767
    mean_inference_ms: 5.397734435135553
    mean_raw_obs_processing_ms: 0.4536503960134253
  time_since_restore: 51.10045146942139
  time_this_iter_s: 24.858145713806152
  time_total_s: 51.10045146942139
  timers:
    learn_throughput: 9795.667
    learn_time_ms: 16516.69
    sample_throughput: 18051.956
    sample_time_ms: 8962.574
    update_time_ms: 26.347
  timestamp: 1602162897
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      2 |          51.1005 | 323584 |  227.369 |              274.859 |              115.788 |            873.472 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3265.0
  date: 2020-10-08_13-15-22
  done: false
  episode_len_mean: 867.8713080168776
  episode_reward_max: 274.85858585858557
  episode_reward_mean: 228.246196138601
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.1271256804466248
        entropy_coeff: 0.0
        kl: 0.007389193354174495
        model: {}
        policy_loss: -0.018508310522884132
        total_loss: 6.457739639282226
        vf_explained_var: 0.9464155435562134
        vf_loss: 6.4747700691223145
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.04
    gpu_util_percent0: 0.4126666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.0699999999999985
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1657725376814399
    mean_env_wait_ms: 1.6143474174526447
    mean_inference_ms: 5.2544808037270725
    mean_raw_obs_processing_ms: 0.4459664380596616
  time_since_restore: 75.95954275131226
  time_this_iter_s: 24.85909128189087
  time_total_s: 75.95954275131226
  timers:
    learn_throughput: 9815.193
    learn_time_ms: 16483.832
    sample_throughput: 18464.91
    sample_time_ms: 8762.133
    update_time_ms: 25.762
  timestamp: 1602162922
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      3 |          75.9595 | 485376 |  228.246 |              274.859 |              115.788 |            867.871 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3230.0
  date: 2020-10-08_13-15-46
  done: false
  episode_len_mean: 862.3544303797469
  episode_reward_max: 278.70707070707056
  episode_reward_mean: 230.3964326812426
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0996861219406129
        entropy_coeff: 0.0
        kl: 0.008276985818520188
        model: {}
        policy_loss: -0.020328705292195083
        total_loss: 5.005046558380127
        vf_explained_var: 0.9697187542915344
        vf_loss: 5.023719763755798
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.686206896551724
    gpu_util_percent0: 0.37241379310344824
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.058620689655171
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16370989334392427
    mean_env_wait_ms: 1.6160268086005207
    mean_inference_ms: 5.150723377241317
    mean_raw_obs_processing_ms: 0.44028141144316024
  time_since_restore: 100.53206896781921
  time_this_iter_s: 24.572526216506958
  time_total_s: 100.53206896781921
  timers:
    learn_throughput: 9846.583
    learn_time_ms: 16431.283
    sample_throughput: 18801.772
    sample_time_ms: 8605.146
    update_time_ms: 29.099
  timestamp: 1602162946
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      4 |          100.532 | 647168 |  230.396 |              278.707 |              115.788 |            862.354 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3223.0
  date: 2020-10-08_13-16-11
  done: false
  episode_len_mean: 852.6247216035634
  episode_reward_max: 278.70707070707056
  episode_reward_mean: 231.18069334773102
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 266
  episodes_total: 898
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0624429881572723
        entropy_coeff: 0.0
        kl: 0.0077964670956134794
        model: {}
        policy_loss: -0.02084309732308611
        total_loss: 7.683893799781799
        vf_explained_var: 0.9791978597640991
        vf_loss: 7.703177666664123
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.542857142857144
    gpu_util_percent0: 0.03
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.121428571428571
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16154215177554349
    mean_env_wait_ms: 1.622384708687623
    mean_inference_ms: 5.032478173228996
    mean_raw_obs_processing_ms: 0.43396318661457844
  time_since_restore: 124.77606844902039
  time_this_iter_s: 24.243999481201172
  time_total_s: 124.77606844902039
  timers:
    learn_throughput: 9848.951
    learn_time_ms: 16427.333
    sample_throughput: 19182.267
    sample_time_ms: 8434.457
    update_time_ms: 30.214
  timestamp: 1602162971
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      5 |          124.776 | 808960 |  231.181 |              278.707 |              115.788 |            852.625 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3223.0
  date: 2020-10-08_13-16-35
  done: false
  episode_len_mean: 846.0479204339964
  episode_reward_max: 278.70707070707056
  episode_reward_mean: 231.96029919447625
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 208
  episodes_total: 1106
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0738083600997925
        entropy_coeff: 0.0
        kl: 0.007217544643208384
        model: {}
        policy_loss: -0.02225890466943383
        total_loss: 4.545075726509094
        vf_explained_var: 0.9842392206192017
        vf_loss: 4.565891194343567
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.48275862068966
    gpu_util_percent0: 0.3993103448275862
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.072413793103447
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1602743259590165
    mean_env_wait_ms: 1.6261454318768824
    mean_inference_ms: 4.968356024071804
    mean_raw_obs_processing_ms: 0.43045935101156774
  time_since_restore: 149.21555709838867
  time_this_iter_s: 24.439488649368286
  time_total_s: 149.21555709838867
  timers:
    learn_throughput: 9854.247
    learn_time_ms: 16418.504
    sample_throughput: 19357.003
    sample_time_ms: 8358.319
    update_time_ms: 31.743
  timestamp: 1602162995
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      6 |          149.216 | 970752 |   231.96 |              278.707 |              115.788 |            846.048 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3170.0
  date: 2020-10-08_13-17-00
  done: false
  episode_len_mean: 841.3995253164557
  episode_reward_max: 284.4040404040406
  episode_reward_mean: 232.7926815624599
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.0473353922367097
        entropy_coeff: 0.0
        kl: 0.006994991353712976
        model: {}
        policy_loss: -0.022564191045239566
        total_loss: 4.000831997394561
        vf_explained_var: 0.9874190092086792
        vf_loss: 4.021997082233429
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.05
    gpu_util_percent0: 0.03607142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.1392857142857125
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15954332548416084
    mean_env_wait_ms: 1.6290227853591808
    mean_inference_ms: 4.928510157079865
    mean_raw_obs_processing_ms: 0.4282714927763549
  time_since_restore: 173.52936792373657
  time_this_iter_s: 24.3138108253479
  time_total_s: 173.52936792373657
  timers:
    learn_throughput: 9848.427
    learn_time_ms: 16428.207
    sample_throughput: 19565.936
    sample_time_ms: 8269.065
    update_time_ms: 33.207
  timestamp: 1602163020
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      7 |          173.529 | 1132544 |  232.793 |              284.404 |              115.788 |              841.4 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3170.0
  date: 2020-10-08_13-17-24
  done: false
  episode_len_mean: 837.3713080168776
  episode_reward_max: 284.4040404040406
  episode_reward_mean: 233.61432184006011
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 1.01868434548378
        entropy_coeff: 0.0
        kl: 0.007189809367991984
        model: {}
        policy_loss: -0.023347471375018358
        total_loss: 3.781139385700226
        vf_explained_var: 0.9891014099121094
        vf_loss: 3.803048861026764
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.237931034482756
    gpu_util_percent0: 0.3775862068965518
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.075862068965516
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15891368528149816
    mean_env_wait_ms: 1.6319569838817485
    mean_inference_ms: 4.893836789565313
    mean_raw_obs_processing_ms: 0.42634126208708445
  time_since_restore: 197.79426956176758
  time_this_iter_s: 24.264901638031006
  time_total_s: 197.79426956176758
  timers:
    learn_throughput: 9856.304
    learn_time_ms: 16415.078
    sample_throughput: 19687.49
    sample_time_ms: 8218.011
    update_time_ms: 31.869
  timestamp: 1602163044
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      8 |          197.794 | 1294336 |  233.614 |              284.404 |              115.788 |            837.371 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-17-49
  done: false
  episode_len_mean: 829.8141542002302
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 235.34277179156337
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 1738
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.9904811769723892
        entropy_coeff: 0.0
        kl: 0.006311689200811088
        model: {}
        policy_loss: -0.020997717510908842
        total_loss: 5.1504497051239015
        vf_explained_var: 0.9909344911575317
        vf_loss: 5.170185089111328
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.67931034482759
    gpu_util_percent0: 0.38068965517241377
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.055172413793103
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.157959829699883
    mean_env_wait_ms: 1.6378718810700204
    mean_inference_ms: 4.838743156811552
    mean_raw_obs_processing_ms: 0.42330816479094296
  time_since_restore: 222.32361674308777
  time_this_iter_s: 24.52934718132019
  time_total_s: 222.32361674308777
  timers:
    learn_throughput: 9853.853
    learn_time_ms: 16419.161
    sample_throughput: 19753.396
    sample_time_ms: 8190.592
    update_time_ms: 32.175
  timestamp: 1602163069
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |      9 |          222.324 | 1456128 |  235.343 |              290.242 |              115.788 |            829.814 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-18-13
  done: false
  episode_len_mean: 826.4541139240506
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 235.7108905510803
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.9730047971010208
        entropy_coeff: 0.0
        kl: 0.006372990598902106
        model: {}
        policy_loss: -0.022790615819394587
        total_loss: 3.343014180660248
        vf_explained_var: 0.9915106892585754
        vf_loss: 3.3645302057266235
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 33.08214285714286
    gpu_util_percent0: 0.16285714285714287
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.103571428571428
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15757910819338425
    mean_env_wait_ms: 1.6406169640202375
    mean_inference_ms: 4.816179947756191
    mean_raw_obs_processing_ms: 0.42204263109223905
  time_since_restore: 246.7284791469574
  time_this_iter_s: 24.40486240386963
  time_total_s: 246.7284791469574
  timers:
    learn_throughput: 9847.675
    learn_time_ms: 16429.462
    sample_throughput: 19849.195
    sample_time_ms: 8151.061
    update_time_ms: 32.321
  timestamp: 1602163093
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     10 |          246.728 | 1617920 |  235.711 |              290.242 |              115.788 |            826.454 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-18-38
  done: false
  episode_len_mean: 823.6002921129503
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 236.65748035368276
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.9577732890844345
        entropy_coeff: 0.0
        kl: 0.006211055861786008
        model: {}
        policy_loss: -0.022765795403392984
        total_loss: 3.0192813992500307
        vf_explained_var: 0.9923363924026489
        vf_loss: 3.0408049702644346
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.77857142857143
    gpu_util_percent0: 0.16107142857142856
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.142857142857141
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15723552203389532
    mean_env_wait_ms: 1.6431788542353838
    mean_inference_ms: 4.795565785178838
    mean_raw_obs_processing_ms: 0.4208698540707466
  time_since_restore: 271.224684715271
  time_this_iter_s: 24.4962055683136
  time_total_s: 271.224684715271
  timers:
    learn_throughput: 9852.058
    learn_time_ms: 16422.153
    sample_throughput: 20269.288
    sample_time_ms: 7982.126
    update_time_ms: 32.124
  timestamp: 1602163118
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     11 |          271.225 | 1779712 |  236.657 |              290.242 |              115.788 |              823.6 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-19-02
  done: false
  episode_len_mean: 820.2957437472576
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 237.36838769440774
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 225
  episodes_total: 2279
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.9244333893060684
        entropy_coeff: 0.0
        kl: 0.006004941323772073
        model: {}
        policy_loss: -0.021168453525751828
        total_loss: 4.074023377895355
        vf_explained_var: 0.9932994842529297
        vf_loss: 4.093990921974182
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.49655172413793
    gpu_util_percent0: 0.37827586206896546
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.065517241379308
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15679164845732013
    mean_env_wait_ms: 1.6467252365879843
    mean_inference_ms: 4.769134762898821
    mean_raw_obs_processing_ms: 0.4193369791609706
  time_since_restore: 295.67071437835693
  time_this_iter_s: 24.446029663085938
  time_total_s: 295.67071437835693
  timers:
    learn_throughput: 9849.111
    learn_time_ms: 16427.067
    sample_throughput: 20390.396
    sample_time_ms: 7934.716
    update_time_ms: 32.684
  timestamp: 1602163142
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     12 |          295.671 | 1941504 |  237.368 |              290.242 |              115.788 |            820.296 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-19-27
  done: false
  episode_len_mean: 817.5490506329114
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 238.05452068149842
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 249
  episodes_total: 2528
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.9116032361984253
        entropy_coeff: 0.0
        kl: 0.0059999656863510605
        model: {}
        policy_loss: -0.020421561488183214
        total_loss: 3.2677656054496764
        vf_explained_var: 0.9931272268295288
        vf_loss: 3.2869871616363526
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.06785714285714
    gpu_util_percent0: 0.38392857142857134
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.057142857142856
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15638443382274794
    mean_env_wait_ms: 1.6501725119830468
    mean_inference_ms: 4.744610246890177
    mean_raw_obs_processing_ms: 0.4179913954280996
  time_since_restore: 320.09689450263977
  time_this_iter_s: 24.426180124282837
  time_total_s: 320.09689450263977
  timers:
    learn_throughput: 9847.161
    learn_time_ms: 16430.32
    sample_throughput: 20512.946
    sample_time_ms: 7887.312
    update_time_ms: 32.655
  timestamp: 1602163167
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     13 |          320.097 | 2103296 |  238.055 |              290.242 |              115.788 |            817.549 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-19-51
  done: false
  episode_len_mean: 816.2442293373045
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 238.46138225140444
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.9013321816921234
        entropy_coeff: 0.0
        kl: 0.006421135948039591
        model: {}
        policy_loss: -0.021805241936817765
        total_loss: 2.9366058349609374
        vf_explained_var: 0.9931826591491699
        vf_loss: 2.9571268558502197
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.646428571428565
    gpu_util_percent0: 0.16392857142857142
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.099999999999999
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15614529648189554
    mean_env_wait_ms: 1.6521389750754119
    mean_inference_ms: 4.73053241417009
    mean_raw_obs_processing_ms: 0.41720474865082524
  time_since_restore: 344.41752886772156
  time_this_iter_s: 24.320634365081787
  time_total_s: 344.41752886772156
  timers:
    learn_throughput: 9837.776
    learn_time_ms: 16445.994
    sample_throughput: 20599.986
    sample_time_ms: 7853.986
    update_time_ms: 30.91
  timestamp: 1602163191
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     14 |          344.418 | 2265088 |  238.461 |              290.242 |              115.788 |            816.244 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-20-16
  done: false
  episode_len_mean: 814.502106741573
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 238.95662736919752
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 162
  episodes_total: 2848
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.8737345904111862
        entropy_coeff: 0.0
        kl: 0.005880716699175536
        model: {}
        policy_loss: -0.023541058914270253
        total_loss: 2.77874299287796
        vf_explained_var: 0.9943079948425293
        vf_loss: 2.801107919216156
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.07931034482758
    gpu_util_percent0: 0.35724137931034483
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.068965517241378
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15591428798709747
    mean_env_wait_ms: 1.6541309900562287
    mean_inference_ms: 4.717179349715265
    mean_raw_obs_processing_ms: 0.41645872662204997
  time_since_restore: 368.9808130264282
  time_this_iter_s: 24.563284158706665
  time_total_s: 368.9808130264282
  timers:
    learn_throughput: 9834.907
    learn_time_ms: 16450.791
    sample_throughput: 20538.191
    sample_time_ms: 7877.617
    update_time_ms: 31.814
  timestamp: 1602163216
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     15 |          368.981 | 2426880 |  238.957 |              290.242 |              115.788 |            814.502 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-20-41
  done: false
  episode_len_mean: 811.5661392405063
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 239.56847270170044
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 312
  episodes_total: 3160
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.836417630314827
        entropy_coeff: 0.0
        kl: 0.005600748467259109
        model: {}
        policy_loss: -0.019153478858061134
        total_loss: 3.4916038155555724
        vf_explained_var: 0.9944165349006653
        vf_loss: 3.5096370816230773
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.385714285714286
    gpu_util_percent0: 0.012499999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.124999999999998
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1555265162232438
    mean_env_wait_ms: 1.657691166928328
    mean_inference_ms: 4.694226265108467
    mean_raw_obs_processing_ms: 0.4151903011455144
  time_since_restore: 393.6567976474762
  time_this_iter_s: 24.675984621047974
  time_total_s: 393.6567976474762
  timers:
    learn_throughput: 9819.613
    learn_time_ms: 16476.413
    sample_throughput: 20548.693
    sample_time_ms: 7873.591
    update_time_ms: 32.324
  timestamp: 1602163241
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     16 |          393.657 | 2588672 |  239.568 |              290.242 |              115.788 |            811.566 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-21-05
  done: false
  episode_len_mean: 810.3282097649186
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 239.7355501975754
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.8335719257593155
        entropy_coeff: 0.0
        kl: 0.006123062083497643
        model: {}
        policy_loss: -0.020987965818494558
        total_loss: 2.507720983028412
        vf_explained_var: 0.9944343566894531
        vf_loss: 2.5274842858314512
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.658620689655166
    gpu_util_percent0: 0.01103448275862069
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.1275862068965505
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15535230640052955
    mean_env_wait_ms: 1.659385700950701
    mean_inference_ms: 4.683905191630317
    mean_raw_obs_processing_ms: 0.41463069133714486
  time_since_restore: 418.1674716472626
  time_this_iter_s: 24.510673999786377
  time_total_s: 418.1674716472626
  timers:
    learn_throughput: 9812.797
    learn_time_ms: 16487.858
    sample_throughput: 20527.515
    sample_time_ms: 7881.714
    update_time_ms: 31.791
  timestamp: 1602163265
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     17 |          418.167 | 2750464 |  239.736 |              290.242 |              115.788 |            810.328 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-21-30
  done: false
  episode_len_mean: 809.0097813578826
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 239.89810649649536
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.830751609802246
        entropy_coeff: 0.0
        kl: 0.005981297581456602
        model: {}
        policy_loss: -0.023448871518485247
        total_loss: 2.440117084980011
        vf_explained_var: 0.994672954082489
        vf_loss: 2.462369680404663
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.66206896551724
    gpu_util_percent0: 0.43655172413793103
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.079310344827585
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15518911270894606
    mean_env_wait_ms: 1.66104596928502
    mean_inference_ms: 4.674219672029851
    mean_raw_obs_processing_ms: 0.41409634295401404
  time_since_restore: 442.4850378036499
  time_this_iter_s: 24.31756615638733
  time_total_s: 442.4850378036499
  timers:
    learn_throughput: 9812.073
    learn_time_ms: 16489.075
    sample_throughput: 20521.455
    sample_time_ms: 7884.041
    update_time_ms: 33.291
  timestamp: 1602163290
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     18 |          442.485 | 2912256 |  239.898 |              290.242 |              115.788 |             809.01 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-21-55
  done: false
  episode_len_mean: 806.8230485232068
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 240.2267639474917
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 316
  episodes_total: 3792
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.7929262965917587
        entropy_coeff: 0.0
        kl: 0.005467748525552452
        model: {}
        policy_loss: -0.018968340079300105
        total_loss: 3.431827688217163
        vf_explained_var: 0.9950782060623169
        vf_loss: 3.4497024059295653
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.84642857142857
    gpu_util_percent0: 0.20142857142857146
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.092857142857142
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15489375855306428
    mean_env_wait_ms: 1.6642226976233971
    mean_inference_ms: 4.65674052024899
    mean_raw_obs_processing_ms: 0.41315027526725906
  time_since_restore: 466.97452116012573
  time_this_iter_s: 24.48948335647583
  time_total_s: 466.97452116012573
  timers:
    learn_throughput: 9814.608
    learn_time_ms: 16484.815
    sample_throughput: 20517.495
    sample_time_ms: 7885.563
    update_time_ms: 33.174
  timestamp: 1602163315
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     19 |          466.975 | 3074048 |  240.227 |              290.242 |              115.788 |            806.823 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-22-19
  done: false
  episode_len_mean: 805.7225316455696
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 240.49984400971735
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3950
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.7794228792190552
        entropy_coeff: 0.0
        kl: 0.005526655982248485
        model: {}
        policy_loss: -0.023039081250317395
        total_loss: 2.078591358661652
        vf_explained_var: 0.9953739047050476
        vf_loss: 2.1005250751972198
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.603448275862068
    gpu_util_percent0: 0.3510344827586207
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.075862068965516
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15476163632995826
    mean_env_wait_ms: 1.6656993184585767
    mean_inference_ms: 4.6488134213727434
    mean_raw_obs_processing_ms: 0.41272395699835374
  time_since_restore: 491.4215154647827
  time_this_iter_s: 24.446994304656982
  time_total_s: 491.4215154647827
  timers:
    learn_throughput: 9817.173
    learn_time_ms: 16480.508
    sample_throughput: 20496.13
    sample_time_ms: 7893.783
    update_time_ms: 32.3
  timestamp: 1602163339
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     20 |          491.422 | 3235840 |    240.5 |              290.242 |              115.788 |            805.723 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-22-44
  done: false
  episode_len_mean: 804.7280915287245
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 240.70876486382807
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4108
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.7865538984537125
        entropy_coeff: 0.0
        kl: 0.005757506913505494
        model: {}
        policy_loss: -0.02310952057596296
        total_loss: 1.973700213432312
        vf_explained_var: 0.9953605532646179
        vf_loss: 1.9956582367420197
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.621428571428574
    gpu_util_percent0: 0.11714285714285715
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.107142857142855
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15463826788744325
    mean_env_wait_ms: 1.6671296389951276
    mean_inference_ms: 4.641298983375448
    mean_raw_obs_processing_ms: 0.41231589636433646
  time_since_restore: 515.9117021560669
  time_this_iter_s: 24.49018669128418
  time_total_s: 515.9117021560669
  timers:
    learn_throughput: 9821.901
    learn_time_ms: 16472.574
    sample_throughput: 20477.444
    sample_time_ms: 7900.986
    update_time_ms: 31.054
  timestamp: 1602163364
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     21 |          515.912 | 3397632 |  240.709 |              290.242 |              115.788 |            804.728 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-23-09
  done: false
  episode_len_mean: 803.1457812144644
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 241.09711855879692
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 289
  episodes_total: 4397
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.755255714058876
        entropy_coeff: 0.0
        kl: 0.005404739850200712
        model: {}
        policy_loss: -0.019464567000977696
        total_loss: 3.0453175783157347
        vf_explained_var: 0.9953736066818237
        vf_loss: 3.0637012124061584
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.451724137931027
    gpu_util_percent0: 0.3524137931034483
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.058620689655171
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15443164992451375
    mean_env_wait_ms: 1.6696716376955234
    mean_inference_ms: 4.628641353057089
    mean_raw_obs_processing_ms: 0.4116237338549396
  time_since_restore: 540.5083248615265
  time_this_iter_s: 24.596622705459595
  time_total_s: 540.5083248615265
  timers:
    learn_throughput: 9807.284
    learn_time_ms: 16497.126
    sample_throughput: 20505.923
    sample_time_ms: 7890.013
    update_time_ms: 31.487
  timestamp: 1602163389
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     22 |          540.508 | 3559424 |  241.097 |              290.242 |              115.788 |            803.146 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-23-34
  done: false
  episode_len_mean: 802.2247926669577
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 241.27666671075653
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 185
  episodes_total: 4582
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.7225345104932785
        entropy_coeff: 0.0
        kl: 0.005478021572344005
        model: {}
        policy_loss: -0.022186438925564288
        total_loss: 1.9642526030540466
        vf_explained_var: 0.9957612752914429
        vf_loss: 1.9853434622287751
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.3551724137931
    gpu_util_percent0: 0.24517241379310345
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.082758620689654
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15430947095824407
    mean_env_wait_ms: 1.6711400307873732
    mean_inference_ms: 4.621209545345874
    mean_raw_obs_processing_ms: 0.41122162004541535
  time_since_restore: 565.12957072258
  time_this_iter_s: 24.621245861053467
  time_total_s: 565.12957072258
  timers:
    learn_throughput: 9811.099
    learn_time_ms: 16490.712
    sample_throughput: 20444.354
    sample_time_ms: 7913.774
    update_time_ms: 33.107
  timestamp: 1602163414
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     23 |           565.13 | 3721216 |  241.277 |              290.242 |              115.788 |            802.225 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-23-59
  done: false
  episode_len_mean: 801.512447257384
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 241.5184460640156
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4740
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.7451686680316925
        entropy_coeff: 0.0
        kl: 0.005771003756672144
        model: {}
        policy_loss: -0.024150656536221504
        total_loss: 1.7480961799621582
        vf_explained_var: 0.9958817362785339
        vf_loss: 1.7710926413536072
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 31.700000000000003
    gpu_util_percent0: 0.2286206896551724
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.141379310344825
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15421167791618215
    mean_env_wait_ms: 1.672353659895845
    mean_inference_ms: 4.615171884779788
    mean_raw_obs_processing_ms: 0.41089512558313934
  time_since_restore: 589.8426554203033
  time_this_iter_s: 24.71308469772339
  time_total_s: 589.8426554203033
  timers:
    learn_throughput: 9799.662
    learn_time_ms: 16509.957
    sample_throughput: 20397.267
    sample_time_ms: 7932.043
    update_time_ms: 34.767
  timestamp: 1602163439
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | RUNNING  | 172.17.0.4:72926 |     24 |          589.843 | 3883008 |  241.518 |              290.242 |              115.788 |            801.512 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_20482_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3125.0
  date: 2020-10-08_13-24-23
  done: true
  episode_len_mean: 800.4764492753624
  episode_reward_max: 290.2424242424239
  episode_reward_mean: 241.8013874656386
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 228
  episodes_total: 4968
  experiment_id: e019eb488f504d908d1b8cde01a67779
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 0.0001
        entropy: 0.7212436735630036
        entropy_coeff: 0.0
        kl: 0.00533560358453542
        model: {}
        policy_loss: -0.020342798670753837
        total_loss: 2.63335440158844
        vf_explained_var: 0.9957489967346191
        vf_loss: 2.65263010263443
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 32.57142857142857
    gpu_util_percent0: 0.010357142857142858
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 7.132142857142855
    vram_util_percent0: 0.16005247622171206
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 72926
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15407978857325982
    mean_env_wait_ms: 1.674048569824602
    mean_inference_ms: 4.606872457251446
    mean_raw_obs_processing_ms: 0.410437719877507
  time_since_restore: 614.4670424461365
  time_this_iter_s: 24.62438702583313
  time_total_s: 614.4670424461365
  timers:
    learn_throughput: 9788.599
    learn_time_ms: 16528.616
    sample_throughput: 20425.639
    sample_time_ms: 7921.025
    update_time_ms: 33.481
  timestamp: 1602163463
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: '20482_00000'
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | TERMINATED |       |     25 |          614.467 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 53.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/531.54 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_20482_00000 | TERMINATED |       |     25 |          614.467 | 4044800 |  241.801 |              290.242 |              115.788 |            800.476 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Traceback (most recent call last):
  File "train.py", line 68, in <module>
    train_func()
  File "train.py", line 53, in train_func
    result = analysis.dataframe().to_dict('index')[0]
  File "/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py", line 89, in dataframe
    metric = self._validate_metric(metric)
  File "/root/miniconda3/lib/python3.8/site-packages/ray/tune/analysis/experiment_analysis.py", line 64, in _validate_metric
    raise ValueError(
ValueError: No `metric` has been passed and  `default_metric` has not been set. Please specify the `metric` parameter.
