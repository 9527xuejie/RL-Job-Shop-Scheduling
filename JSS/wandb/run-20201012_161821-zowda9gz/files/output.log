2020-10-12 16:18:24,937	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_8ea3c_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=22102)[0m 2020-10-12 16:18:27,684	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=22104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22075)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22075)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22094)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22094)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22054)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22054)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22072)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22072)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22091)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22091)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22080)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22080)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21976)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21976)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22035)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22035)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22008)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22008)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22033)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22033)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22036)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22036)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22040)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22040)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22018)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22018)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21979)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21979)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22098)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22098)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22048)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22048)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22114)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22114)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22056)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22056)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22110)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22034)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22034)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22060)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22060)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22042)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22042)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22017)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22017)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22053)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22053)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21980)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21980)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22086)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22086)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22051)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22051)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22058)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22058)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22078)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22078)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21977)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21977)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22077)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22077)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22068)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22068)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=21989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=21989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=22071)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=22071)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3616.3166666666666
    time_step_min: 3355
  date: 2020-10-12_16-19-01
  done: false
  episode_len_mean: 904.8481012658228
  episode_reward_max: 246.595959595959
  episode_reward_mean: 201.8721391126452
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1664008895556133
        entropy_coeff: 0.009999999999999998
        kl: 0.0071652865735813975
        model: {}
        policy_loss: -0.009667242959646197
        total_loss: 369.2308069864909
        vf_explained_var: 0.588043749332428
        vf_loss: 369.2507044474284
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.766666666666666
    gpu_util_percent0: 0.38757575757575763
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.563636363636364
    vram_util_percent0: 0.08582297226114873
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1682234796781384
    mean_env_wait_ms: 1.1765623342920946
    mean_inference_ms: 5.765162977623182
    mean_raw_obs_processing_ms: 0.4506949371450954
  time_since_restore: 28.37631845474243
  time_this_iter_s: 28.37631845474243
  time_total_s: 28.37631845474243
  timers:
    learn_throughput: 8444.442
    learn_time_ms: 19159.584
    sample_throughput: 17686.857
    sample_time_ms: 9147.584
    update_time_ms: 35.891
  timestamp: 1602519541
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |      1 |          28.3763 | 161792 |  201.872 |              246.596 |              106.747 |            904.848 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3635.856115107914
    time_step_min: 3314
  date: 2020-10-12_16-19-27
  done: false
  episode_len_mean: 904.6645569620254
  episode_reward_max: 248.26262626262562
  episode_reward_mean: 199.02403784682238
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.134358783562978
        entropy_coeff: 0.009999999999999998
        kl: 0.009114286939923963
        model: {}
        policy_loss: -0.01145551964873448
        total_loss: 96.7175687154134
        vf_explained_var: 0.8300127387046814
        vf_loss: 96.73854637145996
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.051612903225806
    gpu_util_percent0: 0.29161290322580646
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.761290322580645
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16353913871310494
    mean_env_wait_ms: 1.1741807628471566
    mean_inference_ms: 5.501540906630239
    mean_raw_obs_processing_ms: 0.437124621044246
  time_since_restore: 54.84995746612549
  time_this_iter_s: 26.473639011383057
  time_total_s: 54.84995746612549
  timers:
    learn_throughput: 8505.432
    learn_time_ms: 19022.197
    sample_throughput: 19424.033
    sample_time_ms: 8329.475
    update_time_ms: 32.292
  timestamp: 1602519567
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |      2 |            54.85 | 323584 |  199.024 |              248.263 |              106.747 |            904.665 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3642.261467889908
    time_step_min: 3314
  date: 2020-10-12_16-19-53
  done: false
  episode_len_mean: 903.824894514768
  episode_reward_max: 251.44444444444426
  episode_reward_mean: 198.7110983250221
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1239713827768962
        entropy_coeff: 0.009999999999999998
        kl: 0.009039462000752488
        model: {}
        policy_loss: -0.012942961936156886
        total_loss: 51.27370580037435
        vf_explained_var: 0.9003645777702332
        vf_loss: 51.29607995351156
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.833333333333336
    gpu_util_percent0: 0.38033333333333336
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16060135886474525
    mean_env_wait_ms: 1.1733098405395312
    mean_inference_ms: 5.311515627189537
    mean_raw_obs_processing_ms: 0.42822008209624907
  time_since_restore: 80.62348532676697
  time_this_iter_s: 25.77352786064148
  time_total_s: 80.62348532676697
  timers:
    learn_throughput: 8549.55
    learn_time_ms: 18924.037
    sample_throughput: 20552.379
    sample_time_ms: 7872.179
    update_time_ms: 35.024
  timestamp: 1602519593
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |      3 |          80.6235 | 485376 |  198.711 |              251.444 |              106.747 |            903.825 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3643.0622895622896
    time_step_min: 3314
  date: 2020-10-12_16-20-19
  done: false
  episode_len_mean: 897.5648734177215
  episode_reward_max: 251.44444444444426
  episode_reward_mean: 199.83699335123362
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1157379547754924
        entropy_coeff: 0.009999999999999998
        kl: 0.010069540546586117
        model: {}
        policy_loss: -0.01473260106286034
        total_loss: 37.33880106608073
        vf_explained_var: 0.9228532910346985
        vf_loss: 37.36267852783203
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.933333333333334
    gpu_util_percent0: 0.4139999999999999
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15864036050626332
    mean_env_wait_ms: 1.174495607386176
    mean_inference_ms: 5.175295119083116
    mean_raw_obs_processing_ms: 0.42181356182721746
  time_since_restore: 106.28368377685547
  time_this_iter_s: 25.6601984500885
  time_total_s: 106.28368377685547
  timers:
    learn_throughput: 8570.19
    learn_time_ms: 18878.462
    sample_throughput: 21255.686
    sample_time_ms: 7611.704
    update_time_ms: 35.054
  timestamp: 1602519619
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |      4 |          106.284 | 647168 |  199.837 |              251.444 |              106.747 |            897.565 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3632.1768617021276
    time_step_min: 3273
  date: 2020-10-12_16-20-45
  done: false
  episode_len_mean: 892.3683544303798
  episode_reward_max: 254.47474747474718
  episode_reward_mean: 201.4517325150234
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.097001979748408
        entropy_coeff: 0.009999999999999998
        kl: 0.009007189112404982
        model: {}
        policy_loss: -0.010921089289089045
        total_loss: 31.1905304590861
        vf_explained_var: 0.9355507493019104
        vf_loss: 31.210620085398357
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.126666666666665
    gpu_util_percent0: 0.35
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769999999999999
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15719277441389184
    mean_env_wait_ms: 1.1762232717650116
    mean_inference_ms: 5.073031014473687
    mean_raw_obs_processing_ms: 0.41682091276003563
  time_since_restore: 132.25247764587402
  time_this_iter_s: 25.968793869018555
  time_total_s: 132.25247764587402
  timers:
    learn_throughput: 8575.298
    learn_time_ms: 18867.216
    sample_throughput: 21571.088
    sample_time_ms: 7500.41
    update_time_ms: 36.389
  timestamp: 1602519645
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |      5 |          132.252 | 808960 |  201.452 |              254.475 |              106.747 |            892.368 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3613.1177685950415
    time_step_min: 3243
  date: 2020-10-12_16-21-11
  done: false
  episode_len_mean: 883.3260437375745
  episode_reward_max: 259.0202020202019
  episode_reward_mean: 204.0131232805187
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 216
  episodes_total: 1006
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0529125928878784
        entropy_coeff: 0.009999999999999998
        kl: 0.00937277365786334
        model: {}
        policy_loss: -0.013836070235508183
        total_loss: 35.00457239151001
        vf_explained_var: 0.9494605660438538
        vf_loss: 35.02706321080526
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.990000000000002
    gpu_util_percent0: 0.32800000000000007
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7566666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15573828457435313
    mean_env_wait_ms: 1.17974442707906
    mean_inference_ms: 4.968956628577686
    mean_raw_obs_processing_ms: 0.41162408428119673
  time_since_restore: 158.28538823127747
  time_this_iter_s: 26.032910585403442
  time_total_s: 158.28538823127747
  timers:
    learn_throughput: 8567.954
    learn_time_ms: 18883.388
    sample_throughput: 21825.987
    sample_time_ms: 7412.815
    update_time_ms: 37.611
  timestamp: 1602519671
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |      6 |          158.285 | 970752 |  204.013 |               259.02 |              106.747 |            883.326 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3592.488580750408
    time_step_min: 3243
  date: 2020-10-12_16-21-37
  done: false
  episode_len_mean: 872.4200949367089
  episode_reward_max: 259.0202020202019
  episode_reward_mean: 206.8798107658865
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 258
  episodes_total: 1264
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.066002647082011
        entropy_coeff: 0.009999999999999998
        kl: 0.008672098473956188
        model: {}
        policy_loss: -0.014244500470037261
        total_loss: 23.331302642822266
        vf_explained_var: 0.9583459496498108
        vf_loss: 23.354473272959392
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.653333333333332
    gpu_util_percent0: 0.3553333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.763333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1545267267648534
    mean_env_wait_ms: 1.1835318125986591
    mean_inference_ms: 4.882635016458399
    mean_raw_obs_processing_ms: 0.40754009541484887
  time_since_restore: 184.09133529663086
  time_this_iter_s: 25.805947065353394
  time_total_s: 184.09133529663086
  timers:
    learn_throughput: 8577.359
    learn_time_ms: 18862.682
    sample_throughput: 22009.934
    sample_time_ms: 7350.863
    update_time_ms: 37.481
  timestamp: 1602519697
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |      7 |          184.091 | 1132544 |   206.88 |               259.02 |              106.747 |             872.42 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3582.2095375722542
    time_step_min: 3243
  date: 2020-10-12_16-22-03
  done: false
  episode_len_mean: 866.0668073136428
  episode_reward_max: 263.7171717171716
  episode_reward_mean: 208.59890039636858
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0404679377873738
        entropy_coeff: 0.009999999999999998
        kl: 0.009874162341778478
        model: {}
        policy_loss: -0.01552047820102113
        total_loss: 18.528122742970783
        vf_explained_var: 0.9611799716949463
        vf_loss: 18.552073160807293
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.646666666666665
    gpu_util_percent0: 0.32666666666666677
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15393362672103494
    mean_env_wait_ms: 1.185713414640415
    mean_inference_ms: 4.840440131814276
    mean_raw_obs_processing_ms: 0.40552447702384464
  time_since_restore: 210.03991746902466
  time_this_iter_s: 25.9485821723938
  time_total_s: 210.03991746902466
  timers:
    learn_throughput: 8580.788
    learn_time_ms: 18855.144
    sample_throughput: 22122.315
    sample_time_ms: 7313.52
    update_time_ms: 38.143
  timestamp: 1602519723
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |      8 |           210.04 | 1294336 |  208.599 |              263.717 |              106.747 |            866.067 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3570.001945525292
    time_step_min: 3205
  date: 2020-10-12_16-22-29
  done: false
  episode_len_mean: 860.9506329113924
  episode_reward_max: 264.77777777777817
  episode_reward_mean: 210.16203170949987
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.0222784678141277
        entropy_coeff: 0.009999999999999998
        kl: 0.009850408571461836
        model: {}
        policy_loss: -0.015230184110502401
        total_loss: 16.71285589536031
        vf_explained_var: 0.9633122086524963
        vf_loss: 16.736339171727497
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.796666666666667
    gpu_util_percent0: 0.3393333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15342102166824675
    mean_env_wait_ms: 1.1879046171888816
    mean_inference_ms: 4.8035446582015915
    mean_raw_obs_processing_ms: 0.40372837946415285
  time_since_restore: 235.85202026367188
  time_this_iter_s: 25.812102794647217
  time_total_s: 235.85202026367188
  timers:
    learn_throughput: 8575.542
    learn_time_ms: 18866.679
    sample_throughput: 22305.51
    sample_time_ms: 7253.455
    update_time_ms: 36.936
  timestamp: 1602519749
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |      9 |          235.852 | 1456128 |  210.162 |              264.778 |              106.747 |            860.951 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3553.3161111111112
    time_step_min: 3172
  date: 2020-10-12_16-22-55
  done: false
  episode_len_mean: 853.5560391730141
  episode_reward_max: 269.77777777777777
  episode_reward_mean: 212.4601235422779
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 258
  episodes_total: 1838
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9770858188470205
        entropy_coeff: 0.009999999999999998
        kl: 0.00732714884604017
        model: {}
        policy_loss: -0.012916613991061846
        total_loss: 21.613835334777832
        vf_explained_var: 0.9685309529304504
        vf_loss: 21.63505760828654
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.19
    gpu_util_percent0: 0.38400000000000006
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7633333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1527256036009556
    mean_env_wait_ms: 1.1915061963287175
    mean_inference_ms: 4.75318124927595
    mean_raw_obs_processing_ms: 0.4012814495943239
  time_since_restore: 261.72402930259705
  time_this_iter_s: 25.87200903892517
  time_total_s: 261.72402930259705
  timers:
    learn_throughput: 8573.88
    learn_time_ms: 18870.337
    sample_throughput: 22421.399
    sample_time_ms: 7215.963
    update_time_ms: 36.968
  timestamp: 1602519775
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |     10 |          261.724 | 1617920 |   212.46 |              269.778 |              106.747 |            853.556 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3541.8874007936506
    time_step_min: 3172
  date: 2020-10-12_16-23-20
  done: false
  episode_len_mean: 848.1178188899707
  episode_reward_max: 269.77777777777777
  episode_reward_mean: 214.13217865116582
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 216
  episodes_total: 2054
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9858763416608175
        entropy_coeff: 0.009999999999999998
        kl: 0.007325464044697583
        model: {}
        policy_loss: -0.011898872733581811
        total_loss: 15.248226324717203
        vf_explained_var: 0.9715822339057922
        vf_loss: 15.268518686294556
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.8448275862069
    gpu_util_percent0: 0.31862068965517243
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.768965517241379
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15224406492634135
    mean_env_wait_ms: 1.194196584199246
    mean_inference_ms: 4.718677305505334
    mean_raw_obs_processing_ms: 0.39967228196677035
  time_since_restore: 287.2648468017578
  time_this_iter_s: 25.540817499160767
  time_total_s: 287.2648468017578
  timers:
    learn_throughput: 8597.876
    learn_time_ms: 18817.67
    sample_throughput: 23173.418
    sample_time_ms: 6981.793
    update_time_ms: 37.874
  timestamp: 1602519800
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |     11 |          287.265 | 1779712 |  214.132 |              269.778 |              106.747 |            848.118 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3533.7571297148115
    time_step_min: 3172
  date: 2020-10-12_16-23-46
  done: false
  episode_len_mean: 844.4186256781194
  episode_reward_max: 269.77777777777777
  episode_reward_mean: 215.4014420881508
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9650861273209254
        entropy_coeff: 0.009999999999999998
        kl: 0.009393486116702357
        model: {}
        policy_loss: -0.016552921948914445
        total_loss: 13.458543618520102
        vf_explained_var: 0.9710800647735596
        vf_loss: 13.482868671417236
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.02333333333333
    gpu_util_percent0: 0.26233333333333336
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.78
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15193720587601728
    mean_env_wait_ms: 1.196010630177521
    mean_inference_ms: 4.696431568394887
    mean_raw_obs_processing_ms: 0.3986068785099006
  time_since_restore: 313.1538517475128
  time_this_iter_s: 25.889004945755005
  time_total_s: 313.1538517475128
  timers:
    learn_throughput: 8601.185
    learn_time_ms: 18810.432
    sample_throughput: 23349.624
    sample_time_ms: 6929.105
    update_time_ms: 38.96
  timestamp: 1602519826
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |     12 |          313.154 | 1941504 |  215.401 |              269.778 |              106.747 |            844.419 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3524.8240819812127
    time_step_min: 3172
  date: 2020-10-12_16-24-12
  done: false
  episode_len_mean: 840.5428571428571
  episode_reward_max: 269.77777777777777
  episode_reward_mean: 216.82953484424056
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 168
  episodes_total: 2380
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9279095381498337
        entropy_coeff: 0.009999999999999998
        kl: 0.009434201987460256
        model: {}
        policy_loss: -0.01361750157472367
        total_loss: 13.987144788106283
        vf_explained_var: 0.9729480147361755
        vf_loss: 14.00815455118815
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.27333333333333
    gpu_util_percent0: 0.36399999999999993
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15163927744157366
    mean_env_wait_ms: 1.1979014266457297
    mean_inference_ms: 4.674951471243081
    mean_raw_obs_processing_ms: 0.39755511149941625
  time_since_restore: 338.754771232605
  time_this_iter_s: 25.600919485092163
  time_total_s: 338.754771232605
  timers:
    learn_throughput: 8599.825
    learn_time_ms: 18813.405
    sample_throughput: 23420.583
    sample_time_ms: 6908.112
    update_time_ms: 39.156
  timestamp: 1602519852
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |     13 |          338.755 | 2103296 |   216.83 |              269.778 |              106.747 |            840.543 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3509.407631280695
    time_step_min: 3119
  date: 2020-10-12_16-24-38
  done: false
  episode_len_mean: 834.8964618249535
  episode_reward_max: 277.8080808080806
  episode_reward_mean: 219.1875740646689
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 305
  episodes_total: 2685
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9284262309471766
        entropy_coeff: 0.009999999999999998
        kl: 0.006773244900008042
        model: {}
        policy_loss: -0.011580184761745235
        total_loss: 16.099412838617962
        vf_explained_var: 0.975457489490509
        vf_loss: 16.1189223130544
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.086206896551722
    gpu_util_percent0: 0.34379310344827585
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7586206896551717
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15118134317059206
    mean_env_wait_ms: 1.2011771967707519
    mean_inference_ms: 4.641399094778463
    mean_raw_obs_processing_ms: 0.3959242397876668
  time_since_restore: 364.33378052711487
  time_this_iter_s: 25.579009294509888
  time_total_s: 364.33378052711487
  timers:
    learn_throughput: 8604.124
    learn_time_ms: 18804.007
    sample_throughput: 23422.771
    sample_time_ms: 6907.466
    update_time_ms: 39.705
  timestamp: 1602519878
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |     14 |          364.334 | 2265088 |  219.188 |              277.808 |              106.747 |            834.896 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3502.323235923022
    time_step_min: 3119
  date: 2020-10-12_16-25-04
  done: false
  episode_len_mean: 832.5337552742616
  episode_reward_max: 282.05050505050525
  episode_reward_mean: 220.38064186165434
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 159
  episodes_total: 2844
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9230702469746271
        entropy_coeff: 0.009999999999999998
        kl: 0.007918423352142176
        model: {}
        policy_loss: -0.013649656238461224
        total_loss: 12.810695568720499
        vf_explained_var: 0.9728216528892517
        vf_loss: 12.831992228825888
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.343333333333337
    gpu_util_percent0: 0.29399999999999993
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15097042280542378
    mean_env_wait_ms: 1.202650517097352
    mean_inference_ms: 4.626142616170143
    mean_raw_obs_processing_ms: 0.3951791231802534
  time_since_restore: 390.09765434265137
  time_this_iter_s: 25.7638738155365
  time_total_s: 390.09765434265137
  timers:
    learn_throughput: 8604.389
    learn_time_ms: 18803.427
    sample_throughput: 23493.711
    sample_time_ms: 6886.609
    update_time_ms: 39.882
  timestamp: 1602519904
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |     15 |          390.098 | 2426880 |  220.381 |              282.051 |              106.747 |            832.534 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3494.355937921727
    time_step_min: 3119
  date: 2020-10-12_16-25-29
  done: false
  episode_len_mean: 830.4830113257829
  episode_reward_max: 282.05050505050525
  episode_reward_mean: 221.53413212740318
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.9105358521143595
        entropy_coeff: 0.009999999999999998
        kl: 0.008336603408679366
        model: {}
        policy_loss: -0.011778903348992268
        total_loss: 12.004481474558512
        vf_explained_var: 0.9730057120323181
        vf_loss: 12.023698568344116
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.480000000000004
    gpu_util_percent0: 0.31599999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1507761977486961
    mean_env_wait_ms: 1.2040026876981498
    mean_inference_ms: 4.612117555225517
    mean_raw_obs_processing_ms: 0.3944795116874404
  time_since_restore: 415.76764011383057
  time_this_iter_s: 25.6699857711792
  time_total_s: 415.76764011383057
  timers:
    learn_throughput: 8609.793
    learn_time_ms: 18791.625
    sample_throughput: 23573.198
    sample_time_ms: 6863.388
    update_time_ms: 37.551
  timestamp: 1602519929
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |     16 |          415.768 | 2588672 |  221.534 |              282.051 |              106.747 |            830.483 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3482.751234567901
    time_step_min: 3119
  date: 2020-10-12_16-25-55
  done: false
  episode_len_mean: 827.2037827943868
  episode_reward_max: 282.05050505050525
  episode_reward_mean: 223.24621751375855
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 276
  episodes_total: 3278
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8724450965722402
        entropy_coeff: 0.009999999999999998
        kl: 0.0082933585314701
        model: {}
        policy_loss: -0.012379297598575553
        total_loss: 16.862854798634846
        vf_explained_var: 0.9745149612426758
        vf_loss: 16.88229990005493
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.910344827586208
    gpu_util_percent0: 0.3937931034482759
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7620689655172406
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15046624696699903
    mean_env_wait_ms: 1.2062829499356595
    mean_inference_ms: 4.589890215601134
    mean_raw_obs_processing_ms: 0.393376410005954
  time_since_restore: 441.3771948814392
  time_this_iter_s: 25.609554767608643
  time_total_s: 441.3771948814392
  timers:
    learn_throughput: 8612.398
    learn_time_ms: 18785.941
    sample_throughput: 23623.263
    sample_time_ms: 6848.842
    update_time_ms: 37.126
  timestamp: 1602519955
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |     17 |          441.377 | 2750464 |  223.246 |              282.051 |              106.747 |            827.204 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3474.781559045957
    time_step_min: 3119
  date: 2020-10-12_16-26-21
  done: false
  episode_len_mean: 825.3012082853855
  episode_reward_max: 282.05050505050525
  episode_reward_mean: 224.4128511815507
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 198
  episodes_total: 3476
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8749214361111323
        entropy_coeff: 0.009999999999999998
        kl: 0.009000509899730483
        model: {}
        policy_loss: -0.012712376056394229
        total_loss: 10.444080034891764
        vf_explained_var: 0.9797496795654297
        vf_loss: 10.463741540908813
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.64
    gpu_util_percent0: 0.39299999999999996
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7766666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15027859234976837
    mean_env_wait_ms: 1.2077095561759605
    mean_inference_ms: 4.5760454579838825
    mean_raw_obs_processing_ms: 0.39270832771468434
  time_since_restore: 466.93058609962463
  time_this_iter_s: 25.553391218185425
  time_total_s: 466.93058609962463
  timers:
    learn_throughput: 8620.08
    learn_time_ms: 18769.2
    sample_throughput: 23697.759
    sample_time_ms: 6827.312
    update_time_ms: 35.043
  timestamp: 1602519981
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |     18 |          466.931 | 2912256 |  224.413 |              282.051 |              106.747 |            825.301 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3468.872636262514
    time_step_min: 3119
  date: 2020-10-12_16-26-47
  done: false
  episode_len_mean: 823.6009906439185
  episode_reward_max: 282.05050505050525
  episode_reward_mean: 225.36991266545465
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8683308015267054
        entropy_coeff: 0.009999999999999998
        kl: 0.007259380382796128
        model: {}
        policy_loss: -0.012700891117371308
        total_loss: 9.262305736541748
        vf_explained_var: 0.9782868027687073
        vf_loss: 9.282237847646078
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.070000000000004
    gpu_util_percent0: 0.325
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.776666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15013483610221234
    mean_env_wait_ms: 1.208779404369442
    mean_inference_ms: 4.565641619615034
    mean_raw_obs_processing_ms: 0.39219209343933115
  time_since_restore: 492.6606695652008
  time_this_iter_s: 25.730083465576172
  time_total_s: 492.6606695652008
  timers:
    learn_throughput: 8629.504
    learn_time_ms: 18748.703
    sample_throughput: 23663.631
    sample_time_ms: 6837.159
    update_time_ms: 36.415
  timestamp: 1602520007
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |     19 |          492.661 | 3074048 |   225.37 |              282.051 |              106.747 |            823.601 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3461.391521853607
    time_step_min: 3119
  date: 2020-10-12_16-27-13
  done: false
  episode_len_mean: 821.8451511991658
  episode_reward_max: 282.05050505050525
  episode_reward_mean: 226.48046681623313
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 202
  episodes_total: 3836
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8407121747732162
        entropy_coeff: 0.009999999999999998
        kl: 0.008961600173885623
        model: {}
        policy_loss: -0.011803561751018302
        total_loss: 12.910271088282267
        vf_explained_var: 0.9768204689025879
        vf_loss: 12.928689559300741
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.276666666666667
    gpu_util_percent0: 0.3423333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7766666666666664
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14996394444978747
    mean_env_wait_ms: 1.210121092005693
    mean_inference_ms: 4.55333844028711
    mean_raw_obs_processing_ms: 0.39157677253132717
  time_since_restore: 518.3011474609375
  time_this_iter_s: 25.640477895736694
  time_total_s: 518.3011474609375
  timers:
    learn_throughput: 8640.665
    learn_time_ms: 18724.484
    sample_throughput: 23687.038
    sample_time_ms: 6830.402
    update_time_ms: 42.866
  timestamp: 1602520033
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |     20 |          518.301 | 3235840 |   226.48 |              282.051 |              106.747 |            821.845 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3452.4739429695182
    time_step_min: 3119
  date: 2020-10-12_16-27-38
  done: false
  episode_len_mean: 819.8470530930346
  episode_reward_max: 287.05050505050514
  episode_reward_mean: 228.03631295910873
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 270
  episodes_total: 4106
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8434845507144928
        entropy_coeff: 0.009999999999999998
        kl: 0.0071994160146762924
        model: {}
        policy_loss: -0.012718814134132117
        total_loss: 12.237211147944132
        vf_explained_var: 0.9790468811988831
        vf_loss: 12.256925185521444
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.67666666666667
    gpu_util_percent0: 0.32800000000000007
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7599999999999993
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1497575863490814
    mean_env_wait_ms: 1.2116989008131813
    mean_inference_ms: 4.53820678700806
    mean_raw_obs_processing_ms: 0.390834723777142
  time_since_restore: 544.0510859489441
  time_this_iter_s: 25.749938488006592
  time_total_s: 544.0510859489441
  timers:
    learn_throughput: 8637.108
    learn_time_ms: 18732.196
    sample_throughput: 23675.354
    sample_time_ms: 6833.773
    update_time_ms: 42.279
  timestamp: 1602520058
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |     21 |          544.051 | 3397632 |  228.036 |              287.051 |              106.747 |            819.847 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3446.3356196783348
    time_step_min: 3083
  date: 2020-10-12_16-28-05
  done: false
  episode_len_mean: 818.6455696202531
  episode_reward_max: 287.05050505050514
  episode_reward_mean: 228.95371435877752
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 160
  episodes_total: 4266
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8403069923321406
        entropy_coeff: 0.009999999999999998
        kl: 0.0072936169647922116
        model: {}
        policy_loss: -0.01261749875266105
        total_loss: 10.336752732594809
        vf_explained_var: 0.9766800403594971
        vf_loss: 10.356314579645792
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.540000000000003
    gpu_util_percent0: 0.4106666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333328
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1496444010499292
    mean_env_wait_ms: 1.2125537504871058
    mean_inference_ms: 4.530042204397325
    mean_raw_obs_processing_ms: 0.39042764031840516
  time_since_restore: 570.0382752418518
  time_this_iter_s: 25.987189292907715
  time_total_s: 570.0382752418518
  timers:
    learn_throughput: 8623.946
    learn_time_ms: 18760.786
    sample_throughput: 23744.743
    sample_time_ms: 6813.803
    update_time_ms: 42.268
  timestamp: 1602520085
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |     22 |          570.038 | 3559424 |  228.954 |              287.051 |              106.747 |            818.646 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3439.9995448338645
    time_step_min: 3083
  date: 2020-10-12_16-28-31
  done: false
  episode_len_mean: 817.3883122743682
  episode_reward_max: 287.05050505050514
  episode_reward_mean: 229.9458734456477
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 166
  episodes_total: 4432
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.8127146164576212
        entropy_coeff: 0.009999999999999998
        kl: 0.008128111949190497
        model: {}
        policy_loss: -0.015566321439109743
        total_loss: 9.5201256275177
        vf_explained_var: 0.979200541973114
        vf_loss: 9.542193333307901
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.31
    gpu_util_percent0: 0.40733333333333327
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14953333654798584
    mean_env_wait_ms: 1.2133860115121158
    mean_inference_ms: 4.5219502413654675
    mean_raw_obs_processing_ms: 0.39001450542339405
  time_since_restore: 595.8213214874268
  time_this_iter_s: 25.78304624557495
  time_total_s: 595.8213214874268
  timers:
    learn_throughput: 8618.327
    learn_time_ms: 18773.018
    sample_throughput: 23720.577
    sample_time_ms: 6820.745
    update_time_ms: 40.212
  timestamp: 1602520111
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | RUNNING  | 172.17.0.4:22102 |     23 |          595.821 | 3721216 |  229.946 |              287.051 |              106.747 |            817.388 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_8ea3c_00000:
  custom_metrics:
    time_step_max: 4248
    time_step_mean: 3429.148945237588
    time_step_min: 3083
  date: 2020-10-12_16-28-57
  done: true
  episode_len_mean: 815.279856267174
  episode_reward_max: 287.05050505050514
  episode_reward_mean: 231.57543091024374
  episode_reward_min: 106.74747474747424
  episodes_this_iter: 299
  episodes_total: 4731
  experiment_id: 5492ddbfd1184dfa8ace60455757a43d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 0.7909854501485825
        entropy_coeff: 0.009999999999999998
        kl: 0.0077792728164543705
        model: {}
        policy_loss: -0.010729974436496073
        total_loss: 11.232638518015543
        vf_explained_var: 0.9819092154502869
        vf_loss: 11.249722560246786
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.166666666666668
    gpu_util_percent0: 0.362
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 22102
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1493506864713904
    mean_env_wait_ms: 1.2148414321362602
    mean_inference_ms: 4.5087414773041266
    mean_raw_obs_processing_ms: 0.38935138123533425
  time_since_restore: 621.7400057315826
  time_this_iter_s: 25.918684244155884
  time_total_s: 621.7400057315826
  timers:
    learn_throughput: 8602.633
    learn_time_ms: 18807.264
    sample_throughput: 23722.089
    sample_time_ms: 6820.31
    update_time_ms: 40.495
  timestamp: 1602520137
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 8ea3c_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | TERMINATED |       |     24 |           621.74 | 3883008 |  231.575 |              287.051 |              106.747 |             815.28 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_8ea3c_00000 | TERMINATED |       |     24 |           621.74 | 3883008 |  231.575 |              287.051 |              106.747 |             815.28 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


