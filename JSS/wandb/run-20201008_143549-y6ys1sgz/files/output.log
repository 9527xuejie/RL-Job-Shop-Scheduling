2020-10-08 14:35:51,552	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_915d0_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=62403)[0m 2020-10-08 14:35:54,588	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=62386)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62386)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62376)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62376)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62393)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62393)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62398)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62398)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62383)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62383)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62373)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62373)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62395)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62395)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62371)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62371)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62368)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62368)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62370)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62370)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62327)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62327)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62388)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62388)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62316)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62316)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62342)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62342)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62345)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62345)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62362)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62362)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62365)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62365)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62267)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62267)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62263)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62263)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62280)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62280)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62286)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62286)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62364)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62364)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62363)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62363)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62251)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62251)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62356)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62356)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62384)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62384)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62261)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62261)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62406)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62406)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62359)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62359)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62276)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62276)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62375)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62375)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62258)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62258)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62411)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62411)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62337)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62337)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62287)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62256)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62256)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62268)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62268)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62325)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62325)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62336)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62336)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62281)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62281)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62333)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62333)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62341)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62341)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62273)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62343)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62343)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62323)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62323)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62339)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62339)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62354)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62354)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62249)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62249)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62348)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62348)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62288)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62288)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62334)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62334)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62340)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62340)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62250)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62250)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62377)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62377)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62274)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62274)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62331)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62331)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62391)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62391)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62344)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62344)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62279)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62279)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62284)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62284)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62266)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62266)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62318)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62318)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62319)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62319)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62351)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62351)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62328)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62328)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62338)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62338)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-08_14-36-25
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1634249687194824
        entropy_coeff: 0.0
        kl: 0.0036954283714294434
        model: {}
        policy_loss: -0.006869117938913405
        total_loss: 9.30032901763916
        vf_explained_var: 0.7174946069717407
        vf_loss: 9.306459045410156
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 39.282758620689656
    gpu_util_percent0: 0.27758620689655167
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0003448275862068966
    ram_util_percent: 9.486206896551723
    vram_util_percent0: 0.30692086721480194
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1757240295410156
    mean_env_wait_ms: 1.64632514878238
    mean_inference_ms: 5.702464303031089
    mean_raw_obs_processing_ms: 0.4785182454697177
  time_since_restore: 24.381270170211792
  time_this_iter_s: 24.381270170211792
  time_total_s: 24.381270170211792
  timers:
    learn_throughput: 10955.585
    learn_time_ms: 14767.992
    sample_throughput: 16976.731
    sample_time_ms: 9530.221
    update_time_ms: 49.441
  timestamp: 1602167785
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      1 |          24.3813 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-36-48
  done: false
  episode_len_mean: 867.5569620253165
  episode_reward_max: 287.616161616161
  episode_reward_mean: 226.67721518987318
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.1362101554870605
        entropy_coeff: 0.0
        kl: 0.006970350444316864
        model: {}
        policy_loss: -0.009705625101923942
        total_loss: 10.32210750579834
        vf_explained_var: 0.8451136350631714
        vf_loss: 10.331116104125977
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.548148148148144
    gpu_util_percent0: 0.2866666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.733333333333334
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17100616576939356
    mean_env_wait_ms: 1.647485749663841
    mean_inference_ms: 5.449976105277291
    mean_raw_obs_processing_ms: 0.4667153357279003
  time_since_restore: 47.252567291259766
  time_this_iter_s: 22.871297121047974
  time_total_s: 47.252567291259766
  timers:
    learn_throughput: 11041.238
    learn_time_ms: 14653.429
    sample_throughput: 18199.954
    sample_time_ms: 8889.693
    update_time_ms: 42.206
  timestamp: 1602167808
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      2 |          47.2526 | 323584 |  226.677 |              287.616 |              115.788 |            867.557 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-37-11
  done: false
  episode_len_mean: 859.824894514768
  episode_reward_max: 287.616161616161
  episode_reward_mean: 228.24830584324238
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.12405526638031
        entropy_coeff: 0.0
        kl: 0.006674189120531082
        model: {}
        policy_loss: -0.010977230872958899
        total_loss: 12.676021194458007
        vf_explained_var: 0.8899718523025513
        vf_loss: 12.686330986022949
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.05555555555555
    gpu_util_percent0: 0.2644444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16808367664964877
    mean_env_wait_ms: 1.6489405832417077
    mean_inference_ms: 5.307994845910706
    mean_raw_obs_processing_ms: 0.45738673020424264
  time_since_restore: 70.47958087921143
  time_this_iter_s: 23.22701358795166
  time_total_s: 70.47958087921143
  timers:
    learn_throughput: 11042.229
    learn_time_ms: 14652.115
    sample_throughput: 18479.026
    sample_time_ms: 8755.44
    update_time_ms: 41.454
  timestamp: 1602167831
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      3 |          70.4796 | 485376 |  228.248 |              287.616 |              115.788 |            859.825 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-37-34
  done: false
  episode_len_mean: 853.2689873417721
  episode_reward_max: 287.616161616161
  episode_reward_mean: 228.76543920214786
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.0947366952896118
        entropy_coeff: 0.0
        kl: 0.005848201550543308
        model: {}
        policy_loss: -0.01150441262871027
        total_loss: 13.476828002929688
        vf_explained_var: 0.9183750152587891
        vf_loss: 13.487747383117675
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.855555555555554
    gpu_util_percent0: 0.27814814814814814
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.744444444444445
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16618084056987167
    mean_env_wait_ms: 1.652121993019246
    mean_inference_ms: 5.206010003773685
    mean_raw_obs_processing_ms: 0.45115332512960615
  time_since_restore: 93.41903614997864
  time_this_iter_s: 22.939455270767212
  time_total_s: 93.41903614997864
  timers:
    learn_throughput: 11054.503
    learn_time_ms: 14635.845
    sample_throughput: 18733.219
    sample_time_ms: 8636.637
    update_time_ms: 36.312
  timestamp: 1602167854
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      4 |           93.419 | 647168 |  228.765 |              287.616 |              115.788 |            853.269 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-37-57
  done: false
  episode_len_mean: 842.2431289640592
  episode_reward_max: 287.616161616161
  episode_reward_mean: 228.57511691972567
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 314
  episodes_total: 946
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.0704583883285523
        entropy_coeff: 0.0
        kl: 0.006159011553972959
        model: {}
        policy_loss: -0.01097527714446187
        total_loss: 18.48041114807129
        vf_explained_var: 0.9505600929260254
        vf_loss: 18.490771102905274
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.67142857142857
    gpu_util_percent0: 0.34750000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.739285714285716
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1637216679032345
    mean_env_wait_ms: 1.6595417244788717
    mean_inference_ms: 5.075327722233796
    mean_raw_obs_processing_ms: 0.443719930951552
  time_since_restore: 116.6165714263916
  time_this_iter_s: 23.197535276412964
  time_total_s: 116.6165714263916
  timers:
    learn_throughput: 11077.95
    learn_time_ms: 14604.868
    sample_throughput: 18764.263
    sample_time_ms: 8622.347
    update_time_ms: 48.444
  timestamp: 1602167877
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      5 |          116.617 | 808960 |  228.575 |              287.616 |              115.788 |            842.243 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-38-20
  done: false
  episode_len_mean: 836.750452079566
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 228.89865198093034
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 160
  episodes_total: 1106
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.055753970146179
        entropy_coeff: 0.0
        kl: 0.005695956200361252
        model: {}
        policy_loss: -0.011811013519763946
        total_loss: 10.852777481079102
        vf_explained_var: 0.962054431438446
        vf_loss: 10.864018821716309
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.72222222222222
    gpu_util_percent0: 0.35111111111111115
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75925925925926
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1628602412001804
    mean_env_wait_ms: 1.6629806692878721
    mean_inference_ms: 5.029434693395045
    mean_raw_obs_processing_ms: 0.4411608440723358
  time_since_restore: 139.58397793769836
  time_this_iter_s: 22.967406511306763
  time_total_s: 139.58397793769836
  timers:
    learn_throughput: 11077.097
    learn_time_ms: 14605.993
    sample_throughput: 18897.274
    sample_time_ms: 8561.658
    update_time_ms: 47.548
  timestamp: 1602167900
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      6 |          139.584 | 970752 |  228.899 |              288.677 |              115.788 |             836.75 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-38-43
  done: false
  episode_len_mean: 832.4912974683544
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 229.12192334739794
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 1.0276399850845337
        entropy_coeff: 0.0
        kl: 0.006466569937765598
        model: {}
        policy_loss: -0.011636075656861066
        total_loss: 8.998390388488769
        vf_explained_var: 0.974209189414978
        vf_loss: 9.009379959106445
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.077777777777776
    gpu_util_percent0: 0.3385185185185185
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16214672501095637
    mean_env_wait_ms: 1.6660350123757786
    mean_inference_ms: 4.989792500800228
    mean_raw_obs_processing_ms: 0.4388133207032813
  time_since_restore: 162.63410711288452
  time_this_iter_s: 23.050129175186157
  time_total_s: 162.63410711288452
  timers:
    learn_throughput: 11073.8
    learn_time_ms: 14610.341
    sample_throughput: 18990.249
    sample_time_ms: 8519.741
    update_time_ms: 52.969
  timestamp: 1602167923
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      7 |          162.634 | 1132544 |  229.122 |              288.677 |              115.788 |            832.491 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-39-07
  done: false
  episode_len_mean: 828.9536191145468
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 229.30009156924115
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 159
  episodes_total: 1423
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 0.9808277368545533
        entropy_coeff: 0.0
        kl: 0.005697270948439836
        model: {}
        policy_loss: -0.011643980722874403
        total_loss: 8.807140922546386
        vf_explained_var: 0.9820235371589661
        vf_loss: 8.81821517944336
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.455555555555556
    gpu_util_percent0: 0.3714814814814815
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1615196757247767
    mean_env_wait_ms: 1.6692087104086357
    mean_inference_ms: 4.9554631054043154
    mean_raw_obs_processing_ms: 0.4368050778905272
  time_since_restore: 185.7295219898224
  time_this_iter_s: 23.095414876937866
  time_total_s: 185.7295219898224
  timers:
    learn_throughput: 11079.249
    learn_time_ms: 14603.156
    sample_throughput: 19018.018
    sample_time_ms: 8507.301
    update_time_ms: 52.834
  timestamp: 1602167947
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      8 |           185.73 | 1294336 |    229.3 |              288.677 |              115.788 |            828.954 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-39-30
  done: false
  episode_len_mean: 823.2727272727273
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 229.70394392718896
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 315
  episodes_total: 1738
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 0.9526113629341125
        entropy_coeff: 0.0
        kl: 0.005972906947135925
        model: {}
        policy_loss: -0.009771315287798643
        total_loss: 9.008384895324706
        vf_explained_var: 0.9860280156135559
        vf_loss: 9.017558670043945
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.596296296296295
    gpu_util_percent0: 0.3459259259259259
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.74074074074074
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16052428925609347
    mean_env_wait_ms: 1.6745735041412186
    mean_inference_ms: 4.9012147585196875
    mean_raw_obs_processing_ms: 0.43364063849422935
  time_since_restore: 208.82200074195862
  time_this_iter_s: 23.09247875213623
  time_total_s: 208.82200074195862
  timers:
    learn_throughput: 11075.469
    learn_time_ms: 14608.14
    sample_throughput: 19056.721
    sample_time_ms: 8490.023
    update_time_ms: 51.191
  timestamp: 1602167970
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |      9 |          208.822 | 1456128 |  229.704 |              288.677 |              115.788 |            823.273 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-39-53
  done: false
  episode_len_mean: 820.8449367088608
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 230.00481076588665
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1896
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 0.9210301876068115
        entropy_coeff: 0.0
        kl: 0.005263826157897711
        model: {}
        policy_loss: -0.011546191573143006
        total_loss: 5.099816417694091
        vf_explained_var: 0.9898549914360046
        vf_loss: 5.110836219787598
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.45
    gpu_util_percent0: 0.2765384615384615
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757692307692308
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16012071286521537
    mean_env_wait_ms: 1.6769584200199288
    mean_inference_ms: 4.879351302598748
    mean_raw_obs_processing_ms: 0.4323678345676833
  time_since_restore: 231.66956901550293
  time_this_iter_s: 22.84756827354431
  time_total_s: 231.66956901550293
  timers:
    learn_throughput: 11073.907
    learn_time_ms: 14610.201
    sample_throughput: 19136.067
    sample_time_ms: 8454.82
    update_time_ms: 48.036
  timestamp: 1602167993
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     10 |           231.67 | 1617920 |  230.005 |              288.677 |              115.788 |            820.845 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-40-16
  done: false
  episode_len_mean: 818.5701071080817
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 230.31151338113358
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 0.8982365131378174
        entropy_coeff: 0.0
        kl: 0.005270243715494871
        model: {}
        policy_loss: -0.011099985614418984
        total_loss: 4.830344104766846
        vf_explained_var: 0.9905357360839844
        vf_loss: 4.8409172058105465
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.32592592592592
    gpu_util_percent0: 0.24037037037037037
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75925925925926
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15976122335814968
    mean_env_wait_ms: 1.6793294742284874
    mean_inference_ms: 4.859690278369607
    mean_raw_obs_processing_ms: 0.4312127986341798
  time_since_restore: 254.63108944892883
  time_this_iter_s: 22.961520433425903
  time_total_s: 254.63108944892883
  timers:
    learn_throughput: 11080.095
    learn_time_ms: 14602.04
    sample_throughput: 19448.654
    sample_time_ms: 8318.931
    update_time_ms: 47.064
  timestamp: 1602168016
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     11 |          254.631 | 1779712 |  230.312 |              288.677 |              115.788 |             818.57 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-40-39
  done: false
  episode_len_mean: 814.4644970414201
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 230.61496623035083
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 312
  episodes_total: 2366
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 0.0001
        entropy: 0.8527369737625122
        entropy_coeff: 0.0
        kl: 0.004944136552512646
        model: {}
        policy_loss: -0.009640095010399818
        total_loss: 6.339443302154541
        vf_explained_var: 0.9922040700912476
        vf_loss: 6.348588943481445
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.03703703703704
    gpu_util_percent0: 0.2240740740740741
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.751851851851852
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15916196422536188
    mean_env_wait_ms: 1.6839595823265638
    mean_inference_ms: 4.8266397179770495
    mean_raw_obs_processing_ms: 0.42933881433347315
  time_since_restore: 277.93945264816284
  time_this_iter_s: 23.30836319923401
  time_total_s: 277.93945264816284
  timers:
    learn_throughput: 11068.297
    learn_time_ms: 14617.605
    sample_throughput: 19385.061
    sample_time_ms: 8346.221
    update_time_ms: 47.015
  timestamp: 1602168039
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     12 |          277.939 | 1941504 |  230.615 |              288.677 |              115.788 |            814.464 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-41-02
  done: false
  episode_len_mean: 812.7804588607595
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 230.90040835570895
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 162
  episodes_total: 2528
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 0.0001
        entropy: 0.8162306189537049
        entropy_coeff: 0.0
        kl: 0.00497872568666935
        model: {}
        policy_loss: -0.010843988787382842
        total_loss: 3.4543155670166015
        vf_explained_var: 0.9936901926994324
        vf_loss: 3.464910793304443
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.98148148148148
    gpu_util_percent0: 0.26740740740740737
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75925925925926
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15890126404551247
    mean_env_wait_ms: 1.6860523789466912
    mean_inference_ms: 4.811790479417736
    mean_raw_obs_processing_ms: 0.4284688080412655
  time_since_restore: 301.0768303871155
  time_this_iter_s: 23.137377738952637
  time_total_s: 301.0768303871155
  timers:
    learn_throughput: 11066.15
    learn_time_ms: 14620.441
    sample_throughput: 19414.711
    sample_time_ms: 8333.475
    update_time_ms: 47.125
  timestamp: 1602168062
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     13 |          301.077 | 2103296 |    230.9 |              288.677 |              115.788 |             812.78 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-41-26
  done: false
  episode_len_mean: 811.4441548771407
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 231.20583722556913
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025
        cur_lr: 0.0001
        entropy: 0.8134485006332397
        entropy_coeff: 0.0
        kl: 0.004668395221233368
        model: {}
        policy_loss: -0.010667751869186759
        total_loss: 3.3521031856536867
        vf_explained_var: 0.993451714515686
        vf_loss: 3.3626541614532472
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.41428571428572
    gpu_util_percent0: 0.34785714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.757142857142856
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15866624852978198
    mean_env_wait_ms: 1.6880503883580986
    mean_inference_ms: 4.798423501393424
    mean_raw_obs_processing_ms: 0.4276862143850709
  time_since_restore: 324.2326891422272
  time_this_iter_s: 23.155858755111694
  time_total_s: 324.2326891422272
  timers:
    learn_throughput: 11061.318
    learn_time_ms: 14626.829
    sample_throughput: 19383.803
    sample_time_ms: 8346.763
    update_time_ms: 48.447
  timestamp: 1602168086
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     14 |          324.233 | 2265088 |  231.206 |              288.677 |              115.788 |            811.444 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-41-49
  done: false
  episode_len_mean: 809.7795791652294
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 231.36533322183544
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 213
  episodes_total: 2899
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0125
        cur_lr: 0.0001
        entropy: 0.7931252002716065
        entropy_coeff: 0.0
        kl: 0.004137506242841482
        model: {}
        policy_loss: -0.009278535470366478
        total_loss: 4.043600559234619
        vf_explained_var: 0.994229793548584
        vf_loss: 4.052827453613281
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.10740740740741
    gpu_util_percent0: 0.27888888888888885
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.74814814814815
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15836184068580408
    mean_env_wait_ms: 1.6906282085522633
    mean_inference_ms: 4.781390902438848
    mean_raw_obs_processing_ms: 0.42666406366879706
  time_since_restore: 347.4304196834564
  time_this_iter_s: 23.197730541229248
  time_total_s: 347.4304196834564
  timers:
    learn_throughput: 11047.712
    learn_time_ms: 14644.842
    sample_throughput: 19409.959
    sample_time_ms: 8335.515
    update_time_ms: 40.732
  timestamp: 1602168109
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     15 |           347.43 | 2426880 |  231.365 |              288.677 |              115.788 |             809.78 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-42-12
  done: false
  episode_len_mean: 808.0237341772151
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 231.76442590461576
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 261
  episodes_total: 3160
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00625
        cur_lr: 0.0001
        entropy: 0.7400344252586365
        entropy_coeff: 0.0
        kl: 0.004449633415788412
        model: {}
        policy_loss: -0.009077859995886683
        total_loss: 3.836331510543823
        vf_explained_var: 0.9934042096138
        vf_loss: 3.845381498336792
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.846428571428575
    gpu_util_percent0: 0.32107142857142856
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.746428571428572
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15807067128747165
    mean_env_wait_ms: 1.693667309074253
    mean_inference_ms: 4.764110376040568
    mean_raw_obs_processing_ms: 0.4256924896257747
  time_since_restore: 370.61264729499817
  time_this_iter_s: 23.182227611541748
  time_total_s: 370.61264729499817
  timers:
    learn_throughput: 11049.869
    learn_time_ms: 14641.984
    sample_throughput: 19357.003
    sample_time_ms: 8358.319
    update_time_ms: 39.961
  timestamp: 1602168132
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     16 |          370.613 | 2588672 |  231.764 |              288.677 |              115.788 |            808.024 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-42-35
  done: false
  episode_len_mean: 807.008137432188
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 231.96418373000654
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.003125
        cur_lr: 0.0001
        entropy: 0.7521714091300964
        entropy_coeff: 0.0
        kl: 0.004247208032757044
        model: {}
        policy_loss: -0.009852313436567783
        total_loss: 2.982044219970703
        vf_explained_var: 0.9939174652099609
        vf_loss: 2.9918832302093508
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.707692307692305
    gpu_util_percent0: 0.3053846153846153
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.753846153846155
    vram_util_percent0: 0.35560839619547396
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1579022394461879
    mean_env_wait_ms: 1.6953731891799535
    mean_inference_ms: 4.7543977255094765
    mean_raw_obs_processing_ms: 0.42514884750362825
  time_since_restore: 393.4756169319153
  time_this_iter_s: 22.862969636917114
  time_total_s: 393.4756169319153
  timers:
    learn_throughput: 11054.745
    learn_time_ms: 14635.526
    sample_throughput: 19372.308
    sample_time_ms: 8351.715
    update_time_ms: 33.663
  timestamp: 1602168155
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     17 |          393.476 | 2750464 |  231.964 |              288.677 |              115.788 |            807.008 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-42-58
  done: false
  episode_len_mean: 805.9299051996553
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 232.21915796865528
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 163
  episodes_total: 3481
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625
        cur_lr: 0.0001
        entropy: 0.7381846189498902
        entropy_coeff: 0.0
        kl: 0.004328177822753787
        model: {}
        policy_loss: -0.009172114077955484
        total_loss: 2.917393922805786
        vf_explained_var: 0.9944829940795898
        vf_loss: 2.9265593528747558
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.11785714285714
    gpu_util_percent0: 0.28178571428571425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15773946116667256
    mean_env_wait_ms: 1.6971320622924144
    mean_inference_ms: 4.74513156141914
    mean_raw_obs_processing_ms: 0.4246405849896801
  time_since_restore: 416.46622014045715
  time_this_iter_s: 22.99060320854187
  time_total_s: 416.46622014045715
  timers:
    learn_throughput: 11054.526
    learn_time_ms: 14635.815
    sample_throughput: 19392.338
    sample_time_ms: 8343.089
    update_time_ms: 32.205
  timestamp: 1602168178
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     18 |          416.466 | 2912256 |  232.219 |              288.677 |              115.788 |             805.93 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-43-22
  done: false
  episode_len_mean: 803.9720464135021
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 232.52541235136175
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 311
  episodes_total: 3792
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.00078125
        cur_lr: 0.0001
        entropy: 0.6864297270774842
        entropy_coeff: 0.0
        kl: 0.004362223763018846
        model: {}
        policy_loss: -0.00826046927832067
        total_loss: 3.8431320667266844
        vf_explained_var: 0.9940306544303894
        vf_loss: 3.8513891220092775
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.67037037037037
    gpu_util_percent0: 0.3085185185185185
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.744444444444445
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15744898087113082
    mean_env_wait_ms: 1.7002378228642816
    mean_inference_ms: 4.728785812149751
    mean_raw_obs_processing_ms: 0.4237318353742576
  time_since_restore: 439.4688251018524
  time_this_iter_s: 23.002604961395264
  time_total_s: 439.4688251018524
  timers:
    learn_throughput: 11066.491
    learn_time_ms: 14619.991
    sample_throughput: 19378.342
    sample_time_ms: 8349.115
    update_time_ms: 31.875
  timestamp: 1602168202
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     19 |          439.469 | 3074048 |  232.525 |              288.677 |              115.788 |            803.972 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-43-45
  done: false
  episode_len_mean: 802.9111392405064
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 232.70144482802712
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 3950
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.000390625
        cur_lr: 0.0001
        entropy: 0.6822758197784424
        entropy_coeff: 0.0
        kl: 0.004122969135642052
        model: {}
        policy_loss: -0.009366017626598477
        total_loss: 2.7058754444122313
        vf_explained_var: 0.9939733743667603
        vf_loss: 2.7152398586273194
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 36.140740740740746
    gpu_util_percent0: 0.31037037037037035
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.766666666666666
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1573204446907608
    mean_env_wait_ms: 1.7017000289090103
    mean_inference_ms: 4.72131093191033
    mean_raw_obs_processing_ms: 0.42333091450270516
  time_since_restore: 462.5090730190277
  time_this_iter_s: 23.040247917175293
  time_total_s: 462.5090730190277
  timers:
    learn_throughput: 11070.058
    learn_time_ms: 14615.28
    sample_throughput: 19328.753
    sample_time_ms: 8370.535
    update_time_ms: 33.931
  timestamp: 1602168225
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     20 |          462.509 | 3235840 |  232.701 |              288.677 |              115.788 |            802.911 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-44-08
  done: false
  episode_len_mean: 801.9615384615385
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 232.9417790367158
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4108
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0001953125
        cur_lr: 0.0001
        entropy: 0.6939150810241699
        entropy_coeff: 0.0
        kl: 0.0038853091187775134
        model: {}
        policy_loss: -0.00929813077673316
        total_loss: 2.614949655532837
        vf_explained_var: 0.9943389892578125
        vf_loss: 2.624247121810913
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.833333333333336
    gpu_util_percent0: 0.26592592592592595
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75925925925926
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15719667133198242
    mean_env_wait_ms: 1.7031644298599842
    mean_inference_ms: 4.714239145595165
    mean_raw_obs_processing_ms: 0.4229395159758153
  time_since_restore: 485.65324997901917
  time_this_iter_s: 23.144176959991455
  time_total_s: 485.65324997901917
  timers:
    learn_throughput: 11070.544
    learn_time_ms: 14614.638
    sample_throughput: 19285.271
    sample_time_ms: 8389.408
    update_time_ms: 33.475
  timestamp: 1602168248
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     21 |          485.653 | 3397632 |  232.942 |              288.677 |              115.788 |            801.962 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-44-32
  done: false
  episode_len_mean: 800.1752204386163
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 233.58501131596321
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 315
  episodes_total: 4423
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 9.765625e-05
        cur_lr: 0.0001
        entropy: 0.6475955843925476
        entropy_coeff: 0.0
        kl: 0.003918793052434921
        model: {}
        policy_loss: -0.007945702015422284
        total_loss: 3.4012736797332765
        vf_explained_var: 0.9943913221359253
        vf_loss: 3.4092190742492674
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.47142857142857
    gpu_util_percent0: 0.32535714285714284
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.742857142857144
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1569729204858077
    mean_env_wait_ms: 1.7059883116902628
    mean_inference_ms: 4.701383478336435
    mean_raw_obs_processing_ms: 0.4222566740889189
  time_since_restore: 508.79895997047424
  time_this_iter_s: 23.145709991455078
  time_total_s: 508.79895997047424
  timers:
    learn_throughput: 11078.955
    learn_time_ms: 14603.544
    sample_throughput: 19316.858
    sample_time_ms: 8375.689
    update_time_ms: 33.583
  timestamp: 1602168272
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     22 |          508.799 | 3559424 |  233.585 |              288.677 |              115.788 |            800.175 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-44-55
  done: false
  episode_len_mean: 799.3007420340463
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 233.8373124523278
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 159
  episodes_total: 4582
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 4.8828125e-05
        cur_lr: 0.0001
        entropy: 0.6385339140892029
        entropy_coeff: 0.0
        kl: 0.0037956318818032743
        model: {}
        policy_loss: -0.009124751342460513
        total_loss: 2.3122153282165527
        vf_explained_var: 0.9944027066230774
        vf_loss: 2.321339988708496
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.659259259259265
    gpu_util_percent0: 0.31444444444444447
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75925925925926
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15686607057123841
    mean_env_wait_ms: 1.7073114950130759
    mean_inference_ms: 4.695362403696344
    mean_raw_obs_processing_ms: 0.42192678068604056
  time_since_restore: 531.6357023715973
  time_this_iter_s: 22.836742401123047
  time_total_s: 531.6357023715973
  timers:
    learn_throughput: 11084.733
    learn_time_ms: 14595.932
    sample_throughput: 19366.963
    sample_time_ms: 8354.02
    update_time_ms: 31.278
  timestamp: 1602168295
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     23 |          531.636 | 3721216 |  233.837 |              288.677 |              115.788 |            799.301 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-45-18
  done: false
  episode_len_mean: 798.4059071729957
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 234.1428376592934
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 4740
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 2.44140625e-05
        cur_lr: 0.0001
        entropy: 0.6463713765144348
        entropy_coeff: 0.0
        kl: 0.003904386376962066
        model: {}
        policy_loss: -0.009223602898418903
        total_loss: 2.1876787662506105
        vf_explained_var: 0.9942494630813599
        vf_loss: 2.196902322769165
    num_steps_sampled: 3883008
    num_steps_trained: 3883008
  iterations_since_restore: 24
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.148148148148145
    gpu_util_percent0: 0.3351851851851852
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.755555555555556
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1567675331794161
    mean_env_wait_ms: 1.7086348548200254
    mean_inference_ms: 4.689666459554667
    mean_raw_obs_processing_ms: 0.42161265512221974
  time_since_restore: 554.787023305893
  time_this_iter_s: 23.151320934295654
  time_total_s: 554.787023305893
  timers:
    learn_throughput: 11085.586
    learn_time_ms: 14594.808
    sample_throughput: 19367.793
    sample_time_ms: 8353.662
    update_time_ms: 30.65
  timestamp: 1602168318
  timesteps_since_restore: 0
  timesteps_total: 3883008
  training_iteration: 24
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     24 |          554.787 | 3883008 |  234.143 |              288.677 |              115.788 |            798.406 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-45-41
  done: false
  episode_len_mean: 796.8059347181008
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 234.72653538350875
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 315
  episodes_total: 5055
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 1.220703125e-05
        cur_lr: 0.0001
        entropy: 0.6069099187850953
        entropy_coeff: 0.0
        kl: 0.0036325725726783276
        model: {}
        policy_loss: -0.007836669497191907
        total_loss: 3.0046337127685545
        vf_explained_var: 0.9947741627693176
        vf_loss: 3.0124703884124755
    num_steps_sampled: 4044800
    num_steps_trained: 4044800
  iterations_since_restore: 25
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 34.911111111111104
    gpu_util_percent0: 0.35111111111111115
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.74814814814815
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15658621819163357
    mean_env_wait_ms: 1.7111969862610203
    mean_inference_ms: 4.679160978175085
    mean_raw_obs_processing_ms: 0.42103042163008464
  time_since_restore: 577.67347407341
  time_this_iter_s: 22.88645076751709
  time_total_s: 577.67347407341
  timers:
    learn_throughput: 11089.664
    learn_time_ms: 14589.441
    sample_throughput: 19434.128
    sample_time_ms: 8325.148
    update_time_ms: 32.536
  timestamp: 1602168341
  timesteps_since_restore: 0
  timesteps_total: 4044800
  training_iteration: 25
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | RUNNING  | 172.17.0.4:62403 |     25 |          577.673 | 4044800 |  234.727 |              288.677 |              115.788 |            796.806 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_915d0_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3152.0
  date: 2020-10-08_14-46-04
  done: true
  episode_len_mean: 795.9808208668968
  episode_reward_max: 288.6767676767675
  episode_reward_mean: 235.01295656991863
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 159
  episodes_total: 5214
  experiment_id: 9f9d18d1775c479cb62320e4982fbe23
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 6.103515625e-06
        cur_lr: 0.0001
        entropy: 0.5947624206542969
        entropy_coeff: 0.0
        kl: 0.004086209461092949
        model: {}
        policy_loss: -0.008679755637422204
        total_loss: 2.0134088039398192
        vf_explained_var: 0.9947463870048523
        vf_loss: 2.022088623046875
    num_steps_sampled: 4206592
    num_steps_trained: 4206592
  iterations_since_restore: 26
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 35.37037037037037
    gpu_util_percent0: 0.3133333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.75925925925926
    vram_util_percent0: 0.355608396195474
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 62403
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15650096815312411
    mean_env_wait_ms: 1.7124059658181918
    mean_inference_ms: 4.674190634526671
    mean_raw_obs_processing_ms: 0.4207509961899873
  time_since_restore: 600.6030623912811
  time_this_iter_s: 22.929588317871094
  time_total_s: 600.6030623912811
  timers:
    learn_throughput: 11082.218
    learn_time_ms: 14599.244
    sample_throughput: 19516.032
    sample_time_ms: 8290.21
    update_time_ms: 32.612
  timestamp: 1602168364
  timesteps_since_restore: 0
  timesteps_total: 4206592
  training_iteration: 26
  trial_id: 915d0_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | TERMINATED |       |     26 |          600.603 | 4206592 |  235.013 |              288.677 |              115.788 |            795.981 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_915d0_00000 | TERMINATED |       |     26 |          600.603 | 4206592 |  235.013 |              288.677 |              115.788 |            795.981 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


