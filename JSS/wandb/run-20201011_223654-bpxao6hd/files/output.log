2020-10-11 22:36:58,072	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_464e5_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=20595)[0m 2020-10-11 22:37:00,804	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=20490)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20490)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20492)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20492)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20480)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20480)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20555)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20555)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20603)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20603)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20546)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20546)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20559)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20559)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20542)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20542)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20600)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20600)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20553)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20553)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20506)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20506)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20571)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20571)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20504)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20504)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20583)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20583)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20569)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20569)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20558)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20558)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20565)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20565)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20567)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20567)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20491)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20491)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20584)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20584)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20573)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20573)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20570)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20570)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20508)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20508)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20539)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20539)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20563)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20563)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20591)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20591)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20589)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20589)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20575)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20575)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20585)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20585)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20578)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20578)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20535)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20535)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20479)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20479)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20581)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20581)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20513)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20513)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20596)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20596)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20598)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20598)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20557)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20557)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20545)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20545)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20483)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20483)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20586)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20586)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20564)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20564)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20484)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20484)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20562)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20562)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20488)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20488)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20548)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20548)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20481)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20481)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20604)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20604)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20494)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20494)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20593)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20593)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20560)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20560)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20534)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20534)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20478)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20478)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20511)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20511)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20495)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20495)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20486)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20486)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20502)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20502)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20498)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20498)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20497)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20497)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20500)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20500)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20594)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20594)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20499)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20499)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20554)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20554)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20485)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20485)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20552)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20552)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20608)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20608)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20561)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20561)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20550)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20550)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20501)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20501)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20556)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20556)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20582)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20582)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20487)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20487)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20588)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20588)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20541)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20541)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20482)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20482)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20509)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20509)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20512)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20512)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20547)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20547)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20496)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20496)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=20566)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=20566)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_22-37-39
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1845979293187459
        entropy_coeff: 0.0001
        kl: 0.004941714345477521
        model: {}
        policy_loss: -0.010662895229567463
        total_loss: 502.23693593343097
        vf_explained_var: 0.5664147734642029
        vf_loss: 502.24672444661456
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.3078947368421
    gpu_util_percent0: 0.27263157894736845
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.581578947368421
    vram_util_percent0: 0.08852341578774753
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1709864882268667
    mean_env_wait_ms: 1.1727252570373405
    mean_inference_ms: 6.045924181112283
    mean_raw_obs_processing_ms: 0.466055138385675
  time_since_restore: 33.210957765579224
  time_this_iter_s: 33.210957765579224
  time_total_s: 33.210957765579224
  timers:
    learn_throughput: 6809.509
    learn_time_ms: 23759.717
    sample_throughput: 17274.599
    sample_time_ms: 9365.89
    update_time_ms: 44.821
  timestamp: 1602455859
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |      1 |           33.211 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4055
    time_step_mean: 3620.9201388888887
    time_step_min: 3341
  date: 2020-10-11_22-38-10
  done: false
  episode_len_mean: 890.6012658227849
  episode_reward_max: 262.6868686868683
  episode_reward_mean: 215.81786216596322
  episode_reward_min: 116.4747474747471
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1522138218084972
        entropy_coeff: 0.0001
        kl: 0.007931098264331618
        model: {}
        policy_loss: -0.011280511661122242
        total_loss: 126.10309092203777
        vf_explained_var: 0.8166090846061707
        vf_loss: 126.1136926015218
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.45945945945946
    gpu_util_percent0: 0.3964864864864865
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7648648648648653
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16601361537400058
    mean_env_wait_ms: 1.1676370170506412
    mean_inference_ms: 5.746144217068622
    mean_raw_obs_processing_ms: 0.4513872482897545
  time_since_restore: 64.5746717453003
  time_this_iter_s: 31.36371397972107
  time_total_s: 64.5746717453003
  timers:
    learn_throughput: 6839.046
    learn_time_ms: 23657.102
    sample_throughput: 18933.355
    sample_time_ms: 8545.342
    update_time_ms: 42.091
  timestamp: 1602455890
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |      2 |          64.5747 | 323584 |  215.818 |              262.687 |              116.475 |            890.601 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4055
    time_step_mean: 3616.4058295964123
    time_step_min: 3341
  date: 2020-10-11_22-38-41
  done: false
  episode_len_mean: 884.4451476793249
  episode_reward_max: 262.6868686868683
  episode_reward_mean: 218.03752717043835
  episode_reward_min: 116.4747474747471
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1405681769053142
        entropy_coeff: 0.0001
        kl: 0.009609605185687542
        model: {}
        policy_loss: -0.0148115831737717
        total_loss: 52.60168711344401
        vf_explained_var: 0.9039597511291504
        vf_loss: 52.61565113067627
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.26388888888889
    gpu_util_percent0: 0.35805555555555557
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7750000000000004
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16286926748766503
    mean_env_wait_ms: 1.1667210602926887
    mean_inference_ms: 5.527901171430794
    mean_raw_obs_processing_ms: 0.4410277934407256
  time_since_restore: 95.47832226753235
  time_this_iter_s: 30.903650522232056
  time_total_s: 95.47832226753235
  timers:
    learn_throughput: 6846.04
    learn_time_ms: 23632.933
    sample_throughput: 19954.595
    sample_time_ms: 8108.007
    update_time_ms: 41.327
  timestamp: 1602455921
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |      3 |          95.4783 | 485376 |  218.038 |              262.687 |              116.475 |            884.445 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3615.4139072847684
    time_step_min: 3304
  date: 2020-10-11_22-39-12
  done: false
  episode_len_mean: 879.493670886076
  episode_reward_max: 265.41414141414066
  episode_reward_mean: 217.98894003324364
  episode_reward_min: 110.4141414141415
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1268143057823181
        entropy_coeff: 0.0001
        kl: 0.008136198157444596
        model: {}
        policy_loss: -0.01660729798216683
        total_loss: 42.11880366007487
        vf_explained_var: 0.9290847182273865
        vf_loss: 42.13470904032389
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.344444444444445
    gpu_util_percent0: 0.39888888888888896
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775000000000001
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1606722252527083
    mean_env_wait_ms: 1.1674164729728762
    mean_inference_ms: 5.369054506163647
    mean_raw_obs_processing_ms: 0.43327878860180546
  time_since_restore: 125.9015519618988
  time_this_iter_s: 30.423229694366455
  time_total_s: 125.9015519618988
  timers:
    learn_throughput: 6863.426
    learn_time_ms: 23573.067
    sample_throughput: 20738.573
    sample_time_ms: 7801.501
    update_time_ms: 54.985
  timestamp: 1602455952
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |      4 |          125.902 | 647168 |  217.989 |              265.414 |              110.414 |            879.494 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4327
    time_step_mean: 3611.709973753281
    time_step_min: 3304
  date: 2020-10-11_22-39-43
  done: false
  episode_len_mean: 874.4481012658227
  episode_reward_max: 274.0505050505043
  episode_reward_mean: 218.87674210459
  episode_reward_min: 110.4141414141415
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0861701965332031
        entropy_coeff: 0.0001
        kl: 0.007670978588672976
        model: {}
        policy_loss: -0.013802881830542901
        total_loss: 30.548245588938396
        vf_explained_var: 0.9537122845649719
        vf_loss: 30.561390558878582
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.33333333333333
    gpu_util_percent0: 0.3863888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7805555555555563
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15902749011074196
    mean_env_wait_ms: 1.1687479805580157
    mean_inference_ms: 5.249240601078677
    mean_raw_obs_processing_ms: 0.42731383159001796
  time_since_restore: 156.58544993400574
  time_this_iter_s: 30.683897972106934
  time_total_s: 156.58544993400574
  timers:
    learn_throughput: 6864.504
    learn_time_ms: 23569.364
    sample_throughput: 21197.012
    sample_time_ms: 7632.774
    update_time_ms: 52.818
  timestamp: 1602455983
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |      5 |          156.585 | 808960 |  218.877 |              274.051 |              110.414 |            874.448 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3603.586592178771
    time_step_min: 3234
  date: 2020-10-11_22-40-13
  done: false
  episode_len_mean: 865.5980036297641
  episode_reward_max: 276.0202020202017
  episode_reward_mean: 220.3214724376247
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 312
  episodes_total: 1102
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0862921973069508
        entropy_coeff: 0.0001
        kl: 0.007875574054196477
        model: {}
        policy_loss: -0.013222926047092187
        total_loss: 36.798745473225914
        vf_explained_var: 0.9591273665428162
        vf_loss: 36.811290423075356
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.857142857142858
    gpu_util_percent0: 0.2511428571428571
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15684983095580493
    mean_env_wait_ms: 1.1723367237419444
    mean_inference_ms: 5.088898650467079
    mean_raw_obs_processing_ms: 0.4196855886651211
  time_since_restore: 187.10088276863098
  time_this_iter_s: 30.515432834625244
  time_total_s: 187.10088276863098
  timers:
    learn_throughput: 6869.126
    learn_time_ms: 23553.504
    sample_throughput: 21518.003
    sample_time_ms: 7518.913
    update_time_ms: 50.639
  timestamp: 1602456013
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |      6 |          187.101 | 970752 |  220.321 |               276.02 |              109.051 |            865.598 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3596.4053398058254
    time_step_min: 3234
  date: 2020-10-11_22-40-44
  done: false
  episode_len_mean: 861.0213607594936
  episode_reward_max: 276.0202020202017
  episode_reward_mean: 221.51969856795785
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 162
  episodes_total: 1264
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0740437110265095
        entropy_coeff: 0.0001
        kl: 0.008695898888011774
        model: {}
        policy_loss: -0.015221895941067487
        total_loss: 17.440695921579998
        vf_explained_var: 0.9710730910301208
        vf_loss: 17.45515553156535
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.363888888888887
    gpu_util_percent0: 0.34888888888888886
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7888888888888896
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1560731897763871
    mean_env_wait_ms: 1.1739767886767984
    mean_inference_ms: 5.030114953919625
    mean_raw_obs_processing_ms: 0.41682484436412026
  time_since_restore: 217.43423128128052
  time_this_iter_s: 30.333348512649536
  time_total_s: 217.43423128128052
  timers:
    learn_throughput: 6879.475
    learn_time_ms: 23518.073
    sample_throughput: 21752.928
    sample_time_ms: 7437.711
    update_time_ms: 47.571
  timestamp: 1602456044
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |      7 |          217.434 | 1132544 |   221.52 |               276.02 |              109.051 |            861.021 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3589.5918220946915
    time_step_min: 3234
  date: 2020-10-11_22-41-14
  done: false
  episode_len_mean: 856.4817158931083
  episode_reward_max: 276.0202020202017
  episode_reward_mean: 222.6242168520648
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0498243769009907
        entropy_coeff: 0.0001
        kl: 0.007762666131990652
        model: {}
        policy_loss: -0.01506129972403869
        total_loss: 18.5674090385437
        vf_explained_var: 0.9686254858970642
        vf_loss: 18.581799030303955
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.677142857142854
    gpu_util_percent0: 0.36228571428571427
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857143
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1554092153087157
    mean_env_wait_ms: 1.175453235425848
    mean_inference_ms: 4.980023816857444
    mean_raw_obs_processing_ms: 0.41435980010910656
  time_since_restore: 247.85090947151184
  time_this_iter_s: 30.416678190231323
  time_total_s: 247.85090947151184
  timers:
    learn_throughput: 6881.704
    learn_time_ms: 23510.457
    sample_throughput: 21963.773
    sample_time_ms: 7366.312
    update_time_ms: 46.247
  timestamp: 1602456074
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |      8 |          247.851 | 1294336 |  222.624 |               276.02 |              109.051 |            856.482 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3583.8647778493237
    time_step_min: 3234
  date: 2020-10-11_22-41-44
  done: false
  episode_len_mean: 852.1638203668564
  episode_reward_max: 276.0202020202017
  episode_reward_mean: 223.5045329959939
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 159
  episodes_total: 1581
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0068772335847218
        entropy_coeff: 0.0001
        kl: 0.009047625819221139
        model: {}
        policy_loss: -0.015237496777748069
        total_loss: 19.367111682891846
        vf_explained_var: 0.9707355499267578
        vf_loss: 19.381545066833496
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.54571428571429
    gpu_util_percent0: 0.3985714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15482162150775963
    mean_env_wait_ms: 1.1769815047550416
    mean_inference_ms: 4.935997720633613
    mean_raw_obs_processing_ms: 0.41211952667293145
  time_since_restore: 277.999370098114
  time_this_iter_s: 30.148460626602173
  time_total_s: 277.999370098114
  timers:
    learn_throughput: 6892.649
    learn_time_ms: 23473.124
    sample_throughput: 22121.382
    sample_time_ms: 7313.829
    update_time_ms: 44.386
  timestamp: 1602456104
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |      9 |          277.999 | 1456128 |  223.505 |               276.02 |              109.051 |            852.164 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3569.9983905579397
    time_step_min: 3234
  date: 2020-10-11_22-42-15
  done: false
  episode_len_mean: 844.4392177589853
  episode_reward_max: 276.92929292929244
  episode_reward_mean: 225.801978559378
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 311
  episodes_total: 1892
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9910648465156555
        entropy_coeff: 0.0001
        kl: 0.007140809126819174
        model: {}
        policy_loss: -0.012344766136569282
        total_loss: 26.632726192474365
        vf_explained_var: 0.9699724316596985
        vf_loss: 26.64445622762044
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.430555555555557
    gpu_util_percent0: 0.3638888888888888
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7666666666666675
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15390282128533028
    mean_env_wait_ms: 1.1801258422692928
    mean_inference_ms: 4.866170993606957
    mean_raw_obs_processing_ms: 0.4086202401385703
  time_since_restore: 308.18533086776733
  time_this_iter_s: 30.18596076965332
  time_total_s: 308.18533086776733
  timers:
    learn_throughput: 6900.583
    learn_time_ms: 23446.135
    sample_throughput: 22247.917
    sample_time_ms: 7272.231
    update_time_ms: 43.558
  timestamp: 1602456135
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |     10 |          308.185 | 1617920 |  225.802 |              276.929 |              109.051 |            844.439 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3561.7685093780847
    time_step_min: 3234
  date: 2020-10-11_22-42-45
  done: false
  episode_len_mean: 840.8851022395327
  episode_reward_max: 276.929292929293
  episode_reward_mean: 227.08811090456646
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 162
  episodes_total: 2054
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9775462100903193
        entropy_coeff: 0.0001
        kl: 0.007571308485542734
        model: {}
        policy_loss: -0.017289329320192337
        total_loss: 13.902438004811605
        vf_explained_var: 0.9763643145561218
        vf_loss: 13.919067939122518
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.231428571428573
    gpu_util_percent0: 0.41
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142865
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15350281525740855
    mean_env_wait_ms: 1.181539180186657
    mean_inference_ms: 4.836492322906737
    mean_raw_obs_processing_ms: 0.4071110397360932
  time_since_restore: 338.2397699356079
  time_this_iter_s: 30.054439067840576
  time_total_s: 338.2397699356079
  timers:
    learn_throughput: 6917.413
    learn_time_ms: 23389.09
    sample_throughput: 23064.008
    sample_time_ms: 7014.912
    update_time_ms: 40.997
  timestamp: 1602456165
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |     11 |           338.24 | 1779712 |  227.088 |              276.929 |              109.051 |            840.885 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3553.1080586080584
    time_step_min: 3198
  date: 2020-10-11_22-43-15
  done: false
  episode_len_mean: 837.8318264014466
  episode_reward_max: 281.4747474747478
  episode_reward_mean: 228.27409264434567
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9627491434415182
        entropy_coeff: 0.0001
        kl: 0.007169151833901803
        model: {}
        policy_loss: -0.014201596456890305
        total_loss: 13.748513221740723
        vf_explained_var: 0.9749014377593994
        vf_loss: 13.762094418207804
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.70857142857143
    gpu_util_percent0: 0.3974285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428585
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1531557496438834
    mean_env_wait_ms: 1.1828626024605755
    mean_inference_ms: 4.810171097819315
    mean_raw_obs_processing_ms: 0.40575352610470433
  time_since_restore: 368.59873723983765
  time_this_iter_s: 30.358967304229736
  time_total_s: 368.59873723983765
  timers:
    learn_throughput: 6923.184
    learn_time_ms: 23369.594
    sample_throughput: 23335.005
    sample_time_ms: 6933.446
    update_time_ms: 40.877
  timestamp: 1602456195
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |     12 |          368.599 | 1941504 |  228.274 |              281.475 |              109.051 |            837.832 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3540.2184145334436
    time_step_min: 3159
  date: 2020-10-11_22-43-46
  done: false
  episode_len_mean: 833.4930612244898
  episode_reward_max: 287.383838383838
  episode_reward_mean: 230.2338693052978
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 238
  episodes_total: 2450
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9222608854373296
        entropy_coeff: 0.0001
        kl: 0.007358024129644036
        model: {}
        policy_loss: -0.012704586464678869
        total_loss: 16.081321795781452
        vf_explained_var: 0.9782974123954773
        vf_loss: 16.093383073806763
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.81388888888889
    gpu_util_percent0: 0.34444444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7722222222222226
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15269725081909707
    mean_env_wait_ms: 1.1850057837523493
    mean_inference_ms: 4.774899713816689
    mean_raw_obs_processing_ms: 0.4039404237421066
  time_since_restore: 399.1246700286865
  time_this_iter_s: 30.525932788848877
  time_total_s: 399.1246700286865
  timers:
    learn_throughput: 6929.134
    learn_time_ms: 23349.527
    sample_throughput: 23425.686
    sample_time_ms: 6906.607
    update_time_ms: 41.237
  timestamp: 1602456226
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |     13 |          399.125 | 2103296 |  230.234 |              287.384 |              109.051 |            833.493 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3529.1568848758466
    time_step_min: 3159
  date: 2020-10-11_22-44-16
  done: false
  episode_len_mean: 829.5833953834698
  episode_reward_max: 287.383838383838
  episode_reward_mean: 231.85658145114576
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 236
  episodes_total: 2686
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9192133545875549
        entropy_coeff: 0.0001
        kl: 0.006822101616611083
        model: {}
        policy_loss: -0.016151844184302416
        total_loss: 12.465920289357504
        vf_explained_var: 0.9800860285758972
        vf_loss: 12.481482028961182
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.742857142857144
    gpu_util_percent0: 0.3194285714285714
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.774285714285715
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15230035439091136
    mean_env_wait_ms: 1.1867606583754347
    mean_inference_ms: 4.745267687818374
    mean_raw_obs_processing_ms: 0.4024153341292347
  time_since_restore: 429.443660736084
  time_this_iter_s: 30.31899070739746
  time_total_s: 429.443660736084
  timers:
    learn_throughput: 6930.047
    learn_time_ms: 23346.452
    sample_throughput: 23429.892
    sample_time_ms: 6905.367
    update_time_ms: 34.912
  timestamp: 1602456256
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |     14 |          429.444 | 2265088 |  231.857 |              287.384 |              109.051 |            829.583 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3521.4108664772725
    time_step_min: 3159
  date: 2020-10-11_22-44-47
  done: false
  episode_len_mean: 827.1944444444445
  episode_reward_max: 287.383838383838
  episode_reward_mean: 233.05580062225619
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9072132706642151
        entropy_coeff: 0.0001
        kl: 0.007571491063572466
        model: {}
        policy_loss: -0.014775883017743277
        total_loss: 10.67902167638143
        vf_explained_var: 0.9788177013397217
        vf_loss: 10.693131049474081
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.831428571428575
    gpu_util_percent0: 0.35057142857142864
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7771428571428576
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15206390711784196
    mean_env_wait_ms: 1.1878805094113136
    mean_inference_ms: 4.72733355444684
    mean_raw_obs_processing_ms: 0.40147946868879114
  time_since_restore: 459.78143763542175
  time_this_iter_s: 30.33777689933777
  time_total_s: 459.78143763542175
  timers:
    learn_throughput: 6933.128
    learn_time_ms: 23336.077
    sample_throughput: 23485.331
    sample_time_ms: 6889.066
    update_time_ms: 33.883
  timestamp: 1602456287
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |     15 |          459.781 | 2426880 |  233.056 |              287.384 |              109.051 |            827.194 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3513.1579826319307
    time_step_min: 3159
  date: 2020-10-11_22-45-17
  done: false
  episode_len_mean: 824.6796823295831
  episode_reward_max: 287.383838383838
  episode_reward_mean: 234.19615412898
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 178
  episodes_total: 3022
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8721793442964554
        entropy_coeff: 0.0001
        kl: 0.006953845770719151
        model: {}
        policy_loss: -0.013813901699904818
        total_loss: 13.542894045511881
        vf_explained_var: 0.977494478225708
        vf_loss: 13.55609941482544
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.302777777777777
    gpu_util_percent0: 0.38249999999999995
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7777777777777795
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15181826142344232
    mean_env_wait_ms: 1.1891638541055272
    mean_inference_ms: 4.70871468666551
    mean_raw_obs_processing_ms: 0.4004911129453595
  time_since_restore: 490.1942517757416
  time_this_iter_s: 30.412814140319824
  time_total_s: 490.1942517757416
  timers:
    learn_throughput: 6934.685
    learn_time_ms: 23330.836
    sample_throughput: 23505.234
    sample_time_ms: 6883.233
    update_time_ms: 33.809
  timestamp: 1602456317
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |     16 |          490.194 | 2588672 |  234.196 |              287.384 |              109.051 |             824.68 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3499.5743387047737
    time_step_min: 3159
  date: 2020-10-11_22-45-48
  done: false
  episode_len_mean: 820.9131745553211
  episode_reward_max: 287.383838383838
  episode_reward_mean: 236.24466552775257
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 295
  episodes_total: 3317
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8561922212441763
        entropy_coeff: 0.0001
        kl: 0.006693084452611704
        model: {}
        policy_loss: -0.013814363735339915
        total_loss: 11.206264972686768
        vf_explained_var: 0.9836785793304443
        vf_loss: 11.219495217005411
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.525000000000002
    gpu_util_percent0: 0.3277777777777777
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.775000000000001
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15145456181720743
    mean_env_wait_ms: 1.1910947337496394
    mean_inference_ms: 4.68126834021086
    mean_raw_obs_processing_ms: 0.3990596426412291
  time_since_restore: 520.8253149986267
  time_this_iter_s: 30.631063222885132
  time_total_s: 520.8253149986267
  timers:
    learn_throughput: 6930.057
    learn_time_ms: 23346.415
    sample_throughput: 23456.833
    sample_time_ms: 6897.436
    update_time_ms: 32.654
  timestamp: 1602456348
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |     17 |          520.825 | 2750464 |  236.245 |              287.384 |              109.051 |            820.913 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3494.1809744779584
    time_step_min: 3159
  date: 2020-10-11_22-46-19
  done: false
  episode_len_mean: 819.0002876869966
  episode_reward_max: 287.383838383838
  episode_reward_mean: 237.06808011065772
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 159
  episodes_total: 3476
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8518367956082026
        entropy_coeff: 0.0001
        kl: 0.006655753046895067
        model: {}
        policy_loss: -0.012292408112746974
        total_loss: 10.00081737836202
        vf_explained_var: 0.9804852604866028
        vf_loss: 10.012529214223227
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.986111111111114
    gpu_util_percent0: 0.32166666666666666
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7833333333333337
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15127742565541663
    mean_env_wait_ms: 1.1920571134869653
    mean_inference_ms: 4.668057023629457
    mean_raw_obs_processing_ms: 0.3983676464171298
  time_since_restore: 551.2857551574707
  time_this_iter_s: 30.460440158843994
  time_total_s: 551.2857551574707
  timers:
    learn_throughput: 6936.427
    learn_time_ms: 23324.976
    sample_throughput: 23390.949
    sample_time_ms: 6916.863
    update_time_ms: 30.899
  timestamp: 1602456379
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |     18 |          551.286 | 2912256 |  237.068 |              287.384 |              109.051 |                819 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3487.922949002217
    time_step_min: 3159
  date: 2020-10-11_22-46-49
  done: false
  episode_len_mean: 817.3264576457645
  episode_reward_max: 288.89898989898944
  episode_reward_mean: 238.01173450678394
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 160
  episodes_total: 3636
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8309680372476578
        entropy_coeff: 0.0001
        kl: 0.0074748302189012366
        model: {}
        policy_loss: -0.012168505093238005
        total_loss: 9.40784764289856
        vf_explained_var: 0.9818739295005798
        vf_loss: 9.41935165723165
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.82857142857143
    gpu_util_percent0: 0.31885714285714284
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.782857142857143
    vram_util_percent0: 0.10437848474909808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15111086640792815
    mean_env_wait_ms: 1.1930021697517932
    mean_inference_ms: 4.6555174285960375
    mean_raw_obs_processing_ms: 0.39770885249162735
  time_since_restore: 581.8356490135193
  time_this_iter_s: 30.549893856048584
  time_total_s: 581.8356490135193
  timers:
    learn_throughput: 6928.286
    learn_time_ms: 23352.383
    sample_throughput: 23353.515
    sample_time_ms: 6927.951
    update_time_ms: 31.857
  timestamp: 1602456409
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | RUNNING  | 172.17.0.4:20595 |     19 |          581.836 | 3074048 |  238.012 |              288.899 |              109.051 |            817.326 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_464e5_00000:
  custom_metrics:
    time_step_max: 4336
    time_step_mean: 3477.6596016343206
    time_step_min: 3086
  date: 2020-10-11_22-47-20
  done: true
  episode_len_mean: 814.6970081135903
  episode_reward_max: 298.4444444444441
  episode_reward_mean: 239.52641014608554
  episode_reward_min: 109.05050505050495
  episodes_this_iter: 308
  episodes_total: 3944
  experiment_id: c37eb0a62aad43109825291aa33d5a5d
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8081399450699488
        entropy_coeff: 0.0001
        kl: 0.006784297137831648
        model: {}
        policy_loss: -0.01104643041617237
        total_loss: 11.86494255065918
        vf_explained_var: 0.9839428067207336
        vf_loss: 11.875391324361166
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.32777777777778
    gpu_util_percent0: 0.4469444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.769444444444445
    vram_util_percent0: 0.1043784847490981
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 20595
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1508168530109735
    mean_env_wait_ms: 1.1947139092048398
    mean_inference_ms: 4.6336299317292715
    mean_raw_obs_processing_ms: 0.39656644725693513
  time_since_restore: 611.9285409450531
  time_this_iter_s: 30.092891931533813
  time_total_s: 611.9285409450531
  timers:
    learn_throughput: 6930.915
    learn_time_ms: 23343.528
    sample_throughput: 23383.12
    sample_time_ms: 6919.179
    update_time_ms: 38.927
  timestamp: 1602456440
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 464e5_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | TERMINATED |       |     20 |          611.929 | 3235840 |  239.526 |              298.444 |              109.051 |            814.697 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


[2m[33m(pid=raylet)[0m E1011 22:47:20.259284 20437 20437 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
[2m[33m(pid=raylet)[0m E1011 22:47:20.259577 20437 20437 node_manager.cc:3307] Failed to send get core worker stats request: IOError: 2: HandleServiceClosed
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.06 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_464e5_00000 | TERMINATED |       |     20 |          611.929 | 3235840 |  239.526 |              298.444 |              109.051 |            814.697 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


