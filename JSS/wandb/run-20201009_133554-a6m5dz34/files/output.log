2020-10-09 13:35:58,773	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_5e362_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=55337)[0m 2020-10-09 13:36:01,753	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=55323)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55323)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55282)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55282)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55320)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55320)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55335)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55335)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55314)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55314)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55302)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55302)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55274)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55274)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55269)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55269)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55309)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55309)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55326)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55326)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55296)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55296)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55279)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55279)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55307)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55307)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55213)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55213)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55273)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55273)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55210)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55210)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55265)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55265)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55231)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55277)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55277)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55192)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55192)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55306)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55306)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55284)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55284)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55202)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55202)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55267)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55267)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55218)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55218)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55281)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55281)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55278)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55278)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55205)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55205)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55303)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55303)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55313)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55313)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55328)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55328)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55271)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55271)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55276)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55276)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55300)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55300)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55208)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55208)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55290)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55290)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55322)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55322)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55318)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55318)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55275)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55275)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55308)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55308)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55227)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55227)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55289)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55289)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55268)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55268)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55214)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55214)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55203)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55203)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55311)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55311)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55332)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55332)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55297)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55297)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55216)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55216)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55287)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55287)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55288)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55288)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55304)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55304)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55201)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55201)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55228)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55228)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55286)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55286)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55232)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55232)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55211)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55211)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55339)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55339)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55285)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55285)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55272)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55272)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55331)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55331)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55321)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55321)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=55261)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=55261)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 3881
    time_step_mean: 3492.772151898734
    time_step_min: 3239
  date: 2020-10-09_13-36-37
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 275.262626262626
  episode_reward_mean: 237.0673826876358
  episode_reward_min: 160.7171717171719
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.0391179323196411
        entropy_coeff: 0.0
        kl: 0.003930288239974867
        model: {}
        policy_loss: -0.008114830288501584
        total_loss: 690.5431629527699
        vf_explained_var: 0.47140324115753174
        vf_loss: 690.5504927201705
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.202777777777776
    gpu_util_percent0: 0.34805555555555556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6083333333333334
    vram_util_percent0: 0.09247111985714808
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15994906977541323
    mean_env_wait_ms: 1.2856097838215415
    mean_inference_ms: 4.885685909821245
    mean_raw_obs_processing_ms: 0.41751893960093617
  time_since_restore: 30.201366186141968
  time_this_iter_s: 30.201366186141968
  time_total_s: 30.201366186141968
  timers:
    learn_throughput: 7247.415
    learn_time_ms: 22324.098
    sample_throughput: 20729.349
    sample_time_ms: 7804.973
    update_time_ms: 46.165
  timestamp: 1602250597
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 27.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |      1 |          30.2014 | 161792 |  237.067 |              275.263 |              160.717 |                750 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 3881
    time_step_mean: 3478.3037974683543
    time_step_min: 3230
  date: 2020-10-09_13-37-07
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 276.77777777777754
  episode_reward_mean: 238.09538422196644
  episode_reward_min: 160.7171717171719
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9955163923176852
        entropy_coeff: 0.0
        kl: 0.005713307722048326
        model: {}
        policy_loss: -0.007571520812978799
        total_loss: 221.941162109375
        vf_explained_var: 0.7810420989990234
        vf_loss: 221.9481658935547
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.845714285714287
    gpu_util_percent0: 0.36142857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7628571428571425
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15770606303162646
    mean_env_wait_ms: 1.280185215677775
    mean_inference_ms: 4.815813108590827
    mean_raw_obs_processing_ms: 0.4137064980018926
  time_since_restore: 60.16864800453186
  time_this_iter_s: 29.967281818389893
  time_total_s: 60.16864800453186
  timers:
    learn_throughput: 7267.114
    learn_time_ms: 22263.584
    sample_throughput: 20973.769
    sample_time_ms: 7714.016
    update_time_ms: 40.867
  timestamp: 1602250627
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |      2 |          60.1686 | 323584 |  238.095 |              276.778 |              160.717 |                750 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 3881
    time_step_mean: 3489.731012658228
    time_step_min: 3213
  date: 2020-10-09_13-37-36
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 284.80808080808066
  episode_reward_mean: 237.6290915483953
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 316
  episodes_total: 632
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9705960100347345
        entropy_coeff: 0.0
        kl: 0.004600797525861047
        model: {}
        policy_loss: -0.0023570905799384823
        total_loss: 84.55741466175427
        vf_explained_var: 0.8955318927764893
        vf_loss: 84.55931160666726
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.42941176470588
    gpu_util_percent0: 0.3523529411764706
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7882352941176474
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15508777704935253
    mean_env_wait_ms: 1.2848500345721092
    mean_inference_ms: 4.707094332987877
    mean_raw_obs_processing_ms: 0.4074253827492406
  time_since_restore: 89.59384441375732
  time_this_iter_s: 29.425196409225464
  time_total_s: 89.59384441375732
  timers:
    learn_throughput: 7278.397
    learn_time_ms: 22229.072
    sample_throughput: 21466.226
    sample_time_ms: 7537.049
    update_time_ms: 37.733
  timestamp: 1602250656
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |      3 |          89.5938 | 485376 |  237.629 |              284.808 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 3881
    time_step_mean: 3481.9088607594936
    time_step_min: 3213
  date: 2020-10-09_13-38-06
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 284.80808080808066
  episode_reward_mean: 238.75054340877122
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.9944241426207803
        entropy_coeff: 0.0
        kl: 0.007234951989217238
        model: {}
        policy_loss: -0.005660713737597689
        total_loss: 42.249093142422765
        vf_explained_var: 0.9134978652000427
        vf_loss: 42.254392797296696
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.703030303030303
    gpu_util_percent0: 0.37636363636363634
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8151515151515154
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15423361289683554
    mean_env_wait_ms: 1.2848869112825863
    mean_inference_ms: 4.668482015702295
    mean_raw_obs_processing_ms: 0.40486926714605775
  time_since_restore: 118.76312279701233
  time_this_iter_s: 29.169278383255005
  time_total_s: 118.76312279701233
  timers:
    learn_throughput: 7278.89
    learn_time_ms: 22227.565
    sample_throughput: 21962.947
    sample_time_ms: 7366.589
    update_time_ms: 38.817
  timestamp: 1602250686
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |      4 |          118.763 | 647168 |  238.751 |              284.808 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 3881
    time_step_mean: 3475.1223628691982
    time_step_min: 3213
  date: 2020-10-09_13-38-35
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 284.80808080808066
  episode_reward_mean: 239.66759365809997
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 158
  episodes_total: 948
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.971183717250824
        entropy_coeff: 0.0
        kl: 0.005800729998472062
        model: {}
        policy_loss: -0.010072850368239662
        total_loss: 29.464095722545277
        vf_explained_var: 0.9369828701019287
        vf_loss: 29.4738786870783
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.988235294117647
    gpu_util_percent0: 0.3394117647058823
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8088235294117654
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15347098026559977
    mean_env_wait_ms: 1.284110427426189
    mean_inference_ms: 4.633786428903935
    mean_raw_obs_processing_ms: 0.4023295614329984
  time_since_restore: 147.9642038345337
  time_this_iter_s: 29.201081037521362
  time_total_s: 147.9642038345337
  timers:
    learn_throughput: 7282.615
    learn_time_ms: 22216.197
    sample_throughput: 22219.561
    sample_time_ms: 7281.512
    update_time_ms: 39.474
  timestamp: 1602250715
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |      5 |          147.964 | 808960 |  239.668 |              284.808 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3463.8354430379745
    time_step_min: 3139
  date: 2020-10-09_13-39-04
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 290.4141414141415
  episode_reward_mean: 241.47942238844138
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 316
  episodes_total: 1264
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.9454294443130493
        entropy_coeff: 0.0
        kl: 0.006286031820557334
        model: {}
        policy_loss: -0.007169995226749134
        total_loss: 30.782751256769355
        vf_explained_var: 0.9594754576683044
        vf_loss: 30.789606961337004
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.438235294117646
    gpu_util_percent0: 0.3391176470588235
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7911764705882356
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1523286568518475
    mean_env_wait_ms: 1.2842457473509203
    mean_inference_ms: 4.581191795080461
    mean_raw_obs_processing_ms: 0.39868544487908186
  time_since_restore: 177.24936723709106
  time_this_iter_s: 29.285163402557373
  time_total_s: 177.24936723709106
  timers:
    learn_throughput: 7284.886
    learn_time_ms: 22209.269
    sample_throughput: 22358.264
    sample_time_ms: 7236.34
    update_time_ms: 39.177
  timestamp: 1602250744
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |      6 |          177.249 | 970752 |  241.479 |              290.414 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3461.7890295358648
    time_step_min: 3139
  date: 2020-10-09_13-39-34
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 290.4141414141415
  episode_reward_mean: 242.02785236329538
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.9702570221640847
        entropy_coeff: 0.0
        kl: 0.006504926449534568
        model: {}
        policy_loss: -0.011831911201377145
        total_loss: 16.86334904757413
        vf_explained_var: 0.9645392894744873
        vf_loss: 16.874855995178223
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.817647058823532
    gpu_util_percent0: 0.38794117647058823
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8117647058823527
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15189779545658152
    mean_env_wait_ms: 1.283868029402868
    mean_inference_ms: 4.560920609340746
    mean_raw_obs_processing_ms: 0.3972281145505193
  time_since_restore: 206.51884937286377
  time_this_iter_s: 29.269482135772705
  time_total_s: 206.51884937286377
  timers:
    learn_throughput: 7282.138
    learn_time_ms: 22217.65
    sample_throughput: 22539.043
    sample_time_ms: 7178.3
    update_time_ms: 49.998
  timestamp: 1602250774
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |      7 |          206.519 | 1132544 |  242.028 |              290.414 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3458.5164556962027
    time_step_min: 3139
  date: 2020-10-09_13-40-03
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 290.4141414141415
  episode_reward_mean: 242.7520777394195
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.9141646515239369
        entropy_coeff: 0.0
        kl: 0.005662636027078737
        model: {}
        policy_loss: -0.010353188694518229
        total_loss: 19.32807766307484
        vf_explained_var: 0.9641259908676147
        vf_loss: 19.33814777027477
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.05757575757576
    gpu_util_percent0: 0.3984848484848485
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.809090909090909
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15151369813434268
    mean_env_wait_ms: 1.283451987689453
    mean_inference_ms: 4.54293244943354
    mean_raw_obs_processing_ms: 0.3958683245417908
  time_since_restore: 235.91603660583496
  time_this_iter_s: 29.39718723297119
  time_total_s: 235.91603660583496
  timers:
    learn_throughput: 7279.491
    learn_time_ms: 22225.731
    sample_throughput: 22592.329
    sample_time_ms: 7161.369
    update_time_ms: 46.444
  timestamp: 1602250803
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |      8 |          235.916 | 1294336 |  242.752 |              290.414 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3443.0791139240505
    time_step_min: 3139
  date: 2020-10-09_13-40-33
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 290.4141414141415
  episode_reward_mean: 244.88511699271191
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 316
  episodes_total: 1896
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.9264547499743375
        entropy_coeff: 0.0
        kl: 0.0063152494840323925
        model: {}
        policy_loss: -0.007867377981628206
        total_loss: 17.568159623579547
        vf_explained_var: 0.9728100299835205
        vf_loss: 17.57571099021218
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.24
    gpu_util_percent0: 0.39971428571428574
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.791428571428572
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15088404120913632
    mean_env_wait_ms: 1.282797475195357
    mean_inference_ms: 4.513511832219166
    mean_raw_obs_processing_ms: 0.39370140283203764
  time_since_restore: 265.6678855419159
  time_this_iter_s: 29.751848936080933
  time_total_s: 265.6678855419159
  timers:
    learn_throughput: 7275.725
    learn_time_ms: 22237.235
    sample_throughput: 22599.626
    sample_time_ms: 7159.057
    update_time_ms: 53.929
  timestamp: 1602250833
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |      9 |          265.668 | 1456128 |  244.885 |              290.414 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3438.003894839338
    time_step_min: 3139
  date: 2020-10-09_13-41-02
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 290.4141414141415
  episode_reward_mean: 245.59914628269055
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.9333846243945035
        entropy_coeff: 0.0
        kl: 0.00632860181345181
        model: {}
        policy_loss: -0.004252603256397627
        total_loss: 15.15998276797208
        vf_explained_var: 0.9671684503555298
        vf_loss: 15.163918755271219
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.720588235294116
    gpu_util_percent0: 0.4197058823529411
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8000000000000007
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15062271589167567
    mean_env_wait_ms: 1.282228566462433
    mean_inference_ms: 4.5014301855210155
    mean_raw_obs_processing_ms: 0.3927661792765542
  time_since_restore: 295.00096321105957
  time_this_iter_s: 29.333077669143677
  time_total_s: 295.00096321105957
  timers:
    learn_throughput: 7274.72
    learn_time_ms: 22240.306
    sample_throughput: 22661.14
    sample_time_ms: 7139.623
    update_time_ms: 52.42
  timestamp: 1602250862
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |     10 |          295.001 | 1617920 |  245.599 |              290.414 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3425.324050632911
    time_step_min: 3133
  date: 2020-10-09_13-41-32
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 291.323232323232
  episode_reward_mean: 247.4498146017133
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 316
  episodes_total: 2370
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.8733705228025263
        entropy_coeff: 0.0
        kl: 0.006511143535714258
        model: {}
        policy_loss: -0.006326832004230131
        total_loss: 16.30686023018577
        vf_explained_var: 0.9752892851829529
        vf_loss: 16.312861269170586
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.650000000000002
    gpu_util_percent0: 0.3147058823529412
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7911764705882356
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15017553199282696
    mean_env_wait_ms: 1.2814932315752117
    mean_inference_ms: 4.480796467735912
    mean_raw_obs_processing_ms: 0.39117964668997135
  time_since_restore: 324.51888060569763
  time_this_iter_s: 29.51791739463806
  time_total_s: 324.51888060569763
  timers:
    learn_throughput: 7274.864
    learn_time_ms: 22239.867
    sample_throughput: 22886.504
    sample_time_ms: 7069.319
    update_time_ms: 51.808
  timestamp: 1602250892
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |     11 |          324.519 | 1779712 |   247.45 |              291.323 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3420.9018987341774
    time_step_min: 3133
  date: 2020-10-09_13-42-01
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 291.323232323232
  episode_reward_mean: 248.18966164812682
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 158
  episodes_total: 2528
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.8916169296611439
        entropy_coeff: 0.0
        kl: 0.0064809913747012615
        model: {}
        policy_loss: -0.00923400308767503
        total_loss: 11.959196610884232
        vf_explained_var: 0.9738912582397461
        vf_loss: 11.968106529929422
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.930303030303033
    gpu_util_percent0: 0.3839393939393939
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.796969696969697
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14998558666774822
    mean_env_wait_ms: 1.2809974215001563
    mean_inference_ms: 4.4718949257796785
    mean_raw_obs_processing_ms: 0.39047860660669464
  time_since_restore: 353.7541015148163
  time_this_iter_s: 29.235220909118652
  time_total_s: 353.7541015148163
  timers:
    learn_throughput: 7271.758
    learn_time_ms: 22249.364
    sample_throughput: 23141.838
    sample_time_ms: 6991.32
    update_time_ms: 52.027
  timestamp: 1602250921
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |     12 |          353.754 | 1941504 |   248.19 |              291.323 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3415.3767684288905
    time_step_min: 3129
  date: 2020-10-09_13-42-30
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 291.92929292929307
  episode_reward_mean: 248.9262355498394
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.8739740956913341
        entropy_coeff: 0.0
        kl: 0.0067200795747339725
        model: {}
        policy_loss: -0.003441266612340273
        total_loss: 10.998652284795588
        vf_explained_var: 0.9740970730781555
        vf_loss: 11.001757621765137
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.78235294117647
    gpu_util_percent0: 0.3135294117647059
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8029411764705885
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14981282092547604
    mean_env_wait_ms: 1.280399987661582
    mean_inference_ms: 4.463615647599732
    mean_raw_obs_processing_ms: 0.3898118948580818
  time_since_restore: 382.63848900794983
  time_this_iter_s: 28.884387493133545
  time_total_s: 382.63848900794983
  timers:
    learn_throughput: 7277.101
    learn_time_ms: 22233.03
    sample_throughput: 23271.17
    sample_time_ms: 6952.465
    update_time_ms: 52.25
  timestamp: 1602250950
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |     13 |          382.638 | 2103296 |  248.926 |              291.929 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3404.842771485676
    time_step_min: 3129
  date: 2020-10-09_13-43-00
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 295.26262626262667
  episode_reward_mean: 250.51180357875887
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 316
  episodes_total: 3002
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.8163249763575467
        entropy_coeff: 0.0
        kl: 0.005668656985190782
        model: {}
        policy_loss: -0.0009176392764361067
        total_loss: 15.113983154296875
        vf_explained_var: 0.9779658913612366
        vf_loss: 15.114617521112615
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.676470588235293
    gpu_util_percent0: 0.3747058823529411
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7970588235294125
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14950704162966288
    mean_env_wait_ms: 1.27950320337214
    mean_inference_ms: 4.448995158862077
    mean_raw_obs_processing_ms: 0.3886661588683843
  time_since_restore: 412.2508351802826
  time_this_iter_s: 29.612346172332764
  time_total_s: 412.2508351802826
  timers:
    learn_throughput: 7271.536
    learn_time_ms: 22250.045
    sample_throughput: 23184.569
    sample_time_ms: 6978.435
    update_time_ms: 51.575
  timestamp: 1602250980
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |     14 |          412.251 | 2265088 |  250.512 |              295.263 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3399.520253164557
    time_step_min: 3123
  date: 2020-10-09_13-43-30
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 295.86868686868667
  episode_reward_mean: 251.24627605165574
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.8311027884483337
        entropy_coeff: 0.0
        kl: 0.006960396231575446
        model: {}
        policy_loss: -0.007342422169379212
        total_loss: 8.910025683316318
        vf_explained_var: 0.9796028137207031
        vf_loss: 8.91701975735751
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.670588235294115
    gpu_util_percent0: 0.36382352941176466
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8176470588235296
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14937231653836056
    mean_env_wait_ms: 1.2790064146778977
    mean_inference_ms: 4.442587310184464
    mean_raw_obs_processing_ms: 0.38815375593630996
  time_since_restore: 441.5913963317871
  time_this_iter_s: 29.340561151504517
  time_total_s: 441.5913963317871
  timers:
    learn_throughput: 7267.139
    learn_time_ms: 22263.508
    sample_throughput: 23188.495
    sample_time_ms: 6977.253
    update_time_ms: 51.247
  timestamp: 1602251010
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |     15 |          441.591 | 2426880 |  251.246 |              295.869 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3395.4556962025317
    time_step_min: 3098
  date: 2020-10-09_13-43-59
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 296.62626262626225
  episode_reward_mean: 251.93997844630752
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 158
  episodes_total: 3318
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.8019554398276589
        entropy_coeff: 0.0
        kl: 0.005829330322078683
        model: {}
        policy_loss: -0.009165903807363728
        total_loss: 9.565857193686746
        vf_explained_var: 0.9773910641670227
        vf_loss: 9.574731826782227
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.564705882352943
    gpu_util_percent0: 0.3276470588235294
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8088235294117645
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14924655701408332
    mean_env_wait_ms: 1.2784884349604222
    mean_inference_ms: 4.436600133416786
    mean_raw_obs_processing_ms: 0.38766215533726067
  time_since_restore: 470.96737933158875
  time_this_iter_s: 29.375982999801636
  time_total_s: 470.96737933158875
  timers:
    learn_throughput: 7261.986
    learn_time_ms: 22279.305
    sample_throughput: 23212.739
    sample_time_ms: 6969.966
    update_time_ms: 50.319
  timestamp: 1602251039
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |     16 |          470.967 | 2588672 |   251.94 |              296.626 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3386.436433681893
    time_step_min: 3090
  date: 2020-10-09_13-44-29
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 297.8383838383834
  episode_reward_mean: 253.12665454767816
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 316
  episodes_total: 3634
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.7509693286635659
        entropy_coeff: 0.0
        kl: 0.0062703560953113165
        model: {}
        policy_loss: -0.006602345732972026
        total_loss: 14.54388106953014
        vf_explained_var: 0.9788088202476501
        vf_loss: 14.550169858065518
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.873529411764704
    gpu_util_percent0: 0.3797058823529412
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7941176470588234
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14901811467735243
    mean_env_wait_ms: 1.2776396006327135
    mean_inference_ms: 4.425863685085124
    mean_raw_obs_processing_ms: 0.38679802785866313
  time_since_restore: 500.32944416999817
  time_this_iter_s: 29.362064838409424
  time_total_s: 500.32944416999817
  timers:
    learn_throughput: 7263.117
    learn_time_ms: 22275.837
    sample_throughput: 23152.687
    sample_time_ms: 6988.044
    update_time_ms: 42.841
  timestamp: 1602251069
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |     17 |          500.329 | 2750464 |  253.127 |              297.838 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3381.9166666666665
    time_step_min: 3090
  date: 2020-10-09_13-44-58
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 297.8383838383834
  episode_reward_mean: 253.74967235647608
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 158
  episodes_total: 3792
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.7737306573174216
        entropy_coeff: 0.0
        kl: 0.0054819400168278
        model: {}
        policy_loss: -0.011327400390820747
        total_loss: 8.417920112609863
        vf_explained_var: 0.9793825149536133
        vf_loss: 8.428973588076504
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.95
    gpu_util_percent0: 0.3326470588235294
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8029411764705885
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1489174778685345
    mean_env_wait_ms: 1.277183967312041
    mean_inference_ms: 4.421092058677241
    mean_raw_obs_processing_ms: 0.3864104229066043
  time_since_restore: 529.6734762191772
  time_this_iter_s: 29.344032049179077
  time_total_s: 529.6734762191772
  timers:
    learn_throughput: 7263.85
    learn_time_ms: 22273.588
    sample_throughput: 23175.575
    sample_time_ms: 6981.143
    update_time_ms: 44.444
  timestamp: 1602251098
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |     18 |          529.673 | 2912256 |   253.75 |              297.838 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3378.6911392405063
    time_step_min: 3090
  date: 2020-10-09_13-45-27
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 297.8383838383834
  episode_reward_mean: 254.23631249200866
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 158
  episodes_total: 3950
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.7153156345540826
        entropy_coeff: 0.0
        kl: 0.005994919645176692
        model: {}
        policy_loss: -0.004020375390113754
        total_loss: 9.825998046181418
        vf_explained_var: 0.9804473519325256
        vf_loss: 9.82971884987571
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.58529411764706
    gpu_util_percent0: 0.3688235294117646
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8617647058823534
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14882281298545813
    mean_env_wait_ms: 1.276759928601788
    mean_inference_ms: 4.41658315874501
    mean_raw_obs_processing_ms: 0.3860337923647654
  time_since_restore: 558.9991500377655
  time_this_iter_s: 29.325673818588257
  time_total_s: 558.9991500377655
  timers:
    learn_throughput: 7264.455
    learn_time_ms: 22271.733
    sample_throughput: 23248.043
    sample_time_ms: 6959.381
    update_time_ms: 35.967
  timestamp: 1602251127
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |     19 |          558.999 | 3074048 |  254.236 |              297.838 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3371.419596812002
    time_step_min: 3086
  date: 2020-10-09_13-45-56
  done: false
  episode_len_mean: 750.0
  episode_reward_max: 298.444444444445
  episode_reward_mean: 255.18370768159792
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 316
  episodes_total: 4266
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.7081915952942588
        entropy_coeff: 0.0
        kl: 0.006277962122112513
        model: {}
        policy_loss: -0.012281992951598526
        total_loss: 11.156540610573508
        vf_explained_var: 0.9812889099121094
        vf_loss: 11.168508616360752
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.393939393939398
    gpu_util_percent0: 0.3957575757575757
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.784848484848485
    vram_util_percent0: 0.10897015414890128
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14865041600282872
    mean_env_wait_ms: 1.2759700038451234
    mean_inference_ms: 4.408363902058177
    mean_raw_obs_processing_ms: 0.3853570227789637
  time_since_restore: 587.6986539363861
  time_this_iter_s: 28.699503898620605
  time_total_s: 587.6986539363861
  timers:
    learn_throughput: 7280.531
    learn_time_ms: 22222.554
    sample_throughput: 23291.354
    sample_time_ms: 6946.44
    update_time_ms: 34.174
  timestamp: 1602251156
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | RUNNING  | 172.17.0.4:55337 |     20 |          587.699 | 3235840 |  255.184 |              298.444 |               139.96 |                750 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_5e362_00000:
  custom_metrics:
    time_step_max: 4022
    time_step_mean: 3369.032549728752
    time_step_min: 3086
  date: 2020-10-09_13-46-25
  done: true
  episode_len_mean: 750.0
  episode_reward_max: 299.3535353535355
  episode_reward_mean: 255.58730158730154
  episode_reward_min: 139.95959595959627
  episodes_this_iter: 158
  episodes_total: 4424
  experiment_id: c98cfe1b81dc410f9df289aa84a8f232
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05
        cur_lr: 5.0e-05
        entropy: 0.7350721901113336
        entropy_coeff: 0.0
        kl: 0.005789386701177467
        model: {}
        policy_loss: -0.005328844565982846
        total_loss: 9.588560017672451
        vf_explained_var: 0.9767353534698486
        vf_loss: 9.593599232760342
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.479411764705883
    gpu_util_percent0: 0.34500000000000003
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.858823529411765
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 55337
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14857075632263922
    mean_env_wait_ms: 1.275555227643001
    mean_inference_ms: 4.404598028874967
    mean_raw_obs_processing_ms: 0.3850429927463857
  time_since_restore: 616.7557508945465
  time_this_iter_s: 29.0570969581604
  time_total_s: 616.7557508945465
  timers:
    learn_throughput: 7292.309
    learn_time_ms: 22186.663
    sample_throughput: 23323.156
    sample_time_ms: 6936.969
    update_time_ms: 32.685
  timestamp: 1602251185
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: 5e362_00000
  
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | TERMINATED |       |     21 |          616.756 | 3397632 |  255.587 |              299.354 |               139.96 |                750 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_5e362_00000 | TERMINATED |       |     21 |          616.756 | 3397632 |  255.587 |              299.354 |               139.96 |                750 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


