2020-10-12 15:22:33,490	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_c10d2_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=60268)[0m 2020-10-12 15:22:36,275	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=60260)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60260)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60262)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60262)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60238)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60238)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60274)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60274)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60233)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60233)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60142)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60142)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60202)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60202)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60212)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60212)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60147)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60147)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60224)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60224)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60272)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60272)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60222)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60222)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60241)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60241)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60270)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60270)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60259)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60259)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60239)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60239)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60253)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60253)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60257)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60257)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60237)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60237)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60156)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60156)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60154)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60154)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60160)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60160)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60221)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60221)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60240)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60240)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60244)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60244)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60144)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60144)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60161)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60161)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60213)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60213)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60150)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60150)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60158)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60158)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60231)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60217)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60217)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60146)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60146)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60153)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60153)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60265)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60265)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60200)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60200)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60143)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60143)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60216)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60216)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60148)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60148)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60205)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60205)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60250)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60250)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60236)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60236)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60210)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60210)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60252)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60252)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60248)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60248)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60230)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60230)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60203)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60203)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60227)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60227)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60218)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60218)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60168)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60168)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60245)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60245)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60264)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60264)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60163)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60163)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60204)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60204)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60151)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60151)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60149)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60149)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60157)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60157)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60255)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60255)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=60214)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=60214)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4040
    time_step_mean: 3708.8660714285716
    time_step_min: 3400
  date: 2020-10-12_15-23-10
  done: false
  episode_len_mean: 905.6582278481013
  episode_reward_max: 262.01010101010036
  episode_reward_mean: 216.4606188466943
  episode_reward_min: 164.28282828282764
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.0e-05
        entropy: 1.1647747655709584
        entropy_coeff: 0.0005000000000000001
        kl: 0.00473203028862675
        model: {}
        policy_loss: -0.00807673400170946
        total_loss: 407.51378631591797
        vf_explained_var: 0.5518081784248352
        vf_loss: 407.52150472005206
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.924242424242426
    gpu_util_percent0: 0.26636363636363636
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.566666666666667
    vram_util_percent0: 0.08750757824224535
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1707042636382576
    mean_env_wait_ms: 1.1833550717294048
    mean_inference_ms: 5.763200257581928
    mean_raw_obs_processing_ms: 0.45787261863960527
  time_since_restore: 28.49656391143799
  time_this_iter_s: 28.49656391143799
  time_total_s: 28.49656391143799
  timers:
    learn_throughput: 8346.704
    learn_time_ms: 19383.94
    sample_throughput: 17923.132
    sample_time_ms: 9026.994
    update_time_ms: 44.806
  timestamp: 1602516190
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 27.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |      1 |          28.4966 | 161792 |  216.461 |               262.01 |              164.283 |            905.658 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3723.151851851852
    time_step_min: 3400
  date: 2020-10-12_15-23-37
  done: false
  episode_len_mean: 903.9620253164557
  episode_reward_max: 262.01010101010036
  episode_reward_mean: 214.48708605037675
  episode_reward_min: 131.85858585858549
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1318883697191875
        entropy_coeff: 0.0005000000000000001
        kl: 0.009589768092458447
        model: {}
        policy_loss: -0.01046546475845389
        total_loss: 97.49119822184245
        vf_explained_var: 0.8148381114006042
        vf_loss: 97.50126775105794
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.084375
    gpu_util_percent0: 0.3590625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.753125
    vram_util_percent0: 0.10437848474909807
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1669438600325945
    mean_env_wait_ms: 1.1818354839313385
    mean_inference_ms: 5.614419415858316
    mean_raw_obs_processing_ms: 0.4497282737211035
  time_since_restore: 55.91094779968262
  time_this_iter_s: 27.41438388824463
  time_total_s: 55.91094779968262
  timers:
    learn_throughput: 8381.456
    learn_time_ms: 19303.566
    sample_throughput: 18887.047
    sample_time_ms: 8566.294
    update_time_ms: 37.124
  timestamp: 1602516217
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |      2 |          55.9109 | 323584 |  214.487 |               262.01 |              131.859 |            903.962 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3720.32476635514
    time_step_min: 3400
  date: 2020-10-12_15-24-04
  done: false
  episode_len_mean: 899.9831223628692
  episode_reward_max: 262.01010101010036
  episode_reward_mean: 214.78020713463707
  episode_reward_min: 131.85858585858549
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.12220632036527
        entropy_coeff: 0.0005000000000000001
        kl: 0.009560395032167435
        model: {}
        policy_loss: -0.011902896052864284
        total_loss: 49.42488066355387
        vf_explained_var: 0.8946843147277832
        vf_loss: 49.43638769785563
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.932258064516127
    gpu_util_percent0: 0.2977419354838709
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16399722349552534
    mean_env_wait_ms: 1.1821533188656101
    mean_inference_ms: 5.446483422086207
    mean_raw_obs_processing_ms: 0.44124424438482435
  time_since_restore: 82.46272134780884
  time_this_iter_s: 26.55177354812622
  time_total_s: 82.46272134780884
  timers:
    learn_throughput: 8399.31
    learn_time_ms: 19262.535
    sample_throughput: 19890.535
    sample_time_ms: 8134.12
    update_time_ms: 37.891
  timestamp: 1602516244
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |      3 |          82.4627 | 485376 |   214.78 |               262.01 |              131.859 |            899.983 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3716.0580204778157
    time_step_min: 3400
  date: 2020-10-12_15-24-30
  done: false
  episode_len_mean: 895.9810126582279
  episode_reward_max: 262.01010101010036
  episode_reward_mean: 215.04304117120526
  episode_reward_min: 131.85858585858549
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.1039417584737141
        entropy_coeff: 0.0005000000000000001
        kl: 0.00867797884469231
        model: {}
        policy_loss: -0.013174800493288785
        total_loss: 35.44446245829264
        vf_explained_var: 0.9264928698539734
        vf_loss: 35.45732275644938
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.274193548387096
    gpu_util_percent0: 0.2803225806451612
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16181033315560528
    mean_env_wait_ms: 1.1827398889825573
    mean_inference_ms: 5.313064830547105
    mean_raw_obs_processing_ms: 0.4343062492898235
  time_since_restore: 108.9216079711914
  time_this_iter_s: 26.45888662338257
  time_total_s: 108.9216079711914
  timers:
    learn_throughput: 8407.613
    learn_time_ms: 19243.512
    sample_throughput: 20485.746
    sample_time_ms: 7897.784
    update_time_ms: 38.336
  timestamp: 1602516270
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |      4 |          108.922 | 647168 |  215.043 |               262.01 |              131.859 |            895.981 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3714.5846774193546
    time_step_min: 3400
  date: 2020-10-12_15-24-57
  done: false
  episode_len_mean: 891.0253164556962
  episode_reward_max: 262.01010101010036
  episode_reward_mean: 215.17791842475344
  episode_reward_min: 131.85858585858549
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.082091599702835
        entropy_coeff: 0.0005000000000000001
        kl: 0.0076408466168989735
        model: {}
        policy_loss: -0.012829113693442196
        total_loss: 26.67149782180786
        vf_explained_var: 0.9462361335754395
        vf_loss: 26.68410348892212
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.956666666666663
    gpu_util_percent0: 0.302
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.773333333333333
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1601647168575199
    mean_env_wait_ms: 1.183715575900447
    mean_inference_ms: 5.207776009628039
    mean_raw_obs_processing_ms: 0.42869054053797523
  time_since_restore: 135.21001172065735
  time_this_iter_s: 26.288403749465942
  time_total_s: 135.21001172065735
  timers:
    learn_throughput: 8405.92
    learn_time_ms: 19247.388
    sample_throughput: 20997.729
    sample_time_ms: 7705.214
    update_time_ms: 38.459
  timestamp: 1602516297
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |      5 |           135.21 | 808960 |  215.178 |               262.01 |              131.859 |            891.025 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3709.934759358289
    time_step_min: 3400
  date: 2020-10-12_15-25-23
  done: false
  episode_len_mean: 885.1569826707441
  episode_reward_max: 266.2525252525247
  episode_reward_mean: 215.74500355234255
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 191
  episodes_total: 981
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0345047016938527
        entropy_coeff: 0.0005000000000000001
        kl: 0.008740813548987111
        model: {}
        policy_loss: -0.011801244584300244
        total_loss: 30.00030755996704
        vf_explained_var: 0.9570322036743164
        vf_loss: 30.011751174926758
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.02258064516129
    gpu_util_percent0: 0.34096774193548385
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7580645161290316
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15858506626548557
    mean_env_wait_ms: 1.1855314591574653
    mean_inference_ms: 5.108867698758002
    mean_raw_obs_processing_ms: 0.4233045193829449
  time_since_restore: 161.40742182731628
  time_this_iter_s: 26.197410106658936
  time_total_s: 161.40742182731628
  timers:
    learn_throughput: 8414.526
    learn_time_ms: 19227.702
    sample_throughput: 21332.032
    sample_time_ms: 7584.463
    update_time_ms: 38.329
  timestamp: 1602516323
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |      6 |          161.407 | 970752 |  215.745 |              266.253 |              126.556 |            885.157 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3703.7594417077175
    time_step_min: 3393
  date: 2020-10-12_15-25-49
  done: false
  episode_len_mean: 878.3599683544304
  episode_reward_max: 266.2525252525247
  episode_reward_mean: 216.81483346119379
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 283
  episodes_total: 1264
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0508220891157787
        entropy_coeff: 0.0005000000000000001
        kl: 0.007821178723437091
        model: {}
        policy_loss: -0.010197055215636889
        total_loss: 25.470292727152508
        vf_explained_var: 0.9604597687721252
        vf_loss: 25.480233669281006
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.096774193548388
    gpu_util_percent0: 0.3958064516129033
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322573
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.156973892540339
    mean_env_wait_ms: 1.1881132620046178
    mean_inference_ms: 5.0034705577788525
    mean_raw_obs_processing_ms: 0.4179752577933394
  time_since_restore: 187.84608435630798
  time_this_iter_s: 26.4386625289917
  time_total_s: 187.84608435630798
  timers:
    learn_throughput: 8405.069
    learn_time_ms: 19249.337
    sample_throughput: 21581.531
    sample_time_ms: 7496.781
    update_time_ms: 38.142
  timestamp: 1602516349
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |      7 |          187.846 | 1132544 |  216.815 |              266.253 |              126.556 |             878.36 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3693.2005813953488
    time_step_min: 3342
  date: 2020-10-12_15-26-16
  done: false
  episode_len_mean: 874.0970464135021
  episode_reward_max: 270.0404040404039
  episode_reward_mean: 218.1367685291732
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0273421903451283
        entropy_coeff: 0.0005000000000000001
        kl: 0.008351543258565167
        model: {}
        policy_loss: -0.014941895632849386
        total_loss: 16.31189688046773
        vf_explained_var: 0.966367244720459
        vf_loss: 16.326517740885418
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.503225806451614
    gpu_util_percent0: 0.2848387096774194
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7774193548387096
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15626118904530895
    mean_env_wait_ms: 1.189509060889611
    mean_inference_ms: 4.957779821801152
    mean_raw_obs_processing_ms: 0.4156281506774755
  time_since_restore: 214.21667003631592
  time_this_iter_s: 26.370585680007935
  time_total_s: 214.21667003631592
  timers:
    learn_throughput: 8416.368
    learn_time_ms: 19223.494
    sample_throughput: 21694.927
    sample_time_ms: 7457.596
    update_time_ms: 36.016
  timestamp: 1602516376
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |      8 |          214.217 | 1294336 |  218.137 |               270.04 |              126.556 |            874.097 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3685.148631029987
    time_step_min: 3342
  date: 2020-10-12_15-26-42
  done: false
  episode_len_mean: 869.632911392405
  episode_reward_max: 271.40404040403985
  episode_reward_mean: 219.33883135148915
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 158
  episodes_total: 1580
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 1.0084790935118992
        entropy_coeff: 0.0005000000000000001
        kl: 0.007280519581399858
        model: {}
        policy_loss: -0.0127268874590906
        total_loss: 15.402397950490316
        vf_explained_var: 0.9677316546440125
        vf_loss: 15.414900859196981
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.75806451612903
    gpu_util_percent0: 0.28838709677419355
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7741935483870965
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15563770419384237
    mean_env_wait_ms: 1.190950194940473
    mean_inference_ms: 4.9176698273033495
    mean_raw_obs_processing_ms: 0.4135223288426705
  time_since_restore: 240.5748143196106
  time_this_iter_s: 26.358144283294678
  time_total_s: 240.5748143196106
  timers:
    learn_throughput: 8415.739
    learn_time_ms: 19224.931
    sample_throughput: 21827.886
    sample_time_ms: 7412.17
    update_time_ms: 34.608
  timestamp: 1602516402
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |      9 |          240.575 | 1456128 |  219.339 |              271.404 |              126.556 |            869.633 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3677.5730270906947
    time_step_min: 3342
  date: 2020-10-12_15-27-09
  done: false
  episode_len_mean: 865.266628440367
  episode_reward_max: 271.40404040403985
  episode_reward_mean: 220.30364424057046
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 164
  episodes_total: 1744
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9659438480933508
        entropy_coeff: 0.0005000000000000001
        kl: 0.00674354382014523
        model: {}
        policy_loss: -0.012388948060106486
        total_loss: 21.63013219833374
        vf_explained_var: 0.9617543816566467
        vf_loss: 21.642329851786297
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.951612903225804
    gpu_util_percent0: 0.38774193548387104
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1550667680800019
    mean_env_wait_ms: 1.1924849794352685
    mean_inference_ms: 4.880873221416288
    mean_raw_obs_processing_ms: 0.4115494721531659
  time_since_restore: 267.11308884620667
  time_this_iter_s: 26.53827452659607
  time_total_s: 267.11308884620667
  timers:
    learn_throughput: 8411.335
    learn_time_ms: 19234.997
    sample_throughput: 21935.755
    sample_time_ms: 7375.721
    update_time_ms: 34.998
  timestamp: 1602516429
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |     10 |          267.113 | 1617920 |  220.304 |              271.404 |              126.556 |            865.267 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3664.233416458853
    time_step_min: 3342
  date: 2020-10-12_15-27-36
  done: false
  episode_len_mean: 858.008288639688
  episode_reward_max: 272.61616161616115
  episode_reward_mean: 222.2659998325523
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 307
  episodes_total: 2051
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9442435453335444
        entropy_coeff: 0.0005000000000000001
        kl: 0.0063606204542641836
        model: {}
        policy_loss: -0.00961103243753314
        total_loss: 22.137783527374268
        vf_explained_var: 0.9693326950073242
        vf_loss: 22.147231101989746
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.480645161290315
    gpu_util_percent0: 0.35935483870967744
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.770967741935483
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15418516400983642
    mean_env_wait_ms: 1.195342681469048
    mean_inference_ms: 4.824202731955752
    mean_raw_obs_processing_ms: 0.408581267031187
  time_since_restore: 293.5816767215729
  time_this_iter_s: 26.46858787536621
  time_total_s: 293.5816767215729
  timers:
    learn_throughput: 8416.568
    learn_time_ms: 19223.037
    sample_throughput: 22519.681
    sample_time_ms: 7184.471
    update_time_ms: 34.3
  timestamp: 1602516456
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |     11 |          293.582 | 1779712 |  222.266 |              272.616 |              126.556 |            858.008 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3657.9593721144965
    time_step_min: 3342
  date: 2020-10-12_15-28-02
  done: false
  episode_len_mean: 854.4254068716094
  episode_reward_max: 272.61616161616115
  episode_reward_mean: 223.03865051966278
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 161
  episodes_total: 2212
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9357274522384008
        entropy_coeff: 0.0005000000000000001
        kl: 0.006479084258899093
        model: {}
        policy_loss: -0.011161864347135028
        total_loss: 13.993338823318481
        vf_explained_var: 0.9730336666107178
        vf_loss: 14.004320621490479
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.519354838709678
    gpu_util_percent0: 0.38258064516129037
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15379464673165347
    mean_env_wait_ms: 1.1967786677363998
    mean_inference_ms: 4.799325434519316
    mean_raw_obs_processing_ms: 0.40727806876960576
  time_since_restore: 320.24074482917786
  time_this_iter_s: 26.65906810760498
  time_total_s: 320.24074482917786
  timers:
    learn_throughput: 8415.758
    learn_time_ms: 19224.886
    sample_throughput: 22764.169
    sample_time_ms: 7107.31
    update_time_ms: 34.138
  timestamp: 1602516482
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |     12 |          320.241 | 1941504 |  223.039 |              272.616 |              126.556 |            854.425 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3652.6041308089502
    time_step_min: 3283
  date: 2020-10-12_15-28-29
  done: false
  episode_len_mean: 851.2143459915612
  episode_reward_max: 278.97979797979787
  episode_reward_mean: 223.793312875591
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 158
  episodes_total: 2370
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.9198300937811533
        entropy_coeff: 0.0005000000000000001
        kl: 0.006205780586848657
        model: {}
        policy_loss: -0.011087854742072523
        total_loss: 15.218324422836304
        vf_explained_var: 0.9686550498008728
        vf_loss: 15.229251782099405
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.248387096774195
    gpu_util_percent0: 0.3467741935483871
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7870967741935475
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1534467958249497
    mean_env_wait_ms: 1.1982242722657004
    mean_inference_ms: 4.777031600680736
    mean_raw_obs_processing_ms: 0.40608976203179303
  time_since_restore: 346.614120721817
  time_this_iter_s: 26.37337589263916
  time_total_s: 346.614120721817
  timers:
    learn_throughput: 8416.146
    learn_time_ms: 19224.002
    sample_throughput: 22838.324
    sample_time_ms: 7084.233
    update_time_ms: 40.154
  timestamp: 1602516509
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |     13 |          346.614 | 2103296 |  223.793 |               278.98 |              126.556 |            851.214 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3647.3826915442637
    time_step_min: 3283
  date: 2020-10-12_15-28-55
  done: false
  episode_len_mean: 847.929044834308
  episode_reward_max: 278.97979797979787
  episode_reward_mean: 224.61173134857304
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 195
  episodes_total: 2565
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8750834216674169
        entropy_coeff: 0.0005000000000000001
        kl: 0.006541201728396118
        model: {}
        policy_loss: -0.011567620793357491
        total_loss: 15.469610452651978
        vf_explained_var: 0.975344181060791
        vf_loss: 15.480961720148722
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.706666666666663
    gpu_util_percent0: 0.36133333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15306585949109214
    mean_env_wait_ms: 1.2000305719407012
    mean_inference_ms: 4.752252769542764
    mean_raw_obs_processing_ms: 0.4047310558795028
  time_since_restore: 372.8907308578491
  time_this_iter_s: 26.276610136032104
  time_total_s: 372.8907308578491
  timers:
    learn_throughput: 8412.533
    learn_time_ms: 19232.257
    sample_throughput: 22922.123
    sample_time_ms: 7058.334
    update_time_ms: 38.114
  timestamp: 1602516535
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |     14 |          372.891 | 2265088 |  224.612 |               278.98 |              126.556 |            847.929 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3638.271459227468
    time_step_min: 3283
  date: 2020-10-12_15-29-22
  done: false
  episode_len_mean: 844.0601688951442
  episode_reward_max: 278.97979797979787
  episode_reward_mean: 225.9424576518169
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 277
  episodes_total: 2842
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.866677130262057
        entropy_coeff: 0.0005000000000000001
        kl: 0.006368907323728005
        model: {}
        policy_loss: -0.013498592539690435
        total_loss: 13.751517534255981
        vf_explained_var: 0.9780821800231934
        vf_loss: 13.764812390009562
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.95161290322581
    gpu_util_percent0: 0.2709677419354839
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1525807618706291
    mean_env_wait_ms: 1.2022755317972176
    mean_inference_ms: 4.721326080005391
    mean_raw_obs_processing_ms: 0.4030793798738605
  time_since_restore: 399.2211790084839
  time_this_iter_s: 26.330448150634766
  time_total_s: 399.2211790084839
  timers:
    learn_throughput: 8411.765
    learn_time_ms: 19234.013
    sample_throughput: 22911.691
    sample_time_ms: 7061.548
    update_time_ms: 36.388
  timestamp: 1602516562
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |     15 |          399.221 | 2426880 |  225.942 |               278.98 |              126.556 |             844.06 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3633.0091339648175
    time_step_min: 3278
  date: 2020-10-12_15-29-48
  done: false
  episode_len_mean: 842.4756828780813
  episode_reward_max: 279.73737373737356
  episode_reward_mean: 226.62454996332374
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 160
  episodes_total: 3002
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8529908210039139
        entropy_coeff: 0.0005000000000000001
        kl: 0.006265266837241749
        model: {}
        policy_loss: -0.010987085717109343
        total_loss: 13.621409257253012
        vf_explained_var: 0.9727893471717834
        vf_loss: 13.632196267445883
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.14193548387097
    gpu_util_percent0: 0.2758064516129032
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7838709677419344
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15233386779939873
    mean_env_wait_ms: 1.2034868524234905
    mean_inference_ms: 4.705504320704453
    mean_raw_obs_processing_ms: 0.40222492476582217
  time_since_restore: 425.5726840496063
  time_this_iter_s: 26.351505041122437
  time_total_s: 425.5726840496063
  timers:
    learn_throughput: 8404.782
    learn_time_ms: 19249.993
    sample_throughput: 22921.239
    sample_time_ms: 7058.606
    update_time_ms: 38.049
  timestamp: 1602516588
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |     16 |          425.573 | 2588672 |  226.625 |              279.737 |              126.556 |            842.476 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3627.756262042389
    time_step_min: 3278
  date: 2020-10-12_15-30-14
  done: false
  episode_len_mean: 840.5006329113924
  episode_reward_max: 279.73737373737356
  episode_reward_mean: 227.3260772279756
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 158
  episodes_total: 3160
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8390568047761917
        entropy_coeff: 0.0005000000000000001
        kl: 0.006382488917248945
        model: {}
        policy_loss: -0.010932213355166217
        total_loss: 14.478002707163492
        vf_explained_var: 0.9691622853279114
        vf_loss: 14.488715966542562
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.939999999999998
    gpu_util_percent0: 0.262
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7899999999999996
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15210776983622548
    mean_env_wait_ms: 1.2046541061925606
    mean_inference_ms: 4.690895098364773
    mean_raw_obs_processing_ms: 0.4014273800282454
  time_since_restore: 451.72485756874084
  time_this_iter_s: 26.15217351913452
  time_total_s: 451.72485756874084
  timers:
    learn_throughput: 8414.032
    learn_time_ms: 19228.832
    sample_throughput: 22942.922
    sample_time_ms: 7051.935
    update_time_ms: 36.592
  timestamp: 1602516614
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |     17 |          451.725 | 2750464 |  227.326 |              279.737 |              126.556 |            840.501 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3621.189189189189
    time_step_min: 3278
  date: 2020-10-12_15-30-41
  done: false
  episode_len_mean: 838.0269557573981
  episode_reward_max: 279.73737373737356
  episode_reward_mean: 228.16246851758098
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 253
  episodes_total: 3413
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8095408777395884
        entropy_coeff: 0.0005000000000000001
        kl: 0.006256838950018088
        model: {}
        policy_loss: -0.011800330537274325
        total_loss: 17.46291907628377
        vf_explained_var: 0.9745703339576721
        vf_loss: 17.474498589833576
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.300000000000004
    gpu_util_percent0: 0.34290322580645166
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7645161290322577
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1517783140477611
    mean_env_wait_ms: 1.206412441229029
    mean_inference_ms: 4.669650454844135
    mean_raw_obs_processing_ms: 0.4002491145959974
  time_since_restore: 478.2009365558624
  time_this_iter_s: 26.476078987121582
  time_total_s: 478.2009365558624
  timers:
    learn_throughput: 8403.983
    learn_time_ms: 19251.825
    sample_throughput: 22968.376
    sample_time_ms: 7044.12
    update_time_ms: 38.189
  timestamp: 1602516641
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |     18 |          478.201 | 2912256 |  228.162 |              279.737 |              126.556 |            838.027 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3616.110119877335
    time_step_min: 3278
  date: 2020-10-12_15-31-08
  done: false
  episode_len_mean: 836.1951555188549
  episode_reward_max: 279.73737373737356
  episode_reward_mean: 228.9022679311693
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 220
  episodes_total: 3633
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8085831900437673
        entropy_coeff: 0.0005000000000000001
        kl: 0.005845786615585287
        model: {}
        policy_loss: -0.011725900910581307
        total_loss: 13.433278640111288
        vf_explained_var: 0.9770469665527344
        vf_loss: 13.44482429822286
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.448387096774198
    gpu_util_percent0: 0.37870967741935485
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7709677419354835
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1515199261297488
    mean_env_wait_ms: 1.2078080374603621
    mean_inference_ms: 4.6529029483582836
    mean_raw_obs_processing_ms: 0.39936494850283216
  time_since_restore: 504.5615019798279
  time_this_iter_s: 26.360565423965454
  time_total_s: 504.5615019798279
  timers:
    learn_throughput: 8407.227
    learn_time_ms: 19244.394
    sample_throughput: 22945.568
    sample_time_ms: 7051.122
    update_time_ms: 38.049
  timestamp: 1602516668
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |     19 |          504.562 | 3074048 |  228.902 |              279.737 |              126.556 |            836.195 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3612.632140950347
    time_step_min: 3278
  date: 2020-10-12_15-31-34
  done: false
  episode_len_mean: 835.0163502109705
  episode_reward_max: 279.73737373737356
  episode_reward_mean: 229.41168808336496
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 159
  episodes_total: 3792
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.8010916958252589
        entropy_coeff: 0.0005000000000000001
        kl: 0.005972905977008243
        model: {}
        policy_loss: -0.009757631652367612
        total_loss: 13.557638883590698
        vf_explained_var: 0.9725897908210754
        vf_loss: 13.56720002492269
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.135483870967743
    gpu_util_percent0: 0.3996774193548387
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903222
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15134848061244294
    mean_env_wait_ms: 1.2087619222096397
    mean_inference_ms: 4.6418080288396775
    mean_raw_obs_processing_ms: 0.39876039370496846
  time_since_restore: 530.9620370864868
  time_this_iter_s: 26.400535106658936
  time_total_s: 530.9620370864868
  timers:
    learn_throughput: 8408.528
    learn_time_ms: 19241.418
    sample_throughput: 22960.68
    sample_time_ms: 7046.481
    update_time_ms: 38.248
  timestamp: 1602516694
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |     20 |          530.962 | 3235840 |  229.412 |              279.737 |              126.556 |            835.016 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3609.6734067059124
    time_step_min: 3278
  date: 2020-10-12_15-32-00
  done: false
  episode_len_mean: 834.0045535036681
  episode_reward_max: 279.73737373737356
  episode_reward_mean: 229.8466501595767
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 161
  episodes_total: 3953
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7751961300770441
        entropy_coeff: 0.0005000000000000001
        kl: 0.006770414882339537
        model: {}
        policy_loss: -0.010245077855264148
        total_loss: 13.407913049062094
        vf_explained_var: 0.9741201400756836
        vf_loss: 13.417869011561075
    num_steps_sampled: 3397632
    num_steps_trained: 3397632
  iterations_since_restore: 21
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.89032258064516
    gpu_util_percent0: 0.29354838709677417
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.77741935483871
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15118443579212387
    mean_env_wait_ms: 1.2096775124868446
    mean_inference_ms: 4.631187314283677
    mean_raw_obs_processing_ms: 0.39816906392168294
  time_since_restore: 557.277898311615
  time_this_iter_s: 26.315861225128174
  time_total_s: 557.277898311615
  timers:
    learn_throughput: 8409.691
    learn_time_ms: 19238.756
    sample_throughput: 23005.32
    sample_time_ms: 7032.808
    update_time_ms: 38.341
  timestamp: 1602516720
  timesteps_since_restore: 0
  timesteps_total: 3397632
  training_iteration: 21
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |     21 |          557.278 | 3397632 |  229.847 |              279.737 |              126.556 |            834.005 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3604.7112068965516
    time_step_min: 3212
  date: 2020-10-12_15-32-27
  done: false
  episode_len_mean: 832.7110374230223
  episode_reward_max: 289.73737373737316
  episode_reward_mean: 230.63824651058155
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 269
  episodes_total: 4222
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.7545836915572485
        entropy_coeff: 0.0005000000000000001
        kl: 0.005760976967091362
        model: {}
        policy_loss: -0.009425222723317953
        total_loss: 14.846301396687826
        vf_explained_var: 0.978369951248169
        vf_loss: 14.855527798334757
    num_steps_sampled: 3559424
    num_steps_trained: 3559424
  iterations_since_restore: 22
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.683333333333337
    gpu_util_percent0: 0.34733333333333327
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.766666666666666
    vram_util_percent0: 0.10437848474909811
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15092920762915432
    mean_env_wait_ms: 1.211061241261318
    mean_inference_ms: 4.614790994980333
    mean_raw_obs_processing_ms: 0.397253572465763
  time_since_restore: 583.4412398338318
  time_this_iter_s: 26.163341522216797
  time_total_s: 583.4412398338318
  timers:
    learn_throughput: 8417.723
    learn_time_ms: 19220.4
    sample_throughput: 23108.492
    sample_time_ms: 7001.409
    update_time_ms: 37.557
  timestamp: 1602516747
  timesteps_since_restore: 0
  timesteps_total: 3559424
  training_iteration: 22
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | RUNNING  | 172.17.0.4:60268 |     22 |          583.441 | 3559424 |  230.638 |              289.737 |              126.556 |            832.711 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_c10d2_00000:
  custom_metrics:
    time_step_max: 4254
    time_step_mean: 3600.905643134567
    time_step_min: 3212
  date: 2020-10-12_15-32-53
  done: true
  episode_len_mean: 832.1042278996157
  episode_reward_max: 289.73737373737316
  episode_reward_mean: 231.138554890985
  episode_reward_min: 126.55555555555502
  episodes_this_iter: 201
  episodes_total: 4423
  experiment_id: 3f4e582e6be94933826b92afc540a970
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.0e-05
        entropy: 0.747990553577741
        entropy_coeff: 0.0005000000000000001
        kl: 0.005494295114961763
        model: {}
        policy_loss: -0.010693619498245729
        total_loss: 12.16190242767334
        vf_explained_var: 0.9790762066841125
        vf_loss: 12.172420819600424
    num_steps_sampled: 3721216
    num_steps_trained: 3721216
  iterations_since_restore: 23
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.200000000000003
    gpu_util_percent0: 0.35580645161290314
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7806451612903227
    vram_util_percent0: 0.10437848474909812
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 60268
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15075966806869268
    mean_env_wait_ms: 1.2120085410813248
    mean_inference_ms: 4.603596892062398
    mean_raw_obs_processing_ms: 0.3966594398506638
  time_since_restore: 609.6710937023163
  time_this_iter_s: 26.229853868484497
  time_total_s: 609.6710937023163
  timers:
    learn_throughput: 8415.49
    learn_time_ms: 19225.499
    sample_throughput: 23154.031
    sample_time_ms: 6987.639
    update_time_ms: 31.574
  timestamp: 1602516773
  timesteps_since_restore: 0
  timesteps_total: 3721216
  training_iteration: 23
  trial_id: c10d2_00000
  
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | TERMINATED |       |     23 |          609.671 | 3721216 |  231.139 |              289.737 |              126.556 |            832.104 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/557.47 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_c10d2_00000 | TERMINATED |       |     23 |          609.671 | 3721216 |  231.139 |              289.737 |              126.556 |            832.104 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


