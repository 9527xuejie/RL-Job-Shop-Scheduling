{"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episodes_this_iter": 0, "num_healthy_workers": 7, "timesteps_total": 11200, "episodes_total": 0, "training_iteration": 2, "timestamp": 1601918041, "time_this_iter_s": 355.5167429447174, "time_total_s": 696.4162075519562, "time_since_restore": 696.4162075519562, "timesteps_since_restore": 0, "iterations_since_restore": 2, "timers/sample_time_ms": 5162.88, "timers/sample_throughput": 1084.666, "timers/learn_time_ms": 342962.629, "timers/learn_throughput": 16.328, "timers/update_time_ms": 16.322, "info/num_steps_sampled": 11200, "info/num_steps_trained": 11200, "perf/cpu_util_percent": 16.78902953586498, "perf/ram_util_percent": 3.6736286919831236, "info/learner/default_policy/allreduce_latency": 0.0, "info/learner/default_policy/cur_kl_coeff": 0.44999999999999996, "info/learner/default_policy/cur_lr": 0.00010000000000000003, "info/learner/default_policy/total_loss": 67.70885762301359, "info/learner/default_policy/policy_loss": -0.2028603072447533, "info/learner/default_policy/vf_loss": 67.89436453038996, "info/learner/default_policy/vf_explained_var": 0.6005350947380066, "info/learner/default_policy/kl": 0.038790646771138367, "info/learner/default_policy/entropy": 1.0212658846920186, "info/learner/default_policy/entropy_coeff": 0.00010000000000000003, "_step": 1, "_runtime": 699, "_timestamp": 1601918041}