2020-10-10 19:03:38,807	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_4ef85_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=30965)[0m 2020-10-10 19:03:41,727	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=30942)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30942)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30984)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30984)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30939)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30939)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30958)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30958)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30978)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30978)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30914)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30914)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30946)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30946)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30915)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30915)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30918)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30918)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30909)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30909)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30921)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30921)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30912)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30912)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30880)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30880)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30904)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30904)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30916)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30916)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30872)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30872)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30936)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30936)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30925)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30925)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30955)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30955)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30929)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30927)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30927)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30844)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30844)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30903)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30903)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30886)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30886)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30963)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30963)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30863)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30863)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30922)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30922)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30917)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30917)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30943)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30943)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30924)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30924)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30846)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30846)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30881)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30874)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30874)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30857)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30857)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30843)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30843)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30870)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30870)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30845)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30845)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30941)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30941)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30935)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30935)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30962)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30962)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30898)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30898)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30933)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30933)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30920)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30920)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30934)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30934)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30861)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30861)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30940)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30940)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30867)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30867)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30869)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30869)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30938)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30938)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30847)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30847)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30923)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30923)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30950)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30950)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30930)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30930)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=30944)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=30944)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_19-04-21
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1847648876053947
        entropy_coeff: 0.00010000000000000002
        kl: 0.004644118848123721
        model: {}
        policy_loss: -0.009978268470149487
        total_loss: 9.50983054297311
        vf_explained_var: 0.7608073353767395
        vf_loss: 9.518998350415911
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 26.382051282051286
    gpu_util_percent0: 0.2607692307692307
    gpu_util_percent1: 0.0002564102564102564
    gpu_util_percent2: 0.0002564102564102564
    ram_util_percent: 6.284615384615386
    vram_util_percent0: 0.19117659425957234
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17425251507619238
    mean_env_wait_ms: 1.201234253956676
    mean_inference_ms: 5.874215662203368
    mean_raw_obs_processing_ms: 0.4696596739799309
  time_since_restore: 33.625245571136475
  time_this_iter_s: 33.625245571136475
  time_total_s: 33.625245571136475
  timers:
    learn_throughput: 6673.409
    learn_time_ms: 24244.282
    sample_throughput: 17386.266
    sample_time_ms: 9305.736
    update_time_ms: 31.107
  timestamp: 1602356661
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |      1 |          33.6252 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.7256944444443
    time_step_min: 3321
  date: 2020-10-10_19-04-52
  done: false
  episode_len_mean: 882.4462025316456
  episode_reward_max: 262.8383838383834
  episode_reward_mean: 218.19511571410283
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1518360716956002
        entropy_coeff: 0.00010000000000000002
        kl: 0.007502241991460323
        model: {}
        policy_loss: -0.011560356947094468
        total_loss: 7.968201671327863
        vf_explained_var: 0.8984608054161072
        vf_loss: 7.979127100535801
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.04594594594595
    gpu_util_percent0: 0.43324324324324326
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.464864864864865
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1688904872369294
    mean_env_wait_ms: 1.197548701368942
    mean_inference_ms: 5.611536233274023
    mean_raw_obs_processing_ms: 0.45716257727937765
  time_since_restore: 65.23272228240967
  time_this_iter_s: 31.607476711273193
  time_total_s: 65.23272228240967
  timers:
    learn_throughput: 6752.728
    learn_time_ms: 23959.502
    sample_throughput: 18847.708
    sample_time_ms: 8584.174
    update_time_ms: 25.935
  timestamp: 1602356692
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |      2 |          65.2327 | 323584 |  218.195 |              262.838 |              145.717 |            882.446 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3609.0829596412555
    time_step_min: 3303
  date: 2020-10-10_19-05-24
  done: false
  episode_len_mean: 874.4451476793249
  episode_reward_max: 269.0505050505048
  episode_reward_mean: 218.868622938243
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1333323291369848
        entropy_coeff: 0.00010000000000000002
        kl: 0.009005346069378512
        model: {}
        policy_loss: -0.01316997195993151
        total_loss: 7.779917410441807
        vf_explained_var: 0.9431506395339966
        vf_loss: 7.79229998588562
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.921621621621615
    gpu_util_percent0: 0.3037837837837838
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486486486486487
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16549361439350135
    mean_env_wait_ms: 1.1976376542865435
    mean_inference_ms: 5.419622421577225
    mean_raw_obs_processing_ms: 0.44803000484701555
  time_since_restore: 96.4884603023529
  time_this_iter_s: 31.255738019943237
  time_total_s: 96.4884603023529
  timers:
    learn_throughput: 6760.249
    learn_time_ms: 23932.847
    sample_throughput: 19832.639
    sample_time_ms: 8157.865
    update_time_ms: 25.403
  timestamp: 1602356724
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |      3 |          96.4885 | 485376 |  218.869 |              269.051 |              145.717 |            874.445 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3611.562913907285
    time_step_min: 3303
  date: 2020-10-10_19-05-54
  done: false
  episode_len_mean: 868.3417721518987
  episode_reward_max: 269.0505050505048
  episode_reward_mean: 218.53842219664992
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.1023581198283605
        entropy_coeff: 0.00010000000000000002
        kl: 0.009308189619332552
        model: {}
        policy_loss: -0.014589885366149247
        total_loss: 7.77988771029881
        vf_explained_var: 0.9629537463188171
        vf_loss: 7.793656826019287
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.452777777777776
    gpu_util_percent0: 0.27888888888888885
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16324223907388463
    mean_env_wait_ms: 1.1992725615259612
    mean_inference_ms: 5.281031404165068
    mean_raw_obs_processing_ms: 0.44099916906739445
  time_since_restore: 127.32060289382935
  time_this_iter_s: 30.83214259147644
  time_total_s: 127.32060289382935
  timers:
    learn_throughput: 6790.719
    learn_time_ms: 23825.458
    sample_throughput: 20400.959
    sample_time_ms: 7930.608
    update_time_ms: 23.973
  timestamp: 1602356754
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |      4 |          127.321 | 647168 |  218.538 |              269.051 |              145.717 |            868.342 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3611.436117936118
    time_step_min: 3263
  date: 2020-10-10_19-06-26
  done: false
  episode_len_mean: 859.4109263657957
  episode_reward_max: 271.6262626262625
  episode_reward_mean: 218.67711557379002
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 210
  episodes_total: 842
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0569530640329634
        entropy_coeff: 0.00010000000000000002
        kl: 0.008146991421069418
        model: {}
        policy_loss: -0.01523023724023785
        total_loss: 9.975987843104772
        vf_explained_var: 0.9767522811889648
        vf_loss: 9.990509033203125
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.751351351351353
    gpu_util_percent0: 0.3018918918918919
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.478378378378378
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1611479828289465
    mean_env_wait_ms: 1.20339425034595
    mean_inference_ms: 5.148848220652634
    mean_raw_obs_processing_ms: 0.4339674358879644
  time_since_restore: 158.70828795433044
  time_this_iter_s: 31.3876850605011
  time_total_s: 158.70828795433044
  timers:
    learn_throughput: 6786.358
    learn_time_ms: 23840.771
    sample_throughput: 20673.722
    sample_time_ms: 7825.974
    update_time_ms: 24.917
  timestamp: 1602356786
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |      5 |          158.708 | 808960 |  218.677 |              271.626 |              115.566 |            859.411 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3607.208719851577
    time_step_min: 3263
  date: 2020-10-10_19-06-57
  done: false
  episode_len_mean: 850.0461121157324
  episode_reward_max: 271.6262626262625
  episode_reward_mean: 219.34380879317575
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 264
  episodes_total: 1106
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0582811066082545
        entropy_coeff: 0.00010000000000000002
        kl: 0.00630582296954734
        model: {}
        policy_loss: -0.012449391044875873
        total_loss: 6.933801174163818
        vf_explained_var: 0.9833590388298035
        vf_loss: 6.94572571345738
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.261111111111106
    gpu_util_percent0: 0.39305555555555555
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.475
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1593995159452008
    mean_env_wait_ms: 1.2074441318992977
    mean_inference_ms: 5.040795241925486
    mean_raw_obs_processing_ms: 0.428078708663114
  time_since_restore: 189.81712651252747
  time_this_iter_s: 31.10883855819702
  time_total_s: 189.81712651252747
  timers:
    learn_throughput: 6793.877
    learn_time_ms: 23814.385
    sample_throughput: 20895.292
    sample_time_ms: 7742.988
    update_time_ms: 27.75
  timestamp: 1602356817
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |      6 |          189.817 | 970752 |  219.344 |              271.626 |              115.566 |            850.046 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3602.641585760518
    time_step_min: 3263
  date: 2020-10-10_19-07-28
  done: false
  episode_len_mean: 845.742088607595
  episode_reward_max: 278.2929292929295
  episode_reward_mean: 220.06472158291766
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 1.0249549405915397
        entropy_coeff: 0.00010000000000000002
        kl: 0.006016273151284882
        model: {}
        policy_loss: -0.014427397025948656
        total_loss: 5.084892817905971
        vf_explained_var: 0.9878643155097961
        vf_loss: 5.098821095057896
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.72432432432432
    gpu_util_percent0: 0.4097297297297297
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4837837837837835
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1586072016707537
    mean_env_wait_ms: 1.2095483476986348
    mean_inference_ms: 4.990764756296359
    mean_raw_obs_processing_ms: 0.4254009348295053
  time_since_restore: 220.87552428245544
  time_this_iter_s: 31.05839776992798
  time_total_s: 220.87552428245544
  timers:
    learn_throughput: 6794.393
    learn_time_ms: 23812.575
    sample_throughput: 21122.001
    sample_time_ms: 7659.88
    update_time_ms: 28.057
  timestamp: 1602356848
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |      7 |          220.876 | 1132544 |  220.065 |              278.293 |              115.566 |            845.742 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3597.1011477761836
    time_step_min: 3263
  date: 2020-10-10_19-07-59
  done: false
  episode_len_mean: 842.2180028129395
  episode_reward_max: 278.2929292929295
  episode_reward_mean: 220.86080211396654
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.997833000762122
        entropy_coeff: 0.00010000000000000002
        kl: 0.005373748119122216
        model: {}
        policy_loss: -0.013660562224686146
        total_loss: 4.632702384676252
        vf_explained_var: 0.9896780252456665
        vf_loss: 4.645925351551601
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.05833333333333
    gpu_util_percent0: 0.22055555555555556
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502777777777777
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1579376574050868
    mean_env_wait_ms: 1.2115008296872753
    mean_inference_ms: 4.947777521547804
    mean_raw_obs_processing_ms: 0.4230149099678735
  time_since_restore: 252.03675866127014
  time_this_iter_s: 31.161234378814697
  time_total_s: 252.03675866127014
  timers:
    learn_throughput: 6794.493
    learn_time_ms: 23812.226
    sample_throughput: 21260.227
    sample_time_ms: 7610.079
    update_time_ms: 29.071
  timestamp: 1602356879
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |      8 |          252.037 | 1294336 |  220.861 |              278.293 |              115.566 |            842.218 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3587.7084337349397
    time_step_min: 3263
  date: 2020-10-10_19-08-31
  done: false
  episode_len_mean: 836.8548578199052
  episode_reward_max: 278.2929292929295
  episode_reward_mean: 222.1283809660586
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 266
  episodes_total: 1688
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.958605923822948
        entropy_coeff: 0.00010000000000000002
        kl: 0.006028549812201943
        model: {}
        policy_loss: -0.011906250745856337
        total_loss: 6.174642665045602
        vf_explained_var: 0.9919312596321106
        vf_loss: 6.186042104448591
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.540540540540544
    gpu_util_percent0: 0.37324324324324326
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.467567567567568
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1570257209580662
    mean_env_wait_ms: 1.2148082692066202
    mean_inference_ms: 4.888429888847609
    mean_raw_obs_processing_ms: 0.4197809617157082
  time_since_restore: 283.34899258613586
  time_this_iter_s: 31.312233924865723
  time_total_s: 283.34899258613586
  timers:
    learn_throughput: 6795.38
    learn_time_ms: 23809.118
    sample_throughput: 21312.601
    sample_time_ms: 7591.378
    update_time_ms: 28.881
  timestamp: 1602356911
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |      9 |          283.349 | 1456128 |  222.128 |              278.293 |              115.566 |            836.855 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3581.4935760171306
    time_step_min: 3263
  date: 2020-10-10_19-09-02
  done: false
  episode_len_mean: 834.2605485232068
  episode_reward_max: 278.2929292929295
  episode_reward_mean: 223.10633231044616
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 208
  episodes_total: 1896
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9300487126622882
        entropy_coeff: 0.00010000000000000002
        kl: 0.005668006205399122
        model: {}
        policy_loss: -0.013933567047518278
        total_loss: 3.746108259473528
        vf_explained_var: 0.9932482838630676
        vf_loss: 3.759568078177316
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.42777777777778
    gpu_util_percent0: 0.2672222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494444444444444
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1564626348202372
    mean_env_wait_ms: 1.2168933689673973
    mean_inference_ms: 4.851421690592241
    mean_raw_obs_processing_ms: 0.4177814259082904
  time_since_restore: 314.53672981262207
  time_this_iter_s: 31.187737226486206
  time_total_s: 314.53672981262207
  timers:
    learn_throughput: 6801.66
    learn_time_ms: 23787.133
    sample_throughput: 21338.696
    sample_time_ms: 7582.094
    update_time_ms: 30.279
  timestamp: 1602356942
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |     10 |          314.537 | 1617920 |  223.106 |              278.293 |              115.566 |            834.261 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3577.3307008884503
    time_step_min: 3263
  date: 2020-10-10_19-09-33
  done: false
  episode_len_mean: 832.713729308666
  episode_reward_max: 278.2929292929295
  episode_reward_mean: 223.73744258554376
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.9052012349878039
        entropy_coeff: 0.00010000000000000002
        kl: 0.0051750079396047765
        model: {}
        policy_loss: -0.012825779462998201
        total_loss: 3.2948688779558455
        vf_explained_var: 0.994076669216156
        vf_loss: 3.30726763180324
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.82777777777778
    gpu_util_percent0: 0.34944444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1560784095474722
    mean_env_wait_ms: 1.218276053665979
    mean_inference_ms: 4.826608103107636
    mean_raw_obs_processing_ms: 0.416435743643103
  time_since_restore: 345.6628496646881
  time_this_iter_s: 31.12611985206604
  time_total_s: 345.6628496646881
  timers:
    learn_throughput: 6817.751
    learn_time_ms: 23730.991
    sample_throughput: 21899.464
    sample_time_ms: 7387.943
    update_time_ms: 29.847
  timestamp: 1602356973
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |     11 |          345.663 | 1779712 |  223.737 |              278.293 |              115.566 |            832.714 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3572.467032967033
    time_step_min: 3231
  date: 2020-10-10_19-10-04
  done: false
  episode_len_mean: 831.3155515370705
  episode_reward_max: 278.2929292929295
  episode_reward_mean: 224.4901181799915
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8931240396840232
        entropy_coeff: 0.00010000000000000002
        kl: 0.005281988930489335
        model: {}
        policy_loss: -0.01340305883370872
        total_loss: 3.077025668961661
        vf_explained_var: 0.9944506287574768
        vf_loss: 3.089989866529192
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.297222222222228
    gpu_util_percent0: 0.27194444444444454
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1557281141309168
    mean_env_wait_ms: 1.2195240245830117
    mean_inference_ms: 4.804181038417208
    mean_raw_obs_processing_ms: 0.41519567485534714
  time_since_restore: 376.68333101272583
  time_this_iter_s: 31.02048134803772
  time_total_s: 376.68333101272583
  timers:
    learn_throughput: 6824.591
    learn_time_ms: 23707.207
    sample_throughput: 22005.277
    sample_time_ms: 7352.418
    update_time_ms: 29.828
  timestamp: 1602357004
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |     12 |          376.683 | 1941504 |   224.49 |              278.293 |              115.566 |            831.316 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3566.448723145521
    time_step_min: 3224
  date: 2020-10-10_19-10-35
  done: false
  episode_len_mean: 829.811623246493
  episode_reward_max: 278.2929292929295
  episode_reward_mean: 225.1980729135037
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 283
  episodes_total: 2495
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.8601605551583427
        entropy_coeff: 0.00010000000000000002
        kl: 0.004365290382078716
        model: {}
        policy_loss: -0.010259947656387729
        total_loss: 4.764940772737775
        vf_explained_var: 0.9941977262496948
        vf_loss: 4.774850198200771
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.625
    gpu_util_percent0: 0.31500000000000006
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480555555555556
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15516646605130888
    mean_env_wait_ms: 1.2215496770321423
    mean_inference_ms: 4.769136056741457
    mean_raw_obs_processing_ms: 0.41325774883746785
  time_since_restore: 407.59157848358154
  time_this_iter_s: 30.908247470855713
  time_total_s: 407.59157848358154
  timers:
    learn_throughput: 6832.185
    learn_time_ms: 23680.856
    sample_throughput: 22032.65
    sample_time_ms: 7343.284
    update_time_ms: 29.376
  timestamp: 1602357035
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |     13 |          407.592 | 2103296 |  225.198 |              278.293 |              115.566 |            829.812 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3564.6595184349135
    time_step_min: 3224
  date: 2020-10-10_19-11-06
  done: false
  episode_len_mean: 829.3626209977662
  episode_reward_max: 278.2929292929295
  episode_reward_mean: 225.70329505027937
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 191
  episodes_total: 2686
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 0.8240127520901817
        entropy_coeff: 0.00010000000000000002
        kl: 0.004833582522613662
        model: {}
        policy_loss: -0.012919317786002336
        total_loss: 3.195051908493042
        vf_explained_var: 0.9947142601013184
        vf_loss: 3.2078119856970653
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.438888888888883
    gpu_util_percent0: 0.2719444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222223
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1548679281385576
    mean_env_wait_ms: 1.222708192583369
    mean_inference_ms: 4.749247707068643
    mean_raw_obs_processing_ms: 0.4121860387590361
  time_since_restore: 438.41694259643555
  time_this_iter_s: 30.825364112854004
  time_total_s: 438.41694259643555
  timers:
    learn_throughput: 6831.868
    learn_time_ms: 23681.956
    sample_throughput: 22041.337
    sample_time_ms: 7340.39
    update_time_ms: 30.744
  timestamp: 1602357066
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |     14 |          438.417 | 2265088 |  225.703 |              278.293 |              115.566 |            829.363 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3562.6537642045455
    time_step_min: 3224
  date: 2020-10-10_19-11-37
  done: false
  episode_len_mean: 828.838959212377
  episode_reward_max: 278.2929292929295
  episode_reward_mean: 226.0017154669053
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.000000000000001e-05
        entropy: 0.822911160332816
        entropy_coeff: 0.00010000000000000002
        kl: 0.00517554345008518
        model: {}
        policy_loss: -0.011527769317451333
        total_loss: 2.779497333935329
        vf_explained_var: 0.9951347708702087
        vf_loss: 2.790978057043893
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.36285714285715
    gpu_util_percent0: 0.26685714285714285
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491428571428571
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1546305391097321
    mean_env_wait_ms: 1.2235619227422285
    mean_inference_ms: 4.734001795327339
    mean_raw_obs_processing_ms: 0.4113365913831525
  time_since_restore: 468.9607608318329
  time_this_iter_s: 30.54381823539734
  time_total_s: 468.9607608318329
  timers:
    learn_throughput: 6846.702
    learn_time_ms: 23630.646
    sample_throughput: 22140.222
    sample_time_ms: 7307.605
    update_time_ms: 29.74
  timestamp: 1602357097
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |     15 |          468.961 | 2426880 |  226.002 |              278.293 |              115.566 |            828.839 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3559.6967047747144
    time_step_min: 3224
  date: 2020-10-10_19-12-08
  done: false
  episode_len_mean: 828.290473017988
  episode_reward_max: 278.2929292929295
  episode_reward_mean: 226.46066595333744
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 158
  episodes_total: 3002
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.025000000000000005
        cur_lr: 5.000000000000001e-05
        entropy: 0.8151624245303017
        entropy_coeff: 0.00010000000000000002
        kl: 0.004912548033254487
        model: {}
        policy_loss: -0.012115305293783811
        total_loss: 2.5438684906278337
        vf_explained_var: 0.9954208731651306
        vf_loss: 2.555942484310695
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.241666666666667
    gpu_util_percent0: 0.27861111111111114
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666667
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15440972693511087
    mean_env_wait_ms: 1.2243502710420986
    mean_inference_ms: 4.719820234441021
    mean_raw_obs_processing_ms: 0.4105357681046839
  time_since_restore: 499.64847350120544
  time_this_iter_s: 30.68771266937256
  time_total_s: 499.64847350120544
  timers:
    learn_throughput: 6851.971
    learn_time_ms: 23612.476
    sample_throughput: 22206.89
    sample_time_ms: 7285.667
    update_time_ms: 27.798
  timestamp: 1602357128
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |     16 |          499.648 | 2588672 |  226.461 |              278.293 |              115.566 |             828.29 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3554.439421894219
    time_step_min: 3224
  date: 2020-10-10_19-12-39
  done: false
  episode_len_mean: 827.2493902439024
  episode_reward_max: 278.2929292929295
  episode_reward_mean: 227.2816118502094
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 278
  episodes_total: 3280
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.012500000000000002
        cur_lr: 5.000000000000001e-05
        entropy: 0.7842179025922503
        entropy_coeff: 0.00010000000000000002
        kl: 0.004938584519550204
        model: {}
        policy_loss: -0.009811018822282287
        total_loss: 3.3719296795981273
        vf_explained_var: 0.9956532716751099
        vf_loss: 3.3817574296678816
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.819444444444446
    gpu_util_percent0: 0.2786111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480555555555556
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15404752127249363
    mean_env_wait_ms: 1.2256202228913342
    mean_inference_ms: 4.696881230022025
    mean_raw_obs_processing_ms: 0.4092276282031386
  time_since_restore: 530.5667653083801
  time_this_iter_s: 30.918291807174683
  time_total_s: 530.5667653083801
  timers:
    learn_throughput: 6857.118
    learn_time_ms: 23594.753
    sample_throughput: 22192.1
    sample_time_ms: 7290.522
    update_time_ms: 26.916
  timestamp: 1602357159
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |     17 |          530.567 | 2750464 |  227.282 |              278.293 |              115.566 |            827.249 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3551.1818445475637
    time_step_min: 3224
  date: 2020-10-10_19-13-10
  done: false
  episode_len_mean: 826.3978711162256
  episode_reward_max: 278.2929292929295
  episode_reward_mean: 227.85982959630832
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 196
  episodes_total: 3476
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.006250000000000001
        cur_lr: 5.000000000000001e-05
        entropy: 0.7384911860738482
        entropy_coeff: 0.00010000000000000002
        kl: 0.0049526806521628585
        model: {}
        policy_loss: -0.012027985742861347
        total_loss: 2.2414031199046542
        vf_explained_var: 0.9960728287696838
        vf_loss: 2.2534739800861905
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.368571428571432
    gpu_util_percent0: 0.2788571428571429
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491428571428571
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15384734688306018
    mean_env_wait_ms: 1.226517647801489
    mean_inference_ms: 4.683300390991428
    mean_raw_obs_processing_ms: 0.4084893574583684
  time_since_restore: 561.2326338291168
  time_this_iter_s: 30.665868520736694
  time_total_s: 561.2326338291168
  timers:
    learn_throughput: 6867.495
    learn_time_ms: 23559.098
    sample_throughput: 22232.434
    sample_time_ms: 7277.296
    update_time_ms: 25.324
  timestamp: 1602357190
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |     18 |          561.233 | 2912256 |   227.86 |              278.293 |              115.566 |            826.398 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3548.135052689961
    time_step_min: 3198
  date: 2020-10-10_19-13-41
  done: false
  episode_len_mean: 825.7605943863512
  episode_reward_max: 281.47474747474746
  episode_reward_mean: 228.2667873006343
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0031250000000000006
        cur_lr: 5.000000000000001e-05
        entropy: 0.7518549391201564
        entropy_coeff: 0.00010000000000000002
        kl: 0.00477660636949752
        model: {}
        policy_loss: -0.011928292224183679
        total_loss: 2.12941483940397
        vf_explained_var: 0.9957841634750366
        vf_loss: 2.141403377056122
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 22.194444444444443
    gpu_util_percent0: 0.3747222222222223
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.499999999999999
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15368564755231923
    mean_env_wait_ms: 1.2271804945814249
    mean_inference_ms: 4.672756928714976
    mean_raw_obs_processing_ms: 0.40790389866329985
  time_since_restore: 592.0490889549255
  time_this_iter_s: 30.816455125808716
  time_total_s: 592.0490889549255
  timers:
    learn_throughput: 6872.081
    learn_time_ms: 23543.378
    sample_throughput: 22335.372
    sample_time_ms: 7243.757
    update_time_ms: 24.451
  timestamp: 1602357221
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | RUNNING  | 172.17.0.4:30965 |     19 |          592.049 | 3074048 |  228.267 |              281.475 |              115.566 |            825.761 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_4ef85_00000:
  custom_metrics:
    time_step_max: 4293
    time_step_mean: 3545.9269976108308
    time_step_min: 3198
  date: 2020-10-10_19-14-12
  done: true
  episode_len_mean: 824.93465085639
  episode_reward_max: 281.47474747474746
  episode_reward_mean: 228.6563660318601
  episode_reward_min: 115.56565656565654
  episodes_this_iter: 161
  episodes_total: 3795
  experiment_id: 590ba4db51a34de4907b804cec43b7c0
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.0015625000000000003
        cur_lr: 5.000000000000001e-05
        entropy: 0.7437918441636222
        entropy_coeff: 0.00010000000000000002
        kl: 0.005056826031899878
        model: {}
        policy_loss: -0.01222280806229849
        total_loss: 2.160470349448068
        vf_explained_var: 0.995955765247345
        vf_loss: 2.172759643622807
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.225
    gpu_util_percent0: 0.33944444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 30965
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15352997487554323
    mean_env_wait_ms: 1.2278456413698537
    mean_inference_ms: 4.662645955580495
    mean_raw_obs_processing_ms: 0.40733145864199666
  time_since_restore: 622.8078320026398
  time_this_iter_s: 30.758743047714233
  time_total_s: 622.8078320026398
  timers:
    learn_throughput: 6873.407
    learn_time_ms: 23538.836
    sample_throughput: 22451.157
    sample_time_ms: 7206.399
    update_time_ms: 23.138
  timestamp: 1602357252
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: 4ef85_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | TERMINATED |       |     20 |          622.808 | 3235840 |  228.656 |              281.475 |              115.566 |            824.935 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.45 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_4ef85_00000 | TERMINATED |       |     20 |          622.808 | 3235840 |  228.656 |              281.475 |              115.566 |            824.935 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


