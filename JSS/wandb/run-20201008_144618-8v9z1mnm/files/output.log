2020-10-08 14:46:20,311	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8270[39m[22m
== Status ==
Memory usage on this node: 57.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_0817b_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=9984)[0m 2020-10-08 14:46:23,225	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=9954)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9954)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9982)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9982)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9968)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9968)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9948)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9948)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9934)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9934)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9957)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9957)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9964)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9964)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9986)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9986)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9965)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9965)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9937)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9937)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9970)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9970)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9941)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9941)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9931)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9931)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9952)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9952)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9946)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9946)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9943)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9943)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9849)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9849)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9972)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9972)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9890)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9890)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9868)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9868)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9960)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9960)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9857)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9857)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9995)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9995)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9854)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9854)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9928)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9928)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9951)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9951)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9961)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9961)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9852)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9852)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9925)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9925)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9863)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9863)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9932)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9932)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9861)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9861)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9959)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9959)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9976)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9976)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9974)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9974)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9926)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9926)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9983)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9983)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9885)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9885)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9883)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9883)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9851)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9851)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9865)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9865)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9860)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9860)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9850)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9850)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9981)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9981)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9862)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9862)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9859)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9859)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9878)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9878)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9910)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9910)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9924)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9924)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9879)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9879)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9935)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9935)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9892)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9892)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9855)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9855)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9884)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9884)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9864)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9864)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9944)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9944)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9856)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9856)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9945)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9945)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9876)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9876)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9913)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9913)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9947)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9947)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9916)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9916)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=10000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=10000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9915)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9915)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9858)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9858)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9907)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9907)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9853)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9853)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9912)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9912)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9922)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9922)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9917)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9917)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9923)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9923)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9919)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9919)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9875)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9875)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9929)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9929)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9848)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9848)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9888)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9888)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=9881)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=9881)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3279.0
  date: 2020-10-08_14-47-09
  done: false
  episode_len_mean: 877.1708860759494
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 224.28870988364636
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1592639476060866
        entropy_coeff: 0.0
        kl: 0.007948391686659307
        model: {}
        policy_loss: -0.022543937200680375
        total_loss: 6.240074229240418
        vf_explained_var: 0.8296059370040894
        vf_loss: 6.261028575897217
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 28.273469387755103
    gpu_util_percent0: 0.3116326530612245
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.534693877551021
    vram_util_percent0: 0.2520314455726535
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1783144433544756
    mean_env_wait_ms: 1.650301670358298
    mean_inference_ms: 6.069417210337776
    mean_raw_obs_processing_ms: 0.4895891323248594
  time_since_restore: 40.30372738838196
  time_this_iter_s: 40.30372738838196
  time_total_s: 40.30372738838196
  timers:
    learn_throughput: 5366.94
    learn_time_ms: 30146.041
    sample_throughput: 16044.531
    sample_time_ms: 10083.934
    update_time_ms: 28.919
  timestamp: 1602168429
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 72.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |      1 |          40.3037 | 161792 |  224.289 |              273.131 |              115.788 |            877.171 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3257.0
  date: 2020-10-08_14-47-48
  done: false
  episode_len_mean: 872.2246835443038
  episode_reward_max: 273.13131313131294
  episode_reward_mean: 225.3844457230531
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.1296887159347535
        entropy_coeff: 0.0
        kl: 0.008525328745599836
        model: {}
        policy_loss: -0.028191588423214852
        total_loss: 4.803836739063263
        vf_explained_var: 0.936334490776062
        vf_loss: 4.8303231477737425
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.397826086956524
    gpu_util_percent0: 0.29826086956521736
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.76304347826087
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1731203001601768
    mean_env_wait_ms: 1.6477533730345844
    mean_inference_ms: 5.737647433638773
    mean_raw_obs_processing_ms: 0.4733236914828316
  time_since_restore: 78.83796572685242
  time_this_iter_s: 38.53423833847046
  time_total_s: 78.83796572685242
  timers:
    learn_throughput: 5370.704
    learn_time_ms: 30124.912
    sample_throughput: 17557.631
    sample_time_ms: 9214.911
    update_time_ms: 32.418
  timestamp: 1602168468
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |      2 |           78.838 | 323584 |  225.384 |              273.131 |              115.788 |            872.225 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3210.0
  date: 2020-10-08_14-48-26
  done: false
  episode_len_mean: 867.3649789029536
  episode_reward_max: 279.0707070707072
  episode_reward_mean: 226.2276349997867
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.117047417163849
        entropy_coeff: 0.0
        kl: 0.009439966594800352
        model: {}
        policy_loss: -0.034238369972445074
        total_loss: 3.529190015792847
        vf_explained_var: 0.9731075167655945
        vf_loss: 3.5615403831005095
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.097777777777786
    gpu_util_percent0: 0.3348888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.775555555555558
    vram_util_percent0: 0.257051492292555
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16961927268934604
    mean_env_wait_ms: 1.6469866243455586
    mean_inference_ms: 5.548038411476553
    mean_raw_obs_processing_ms: 0.46218913140483775
  time_since_restore: 117.11967849731445
  time_this_iter_s: 38.281712770462036
  time_total_s: 117.11967849731445
  timers:
    learn_throughput: 5383.601
    learn_time_ms: 30052.75
    sample_throughput: 18166.238
    sample_time_ms: 8906.192
    update_time_ms: 33.785
  timestamp: 1602168506
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |      3 |           117.12 | 485376 |  226.228 |              279.071 |              115.788 |            867.365 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3210.0
  date: 2020-10-08_14-49-05
  done: false
  episode_len_mean: 862.0617088607595
  episode_reward_max: 279.0707070707072
  episode_reward_mean: 226.56910880961496
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0891690492630004
        entropy_coeff: 0.0
        kl: 0.010195579170249403
        model: {}
        policy_loss: -0.03982555363327265
        total_loss: 3.150597554445267
        vf_explained_var: 0.982883095741272
        vf_loss: 3.1883840203285216
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.686956521739127
    gpu_util_percent0: 0.3069565217391304
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.769565217391307
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1672562130180571
    mean_env_wait_ms: 1.648701265243827
    mean_inference_ms: 5.410601431877465
    mean_raw_obs_processing_ms: 0.4545399933035608
  time_since_restore: 155.53774642944336
  time_this_iter_s: 38.418067932128906
  time_total_s: 155.53774642944336
  timers:
    learn_throughput: 5392.327
    learn_time_ms: 30004.115
    sample_throughput: 18384.494
    sample_time_ms: 8800.46
    update_time_ms: 30.963
  timestamp: 1602168545
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |      4 |          155.538 | 647168 |  226.569 |              279.071 |              115.788 |            862.062 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3210.0
  date: 2020-10-08_14-49-43
  done: false
  episode_len_mean: 852.1263858093126
  episode_reward_max: 279.32323232323193
  episode_reward_mean: 226.9749154516337
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 270
  episodes_total: 902
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0533890515565871
        entropy_coeff: 0.0
        kl: 0.009304816112853586
        model: {}
        policy_loss: -0.04371898924000561
        total_loss: 5.12883574962616
        vf_explained_var: 0.9868589639663696
        vf_loss: 5.170693731307983
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.960869565217386
    gpu_util_percent0: 0.30869565217391304
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765217391304349
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16472878604108404
    mean_env_wait_ms: 1.654769446853481
    mean_inference_ms: 5.255028595856195
    mean_raw_obs_processing_ms: 0.4468815990887715
  time_since_restore: 193.72312140464783
  time_this_iter_s: 38.18537497520447
  time_total_s: 193.72312140464783
  timers:
    learn_throughput: 5395.506
    learn_time_ms: 29986.437
    sample_throughput: 18648.142
    sample_time_ms: 8676.038
    update_time_ms: 32.749
  timestamp: 1602168583
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |      5 |          193.723 | 808960 |  226.975 |              279.323 |              115.788 |            852.126 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3210.0
  date: 2020-10-08_14-50-21
  done: false
  episode_len_mean: 846.9891500904159
  episode_reward_max: 279.32323232323193
  episode_reward_mean: 226.93595082835574
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 204
  episodes_total: 1106
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0660148084163665
        entropy_coeff: 0.0
        kl: 0.009780311863869429
        model: {}
        policy_loss: -0.04468258414417505
        total_loss: 2.9281822681427
        vf_explained_var: 0.9906903505325317
        vf_loss: 2.9709088265895844
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.34347826086957
    gpu_util_percent0: 0.3019565217391305
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.765217391304349
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16337296386637554
    mean_env_wait_ms: 1.6576438641774298
    mean_inference_ms: 5.1748807314964855
    mean_raw_obs_processing_ms: 0.44283691372742
  time_since_restore: 231.9906542301178
  time_this_iter_s: 38.26753282546997
  time_total_s: 231.9906542301178
  timers:
    learn_throughput: 5395.701
    learn_time_ms: 29985.355
    sample_throughput: 18839.78
    sample_time_ms: 8587.786
    update_time_ms: 31.27
  timestamp: 1602168621
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |      6 |          231.991 | 970752 |  226.936 |              279.323 |              115.788 |            846.989 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3185.0
  date: 2020-10-08_14-50-59
  done: false
  episode_len_mean: 843.0680379746835
  episode_reward_max: 281.79797979797956
  episode_reward_mean: 227.2633694540339
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0390727072954178
        entropy_coeff: 0.0
        kl: 0.009381772321648895
        model: {}
        policy_loss: -0.047484182519838214
        total_loss: 2.5134040772914887
        vf_explained_var: 0.9927171468734741
        vf_loss: 2.5590119063854218
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.20444444444445
    gpu_util_percent0: 0.2937777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.773333333333335
    vram_util_percent0: 0.257051492292555
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16258743873319656
    mean_env_wait_ms: 1.6601336474241082
    mean_inference_ms: 5.124107285384215
    mean_raw_obs_processing_ms: 0.4403770020049003
  time_since_restore: 270.19439721107483
  time_this_iter_s: 38.20374298095703
  time_total_s: 270.19439721107483
  timers:
    learn_throughput: 5402.628
    learn_time_ms: 29946.906
    sample_throughput: 18902.174
    sample_time_ms: 8559.439
    update_time_ms: 32.112
  timestamp: 1602168659
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |      7 |          270.194 | 1132544 |  227.263 |              281.798 |              115.788 |            843.068 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3185.0
  date: 2020-10-08_14-51-38
  done: false
  episode_len_mean: 839.9458509142054
  episode_reward_max: 281.79797979797956
  episode_reward_mean: 227.77947548622643
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 1.0156935468316077
        entropy_coeff: 0.0
        kl: 0.009458976401947438
        model: {}
        policy_loss: -0.0521769187413156
        total_loss: 2.4901450872421265
        vf_explained_var: 0.9934619665145874
        vf_loss: 2.5404302209615706
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.791304347826095
    gpu_util_percent0: 0.3089130434782608
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771739130434785
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16191827267798584
    mean_env_wait_ms: 1.6624141189215649
    mean_inference_ms: 5.080138947049479
    mean_raw_obs_processing_ms: 0.4381847499788187
  time_since_restore: 308.3312146663666
  time_this_iter_s: 38.13681745529175
  time_total_s: 308.3312146663666
  timers:
    learn_throughput: 5404.71
    learn_time_ms: 29935.372
    sample_throughput: 19001.38
    sample_time_ms: 8514.75
    update_time_ms: 30.808
  timestamp: 1602168698
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |      8 |          308.331 | 1294336 |  227.779 |              281.798 |              115.788 |            839.946 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3185.0
  date: 2020-10-08_14-52-16
  done: false
  episode_len_mean: 835.2857142857143
  episode_reward_max: 281.79797979797956
  episode_reward_mean: 228.5803987395823
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 293
  episodes_total: 1715
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9816052317619324
        entropy_coeff: 0.0
        kl: 0.00929078480694443
        model: {}
        policy_loss: -0.050440557114779946
        total_loss: 4.027209287881851
        vf_explained_var: 0.993869423866272
        vf_loss: 4.075791692733764
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.706521739130444
    gpu_util_percent0: 0.3076086956521739
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.767391304347827
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1609327977377158
    mean_env_wait_ms: 1.6664567315447043
    mean_inference_ms: 5.01521421732558
    mean_raw_obs_processing_ms: 0.4350103869700399
  time_since_restore: 346.8683125972748
  time_this_iter_s: 38.5370979309082
  time_total_s: 346.8683125972748
  timers:
    learn_throughput: 5399.967
    learn_time_ms: 29961.662
    sample_throughput: 19064.443
    sample_time_ms: 8486.584
    update_time_ms: 32.696
  timestamp: 1602168736
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |      9 |          346.868 | 1456128 |   228.58 |              281.798 |              115.788 |            835.286 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3185.0
  date: 2020-10-08_14-52-55
  done: false
  episode_len_mean: 832.882911392405
  episode_reward_max: 281.79797979797956
  episode_reward_mean: 228.91709819716138
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 181
  episodes_total: 1896
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9750424057245255
        entropy_coeff: 0.0
        kl: 0.009096412127837539
        model: {}
        policy_loss: -0.0501532347407192
        total_loss: 2.4035121321678163
        vf_explained_var: 0.9949032068252563
        vf_loss: 2.451846122741699
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.64565217391304
    gpu_util_percent0: 0.2971739130434782
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.767391304347827
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16042992921880403
    mean_env_wait_ms: 1.668297182261619
    mean_inference_ms: 4.982508393763542
    mean_raw_obs_processing_ms: 0.43335836618586776
  time_since_restore: 385.0608251094818
  time_this_iter_s: 38.19251251220703
  time_total_s: 385.0608251094818
  timers:
    learn_throughput: 5401.482
    learn_time_ms: 29953.263
    sample_throughput: 19120.786
    sample_time_ms: 8461.577
    update_time_ms: 31.639
  timestamp: 1602168775
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |     10 |          385.061 | 1617920 |  228.917 |              281.798 |              115.788 |            832.883 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3185.0
  date: 2020-10-08_14-53-33
  done: false
  episode_len_mean: 831.1830574488803
  episode_reward_max: 282.3838383838384
  episode_reward_mean: 229.18083463653076
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9576577469706535
        entropy_coeff: 0.0
        kl: 0.008958257175981999
        model: {}
        policy_loss: -0.05053197899833321
        total_loss: 2.2172914415597917
        vf_explained_var: 0.9955032467842102
        vf_loss: 2.2660318076610566
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.173333333333332
    gpu_util_percent0: 0.3104444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.773333333333335
    vram_util_percent0: 0.257051492292555
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1600454319827222
    mean_env_wait_ms: 1.6698576624063575
    mean_inference_ms: 4.957300792054742
    mean_raw_obs_processing_ms: 0.4320678028692031
  time_since_restore: 423.282279253006
  time_this_iter_s: 38.22145414352417
  time_total_s: 423.282279253006
  timers:
    learn_throughput: 5412.216
    learn_time_ms: 29893.855
    sample_throughput: 19465.136
    sample_time_ms: 8311.887
    update_time_ms: 30.924
  timestamp: 1602168813
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |     11 |          423.282 | 1779712 |  229.181 |              282.384 |              115.788 |            831.183 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_14-54-11
  done: false
  episode_len_mean: 829.4905063291139
  episode_reward_max: 283.40404040404024
  episode_reward_mean: 229.2969523444206
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9391592800617218
        entropy_coeff: 0.0
        kl: 0.009445522562600672
        model: {}
        policy_loss: -0.05478629060089588
        total_loss: 2.2278044700622557
        vf_explained_var: 0.9958022236824036
        vf_loss: 2.280701658129692
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.867391304347827
    gpu_util_percent0: 0.3015217391304348
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771739130434783
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1596968064524376
    mean_env_wait_ms: 1.671323271720911
    mean_inference_ms: 4.934578486470254
    mean_raw_obs_processing_ms: 0.4308892736699046
  time_since_restore: 461.5014171600342
  time_this_iter_s: 38.2191379070282
  time_total_s: 461.5014171600342
  timers:
    learn_throughput: 5413.287
    learn_time_ms: 29887.943
    sample_throughput: 19525.424
    sample_time_ms: 8286.222
    update_time_ms: 29.622
  timestamp: 1602168851
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |     12 |          461.501 | 1941504 |  229.297 |              283.404 |              115.788 |            829.491 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_14-54-50
  done: false
  episode_len_mean: 826.9766058683584
  episode_reward_max: 283.40404040404024
  episode_reward_mean: 230.0283364974086
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 310
  episodes_total: 2522
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.9088199973106384
        entropy_coeff: 0.0
        kl: 0.008949108957313
        model: {}
        policy_loss: -0.046782314940355715
        total_loss: 3.1065574049949647
        vf_explained_var: 0.9959770441055298
        vf_loss: 3.1515498876571657
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.735555555555553
    gpu_util_percent0: 0.3211111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.766666666666667
    vram_util_percent0: 0.257051492292555
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15910780382724396
    mean_env_wait_ms: 1.6739828363696263
    mean_inference_ms: 4.896482547704333
    mean_raw_obs_processing_ms: 0.42896977342326853
  time_since_restore: 499.5115191936493
  time_this_iter_s: 38.01010203361511
  time_total_s: 499.5115191936493
  timers:
    learn_throughput: 5415.523
    learn_time_ms: 29875.6
    sample_throughput: 19564.145
    sample_time_ms: 8269.822
    update_time_ms: 30.351
  timestamp: 1602168890
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |     13 |          499.512 | 2103296 |  230.028 |              283.404 |              115.788 |            826.977 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_14-55-28
  done: false
  episode_len_mean: 826.1135517498138
  episode_reward_max: 283.40404040404024
  episode_reward_mean: 230.43506923290983
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 164
  episodes_total: 2686
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.8924642086029053
        entropy_coeff: 0.0
        kl: 0.009387114527635276
        model: {}
        policy_loss: -0.05357600767165423
        total_loss: 1.8019031524658202
        vf_explained_var: 0.9966928362846375
        vf_loss: 1.853601735830307
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.208695652173915
    gpu_util_percent0: 0.31130434782608696
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.773913043478263
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15882693258596958
    mean_env_wait_ms: 1.675173906031347
    mean_inference_ms: 4.878950125383862
    mean_raw_obs_processing_ms: 0.42808279530680976
  time_since_restore: 537.6373221874237
  time_this_iter_s: 38.125802993774414
  time_total_s: 537.6373221874237
  timers:
    learn_throughput: 5417.025
    learn_time_ms: 29867.315
    sample_throughput: 19614.815
    sample_time_ms: 8248.459
    update_time_ms: 30.216
  timestamp: 1602168928
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |     14 |          537.637 | 2265088 |  230.435 |              283.404 |              115.788 |            826.114 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_14-56-06
  done: false
  episode_len_mean: 825.506329113924
  episode_reward_max: 283.40404040404024
  episode_reward_mean: 230.81870391680513
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.8953717708587646
        entropy_coeff: 0.0
        kl: 0.00942096272483468
        model: {}
        policy_loss: -0.054289334313943984
        total_loss: 1.632664692401886
        vf_explained_var: 0.9969428777694702
        vf_loss: 1.6850698381662368
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.94347826086956
    gpu_util_percent0: 0.30782608695652175
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.773913043478263
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1585872222192178
    mean_env_wait_ms: 1.6762724980052552
    mean_inference_ms: 4.863464460341154
    mean_raw_obs_processing_ms: 0.4273048025070616
  time_since_restore: 576.0887100696564
  time_this_iter_s: 38.451387882232666
  time_total_s: 576.0887100696564
  timers:
    learn_throughput: 5412.588
    learn_time_ms: 29891.802
    sample_throughput: 19611.844
    sample_time_ms: 8249.709
    update_time_ms: 30.298
  timestamp: 1602168966
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | RUNNING  | 172.17.0.4:9984 |     15 |          576.089 | 2426880 |  230.819 |              283.404 |              115.788 |            825.506 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_0817b_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3178.0
  date: 2020-10-08_14-56-44
  done: true
  episode_len_mean: 825.2599001663893
  episode_reward_max: 283.40404040404024
  episode_reward_mean: 231.10124876048334
  episode_reward_min: 115.78787878787875
  episodes_this_iter: 161
  episodes_total: 3005
  experiment_id: 9c51d68054704d51abcb98bad1908f9a
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 0.0001
        entropy: 0.8705779403448105
        entropy_coeff: 0.0
        kl: 0.00963225900195539
        model: {}
        policy_loss: -0.05337324645370245
        total_loss: 1.9043446868658065
        vf_explained_var: 0.996699333190918
        vf_loss: 1.955791461467743
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.743478260869566
    gpu_util_percent0: 0.3115217391304348
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 9.771739130434783
    vram_util_percent0: 0.25705149229255503
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 9984
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15836388975452984
    mean_env_wait_ms: 1.6772281694540716
    mean_inference_ms: 4.848807242762819
    mean_raw_obs_processing_ms: 0.4265422162265373
  time_since_restore: 613.9354803562164
  time_this_iter_s: 37.84677028656006
  time_total_s: 613.9354803562164
  timers:
    learn_throughput: 5419.137
    learn_time_ms: 29855.676
    sample_throughput: 19629.147
    sample_time_ms: 8242.436
    update_time_ms: 36.625
  timestamp: 1602169004
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 0817b_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 73.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | TERMINATED |       |     16 |          613.935 | 2588672 |  231.101 |              283.404 |              115.788 |             825.26 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 73.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/512.65 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_0817b_00000 | TERMINATED |       |     16 |          613.935 | 2588672 |  231.101 |              283.404 |              115.788 |             825.26 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


