2020-10-10 22:48:09,540	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_ac2c0_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=62780)[0m 2020-10-10 22:48:12,515	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=62732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62743)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62743)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62713)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62713)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62735)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62735)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62742)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62742)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62724)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62724)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62761)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62761)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62758)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62758)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62715)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62715)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62740)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62740)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62755)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62755)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62763)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62763)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62666)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62666)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62640)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62640)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62634)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62634)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62669)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62669)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62645)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62645)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62707)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62707)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62643)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62643)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62651)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62651)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62663)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62663)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62650)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62650)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62662)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62662)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62652)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62652)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62642)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62642)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62677)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62677)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62727)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62727)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62744)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62744)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62655)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62655)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62647)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62647)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62648)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62648)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62664)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62664)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62653)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62653)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62712)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62712)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62748)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62748)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62672)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62672)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62675)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62675)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62658)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62658)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62719)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62719)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62670)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62670)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62717)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62717)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62639)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62639)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62637)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62637)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62649)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62649)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62644)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62644)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62636)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62636)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62635)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62635)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62668)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62668)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62723)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62723)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62733)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62733)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62716)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62716)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=62638)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=62638)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_22-48-50
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 1.0e-05
        entropy: 1.1857118351118905
        entropy_coeff: 0.0
        kl: 0.0036707079437162194
        model: {}
        policy_loss: -0.003131502033543906
        total_loss: 701.1912928989956
        vf_explained_var: 0.005364171229302883
        vf_loss: 701.1936819893973
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.26923076923077
    gpu_util_percent0: 0.34641025641025636
    gpu_util_percent1: 0.0002564102564102564
    gpu_util_percent2: 0.0002564102564102564
    ram_util_percent: 6.282051282051283
    vram_util_percent0: 0.19117659425957234
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16961777272802994
    mean_env_wait_ms: 1.193416235659659
    mean_inference_ms: 5.668045931960668
    mean_raw_obs_processing_ms: 0.45170904714849924
  time_since_restore: 32.12326264381409
  time_this_iter_s: 32.12326264381409
  time_total_s: 32.12326264381409
  timers:
    learn_throughput: 7081.631
    learn_time_ms: 22846.716
    sample_throughput: 17596.965
    sample_time_ms: 9194.313
    update_time_ms: 46.332
  timestamp: 1602370130
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |      1 |          32.1233 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3609.0104166666665
    time_step_min: 3339
  date: 2020-10-10_22-49-20
  done: false
  episode_len_mean: 888.7405063291139
  episode_reward_max: 260.1111111111109
  episode_reward_mean: 217.01320163661913
  episode_reward_min: 137.53535353535332
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.156812276159014
        entropy_coeff: 0.0
        kl: 0.006597410554864577
        model: {}
        policy_loss: -0.003096208267379552
        total_loss: 377.10228402274
        vf_explained_var: 0.41833966970443726
        vf_loss: 377.10471888950894
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.983783783783785
    gpu_util_percent0: 0.37891891891891893
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4594594594594605
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16545532617442588
    mean_env_wait_ms: 1.1881437338452308
    mean_inference_ms: 5.466498005344401
    mean_raw_obs_processing_ms: 0.4427590364492857
  time_since_restore: 62.61076045036316
  time_this_iter_s: 30.487497806549072
  time_total_s: 62.61076045036316
  timers:
    learn_throughput: 7148.176
    learn_time_ms: 22634.027
    sample_throughput: 18902.362
    sample_time_ms: 8559.354
    update_time_ms: 34.289
  timestamp: 1602370160
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |      2 |          62.6108 | 323584 |  217.013 |              260.111 |              137.535 |            888.741 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3605.275784753363
    time_step_min: 3326
  date: 2020-10-10_22-49-50
  done: false
  episode_len_mean: 883.2995780590717
  episode_reward_max: 262.0808080808081
  episode_reward_mean: 218.33895921237672
  episode_reward_min: 137.53535353535332
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1489790337426322
        entropy_coeff: 0.0
        kl: 0.006816706886248929
        model: {}
        policy_loss: -0.004201549442119098
        total_loss: 164.76489584786552
        vf_explained_var: 0.7107543349266052
        vf_loss: 164.76841626848494
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.668571428571433
    gpu_util_percent0: 0.42657142857142855
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.482857142857142
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16272442447956176
    mean_env_wait_ms: 1.1868343154161667
    mean_inference_ms: 5.303896423317555
    mean_raw_obs_processing_ms: 0.43554317137237586
  time_since_restore: 92.4633936882019
  time_this_iter_s: 29.852633237838745
  time_total_s: 92.4633936882019
  timers:
    learn_throughput: 7179.187
    learn_time_ms: 22536.257
    sample_throughput: 19764.088
    sample_time_ms: 8186.161
    update_time_ms: 30.861
  timestamp: 1602370190
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |      3 |          92.4634 | 485376 |  218.339 |              262.081 |              137.535 |              883.3 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3597.2152317880796
    time_step_min: 3245
  date: 2020-10-10_22-50-21
  done: false
  episode_len_mean: 877.3939873417721
  episode_reward_max: 274.3535353535351
  episode_reward_mean: 219.617248433704
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.141122247491564
        entropy_coeff: 0.0
        kl: 0.00684892652290208
        model: {}
        policy_loss: -0.005375357544315713
        total_loss: 101.30970110212054
        vf_explained_var: 0.8126769065856934
        vf_loss: 101.31439317975726
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.075675675675676
    gpu_util_percent0: 0.3837837837837837
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4837837837837835
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16081730190564672
    mean_env_wait_ms: 1.187280690540418
    mean_inference_ms: 5.183781180495974
    mean_raw_obs_processing_ms: 0.4298333059196207
  time_since_restore: 122.7805905342102
  time_this_iter_s: 30.3171968460083
  time_total_s: 122.7805905342102
  timers:
    learn_throughput: 7165.702
    learn_time_ms: 22578.668
    sample_throughput: 20161.461
    sample_time_ms: 8024.815
    update_time_ms: 28.318
  timestamp: 1602370221
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |      4 |          122.781 | 647168 |  219.617 |              274.354 |              132.687 |            877.394 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3592.267716535433
    time_step_min: 3245
  date: 2020-10-10_22-50-51
  done: false
  episode_len_mean: 873.3683544303798
  episode_reward_max: 274.3535353535351
  episode_reward_mean: 220.63700294080022
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 158
  episodes_total: 790
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.097932185445513
        entropy_coeff: 0.0
        kl: 0.007755463776577797
        model: {}
        policy_loss: -0.00425748061388731
        total_loss: 71.56081226893834
        vf_explained_var: 0.8737273812294006
        vf_loss: 71.5642956324986
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.49722222222222
    gpu_util_percent0: 0.3352777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477777777777778
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1594245563808833
    mean_env_wait_ms: 1.188718971310746
    mean_inference_ms: 5.093156470019205
    mean_raw_obs_processing_ms: 0.4252555413190608
  time_since_restore: 153.0362720489502
  time_this_iter_s: 30.25568151473999
  time_total_s: 153.0362720489502
  timers:
    learn_throughput: 7155.242
    learn_time_ms: 22611.674
    sample_throughput: 20469.223
    sample_time_ms: 7904.159
    update_time_ms: 30.055
  timestamp: 1602370251
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |      5 |          153.036 | 808960 |  220.637 |              274.354 |              132.687 |            873.368 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3588.06586270872
    time_step_min: 3245
  date: 2020-10-10_22-51-21
  done: false
  episode_len_mean: 864.1582278481013
  episode_reward_max: 274.3535353535351
  episode_reward_mean: 221.446526750324
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 316
  episodes_total: 1106
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.1009520292282104
        entropy_coeff: 0.0
        kl: 0.007190790326733675
        model: {}
        policy_loss: -0.005082255154515484
        total_loss: 82.34506825038365
        vf_explained_var: 0.904751718044281
        vf_loss: 82.34943008422852
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.013513513513512
    gpu_util_percent0: 0.3556756756756757
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.472972972972973
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1575798638553959
    mean_env_wait_ms: 1.1929882901980526
    mean_inference_ms: 4.971403545915118
    mean_raw_obs_processing_ms: 0.41940547527165517
  time_since_restore: 183.0645022392273
  time_this_iter_s: 30.0282301902771
  time_total_s: 183.0645022392273
  timers:
    learn_throughput: 7164.455
    learn_time_ms: 22582.598
    sample_throughput: 20672.148
    sample_time_ms: 7826.569
    update_time_ms: 32.093
  timestamp: 1602370281
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |      6 |          183.065 | 970752 |  221.447 |              274.354 |              132.687 |            864.158 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3582.8673139158577
    time_step_min: 3245
  date: 2020-10-10_22-51-52
  done: false
  episode_len_mean: 859.5261075949367
  episode_reward_max: 274.3535353535351
  episode_reward_mean: 222.39222925457082
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.096095280987876
        entropy_coeff: 0.0
        kl: 0.00685095800352948
        model: {}
        policy_loss: -0.00497903723122103
        total_loss: 51.66942596435547
        vf_explained_var: 0.9040236473083496
        vf_loss: 51.673719678606304
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.319444444444443
    gpu_util_percent0: 0.33083333333333337
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15692657336218346
    mean_env_wait_ms: 1.194865424914418
    mean_inference_ms: 4.927556802825177
    mean_raw_obs_processing_ms: 0.41728463191125303
  time_since_restore: 213.29425168037415
  time_this_iter_s: 30.22974944114685
  time_total_s: 213.29425168037415
  timers:
    learn_throughput: 7159.517
    learn_time_ms: 22598.173
    sample_throughput: 20820.15
    sample_time_ms: 7770.933
    update_time_ms: 33.954
  timestamp: 1602370312
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |      7 |          213.294 | 1132544 |  222.392 |              274.354 |              132.687 |            859.526 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3576.167144906743
    time_step_min: 3245
  date: 2020-10-10_22-52-22
  done: false
  episode_len_mean: 854.6497890295359
  episode_reward_max: 274.3535353535351
  episode_reward_mean: 223.312960831948
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0790976881980896
        entropy_coeff: 0.0
        kl: 0.005692195879029376
        model: {}
        policy_loss: -0.004219523917916896
        total_loss: 51.23178618294852
        vf_explained_var: 0.9049047827720642
        vf_loss: 51.23543684823172
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.975
    gpu_util_percent0: 0.3591666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486111111111111
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15636562142360616
    mean_env_wait_ms: 1.1966979097011214
    mean_inference_ms: 4.8894402675631605
    mean_raw_obs_processing_ms: 0.41542868838004676
  time_since_restore: 243.62688088417053
  time_this_iter_s: 30.332629203796387
  time_total_s: 243.62688088417053
  timers:
    learn_throughput: 7146.857
    learn_time_ms: 22638.202
    sample_throughput: 20972.319
    sample_time_ms: 7714.55
    update_time_ms: 34.077
  timestamp: 1602370342
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |      8 |          243.627 | 1294336 |  223.313 |              274.354 |              132.687 |             854.65 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3571.6934964584675
    time_step_min: 3245
  date: 2020-10-10_22-52-52
  done: false
  episode_len_mean: 850.0506008855155
  episode_reward_max: 274.3535353535351
  episode_reward_mean: 224.27427979989633
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 159
  episodes_total: 1581
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0468342644827706
        entropy_coeff: 0.0
        kl: 0.005888324197647827
        model: {}
        policy_loss: -0.002771010252347748
        total_loss: 43.855707441057476
        vf_explained_var: 0.9246741533279419
        vf_loss: 43.857889720371794
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.26111111111111
    gpu_util_percent0: 0.3408333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15586861923857176
    mean_env_wait_ms: 1.1987334693006413
    mean_inference_ms: 4.856053428258998
    mean_raw_obs_processing_ms: 0.41373951294330147
  time_since_restore: 273.4227201938629
  time_this_iter_s: 29.795839309692383
  time_total_s: 273.4227201938629
  timers:
    learn_throughput: 7151.717
    learn_time_ms: 22622.818
    sample_throughput: 21122.199
    sample_time_ms: 7659.808
    update_time_ms: 32.885
  timestamp: 1602370372
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |      9 |          273.423 | 1456128 |  224.274 |              274.354 |              132.687 |            850.051 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3559.8891862955034
    time_step_min: 3245
  date: 2020-10-10_22-53-22
  done: false
  episode_len_mean: 841.910864978903
  episode_reward_max: 274.80808080808043
  episode_reward_mean: 226.02323871627655
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 315
  episodes_total: 1896
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0451553804533822
        entropy_coeff: 0.0
        kl: 0.005725135860432472
        model: {}
        policy_loss: -0.004343009566322767
        total_loss: 47.56314032418387
        vf_explained_var: 0.9409799575805664
        vf_loss: 47.56691115243094
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.380555555555556
    gpu_util_percent0: 0.3588888888888888
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477777777777778
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15507347351340023
    mean_env_wait_ms: 1.202745815010892
    mean_inference_ms: 4.802182614888707
    mean_raw_obs_processing_ms: 0.4111370299045277
  time_since_restore: 303.45710134506226
  time_this_iter_s: 30.03438115119934
  time_total_s: 303.45710134506226
  timers:
    learn_throughput: 7146.025
    learn_time_ms: 22640.84
    sample_throughput: 21266.962
    sample_time_ms: 7607.669
    update_time_ms: 33.567
  timestamp: 1602370402
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |     10 |          303.457 | 1617920 |  226.023 |              274.808 |              132.687 |            841.911 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3556.1757156959525
    time_step_min: 3245
  date: 2020-10-10_22-53-52
  done: false
  episode_len_mean: 838.0968841285297
  episode_reward_max: 274.80808080808043
  episode_reward_mean: 226.64167969864158
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0307179178510393
        entropy_coeff: 0.0
        kl: 0.006686440669000149
        model: {}
        policy_loss: -0.0030903771881379987
        total_loss: 32.88947214399065
        vf_explained_var: 0.9417413473129272
        vf_loss: 32.891893659319194
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.919444444444444
    gpu_util_percent0: 0.3725
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486111111111111
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.154745542606976
    mean_env_wait_ms: 1.2045822194052946
    mean_inference_ms: 4.779897516005883
    mean_raw_obs_processing_ms: 0.4100466931014886
  time_since_restore: 333.31070470809937
  time_this_iter_s: 29.85360336303711
  time_total_s: 333.31070470809937
  timers:
    learn_throughput: 7152.006
    learn_time_ms: 22621.906
    sample_throughput: 21865.735
    sample_time_ms: 7399.34
    update_time_ms: 31.909
  timestamp: 1602370432
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |     11 |          333.311 | 1779712 |  226.642 |              274.808 |              132.687 |            838.097 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3551.790293040293
    time_step_min: 3245
  date: 2020-10-10_22-54-22
  done: false
  episode_len_mean: 834.5519891500904
  episode_reward_max: 274.80808080808043
  episode_reward_mean: 227.2645852740788
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 1.0057608570371355
        entropy_coeff: 0.0
        kl: 0.005372639745473862
        model: {}
        policy_loss: -0.003941118382499553
        total_loss: 29.10758032117571
        vf_explained_var: 0.945239245891571
        vf_loss: 29.110983303615026
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.033333333333335
    gpu_util_percent0: 0.35944444444444446
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494444444444444
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1544491630664429
    mean_env_wait_ms: 1.2063871574901204
    mean_inference_ms: 4.759620213908085
    mean_raw_obs_processing_ms: 0.4090295783066868
  time_since_restore: 363.3859016895294
  time_this_iter_s: 30.075196981430054
  time_total_s: 363.3859016895294
  timers:
    learn_throughput: 7140.981
    learn_time_ms: 22656.831
    sample_throughput: 22073.506
    sample_time_ms: 7329.692
    update_time_ms: 31.678
  timestamp: 1602370462
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |     12 |          363.386 | 1941504 |  227.265 |              274.808 |              132.687 |            834.552 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3545.270389714745
    time_step_min: 3245
  date: 2020-10-10_22-54-52
  done: false
  episode_len_mean: 828.2542709574891
  episode_reward_max: 276.7777777777779
  episode_reward_mean: 228.43986949350466
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 305
  episodes_total: 2517
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9766415911061423
        entropy_coeff: 0.0
        kl: 0.005584292512919221
        model: {}
        policy_loss: -0.004842217269469984
        total_loss: 35.8076354435512
        vf_explained_var: 0.9580212831497192
        vf_loss: 35.81191989353725
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.50277777777778
    gpu_util_percent0: 0.39944444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4750000000000005
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15396624504958495
    mean_env_wait_ms: 1.2100568118865616
    mean_inference_ms: 4.725966379476248
    mean_raw_obs_processing_ms: 0.4073932644230994
  time_since_restore: 393.2645118236542
  time_this_iter_s: 29.878610134124756
  time_total_s: 393.2645118236542
  timers:
    learn_throughput: 7132.134
    learn_time_ms: 22684.935
    sample_throughput: 22159.646
    sample_time_ms: 7301.2
    update_time_ms: 33.835
  timestamp: 1602370492
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |     13 |          393.265 | 2103296 |   228.44 |              276.778 |              132.687 |            828.254 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3541.744544770504
    time_step_min: 3245
  date: 2020-10-10_22-55-22
  done: false
  episode_len_mean: 824.9925539836188
  episode_reward_max: 276.7777777777779
  episode_reward_mean: 229.04971532149483
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 169
  episodes_total: 2686
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9733290118830544
        entropy_coeff: 0.0
        kl: 0.005947766393156988
        model: {}
        policy_loss: -0.003148390695319644
        total_loss: 23.215397153581893
        vf_explained_var: 0.9604015946388245
        vf_loss: 23.217950139726913
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.53333333333333
    gpu_util_percent0: 0.3986111111111111
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15374263426469187
    mean_env_wait_ms: 1.2118347591433796
    mean_inference_ms: 4.709787576658087
    mean_raw_obs_processing_ms: 0.4065957236733733
  time_since_restore: 423.2609100341797
  time_this_iter_s: 29.996398210525513
  time_total_s: 423.2609100341797
  timers:
    learn_throughput: 7133.975
    learn_time_ms: 22679.081
    sample_throughput: 22265.788
    sample_time_ms: 7266.395
    update_time_ms: 39.402
  timestamp: 1602370522
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |     14 |          423.261 | 2265088 |   229.05 |              276.778 |              132.687 |            824.993 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3538.450994318182
    time_step_min: 3219
  date: 2020-10-10_22-55-52
  done: false
  episode_len_mean: 822.1684247538678
  episode_reward_max: 278.2929292929294
  episode_reward_mean: 229.5626411797297
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.96014603972435
        entropy_coeff: 0.0
        kl: 0.005421211011707783
        model: {}
        policy_loss: -0.002804898507227855
        total_loss: 19.588409560067312
        vf_explained_var: 0.9634431004524231
        vf_loss: 19.59067235674177
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.08888888888889
    gpu_util_percent0: 0.40388888888888896
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4944444444444445
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1535468376169015
    mean_env_wait_ms: 1.2134483133405651
    mean_inference_ms: 4.695920040873475
    mean_raw_obs_processing_ms: 0.40588818824706435
  time_since_restore: 453.181875705719
  time_this_iter_s: 29.920965671539307
  time_total_s: 453.181875705719
  timers:
    learn_throughput: 7141.161
    learn_time_ms: 22656.258
    sample_throughput: 22313.849
    sample_time_ms: 7250.744
    update_time_ms: 37.852
  timestamp: 1602370552
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |     15 |          453.182 | 2426880 |  229.563 |              278.293 |              132.687 |            822.168 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3532.4932388924663
    time_step_min: 3219
  date: 2020-10-10_22-56-23
  done: false
  episode_len_mean: 817.6088066368858
  episode_reward_max: 278.2929292929294
  episode_reward_mean: 230.554488729026
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 290
  episodes_total: 3134
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.10000000000000002
        cur_lr: 1.0e-05
        entropy: 0.9213948931012835
        entropy_coeff: 0.0
        kl: 0.004948055072288428
        model: {}
        policy_loss: -0.0037478825470316224
        total_loss: 29.231665202549525
        vf_explained_var: 0.9652220010757446
        vf_loss: 29.234917776925222
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.844444444444445
    gpu_util_percent0: 0.3713888888888888
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.483333333333333
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15322137872295694
    mean_env_wait_ms: 1.2163850796931446
    mean_inference_ms: 4.673177129322743
    mean_raw_obs_processing_ms: 0.404711033261626
  time_since_restore: 483.44416332244873
  time_this_iter_s: 30.262287616729736
  time_total_s: 483.44416332244873
  timers:
    learn_throughput: 7127.077
    learn_time_ms: 22701.032
    sample_throughput: 22363.756
    sample_time_ms: 7234.563
    update_time_ms: 37.075
  timestamp: 1602370583
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |     16 |          483.444 | 2588672 |  230.554 |              278.293 |              132.687 |            817.609 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3528.813981762918
    time_step_min: 3183
  date: 2020-10-10_22-56-53
  done: false
  episode_len_mean: 815.089813140446
  episode_reward_max: 283.747474747475
  episode_reward_mean: 231.16253858658914
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 184
  episodes_total: 3318
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.9089309998920986
        entropy_coeff: 0.0
        kl: 0.0064510860413845095
        model: {}
        policy_loss: -0.004714348802476057
        total_loss: 20.48334312438965
        vf_explained_var: 0.9655241370201111
        vf_loss: 20.487735203334264
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.96666666666667
    gpu_util_percent0: 0.33972222222222226
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.494444444444444
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15304352554826797
    mean_env_wait_ms: 1.218097325947976
    mean_inference_ms: 4.660570402304314
    mean_raw_obs_processing_ms: 0.4040823189320664
  time_since_restore: 513.5351767539978
  time_this_iter_s: 30.091013431549072
  time_total_s: 513.5351767539978
  timers:
    learn_throughput: 7126.477
    learn_time_ms: 22702.942
    sample_throughput: 22411.394
    sample_time_ms: 7219.185
    update_time_ms: 36.278
  timestamp: 1602370613
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |     17 |          513.535 | 2750464 |  231.163 |              283.747 |              132.687 |             815.09 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3525.1963457076567
    time_step_min: 3176
  date: 2020-10-10_22-57-23
  done: false
  episode_len_mean: 813.1582278481013
  episode_reward_max: 284.8080808080807
  episode_reward_mean: 231.70045100022077
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 158
  episodes_total: 3476
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.8954875767230988
        entropy_coeff: 0.0
        kl: 0.006475774438253471
        model: {}
        policy_loss: -0.004507564166228154
        total_loss: 18.594705990382604
        vf_explained_var: 0.9645894169807434
        vf_loss: 18.598889895847865
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.2
    gpu_util_percent0: 0.3044444444444444
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502777777777777
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15290227749666244
    mean_env_wait_ms: 1.2194575855838243
    mean_inference_ms: 4.650460402191184
    mean_raw_obs_processing_ms: 0.4035588902646625
  time_since_restore: 543.5541553497314
  time_this_iter_s: 30.018978595733643
  time_total_s: 543.5541553497314
  timers:
    learn_throughput: 7132.103
    learn_time_ms: 22685.035
    sample_throughput: 22455.254
    sample_time_ms: 7205.085
    update_time_ms: 36.26
  timestamp: 1602370643
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |     18 |          543.554 | 2912256 |    231.7 |              284.808 |              132.687 |            813.158 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3519.4115115653576
    time_step_min: 3176
  date: 2020-10-10_22-57-53
  done: false
  episode_len_mean: 810.194874532835
  episode_reward_max: 284.8080808080807
  episode_reward_mean: 232.73305937107318
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 270
  episodes_total: 3746
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.8535991098199572
        entropy_coeff: 0.0
        kl: 0.006060754780524543
        model: {}
        policy_loss: -0.0034122397690745337
        total_loss: 20.66082259586879
        vf_explained_var: 0.9728842377662659
        vf_loss: 20.66393198285784
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.166666666666664
    gpu_util_percent0: 0.32555555555555554
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491666666666666
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1526799658939983
    mean_env_wait_ms: 1.2217283959783856
    mean_inference_ms: 4.634619442660131
    mean_raw_obs_processing_ms: 0.4027229523073257
  time_since_restore: 573.7142386436462
  time_this_iter_s: 30.160083293914795
  time_total_s: 573.7142386436462
  timers:
    learn_throughput: 7125.139
    learn_time_ms: 22707.206
    sample_throughput: 22413.976
    sample_time_ms: 7218.353
    update_time_ms: 36.251
  timestamp: 1602370673
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | RUNNING  | 172.17.0.4:62780 |     19 |          573.714 | 3074048 |  232.733 |              284.808 |              132.687 |            810.195 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_ac2c0_00000:
  custom_metrics:
    time_step_max: 4180
    time_step_mean: 3513.3587455379907
    time_step_min: 3176
  date: 2020-10-10_22-58-24
  done: true
  episode_len_mean: 808.12
  episode_reward_max: 284.8080808080807
  episode_reward_mean: 233.67083493159436
  episode_reward_min: 132.68686868686845
  episodes_this_iter: 204
  episodes_total: 3950
  experiment_id: 63f82aa932d14978938d233fd6dd7b07
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.05000000000000001
        cur_lr: 1.0e-05
        entropy: 0.84144441144807
        entropy_coeff: 0.0
        kl: 0.006069402044106807
        model: {}
        policy_loss: -0.004506031622960498
        total_loss: 15.529153278895787
        vf_explained_var: 0.9729143977165222
        vf_loss: 15.533355644771031
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.86388888888889
    gpu_util_percent0: 0.37194444444444447
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.502777777777777
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 62780
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1525270630175158
    mean_env_wait_ms: 1.2233206554059042
    mean_inference_ms: 4.623840971661876
    mean_raw_obs_processing_ms: 0.4021819334443049
  time_since_restore: 603.7982726097107
  time_this_iter_s: 30.084033966064453
  time_total_s: 603.7982726097107
  timers:
    learn_throughput: 7120.255
    learn_time_ms: 22722.783
    sample_throughput: 22451.597
    sample_time_ms: 7206.258
    update_time_ms: 36.495
  timestamp: 1602370704
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: ac2c0_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | TERMINATED |       |     20 |          603.798 | 3235840 |  233.671 |              284.808 |              132.687 |             808.12 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.26 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_ac2c0_00000 | TERMINATED |       |     20 |          603.798 | 3235840 |  233.671 |              284.808 |              132.687 |             808.12 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


