2020-10-10 21:11:43,726	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.0/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_33920_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=37251)[0m 2020-10-10 21:11:46,651	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=37136)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37136)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37110)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37110)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37244)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37244)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37215)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37215)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37229)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37229)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37184)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37184)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37116)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37116)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37126)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37126)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37107)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37122)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37122)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37165)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37165)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37131)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37131)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37203)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37203)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37210)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37210)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37214)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37214)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37171)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37171)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37178)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37178)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37181)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37181)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37220)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37220)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37206)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37206)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37226)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37226)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37174)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37174)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37182)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37182)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37188)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37188)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37209)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37209)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37205)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37205)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37141)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37141)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37193)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37193)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37212)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37212)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37218)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37218)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37231)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37231)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37159)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37159)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37198)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37198)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37179)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37179)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37129)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37129)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37177)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37177)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37134)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37134)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37208)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37208)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37145)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37145)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37138)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37138)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37104)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37104)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37120)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37120)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37105)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37105)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37186)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37186)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37201)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37201)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37180)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37180)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37139)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37139)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37162)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37162)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37160)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37160)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37111)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37111)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37196)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37196)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37194)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37194)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37108)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37108)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37103)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37103)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37191)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37191)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37248)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37248)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37143)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37143)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37166)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37166)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37183)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37183)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37207)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37207)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37199)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37199)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37132)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37132)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37189)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37189)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37185)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37185)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37170)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37170)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37234)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37234)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37223)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37223)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37176)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37176)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37112)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37112)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37164)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37164)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=37187)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=37187)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-10_21-12-24
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1813811234065466
        entropy_coeff: 0.0
        kl: 0.008098298118316702
        model: {}
        policy_loss: -0.01183206832813864
        total_loss: 9.50878620147705
        vf_explained_var: 0.7608073353767395
        vf_loss: 9.518998350415911
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 27.835897435897433
    gpu_util_percent0: 0.3630769230769231
    gpu_util_percent1: 0.0002564102564102564
    gpu_util_percent2: 0.0002564102564102564
    ram_util_percent: 6.27948717948718
    vram_util_percent0: 0.19117659425957234
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.17267643798093216
    mean_env_wait_ms: 1.2056625533449903
    mean_inference_ms: 5.726076598960921
    mean_raw_obs_processing_ms: 0.461277983813567
  time_since_restore: 31.854201793670654
  time_this_iter_s: 31.854201793670654
  time_total_s: 31.854201793670654
  timers:
    learn_throughput: 7082.566
    learn_time_ms: 22843.699
    sample_throughput: 18082.506
    sample_time_ms: 8947.432
    update_time_ms: 27.929
  timestamp: 1602364344
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |      1 |          31.8542 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3625.2916666666665
    time_step_min: 3335
  date: 2020-10-10_21-12-54
  done: false
  episode_len_mean: 878.8607594936709
  episode_reward_max: 260.71717171717137
  episode_reward_mean: 217.36513872906258
  episode_reward_min: 137.68686868686873
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.147958483014788
        entropy_coeff: 0.0
        kl: 0.009683761679168259
        model: {}
        policy_loss: -0.012434215978178795
        total_loss: 8.110008035387311
        vf_explained_var: 0.8977132439613342
        vf_loss: 8.120505230767387
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 25.54324324324324
    gpu_util_percent0: 0.3986486486486487
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.462162162162163
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1683170550156296
    mean_env_wait_ms: 1.2038038155448416
    mean_inference_ms: 5.527951732258312
    mean_raw_obs_processing_ms: 0.45028442292285803
  time_since_restore: 62.522528886795044
  time_this_iter_s: 30.66832709312439
  time_total_s: 62.522528886795044
  timers:
    learn_throughput: 7133.797
    learn_time_ms: 22679.649
    sample_throughput: 19035.263
    sample_time_ms: 8499.593
    update_time_ms: 40.315
  timestamp: 1602364374
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |      2 |          62.5225 | 323584 |  217.365 |              260.717 |              137.687 |            878.861 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3625.230941704036
    time_step_min: 3285
  date: 2020-10-10_21-13-25
  done: false
  episode_len_mean: 872.3143459915611
  episode_reward_max: 268.2929292929294
  episode_reward_mean: 217.00473085283195
  episode_reward_min: 137.68686868686873
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1280861837523324
        entropy_coeff: 0.0
        kl: 0.010060045735112258
        model: {}
        policy_loss: -0.014715149117234563
        total_loss: 8.229058197566442
        vf_explained_var: 0.9422475695610046
        vf_loss: 8.241761548178536
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.343243243243244
    gpu_util_percent0: 0.36702702702702705
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.481081081081081
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16555832167549903
    mean_env_wait_ms: 1.2036543522743643
    mean_inference_ms: 5.375901171121809
    mean_raw_obs_processing_ms: 0.4424495857037301
  time_since_restore: 93.19610381126404
  time_this_iter_s: 30.673574924468994
  time_total_s: 93.19610381126404
  timers:
    learn_throughput: 7136.545
    learn_time_ms: 22670.914
    sample_throughput: 19529.448
    sample_time_ms: 8284.515
    update_time_ms: 42.085
  timestamp: 1602364405
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |      3 |          93.1961 | 485376 |  217.005 |              268.293 |              137.687 |            872.314 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3623.2400662251657
    time_step_min: 3285
  date: 2020-10-10_21-13-55
  done: false
  episode_len_mean: 865.376582278481
  episode_reward_max: 268.2929292929294
  episode_reward_mean: 217.370412990666
  episode_reward_min: 137.68686868686873
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1006909779139928
        entropy_coeff: 0.0
        kl: 0.00868662420128073
        model: {}
        policy_loss: -0.015069303751390959
        total_loss: 8.209048748016357
        vf_explained_var: 0.960755467414856
        vf_loss: 8.222380604062762
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.95
    gpu_util_percent0: 0.3758333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480555555555556
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.163560143348631
    mean_env_wait_ms: 1.2049279007639957
    mean_inference_ms: 5.25711672815424
    mean_raw_obs_processing_ms: 0.4360350058664056
  time_since_restore: 123.39845418930054
  time_this_iter_s: 30.2023503780365
  time_total_s: 123.39845418930054
  timers:
    learn_throughput: 7131.816
    learn_time_ms: 22685.948
    sample_throughput: 20069.209
    sample_time_ms: 8061.703
    update_time_ms: 39.065
  timestamp: 1602364435
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |      4 |          123.398 | 647168 |   217.37 |              268.293 |              137.687 |            865.377 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3619.406976744186
    time_step_min: 3282
  date: 2020-10-10_21-14-25
  done: false
  episode_len_mean: 853.9718468468468
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 217.3550027300026
  episode_reward_min: 137.68686868686873
  episodes_this_iter: 256
  episodes_total: 888
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0597929528781347
        entropy_coeff: 0.0
        kl: 0.008361180113362414
        model: {}
        policy_loss: -0.014231862084540938
        total_loss: 11.267589500972203
        vf_explained_var: 0.9751243591308594
        vf_loss: 11.280149459838867
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.12222222222222
    gpu_util_percent0: 0.36722222222222217
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.469444444444445
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16131136279048883
    mean_env_wait_ms: 1.2093154229452672
    mean_inference_ms: 5.121370458844833
    mean_raw_obs_processing_ms: 0.42877258047663047
  time_since_restore: 153.46409034729004
  time_this_iter_s: 30.065636157989502
  time_total_s: 153.46409034729004
  timers:
    learn_throughput: 7130.938
    learn_time_ms: 22688.741
    sample_throughput: 20462.786
    sample_time_ms: 7906.646
    update_time_ms: 36.985
  timestamp: 1602364465
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |      5 |          153.464 | 808960 |  217.355 |              273.444 |              137.687 |            853.972 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4092
    time_step_mean: 3618.4499072356216
    time_step_min: 3255
  date: 2020-10-10_21-14-56
  done: false
  episode_len_mean: 846.117540687161
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 217.87811204266887
  episode_reward_min: 137.68686868686873
  episodes_this_iter: 218
  episodes_total: 1106
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0531239254134042
        entropy_coeff: 0.0
        kl: 0.008795704958694322
        model: {}
        policy_loss: -0.014884140557634444
        total_loss: 6.4166315623692105
        vf_explained_var: 0.9836602210998535
        vf_loss: 6.42975640296936
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.147222222222226
    gpu_util_percent0: 0.38166666666666665
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.469444444444445
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15997592503588937
    mean_env_wait_ms: 1.21261748156087
    mean_inference_ms: 5.042383005408755
    mean_raw_obs_processing_ms: 0.4246146420054405
  time_since_restore: 183.44846177101135
  time_this_iter_s: 29.984371423721313
  time_total_s: 183.44846177101135
  timers:
    learn_throughput: 7133.678
    learn_time_ms: 22680.024
    sample_throughput: 20739.1
    sample_time_ms: 7801.303
    update_time_ms: 34.616
  timestamp: 1602364496
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |      6 |          183.448 | 970752 |  217.878 |              273.444 |              137.687 |            846.118 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3613.2710355987056
    time_step_min: 3255
  date: 2020-10-10_21-15-26
  done: false
  episode_len_mean: 841.3473101265823
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 218.30191951157133
  episode_reward_min: 133.292929292929
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0199133157730103
        entropy_coeff: 0.0
        kl: 0.009151129118566002
        model: {}
        policy_loss: -0.01699414915804352
        total_loss: 5.050250359943935
        vf_explained_var: 0.9878878593444824
        vf_loss: 5.065414224352155
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.708333333333332
    gpu_util_percent0: 0.3505555555555555
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15917596173281492
    mean_env_wait_ms: 1.214787329105499
    mean_inference_ms: 4.9948830358459775
    mean_raw_obs_processing_ms: 0.4220546448439261
  time_since_restore: 213.4351043701172
  time_this_iter_s: 29.986642599105835
  time_total_s: 213.4351043701172
  timers:
    learn_throughput: 7143.006
    learn_time_ms: 22650.409
    sample_throughput: 20880.436
    sample_time_ms: 7748.497
    update_time_ms: 33.406
  timestamp: 1602364526
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |      7 |          213.435 | 1132544 |  218.302 |              273.444 |              133.293 |            841.347 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3608.5523672883787
    time_step_min: 3255
  date: 2020-10-10_21-15-56
  done: false
  episode_len_mean: 837.8305203938115
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 219.2138473341004
  episode_reward_min: 133.292929292929
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9826595612934658
        entropy_coeff: 0.0
        kl: 0.008686561603099108
        model: {}
        policy_loss: -0.017473672217290317
        total_loss: 4.549292462212699
        vf_explained_var: 0.9901579022407532
        vf_loss: 4.565028803689139
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.458333333333332
    gpu_util_percent0: 0.4225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.480555555555556
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1584855110346873
    mean_env_wait_ms: 1.2168249506357638
    mean_inference_ms: 4.953644976489701
    mean_raw_obs_processing_ms: 0.4197858336933572
  time_since_restore: 243.26283645629883
  time_this_iter_s: 29.82773208618164
  time_total_s: 243.26283645629883
  timers:
    learn_throughput: 7147.596
    learn_time_ms: 22635.863
    sample_throughput: 21060.083
    sample_time_ms: 7682.401
    update_time_ms: 32.239
  timestamp: 1602364556
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |      8 |          243.263 | 1294336 |  219.214 |              273.444 |              133.293 |            837.831 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3598.6686217008796
    time_step_min: 3255
  date: 2020-10-10_21-16-26
  done: false
  episode_len_mean: 831.7264858626659
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 221.08944610560297
  episode_reward_min: 133.292929292929
  episodes_this_iter: 311
  episodes_total: 1733
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9424859242779868
        entropy_coeff: 0.0
        kl: 0.008218996892017978
        model: {}
        policy_loss: -0.014334613024922354
        total_loss: 5.702694075448172
        vf_explained_var: 0.9925789833068848
        vf_loss: 5.715384755815778
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.950000000000003
    gpu_util_percent0: 0.4141666666666667
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.472222222222222
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15739228422909424
    mean_env_wait_ms: 1.2206831116072276
    mean_inference_ms: 4.8884841842900775
    mean_raw_obs_processing_ms: 0.41628275887496213
  time_since_restore: 273.2764058113098
  time_this_iter_s: 30.013569355010986
  time_total_s: 273.2764058113098
  timers:
    learn_throughput: 7146.868
    learn_time_ms: 22638.168
    sample_throughput: 21185.519
    sample_time_ms: 7636.915
    update_time_ms: 31.415
  timestamp: 1602364586
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |      9 |          273.276 | 1456128 |  221.089 |              273.444 |              133.293 |            831.726 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4176
    time_step_mean: 3591.2906852248393
    time_step_min: 3255
  date: 2020-10-10_21-16-56
  done: false
  episode_len_mean: 829.418776371308
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 222.11189425904612
  episode_reward_min: 133.292929292929
  episodes_this_iter: 163
  episodes_total: 1896
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9049551657267979
        entropy_coeff: 0.0
        kl: 0.008324481347309691
        model: {}
        policy_loss: -0.0166432900503943
        total_loss: 3.0687819378716603
        vf_explained_var: 0.9940801858901978
        vf_loss: 3.083760380744934
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.982857142857142
    gpu_util_percent0: 0.4062857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491428571428571
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1569196717304065
    mean_env_wait_ms: 1.2223987684721165
    mean_inference_ms: 4.86025792925037
    mean_raw_obs_processing_ms: 0.41476047464378973
  time_since_restore: 303.2374951839447
  time_this_iter_s: 29.961089372634888
  time_total_s: 303.2374951839447
  timers:
    learn_throughput: 7148.113
    learn_time_ms: 22634.226
    sample_throughput: 21289.119
    sample_time_ms: 7599.751
    update_time_ms: 31.25
  timestamp: 1602364616
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |     10 |          303.237 | 1617920 |  222.112 |              273.444 |              133.293 |            829.419 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3586.6791707798616
    time_step_min: 3255
  date: 2020-10-10_21-17-26
  done: false
  episode_len_mean: 828.2254138266796
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 223.03165048734664
  episode_reward_min: 123.89898989898992
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8874276535851615
        entropy_coeff: 0.0
        kl: 0.007555240332814199
        model: {}
        policy_loss: -0.015526585912864124
        total_loss: 3.0020308835165843
        vf_explained_var: 0.9943491816520691
        vf_loss: 3.0160463537488664
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.8972972972973
    gpu_util_percent0: 0.3816216216216216
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4837837837837835
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15651245839539152
    mean_env_wait_ms: 1.2238267820967645
    mean_inference_ms: 4.835688637631333
    mean_raw_obs_processing_ms: 0.41342575006209276
  time_since_restore: 333.3730800151825
  time_this_iter_s: 30.135584831237793
  time_total_s: 333.3730800151825
  timers:
    learn_throughput: 7149.149
    learn_time_ms: 22630.945
    sample_throughput: 21781.556
    sample_time_ms: 7427.936
    update_time_ms: 30.594
  timestamp: 1602364646
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |     11 |          333.373 | 1779712 |  223.032 |              273.444 |              123.899 |            828.225 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3581.2630375114363
    time_step_min: 3255
  date: 2020-10-10_21-17-56
  done: false
  episode_len_mean: 827.1160794941283
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 223.9219156332977
  episode_reward_min: 123.89898989898992
  episodes_this_iter: 160
  episodes_total: 2214
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8592164942196437
        entropy_coeff: 0.0
        kl: 0.007507847089852605
        model: {}
        policy_loss: -0.01494089450820216
        total_loss: 2.8443305492401123
        vf_explained_var: 0.9952103495597839
        vf_loss: 2.8577699661254883
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.96388888888889
    gpu_util_percent0: 0.36583333333333334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15614257333468776
    mean_env_wait_ms: 1.2251716062219797
    mean_inference_ms: 4.813058851694416
    mean_raw_obs_processing_ms: 0.4121647680824603
  time_since_restore: 363.3918876647949
  time_this_iter_s: 30.018807649612427
  time_total_s: 363.3918876647949
  timers:
    learn_throughput: 7147.104
    learn_time_ms: 22637.421
    sample_throughput: 22007.004
    sample_time_ms: 7351.841
    update_time_ms: 34.568
  timestamp: 1602364676
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |     12 |          363.392 | 1941504 |  223.922 |              273.444 |              123.899 |            827.116 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3573.0016019223067
    time_step_min: 3255
  date: 2020-10-10_21-18-26
  done: false
  episode_len_mean: 825.4661386138614
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 225.17171717171715
  episode_reward_min: 123.89898989898992
  episodes_this_iter: 311
  episodes_total: 2525
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8179358456815992
        entropy_coeff: 0.0
        kl: 0.006943513306656054
        model: {}
        policy_loss: -0.011960417204785958
        total_loss: 3.686419657298497
        vf_explained_var: 0.9951567053794861
        vf_loss: 3.6969913755144392
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.063888888888886
    gpu_util_percent0: 0.3722222222222222
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477777777777778
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15553966815926623
    mean_env_wait_ms: 1.2275190497861188
    mean_inference_ms: 4.7756763800316495
    mean_raw_obs_processing_ms: 0.41014554601588593
  time_since_restore: 393.61110162734985
  time_this_iter_s: 30.21921396255493
  time_total_s: 393.61110162734985
  timers:
    learn_throughput: 7143.979
    learn_time_ms: 22647.324
    sample_throughput: 22149.859
    sample_time_ms: 7304.426
    update_time_ms: 32.241
  timestamp: 1602364706
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |     13 |          393.611 | 2103296 |  225.172 |              273.444 |              123.899 |            825.466 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3569.0063957863053
    time_step_min: 3255
  date: 2020-10-10_21-18-56
  done: false
  episode_len_mean: 825.2691734921817
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 225.68202877622087
  episode_reward_min: 123.89898989898992
  episodes_this_iter: 161
  episodes_total: 2686
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.790888752256121
        entropy_coeff: 0.0
        kl: 0.006819868293989982
        model: {}
        policy_loss: -0.01319677708670497
        total_loss: 2.4242463452475413
        vf_explained_var: 0.9957022070884705
        vf_loss: 2.4360790933881487
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.005555555555556
    gpu_util_percent0: 0.3958333333333333
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888889
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15526310290307643
    mean_env_wait_ms: 1.2285183952566785
    mean_inference_ms: 4.758658330230385
    mean_raw_obs_processing_ms: 0.40922763735547796
  time_since_restore: 423.51536560058594
  time_this_iter_s: 29.904263973236084
  time_total_s: 423.51536560058594
  timers:
    learn_throughput: 7145.563
    learn_time_ms: 22642.303
    sample_throughput: 22228.271
    sample_time_ms: 7278.659
    update_time_ms: 31.883
  timestamp: 1602364736
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |     14 |          423.515 | 2265088 |  225.682 |              273.444 |              123.899 |            825.269 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3565.138849431818
    time_step_min: 3255
  date: 2020-10-10_21-19-26
  done: false
  episode_len_mean: 825.0428973277075
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 226.08791501513016
  episode_reward_min: 123.89898989898992
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7770033010414669
        entropy_coeff: 0.0
        kl: 0.006983238471938031
        model: {}
        policy_loss: -0.012638319782646639
        total_loss: 2.5113159588405063
        vf_explained_var: 0.9952941536903381
        vf_loss: 2.522557718413217
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.96388888888889
    gpu_util_percent0: 0.3888888888888889
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4944444444444445
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15501569364821338
    mean_env_wait_ms: 1.2294192359914573
    mean_inference_ms: 4.743352714197674
    mean_raw_obs_processing_ms: 0.40839014697518566
  time_since_restore: 453.3698170185089
  time_this_iter_s: 29.854451417922974
  time_total_s: 453.3698170185089
  timers:
    learn_throughput: 7148.394
    learn_time_ms: 22633.335
    sample_throughput: 22270.822
    sample_time_ms: 7264.752
    update_time_ms: 32.306
  timestamp: 1602364766
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |     15 |           453.37 | 2426880 |  226.088 |              273.444 |              123.899 |            825.043 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3561.8560910307897
    time_step_min: 3255
  date: 2020-10-10_21-19-56
  done: false
  episode_len_mean: 824.4565649867374
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 226.59270423063523
  episode_reward_min: 123.89898989898992
  episodes_this_iter: 172
  episodes_total: 3016
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7567387223243713
        entropy_coeff: 0.0
        kl: 0.006653123136077609
        model: {}
        policy_loss: -0.013419831928331405
        total_loss: 2.805871384484427
        vf_explained_var: 0.9953413605690002
        vf_loss: 2.8179605518068587
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.45277777777778
    gpu_util_percent0: 0.3980555555555555
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.486111111111111
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15476101104817008
    mean_env_wait_ms: 1.2303257685702405
    mean_inference_ms: 4.727927452769116
    mean_raw_obs_processing_ms: 0.4075466214441094
  time_since_restore: 483.33028197288513
  time_this_iter_s: 29.96046495437622
  time_total_s: 483.33028197288513
  timers:
    learn_throughput: 7148.303
    learn_time_ms: 22633.623
    sample_throughput: 22289.027
    sample_time_ms: 7258.819
    update_time_ms: 34.301
  timestamp: 1602364796
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |     16 |           483.33 | 2588672 |  226.593 |              273.444 |              123.899 |            824.457 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3555.979299847793
    time_step_min: 3255
  date: 2020-10-10_21-20-26
  done: false
  episode_len_mean: 823.728342891639
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 227.3793564988856
  episode_reward_min: 123.89898989898992
  episodes_this_iter: 297
  episodes_total: 3313
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7095818860190255
        entropy_coeff: 0.0
        kl: 0.006362560504515257
        model: {}
        policy_loss: -0.011702352311528687
        total_loss: 3.149651885032654
        vf_explained_var: 0.9957745671272278
        vf_loss: 3.160081846373422
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 24.345714285714287
    gpu_util_percent0: 0.378
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.477142857142857
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15438231351264917
    mean_env_wait_ms: 1.2317434215371947
    mean_inference_ms: 4.7042589620850395
    mean_raw_obs_processing_ms: 0.4062994446472756
  time_since_restore: 513.1111836433411
  time_this_iter_s: 29.780901670455933
  time_total_s: 513.1111836433411
  timers:
    learn_throughput: 7148.86
    learn_time_ms: 22631.859
    sample_throughput: 22348.082
    sample_time_ms: 7239.637
    update_time_ms: 34.439
  timestamp: 1602364826
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |     17 |          513.111 | 2750464 |  227.379 |              273.444 |              123.899 |            823.728 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3553.705626450116
    time_step_min: 3255
  date: 2020-10-10_21-20-57
  done: false
  episode_len_mean: 823.1582278481013
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 227.76746463484093
  episode_reward_min: 123.89898989898992
  episodes_this_iter: 163
  episodes_total: 3476
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.6918006539344788
        entropy_coeff: 0.0
        kl: 0.006587540830618569
        model: {}
        policy_loss: -0.013214999427353697
        total_loss: 1.9700517228671484
        vf_explained_var: 0.9963511228561401
        vf_loss: 1.9819492186818803
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.82162162162162
    gpu_util_percent0: 0.36621621621621625
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4972972972972975
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1541886018731711
    mean_env_wait_ms: 1.2324577652975157
    mean_inference_ms: 4.692620320920742
    mean_raw_obs_processing_ms: 0.4056933596410748
  time_since_restore: 543.2416834831238
  time_this_iter_s: 30.130499839782715
  time_total_s: 543.2416834831238
  timers:
    learn_throughput: 7142.884
    learn_time_ms: 22650.795
    sample_throughput: 22318.925
    sample_time_ms: 7249.095
    update_time_ms: 34.759
  timestamp: 1602364857
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |     18 |          543.242 | 2912256 |  227.767 |              273.444 |              123.899 |            823.158 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3551.675540765391
    time_step_min: 3255
  date: 2020-10-10_21-21-27
  done: false
  episode_len_mean: 822.4744083654375
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 228.182649277586
  episode_reward_min: 123.89898989898992
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.6905871714864459
        entropy_coeff: 0.0
        kl: 0.006471311640260475
        model: {}
        policy_loss: -0.015669950916032706
        total_loss: 1.9737645557948522
        vf_explained_var: 0.9960373044013977
        vf_loss: 1.9881402254104614
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.413888888888888
    gpu_util_percent0: 0.37222222222222223
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497222222222222
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15401730001598865
    mean_env_wait_ms: 1.233110400983023
    mean_inference_ms: 4.682003712959113
    mean_raw_obs_processing_ms: 0.4051324271262923
  time_since_restore: 573.5535197257996
  time_this_iter_s: 30.31183624267578
  time_total_s: 573.5535197257996
  timers:
    learn_throughput: 7137.12
    learn_time_ms: 22669.088
    sample_throughput: 22284.943
    sample_time_ms: 7260.149
    update_time_ms: 34.79
  timestamp: 1602364887
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | RUNNING  | 172.17.0.4:37251 |     19 |          573.554 | 3074048 |  228.183 |              273.444 |              123.899 |            822.474 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_33920_00000:
  custom_metrics:
    time_step_max: 4238
    time_step_mean: 3546.976878612717
    time_step_min: 3255
  date: 2020-10-10_21-21-57
  done: true
  episode_len_mean: 821.604590505999
  episode_reward_max: 273.4444444444446
  episode_reward_mean: 228.82611719700918
  episode_reward_min: 123.89898989898992
  episodes_this_iter: 200
  episodes_total: 3834
  experiment_id: ed69fc6a14e748d5b8b633ab0726d467
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.6724847214562553
        entropy_coeff: 0.0
        kl: 0.006357417940827352
        model: {}
        policy_loss: -0.012209745556382197
        total_loss: 2.249972105026245
        vf_explained_var: 0.9963480234146118
        vf_loss: 2.260910391807556
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.838888888888885
    gpu_util_percent0: 0.33527777777777773
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4833333333333325
    vram_util_percent0: 0.20465726467694328
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 37251
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1538163897139379
    mean_env_wait_ms: 1.2339702261764822
    mean_inference_ms: 4.669588556348047
    mean_raw_obs_processing_ms: 0.4044708518172306
  time_since_restore: 603.6032314300537
  time_this_iter_s: 30.04971170425415
  time_total_s: 603.6032314300537
  timers:
    learn_throughput: 7133.698
    learn_time_ms: 22679.961
    sample_throughput: 22289.079
    sample_time_ms: 7258.801
    update_time_ms: 34.263
  timestamp: 1602364917
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: '33920_00000'
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | TERMINATED |       |     20 |          603.603 | 3235840 |  228.826 |              273.444 |              123.899 |            821.605 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.35 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_33920_00000 | TERMINATED |       |     20 |          603.603 | 3235840 |  228.826 |              273.444 |              123.899 |            821.605 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


