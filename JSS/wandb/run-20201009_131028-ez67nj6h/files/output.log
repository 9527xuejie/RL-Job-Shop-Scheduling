2020-10-09 13:10:31,926	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8265[39m[22m
== Status ==
Memory usage on this node: 11.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_d02a9_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=1781)[0m 2020-10-09 13:10:34,943	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=1825)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1825)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1798)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1798)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1786)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1786)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1816)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1816)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1822)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1822)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1823)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1823)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1794)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1794)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1718)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1718)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1839)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1839)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1815)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1815)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1776)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1776)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1804)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1804)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1797)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1797)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1775)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1775)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1737)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1737)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1805)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1805)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1695)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1695)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1800)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1800)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1809)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1809)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1722)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1722)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1760)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1760)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1785)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1785)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1705)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1705)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1833)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1833)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1701)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1701)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1782)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1782)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1714)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1714)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1728)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1728)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1704)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1704)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1732)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1732)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1696)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1696)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1819)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1819)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1814)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1814)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1694)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1694)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1762)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1762)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1711)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1711)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1706)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1706)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1806)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1806)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1710)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1710)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1788)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1788)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1751)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1751)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1725)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1725)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1698)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1698)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1702)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1702)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1753)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1753)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1831)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1831)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1778)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1778)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1708)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1708)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1828)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1828)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1752)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1752)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1811)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1811)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1835)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1835)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1780)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1780)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1787)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1787)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1810)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1810)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1730)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1730)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1700)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1700)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1784)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1784)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1765)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1765)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1707)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1707)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1693)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1693)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1734)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1734)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1791)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1791)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1759)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1759)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1709)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1709)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1703)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1703)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1697)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1697)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1754)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1754)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1808)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1808)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1779)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1779)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1699)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1699)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1736)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1736)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1720)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1720)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1774)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1774)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1783)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1783)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1772)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1772)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1818)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1818)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1793)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1793)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=1789)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=1789)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3302.0
  date: 2020-10-09_13-11-11
  done: false
  episode_len_mean: 875.2088607594936
  episode_reward_max: 265.7171717171717
  episode_reward_mean: 221.69434854877878
  episode_reward_min: 137.23232323232358
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.2
        cur_lr: 5.0e-05
        entropy: 1.1703049269589512
        entropy_coeff: 0.0
        kl: 0.0037405005952512674
        model: {}
        policy_loss: -0.005583010370504449
        total_loss: 509.96131758256394
        vf_explained_var: 0.5414502620697021
        vf_loss: 509.9661504572088
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 23.30833333333333
    gpu_util_percent0: 0.3402777777777778
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.6166666666666663
    vram_util_percent0: 0.09392423745490326
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15794054451236095
    mean_env_wait_ms: 1.1716267031333667
    mean_inference_ms: 4.668034818224716
    mean_raw_obs_processing_ms: 0.41199775123419524
  time_since_restore: 30.993719339370728
  time_this_iter_s: 30.993719339370728
  time_total_s: 30.993719339370728
  timers:
    learn_throughput: 6882.89
    learn_time_ms: 23506.404
    sample_throughput: 21838.485
    sample_time_ms: 7408.573
    update_time_ms: 43.396
  timestamp: 1602249071
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 27.9/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |      1 |          30.9937 | 161792 |  221.694 |              265.717 |              137.232 |            875.209 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3302.0
  date: 2020-10-09_13-11-42
  done: false
  episode_len_mean: 872.4620253164557
  episode_reward_max: 265.7171717171717
  episode_reward_mean: 220.94923922772008
  episode_reward_min: 137.23232323232358
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.143100987781178
        entropy_coeff: 0.0
        kl: 0.007187907711010088
        model: {}
        policy_loss: -0.0012818412558937614
        total_loss: 137.0407257080078
        vf_explained_var: 0.7956389784812927
        vf_loss: 137.0412861217152
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.955555555555556
    gpu_util_percent0: 0.3225
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7916666666666674
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1566223989756852
    mean_env_wait_ms: 1.1732737279816068
    mean_inference_ms: 4.651306009122846
    mean_raw_obs_processing_ms: 0.41032215520894977
  time_since_restore: 61.521783113479614
  time_this_iter_s: 30.528063774108887
  time_total_s: 61.521783113479614
  timers:
    learn_throughput: 6956.495
    learn_time_ms: 23257.688
    sample_throughput: 21790.259
    sample_time_ms: 7424.969
    update_time_ms: 33.184
  timestamp: 1602249102
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |      2 |          61.5218 | 323584 |  220.949 |              265.717 |              137.232 |            872.462 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3299.0
  date: 2020-10-09_13-12-12
  done: false
  episode_len_mean: 868.9957805907173
  episode_reward_max: 268.74747474747454
  episode_reward_mean: 223.12575118271306
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.1285142356699163
        entropy_coeff: 0.0
        kl: 0.008831876499409025
        model: {}
        policy_loss: -0.009647401070899585
        total_loss: 59.56264738603072
        vf_explained_var: 0.8870067000389099
        vf_loss: 59.571412866765804
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.271428571428576
    gpu_util_percent0: 0.33885714285714286
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8000000000000007
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15528627136123796
    mean_env_wait_ms: 1.1736576997999835
    mean_inference_ms: 4.607218572530222
    mean_raw_obs_processing_ms: 0.4067211097249332
  time_since_restore: 91.82444787025452
  time_this_iter_s: 30.302664756774902
  time_total_s: 91.82444787025452
  timers:
    learn_throughput: 6948.784
    learn_time_ms: 23283.498
    sample_throughput: 22337.624
    sample_time_ms: 7243.026
    update_time_ms: 36.065
  timestamp: 1602249132
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.3/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |      3 |          91.8244 | 485376 |  223.126 |              268.747 |               104.96 |            868.996 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3299.0
  date: 2020-10-09_13-12-42
  done: false
  episode_len_mean: 865.0348101265823
  episode_reward_max: 268.74747474747454
  episode_reward_mean: 225.50284490474348
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.10246018929915
        entropy_coeff: 0.0
        kl: 0.009038414509797638
        model: {}
        policy_loss: -0.007967624622820453
        total_loss: 37.711504155939274
        vf_explained_var: 0.9223136901855469
        vf_loss: 37.718569322065875
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.332352941176474
    gpu_util_percent0: 0.33794117647058824
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7970588235294116
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15421470842900264
    mean_env_wait_ms: 1.174718212933129
    mean_inference_ms: 4.568383574654123
    mean_raw_obs_processing_ms: 0.40334796829999914
  time_since_restore: 121.76868844032288
  time_this_iter_s: 29.94424057006836
  time_total_s: 121.76868844032288
  timers:
    learn_throughput: 6964.854
    learn_time_ms: 23229.777
    sample_throughput: 22699.902
    sample_time_ms: 7127.432
    update_time_ms: 36.511
  timestamp: 1602249162
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |      4 |          121.769 | 647168 |  225.503 |              268.747 |               104.96 |            865.035 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3251.0
  date: 2020-10-09_13-13-12
  done: false
  episode_len_mean: 858.9746987951808
  episode_reward_max: 273.4444444444443
  episode_reward_mean: 227.8044298405743
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 198
  episodes_total: 830
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0634922005913474
        entropy_coeff: 0.0
        kl: 0.0075960217721082945
        model: {}
        policy_loss: -0.006210092645646496
        total_loss: 32.655061201615766
        vf_explained_var: 0.9548941254615784
        vf_loss: 32.66051171042702
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.02
    gpu_util_percent0: 0.3131428571428571
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7942857142857145
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15324508782313562
    mean_env_wait_ms: 1.1778633107413827
    mean_inference_ms: 4.530170754601145
    mean_raw_obs_processing_ms: 0.39985101855582394
  time_since_restore: 152.02932500839233
  time_this_iter_s: 30.260636568069458
  time_total_s: 152.02932500839233
  timers:
    learn_throughput: 6960.337
    learn_time_ms: 23244.852
    sample_throughput: 22887.887
    sample_time_ms: 7068.892
    update_time_ms: 36.537
  timestamp: 1602249192
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.4/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |      5 |          152.029 | 808960 |  227.804 |              273.444 |               104.96 |            858.975 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3222.0
  date: 2020-10-09_13-13-42
  done: false
  episode_len_mean: 853.0406871609404
  episode_reward_max: 277.83838383838344
  episode_reward_mean: 229.45532175278993
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 276
  episodes_total: 1106
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0883275053717874
        entropy_coeff: 0.0
        kl: 0.00771880518137054
        model: {}
        policy_loss: -0.010498841451904313
        total_loss: 27.66439437866211
        vf_explained_var: 0.9569612145423889
        vf_loss: 27.674120816317473
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.691428571428574
    gpu_util_percent0: 0.30800000000000005
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.791428571428572
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15225867271384155
    mean_env_wait_ms: 1.1807582793772091
    mean_inference_ms: 4.492713044476831
    mean_raw_obs_processing_ms: 0.3969198435264683
  time_since_restore: 182.02366065979004
  time_this_iter_s: 29.994335651397705
  time_total_s: 182.02366065979004
  timers:
    learn_throughput: 6962.658
    learn_time_ms: 23237.102
    sample_throughput: 23083.563
    sample_time_ms: 7008.97
    update_time_ms: 36.883
  timestamp: 1602249222
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |      6 |          182.024 | 970752 |  229.455 |              277.838 |               104.96 |            853.041 |
+-------------------------+----------+-----------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3222.0
  date: 2020-10-09_13-14-13
  done: false
  episode_len_mean: 849.9375
  episode_reward_max: 277.83838383838344
  episode_reward_mean: 230.50548203554519
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0651226152073254
        entropy_coeff: 0.0
        kl: 0.006654731548306617
        model: {}
        policy_loss: -0.009473668546310033
        total_loss: 16.450937964699484
        vf_explained_var: 0.968959629535675
        vf_loss: 16.4597468809648
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.04571428571429
    gpu_util_percent0: 0.41028571428571425
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8000000000000007
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15184125592549816
    mean_env_wait_ms: 1.1821083397847405
    mean_inference_ms: 4.476046364074775
    mean_raw_obs_processing_ms: 0.3955557595914114
  time_since_restore: 212.1410572528839
  time_this_iter_s: 30.117396593093872
  time_total_s: 212.1410572528839
  timers:
    learn_throughput: 6962.634
    learn_time_ms: 23237.184
    sample_throughput: 23221.966
    sample_time_ms: 6967.197
    update_time_ms: 45.324
  timestamp: 1602249253
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |      7 |          212.141 | 1132544 |  230.505 |              277.838 |               104.96 |            849.938 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3222.0
  date: 2020-10-09_13-14-43
  done: false
  episode_len_mean: 847.3502109704641
  episode_reward_max: 277.83838383838344
  episode_reward_mean: 231.36990154711657
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 1.0372642278671265
        entropy_coeff: 0.0
        kl: 0.008530885362150993
        model: {}
        policy_loss: -0.003596586005931551
        total_loss: 17.56079795143821
        vf_explained_var: 0.9658962488174438
        vf_loss: 17.563541412353516
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.570588235294117
    gpu_util_percent0: 0.3414705882352941
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8088235294117645
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15147946031414572
    mean_env_wait_ms: 1.1832233545749202
    mean_inference_ms: 4.46159745693642
    mean_raw_obs_processing_ms: 0.3942772423585162
  time_since_restore: 242.25397968292236
  time_this_iter_s: 30.112922430038452
  time_total_s: 242.25397968292236
  timers:
    learn_throughput: 6964.514
    learn_time_ms: 23230.909
    sample_throughput: 23275.355
    sample_time_ms: 6951.215
    update_time_ms: 44.458
  timestamp: 1602249283
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |      8 |          242.254 | 1294336 |   231.37 |              277.838 |               104.96 |             847.35 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3222.0
  date: 2020-10-09_13-15-13
  done: false
  episode_len_mean: 845.1095717884131
  episode_reward_max: 277.83838383838344
  episode_reward_mean: 232.04922652214833
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 166
  episodes_total: 1588
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9912238717079163
        entropy_coeff: 0.0
        kl: 0.007362418511713093
        model: {}
        policy_loss: -0.008691810568879273
        total_loss: 18.69759126143022
        vf_explained_var: 0.9714292287826538
        vf_loss: 18.70554715936834
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.108571428571427
    gpu_util_percent0: 0.3380000000000001
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.791428571428572
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15115723710138895
    mean_env_wait_ms: 1.1844601063172426
    mean_inference_ms: 4.448144522525162
    mean_raw_obs_processing_ms: 0.3930840739948023
  time_since_restore: 272.4935007095337
  time_this_iter_s: 30.239521026611328
  time_total_s: 272.4935007095337
  timers:
    learn_throughput: 6962.86
    learn_time_ms: 23236.429
    sample_throughput: 23302.158
    sample_time_ms: 6943.22
    update_time_ms: 42.472
  timestamp: 1602249313
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |      9 |          272.494 | 1456128 |  232.049 |              277.838 |               104.96 |             845.11 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3184.0
  date: 2020-10-09_13-15-44
  done: false
  episode_len_mean: 840.9103375527426
  episode_reward_max: 283.5959595959598
  episode_reward_mean: 234.05945531261975
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 308
  episodes_total: 1896
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9908376336097717
        entropy_coeff: 0.0
        kl: 0.0072551170279356566
        model: {}
        policy_loss: -0.0070585840148851275
        total_loss: 17.522349964488637
        vf_explained_var: 0.9753187298774719
        vf_loss: 17.528683228926226
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.114285714285714
    gpu_util_percent0: 0.36028571428571426
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7885714285714283
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.150654810268589
    mean_env_wait_ms: 1.186531537578827
    mean_inference_ms: 4.428118985143308
    mean_raw_obs_processing_ms: 0.39140457893778646
  time_since_restore: 302.87319135665894
  time_this_iter_s: 30.379690647125244
  time_total_s: 302.87319135665894
  timers:
    learn_throughput: 6964.204
    learn_time_ms: 23231.944
    sample_throughput: 23252.892
    sample_time_ms: 6957.93
    update_time_ms: 42.309
  timestamp: 1602249344
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |     10 |          302.873 | 1617920 |  234.059 |              283.596 |               104.96 |             840.91 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3184.0
  date: 2020-10-09_13-16-14
  done: false
  episode_len_mean: 838.3315481986368
  episode_reward_max: 283.5959595959598
  episode_reward_mean: 235.17506614342048
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9772959839213978
        entropy_coeff: 0.0
        kl: 0.006607516711069779
        model: {}
        policy_loss: -0.006509003086565909
        total_loss: 12.320954149419611
        vf_explained_var: 0.9763029217720032
        vf_loss: 12.326802167025479
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.94857142857143
    gpu_util_percent0: 0.2968571428571428
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.805714285714286
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15044328507930693
    mean_env_wait_ms: 1.1874908914071292
    mean_inference_ms: 4.419592429583951
    mean_raw_obs_processing_ms: 0.39068783225415116
  time_since_restore: 332.8842878341675
  time_this_iter_s: 30.011096477508545
  time_total_s: 332.8842878341675
  timers:
    learn_throughput: 6977.896
    learn_time_ms: 23186.358
    sample_throughput: 23439.527
    sample_time_ms: 6902.528
    update_time_ms: 42.031
  timestamp: 1602249374
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |     11 |          332.884 | 1779712 |  235.175 |              283.596 |               104.96 |            838.332 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3184.0
  date: 2020-10-09_13-16-44
  done: false
  episode_len_mean: 835.9669981916817
  episode_reward_max: 283.5959595959598
  episode_reward_mean: 236.16445649989942
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 158
  episodes_total: 2212
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9589243260296908
        entropy_coeff: 0.0
        kl: 0.006812991786070846
        model: {}
        policy_loss: -0.009207123689438131
        total_loss: 12.291858759793369
        vf_explained_var: 0.9748014211654663
        vf_loss: 12.300384521484375
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.9
    gpu_util_percent0: 0.37399999999999994
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8114285714285723
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1502510907389521
    mean_env_wait_ms: 1.1883857928247383
    mean_inference_ms: 4.411909290186335
    mean_raw_obs_processing_ms: 0.3900109665930595
  time_since_restore: 363.16600799560547
  time_this_iter_s: 30.28172016143799
  time_total_s: 363.16600799560547
  timers:
    learn_throughput: 6968.66
    learn_time_ms: 23217.09
    sample_throughput: 23637.368
    sample_time_ms: 6844.755
    update_time_ms: 43.407
  timestamp: 1602249404
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |     12 |          363.166 | 1941504 |  236.164 |              283.596 |               104.96 |            835.967 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3184.0
  date: 2020-10-09_13-17-14
  done: false
  episode_len_mean: 832.8795918367347
  episode_reward_max: 286.77777777777806
  episode_reward_mean: 237.3221191506905
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 238
  episodes_total: 2450
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9176090847362172
        entropy_coeff: 0.0
        kl: 0.006804890930652618
        model: {}
        policy_loss: -0.006001168025911532
        total_loss: 15.606023875149814
        vf_explained_var: 0.9788637757301331
        vf_loss: 15.611344337463379
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.694285714285716
    gpu_util_percent0: 0.334
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.791428571428572
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15001267079290592
    mean_env_wait_ms: 1.1898196032005266
    mean_inference_ms: 4.401505819427667
    mean_raw_obs_processing_ms: 0.3890952260873357
  time_since_restore: 393.35549330711365
  time_this_iter_s: 30.18948531150818
  time_total_s: 393.35549330711365
  timers:
    learn_throughput: 6971.739
    learn_time_ms: 23206.835
    sample_throughput: 23644.972
    sample_time_ms: 6842.554
    update_time_ms: 43.296
  timestamp: 1602249434
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |     13 |          393.355 | 2103296 |  237.322 |              286.778 |               104.96 |             832.88 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3184.0
  date: 2020-10-09_13-17-45
  done: false
  episode_len_mean: 830.2066269545793
  episode_reward_max: 286.77777777777806
  episode_reward_mean: 238.57238054408563
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 236
  episodes_total: 2686
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9112121950496327
        entropy_coeff: 0.0
        kl: 0.006325646853921088
        model: {}
        policy_loss: -0.008979435916527027
        total_loss: 13.858070893721147
        vf_explained_var: 0.9769808053970337
        vf_loss: 13.86641788482666
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.954285714285714
    gpu_util_percent0: 0.35428571428571426
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8028571428571434
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14977761863925718
    mean_env_wait_ms: 1.1910202387530977
    mean_inference_ms: 4.392858102364614
    mean_raw_obs_processing_ms: 0.388363926006588
  time_since_restore: 423.6577560901642
  time_this_iter_s: 30.302262783050537
  time_total_s: 423.6577560901642
  timers:
    learn_throughput: 6962.614
    learn_time_ms: 23237.249
    sample_throughput: 23629.328
    sample_time_ms: 6847.084
    update_time_ms: 43.044
  timestamp: 1602249465
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |     14 |          423.658 | 2265088 |  238.572 |              286.778 |               104.96 |            830.207 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3174.0
  date: 2020-10-09_13-18-15
  done: false
  episode_len_mean: 828.4690576652602
  episode_reward_max: 286.77777777777806
  episode_reward_mean: 239.38193112560194
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.9006395177407698
        entropy_coeff: 0.0
        kl: 0.006466609383509917
        model: {}
        policy_loss: -0.004938156867865473
        total_loss: 11.682711167768998
        vf_explained_var: 0.976933479309082
        vf_loss: 11.687002182006836
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.214285714285715
    gpu_util_percent0: 0.38
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14964764566997196
    mean_env_wait_ms: 1.1917790749064836
    mean_inference_ms: 4.387529361555533
    mean_raw_obs_processing_ms: 0.3879124561492799
  time_since_restore: 453.73352551460266
  time_this_iter_s: 30.075769424438477
  time_total_s: 453.73352551460266
  timers:
    learn_throughput: 6964.02
    learn_time_ms: 23232.557
    sample_throughput: 23663.796
    sample_time_ms: 6837.111
    update_time_ms: 41.773
  timestamp: 1602249495
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |     15 |          453.734 | 2426880 |  239.382 |              286.778 |               104.96 |            828.469 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3174.0
  date: 2020-10-09_13-18-45
  done: false
  episode_len_mean: 826.7389277389277
  episode_reward_max: 286.77777777777806
  episode_reward_mean: 240.0358833086105
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 159
  episodes_total: 3003
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8723352768204429
        entropy_coeff: 0.0
        kl: 0.007229925302619284
        model: {}
        policy_loss: -0.008756920525973494
        total_loss: 14.402671120383523
        vf_explained_var: 0.973903238773346
        vf_loss: 14.41070487282493
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.954285714285714
    gpu_util_percent0: 0.41857142857142854
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8685714285714288
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14952458863145715
    mean_env_wait_ms: 1.192527146464627
    mean_inference_ms: 4.382465369538347
    mean_raw_obs_processing_ms: 0.3874739554015017
  time_since_restore: 484.008944272995
  time_this_iter_s: 30.275418758392334
  time_total_s: 484.008944272995
  timers:
    learn_throughput: 6961.059
    learn_time_ms: 23242.439
    sample_throughput: 23609.48
    sample_time_ms: 6852.84
    update_time_ms: 42.28
  timestamp: 1602249525
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |     16 |          484.009 | 2588672 |  240.036 |              286.778 |               104.96 |            826.739 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3174.0
  date: 2020-10-09_13-19-15
  done: false
  episode_len_mean: 823.3832226916113
  episode_reward_max: 286.77777777777806
  episode_reward_mean: 241.5302054949007
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 311
  episodes_total: 3314
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8434323614293878
        entropy_coeff: 0.0
        kl: 0.005665423390878873
        model: {}
        policy_loss: -0.0038657286125023597
        total_loss: 14.75777478651567
        vf_explained_var: 0.9797275066375732
        vf_loss: 14.761073806069113
    num_steps_sampled: 2750464
    num_steps_trained: 2750464
  iterations_since_restore: 17
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.685714285714283
    gpu_util_percent0: 0.3271428571428572
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.7857142857142865
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14930785332356716
    mean_env_wait_ms: 1.193998753573406
    mean_inference_ms: 4.373571823969361
    mean_raw_obs_processing_ms: 0.3867432865229819
  time_since_restore: 514.0862047672272
  time_this_iter_s: 30.077260494232178
  time_total_s: 514.0862047672272
  timers:
    learn_throughput: 6960.622
    learn_time_ms: 23243.899
    sample_throughput: 23606.501
    sample_time_ms: 6853.705
    update_time_ms: 36.589
  timestamp: 1602249555
  timesteps_since_restore: 0
  timesteps_total: 2750464
  training_iteration: 17
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |     17 |          514.086 | 2750464 |   241.53 |              286.778 |               104.96 |            823.383 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3174.0
  date: 2020-10-09_13-19-46
  done: false
  episode_len_mean: 821.6694476409666
  episode_reward_max: 286.77777777777806
  episode_reward_mean: 242.1028204949378
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 162
  episodes_total: 3476
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8303303447636691
        entropy_coeff: 0.0
        kl: 0.006192686459557576
        model: {}
        policy_loss: -0.009919890297830782
        total_loss: 10.038436889648438
        vf_explained_var: 0.9805930852890015
        vf_loss: 10.047737381675027
    num_steps_sampled: 2912256
    num_steps_trained: 2912256
  iterations_since_restore: 18
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.082857142857144
    gpu_util_percent0: 0.35742857142857143
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.805714285714286
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14920678662427503
    mean_env_wait_ms: 1.1947153812768885
    mean_inference_ms: 4.3694517486749795
    mean_raw_obs_processing_ms: 0.3864028753079076
  time_since_restore: 544.2953171730042
  time_this_iter_s: 30.209112405776978
  time_total_s: 544.2953171730042
  timers:
    learn_throughput: 6957.872
    learn_time_ms: 23253.087
    sample_throughput: 23614.088
    sample_time_ms: 6851.503
    update_time_ms: 37.243
  timestamp: 1602249586
  timesteps_since_restore: 0
  timesteps_total: 2912256
  training_iteration: 18
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |     18 |          544.295 | 2912256 |  242.103 |              286.778 |               104.96 |            821.669 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3174.0
  date: 2020-10-09_13-20-16
  done: false
  episode_len_mean: 820.062740781508
  episode_reward_max: 286.77777777777806
  episode_reward_mean: 242.79869137161373
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 158
  episodes_total: 3634
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.8157092712142251
        entropy_coeff: 0.0
        kl: 0.005598700732331385
        model: {}
        policy_loss: -0.006305614962581207
        total_loss: 10.293941064314408
        vf_explained_var: 0.97786945104599
        vf_loss: 10.299686778675426
    num_steps_sampled: 3074048
    num_steps_trained: 3074048
  iterations_since_restore: 19
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.765714285714285
    gpu_util_percent0: 0.3437142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.8685714285714288
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14911441863957067
    mean_env_wait_ms: 1.1954006387874294
    mean_inference_ms: 4.365649944260136
    mean_raw_obs_processing_ms: 0.3860839003125854
  time_since_restore: 574.7607808113098
  time_this_iter_s: 30.465463638305664
  time_total_s: 574.7607808113098
  timers:
    learn_throughput: 6951.917
    learn_time_ms: 23273.005
    sample_throughput: 23617.277
    sample_time_ms: 6850.578
    update_time_ms: 38.641
  timestamp: 1602249616
  timesteps_since_restore: 0
  timesteps_total: 3074048
  training_iteration: 19
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc             |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | RUNNING  | 172.17.0.4:1781 |     19 |          574.761 | 3074048 |  242.799 |              286.778 |               104.96 |            820.063 |
+-------------------------+----------+-----------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_d02a9_00000:
  custom_metrics:
    time_step_max: .inf
    time_step_mean: .inf
    time_step_min: 3131.0
  date: 2020-10-09_13-20-47
  done: true
  episode_len_mean: 817.2529936305732
  episode_reward_max: 291.62626262626264
  episode_reward_mean: 243.75257028887594
  episode_reward_min: 104.95959595959629
  episodes_this_iter: 291
  episodes_total: 3925
  experiment_id: 2f83f042aba84ecdaed54a9a5a3e5e3e
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.1
        cur_lr: 5.0e-05
        entropy: 0.778048883784901
        entropy_coeff: 0.0
        kl: 0.006528660528023134
        model: {}
        policy_loss: -0.0037039551058445463
        total_loss: 15.304632100191983
        vf_explained_var: 0.9787940979003906
        vf_loss: 15.307683251120828
    num_steps_sampled: 3235840
    num_steps_trained: 3235840
  iterations_since_restore: 20
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.242857142857144
    gpu_util_percent0: 0.3717142857142857
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 3.791428571428572
    vram_util_percent0: 0.1089701541489013
    vram_util_percent1: 0.0
    vram_util_percent2: 0.0
  pid: 1781
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.14896072124872203
    mean_env_wait_ms: 1.1966928764218512
    mean_inference_ms: 4.359075321299055
    mean_raw_obs_processing_ms: 0.3855488289013338
  time_since_restore: 605.2111825942993
  time_this_iter_s: 30.450401782989502
  time_total_s: 605.2111825942993
  timers:
    learn_throughput: 6942.921
    learn_time_ms: 23303.159
    sample_throughput: 23701.363
    sample_time_ms: 6826.274
    update_time_ms: 38.354
  timestamp: 1602249647
  timesteps_since_restore: 0
  timesteps_total: 3235840
  training_iteration: 20
  trial_id: d02a9_00000
  
WARNING:root:NaN or Inf found in input tensor.
WARNING:root:NaN or Inf found in input tensor.
== Status ==
Memory usage on this node: 28.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | TERMINATED |       |     20 |          605.211 | 3235840 |  243.753 |              291.626 |               104.96 |            817.253 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


== Status ==
Memory usage on this node: 28.2/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/558.4 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_d02a9_00000 | TERMINATED |       |     20 |          605.211 | 3235840 |  243.753 |              291.626 |               104.96 |            817.253 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


