2020-10-11 01:50:24,549	INFO services.py:1164 -- View the Ray dashboard at [1m[32mhttp://127.0.0.1:8266[39m[22m
== Status ==
Memory usage on this node: 32.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+-------+
| Trial name              | status   | loc   |
|-------------------------+----------+-------|
| PPO_jss_env_21ee9_00000 | RUNNING  |       |
+-------------------------+----------+-------+


[2m[36m(pid=18079)[0m 2020-10-11 01:50:27,457	INFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
[2m[36m(pid=18073)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18073)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18081)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18081)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18063)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18063)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18100)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18100)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18128)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18128)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18096)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18096)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18102)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18102)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18097)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18097)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18131)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18131)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18111)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18111)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18071)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18071)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18118)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18118)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18055)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18055)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18099)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18099)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18106)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18106)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18082)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18082)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18093)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18093)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18059)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18059)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18015)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18015)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18088)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18088)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18061)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18061)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18067)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18067)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17994)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17994)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18109)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18109)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18070)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18070)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18001)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18001)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18002)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18002)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18019)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18019)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18075)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18075)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18056)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18056)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18080)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18080)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17993)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17993)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18085)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18085)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18092)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18092)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17996)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17996)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17989)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17989)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18030)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18030)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17997)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17997)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18046)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18046)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17991)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17991)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18029)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18029)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18053)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18053)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18023)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18023)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18049)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18049)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18010)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18010)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18052)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18052)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18009)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18009)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18000)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18000)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18123)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18123)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17998)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17998)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18004)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18004)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18087)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18087)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18098)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18098)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18113)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18113)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18083)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18083)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18064)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18064)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18121)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18121)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18065)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18065)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18012)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18012)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18016)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18016)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18062)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18062)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18013)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18013)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18050)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18050)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17988)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17988)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17992)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17992)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18003)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18003)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18115)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18115)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17990)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17990)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18020)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18020)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18005)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18005)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18057)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18057)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=17987)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=17987)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18044)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18044)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18066)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18066)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18119)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18119)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18069)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18069)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18026)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18026)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18007)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18007)[0m   tensor = torch.from_numpy(np.asarray(item))
[2m[36m(pid=18107)[0m /root/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/torch_ops.py:65: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629401015/work/torch/csrc/utils/tensor_numpy.cpp:141.)
[2m[36m(pid=18107)[0m   tensor = torch.from_numpy(np.asarray(item))
Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3615.0923076923077
    time_step_min: 3379
  date: 2020-10-11_01-51-13
  done: false
  episode_len_mean: 891.1139240506329
  episode_reward_max: 258.59595959595964
  episode_reward_mean: 216.07678046285614
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 158
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.176275713103158
        entropy_coeff: 0.0
        kl: 0.012819960779909576
        model: {}
        policy_loss: -0.01571179746159552
        total_loss: 9.177862303597587
        vf_explained_var: 0.7775402665138245
        vf_loss: 9.191010407039098
    num_steps_sampled: 161792
    num_steps_trained: 161792
  iterations_since_restore: 1
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 21.931250000000002
    gpu_util_percent0: 0.28854166666666664
    gpu_util_percent1: 0.00020833333333333335
    gpu_util_percent2: 0.00020833333333333335
    ram_util_percent: 6.310416666666666
    vram_util_percent0: 0.19461640428555813
    vram_util_percent1: 0.0009075233687267447
    vram_util_percent2: 0.0009075233687267447
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16473240453396804
    mean_env_wait_ms: 1.1788367636228057
    mean_inference_ms: 5.380640138848103
    mean_raw_obs_processing_ms: 0.433476981869374
  time_since_restore: 40.501185178756714
  time_this_iter_s: 40.501185178756714
  time_total_s: 40.501185178756714
  timers:
    learn_throughput: 5107.812
    learn_time_ms: 31675.404
    sample_throughput: 18482.207
    sample_time_ms: 8753.933
    update_time_ms: 36.423
  timestamp: 1602381073
  timesteps_since_restore: 0
  timesteps_total: 161792
  training_iteration: 1
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.1/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |      1 |          40.5012 | 161792 |  216.077 |              258.596 |              145.717 |            891.114 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4054
    time_step_mean: 3616.2708333333335
    time_step_min: 3355
  date: 2020-10-11_01-51-53
  done: false
  episode_len_mean: 877.5854430379746
  episode_reward_max: 259.2020202020204
  episode_reward_mean: 216.97580232706792
  episode_reward_min: 145.7171717171716
  episodes_this_iter: 158
  episodes_total: 316
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1354172655514307
        entropy_coeff: 0.0
        kl: 0.014995500578411989
        model: {}
        policy_loss: -0.01958342789605792
        total_loss: 6.952403988157
        vf_explained_var: 0.9131713509559631
        vf_loss: 6.968988350459507
    num_steps_sampled: 323584
    num_steps_trained: 323584
  iterations_since_restore: 2
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.429787234042557
    gpu_util_percent0: 0.327872340425532
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4787234042553195
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267445
    vram_util_percent2: 0.0009075233687267445
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.16168356355296007
    mean_env_wait_ms: 1.1852488350378134
    mean_inference_ms: 5.234817401141032
    mean_raw_obs_processing_ms: 0.4282794628874115
  time_since_restore: 80.1160454750061
  time_this_iter_s: 39.61486029624939
  time_total_s: 80.1160454750061
  timers:
    learn_throughput: 5115.981
    learn_time_ms: 31624.825
    sample_throughput: 19431.085
    sample_time_ms: 8326.452
    update_time_ms: 27.742
  timestamp: 1602381113
  timesteps_since_restore: 0
  timesteps_total: 323584
  training_iteration: 2
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.6/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |      2 |           80.116 | 323584 |  216.976 |              259.202 |              145.717 |            877.585 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4126
    time_step_mean: 3612.154708520179
    time_step_min: 3245
  date: 2020-10-11_01-52-32
  done: false
  episode_len_mean: 868.2257383966245
  episode_reward_max: 274.3535353535348
  episode_reward_mean: 217.35443037974665
  episode_reward_min: 140.8686868686867
  episodes_this_iter: 158
  episodes_total: 474
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.1115645936557226
        entropy_coeff: 0.0
        kl: 0.014166313955294234
        model: {}
        policy_loss: -0.020056701839036708
        total_loss: 6.956663165773664
        vf_explained_var: 0.9509100317955017
        vf_loss: 6.97388642174857
    num_steps_sampled: 485376
    num_steps_trained: 485376
  iterations_since_restore: 3
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 20.119565217391305
    gpu_util_percent0: 0.3189130434782609
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.491304347826087
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15956878997371748
    mean_env_wait_ms: 1.1895819280071853
    mean_inference_ms: 5.113487667048926
    mean_raw_obs_processing_ms: 0.4236019343413594
  time_since_restore: 119.1000747680664
  time_this_iter_s: 38.9840292930603
  time_total_s: 119.1000747680664
  timers:
    learn_throughput: 5124.428
    learn_time_ms: 31572.696
    sample_throughput: 20149.912
    sample_time_ms: 8029.415
    update_time_ms: 27.688
  timestamp: 1602381152
  timesteps_since_restore: 0
  timesteps_total: 485376
  training_iteration: 3
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.5/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |      3 |            119.1 | 485376 |  217.354 |              274.354 |              140.869 |            868.226 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3606.640728476821
    time_step_min: 3245
  date: 2020-10-11_01-53-11
  done: false
  episode_len_mean: 860.4683544303797
  episode_reward_max: 274.3535353535348
  episode_reward_mean: 218.6300025572176
  episode_reward_min: 125.41414141414124
  episodes_this_iter: 158
  episodes_total: 632
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0682147315570287
        entropy_coeff: 0.0
        kl: 0.013889137522450514
        model: {}
        policy_loss: -0.022816028778574297
        total_loss: 6.182435512542725
        vf_explained_var: 0.9700140953063965
        vf_loss: 6.202473538262503
    num_steps_sampled: 647168
    num_steps_trained: 647168
  iterations_since_restore: 4
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.80217391304348
    gpu_util_percent0: 0.46043478260869564
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.484782608695652
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15817429137209604
    mean_env_wait_ms: 1.1935947278270784
    mean_inference_ms: 5.024676403150919
    mean_raw_obs_processing_ms: 0.4198105838591809
  time_since_restore: 158.12651586532593
  time_this_iter_s: 39.02644109725952
  time_total_s: 158.12651586532593
  timers:
    learn_throughput: 5127.479
    learn_time_ms: 31553.906
    sample_throughput: 20518.052
    sample_time_ms: 7885.349
    update_time_ms: 27.631
  timestamp: 1602381191
  timesteps_since_restore: 0
  timesteps_total: 647168
  training_iteration: 4
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |      4 |          158.127 | 647168 |   218.63 |              274.354 |              125.414 |            860.468 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3595.6699779249448
    time_step_min: 3217
  date: 2020-10-11_01-53-50
  done: false
  episode_len_mean: 847.5706638115631
  episode_reward_max: 278.5959595959589
  episode_reward_mean: 220.486330110527
  episode_reward_min: 125.41414141414124
  episodes_this_iter: 302
  episodes_total: 934
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0356671469552177
        entropy_coeff: 0.0
        kl: 0.0127262634757374
        model: {}
        policy_loss: -0.020692181108253344
        total_loss: 9.166893482208252
        vf_explained_var: 0.9797462224960327
        vf_loss: 9.185040542057582
    num_steps_sampled: 808960
    num_steps_trained: 808960
  iterations_since_restore: 5
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.684782608695656
    gpu_util_percent0: 0.3932608695652174
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489130434782608
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1564731728590564
    mean_env_wait_ms: 1.20149288333436
    mean_inference_ms: 4.909946221676449
    mean_raw_obs_processing_ms: 0.41519326916326627
  time_since_restore: 197.2142539024353
  time_this_iter_s: 39.087738037109375
  time_total_s: 197.2142539024353
  timers:
    learn_throughput: 5130.349
    learn_time_ms: 31536.254
    sample_throughput: 20701.653
    sample_time_ms: 7815.414
    update_time_ms: 29.545
  timestamp: 1602381230
  timesteps_since_restore: 0
  timesteps_total: 808960
  training_iteration: 5
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |      5 |          197.214 | 808960 |  220.486 |              278.596 |              125.414 |            847.571 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3594.3682745825604
    time_step_min: 3217
  date: 2020-10-11_01-54-30
  done: false
  episode_len_mean: 842.0189873417721
  episode_reward_max: 278.5959595959589
  episode_reward_mean: 220.77539408552053
  episode_reward_min: 125.41414141414124
  episodes_this_iter: 172
  episodes_total: 1106
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 1.0152793696948461
        entropy_coeff: 0.0
        kl: 0.013039069516318185
        model: {}
        policy_loss: -0.02181299973744899
        total_loss: 5.1188803400312155
        vf_explained_var: 0.9851247072219849
        vf_loss: 5.138085501534598
    num_steps_sampled: 970752
    num_steps_trained: 970752
  iterations_since_restore: 6
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.530434782608694
    gpu_util_percent0: 0.2941304347826087
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.504347826086956
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15583434866678414
    mean_env_wait_ms: 1.2046242752076166
    mean_inference_ms: 4.865260550131203
    mean_raw_obs_processing_ms: 0.41333024008838076
  time_since_restore: 236.46562552452087
  time_this_iter_s: 39.25137162208557
  time_total_s: 236.46562552452087
  timers:
    learn_throughput: 5124.134
    learn_time_ms: 31574.503
    sample_throughput: 20888.297
    sample_time_ms: 7745.581
    update_time_ms: 31.321
  timestamp: 1602381270
  timesteps_since_restore: 0
  timesteps_total: 970752
  training_iteration: 6
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |     ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |      6 |          236.466 | 970752 |  220.775 |              278.596 |              125.414 |            842.019 |
+-------------------------+----------+------------------+--------+------------------+--------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3590.1480582524273
    time_step_min: 3217
  date: 2020-10-11_01-55-08
  done: false
  episode_len_mean: 837.7650316455696
  episode_reward_max: 280.1111111111109
  episode_reward_mean: 221.5249728295613
  episode_reward_min: 125.41414141414124
  episodes_this_iter: 158
  episodes_total: 1264
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9765802664416177
        entropy_coeff: 0.0
        kl: 0.013814742610390698
        model: {}
        policy_loss: -0.023668690651123012
        total_loss: 4.223826204027448
        vf_explained_var: 0.9893496632575989
        vf_loss: 4.244732005255563
    num_steps_sampled: 1132544
    num_steps_trained: 1132544
  iterations_since_restore: 7
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.678260869565214
    gpu_util_percent0: 0.3597826086956522
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.489130434782608
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15532455624856253
    mean_env_wait_ms: 1.2073820221672353
    mean_inference_ms: 4.830303843116539
    mean_raw_obs_processing_ms: 0.41181858321531417
  time_since_restore: 275.33203959465027
  time_this_iter_s: 38.866414070129395
  time_total_s: 275.33203959465027
  timers:
    learn_throughput: 5132.222
    learn_time_ms: 31524.745
    sample_throughput: 20997.993
    sample_time_ms: 7705.117
    update_time_ms: 32.423
  timestamp: 1602381308
  timesteps_since_restore: 0
  timesteps_total: 1132544
  training_iteration: 7
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |      7 |          275.332 | 1132544 |  221.525 |              280.111 |              125.414 |            837.765 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3585.509325681492
    time_step_min: 3217
  date: 2020-10-11_01-55-48
  done: false
  episode_len_mean: 834.1603375527426
  episode_reward_max: 280.1111111111109
  episode_reward_mean: 222.4021651110258
  episode_reward_min: 125.41414141414124
  episodes_this_iter: 158
  episodes_total: 1422
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.9290098079613277
        entropy_coeff: 0.0
        kl: 0.014025719370692968
        model: {}
        policy_loss: -0.023730480976934944
        total_loss: 4.03074894632612
        vf_explained_var: 0.9910416603088379
        vf_loss: 4.0516742297581265
    num_steps_sampled: 1294336
    num_steps_trained: 1294336
  iterations_since_restore: 8
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.42608695652174
    gpu_util_percent0: 0.3071739130434783
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497826086956523
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15486905438842213
    mean_env_wait_ms: 1.2099749904615837
    mean_inference_ms: 4.799917583374956
    mean_raw_obs_processing_ms: 0.41037973010018797
  time_since_restore: 314.7604019641876
  time_this_iter_s: 39.42836236953735
  time_total_s: 314.7604019641876
  timers:
    learn_throughput: 5124.846
    learn_time_ms: 31570.118
    sample_throughput: 21085.387
    sample_time_ms: 7673.182
    update_time_ms: 33.473
  timestamp: 1602381348
  timesteps_since_restore: 0
  timesteps_total: 1294336
  training_iteration: 8
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |      8 |           314.76 | 1294336 |  222.402 |              280.111 |              125.414 |             834.16 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3572.1983616149796
    time_step_min: 3217
  date: 2020-10-11_01-56-27
  done: false
  episode_len_mean: 827.5256188831319
  episode_reward_max: 280.1111111111109
  episode_reward_mean: 224.652989305839
  episode_reward_min: 125.41414141414124
  episodes_this_iter: 315
  episodes_total: 1737
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.88296868119921
        entropy_coeff: 0.0
        kl: 0.012694345986736673
        model: {}
        policy_loss: -0.020179706692163433
        total_loss: 4.937167985098703
        vf_explained_var: 0.9927791953086853
        vf_loss: 4.954808814185006
    num_steps_sampled: 1456128
    num_steps_trained: 1456128
  iterations_since_restore: 9
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.89782608695652
    gpu_util_percent0: 0.3310869565217391
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.48695652173913
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15413740871214715
    mean_env_wait_ms: 1.2147751919762944
    mean_inference_ms: 4.751505375450764
    mean_raw_obs_processing_ms: 0.4081719036645858
  time_since_restore: 353.97167563438416
  time_this_iter_s: 39.21127367019653
  time_total_s: 353.97167563438416
  timers:
    learn_throughput: 5124.562
    learn_time_ms: 31571.871
    sample_throughput: 21126.705
    sample_time_ms: 7658.175
    update_time_ms: 33.598
  timestamp: 1602381387
  timesteps_since_restore: 0
  timesteps_total: 1456128
  training_iteration: 9
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |      9 |          353.972 | 1456128 |  224.653 |              280.111 |              125.414 |            827.526 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3568.119379014989
    time_step_min: 3217
  date: 2020-10-11_01-57-07
  done: false
  episode_len_mean: 825.6429324894515
  episode_reward_max: 280.1111111111109
  episode_reward_mean: 225.1898254698887
  episode_reward_min: 125.41414141414124
  episodes_this_iter: 159
  episodes_total: 1896
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8432174495288304
        entropy_coeff: 0.0
        kl: 0.013431162839489324
        model: {}
        policy_loss: -0.022568634445113794
        total_loss: 3.0336241211209978
        vf_explained_var: 0.993761420249939
        vf_loss: 3.053506510598319
    num_steps_sampled: 1617920
    num_steps_trained: 1617920
  iterations_since_restore: 10
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.55217391304348
    gpu_util_percent0: 0.2734782608695653
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497826086956521
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15383630488114827
    mean_env_wait_ms: 1.216764612077457
    mean_inference_ms: 4.7314549324558905
    mean_raw_obs_processing_ms: 0.4072441697781589
  time_since_restore: 393.1941788196564
  time_this_iter_s: 39.22250318527222
  time_total_s: 393.1941788196564
  timers:
    learn_throughput: 5124.419
    learn_time_ms: 31572.748
    sample_throughput: 21153.95
    sample_time_ms: 7648.312
    update_time_ms: 32.571
  timestamp: 1602381427
  timesteps_since_restore: 0
  timesteps_total: 1617920
  training_iteration: 10
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |     10 |          393.194 | 1617920 |   225.19 |              280.111 |              125.414 |            825.643 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3563.0088845014807
    time_step_min: 3217
  date: 2020-10-11_01-57-46
  done: false
  episode_len_mean: 823.8690360272639
  episode_reward_max: 280.1111111111109
  episode_reward_mean: 225.92150325061712
  episode_reward_min: 125.41414141414124
  episodes_this_iter: 158
  episodes_total: 2054
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.8107591952596392
        entropy_coeff: 0.0
        kl: 0.012790864133941275
        model: {}
        policy_loss: -0.021695565033171858
        total_loss: 2.8903487409864153
        vf_explained_var: 0.9938410520553589
        vf_loss: 2.909486174583435
    num_steps_sampled: 1779712
    num_steps_trained: 1779712
  iterations_since_restore: 11
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.923913043478258
    gpu_util_percent0: 0.2506521739130435
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.513043478260872
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15356579794112046
    mean_env_wait_ms: 1.2186087849917746
    mean_inference_ms: 4.713476251363651
    mean_raw_obs_processing_ms: 0.40638677200292106
  time_since_restore: 432.32773303985596
  time_this_iter_s: 39.133554220199585
  time_total_s: 432.32773303985596
  timers:
    learn_throughput: 5126.726
    learn_time_ms: 31558.54
    sample_throughput: 21501.761
    sample_time_ms: 7524.593
    update_time_ms: 31.901
  timestamp: 1602381466
  timesteps_since_restore: 0
  timesteps_total: 1779712
  training_iteration: 11
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |     11 |          432.328 | 1779712 |  225.922 |              280.111 |              125.414 |            823.869 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3558.907947911989
    time_step_min: 3200
  date: 2020-10-11_01-58-25
  done: false
  episode_len_mean: 822.1223946784922
  episode_reward_max: 281.1717171717167
  episode_reward_mean: 226.3945889045667
  episode_reward_min: 125.41414141414124
  episodes_this_iter: 201
  episodes_total: 2255
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.778583939586367
        entropy_coeff: 0.0
        kl: 0.010597485450229474
        model: {}
        policy_loss: -0.01644165764030601
        total_loss: 3.7864486319678172
        vf_explained_var: 0.9942495226860046
        vf_loss: 3.8007708277021135
    num_steps_sampled: 1941504
    num_steps_trained: 1941504
  iterations_since_restore: 12
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.83478260869565
    gpu_util_percent0: 0.27673913043478265
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.4913043478260875
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15327500219982124
    mean_env_wait_ms: 1.2208268481641191
    mean_inference_ms: 4.692883698318243
    mean_raw_obs_processing_ms: 0.40538890617319956
  time_since_restore: 471.5081789493561
  time_this_iter_s: 39.18044590950012
  time_total_s: 471.5081789493561
  timers:
    learn_throughput: 5127.187
    learn_time_ms: 31555.704
    sample_throughput: 21604.56
    sample_time_ms: 7488.79
    update_time_ms: 34.08
  timestamp: 1602381505
  timesteps_since_restore: 0
  timesteps_total: 1941504
  training_iteration: 12
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |     12 |          471.508 | 1941504 |  226.395 |              281.172 |              125.414 |            822.122 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3554.7076
    time_step_min: 3200
  date: 2020-10-11_01-59-04
  done: false
  episode_len_mean: 819.8378164556962
  episode_reward_max: 281.1717171717167
  episode_reward_mean: 227.08056834164424
  episode_reward_min: 125.41414141414124
  episodes_this_iter: 273
  episodes_total: 2528
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7460653143269675
        entropy_coeff: 0.0
        kl: 0.011603339508708035
        model: {}
        policy_loss: -0.017536026891320944
        total_loss: 3.0207373755318776
        vf_explained_var: 0.9949573874473572
        vf_loss: 3.035952636173793
    num_steps_sampled: 2103296
    num_steps_trained: 2103296
  iterations_since_restore: 13
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.056521739130435
    gpu_util_percent0: 0.23804347826086958
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.504347826086959
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1529289208843439
    mean_env_wait_ms: 1.2235268257948477
    mean_inference_ms: 4.669034793877692
    mean_raw_obs_processing_ms: 0.40427177827924177
  time_since_restore: 510.66234588623047
  time_this_iter_s: 39.15416693687439
  time_total_s: 510.66234588623047
  timers:
    learn_throughput: 5124.487
    learn_time_ms: 31572.333
    sample_throughput: 21608.571
    sample_time_ms: 7487.399
    update_time_ms: 34.39
  timestamp: 1602381544
  timesteps_since_restore: 0
  timesteps_total: 2103296
  training_iteration: 13
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |     13 |          510.662 | 2103296 |  227.081 |              281.172 |              125.414 |            819.838 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3550.5989465763732
    time_step_min: 3200
  date: 2020-10-11_01-59-43
  done: false
  episode_len_mean: 818.3775130305287
  episode_reward_max: 281.1717171717167
  episode_reward_mean: 227.83624028821345
  episode_reward_min: 125.41414141414124
  episodes_this_iter: 158
  episodes_total: 2686
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.7201036725725446
        entropy_coeff: 0.0
        kl: 0.012058765693966831
        model: {}
        policy_loss: -0.020450936680260514
        total_loss: 2.0305573769978116
        vf_explained_var: 0.9957568049430847
        vf_loss: 2.0485965609550476
    num_steps_sampled: 2265088
    num_steps_trained: 2265088
  iterations_since_restore: 14
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.519565217391303
    gpu_util_percent0: 0.36847826086956514
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.497826086956524
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.15275667736049464
    mean_env_wait_ms: 1.2249098241157197
    mean_inference_ms: 4.656895607323416
    mean_raw_obs_processing_ms: 0.40369244952772687
  time_since_restore: 549.6643757820129
  time_this_iter_s: 39.00202989578247
  time_total_s: 549.6643757820129
  timers:
    learn_throughput: 5123.014
    learn_time_ms: 31581.407
    sample_throughput: 21643.086
    sample_time_ms: 7475.459
    update_time_ms: 33.791
  timestamp: 1602381583
  timesteps_since_restore: 0
  timesteps_total: 2265088
  training_iteration: 14
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |     14 |          549.664 | 2265088 |  227.836 |              281.172 |              125.414 |            818.378 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3546.735440340909
    time_step_min: 3200
  date: 2020-10-11_02-00-23
  done: false
  episode_len_mean: 816.9384669479606
  episode_reward_max: 281.1717171717167
  episode_reward_mean: 228.43746537100967
  episode_reward_min: 125.41414141414124
  episodes_this_iter: 158
  episodes_total: 2844
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.6995236916201455
        entropy_coeff: 0.0
        kl: 0.012355942279100418
        model: {}
        policy_loss: -0.020896892778442373
        total_loss: 2.281056829861232
        vf_explained_var: 0.9954228401184082
        vf_loss: 2.299482532909938
    num_steps_sampled: 2426880
    num_steps_trained: 2426880
  iterations_since_restore: 15
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 18.782608695652176
    gpu_util_percent0: 0.4415217391304349
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.504347826086957
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1525971887418416
    mean_env_wait_ms: 1.2262796556827626
    mean_inference_ms: 4.645554952373207
    mean_raw_obs_processing_ms: 0.4031321589706686
  time_since_restore: 588.6991488933563
  time_this_iter_s: 39.034773111343384
  time_total_s: 588.6991488933563
  timers:
    learn_throughput: 5120.401
    learn_time_ms: 31597.523
    sample_throughput: 21713.401
    sample_time_ms: 7451.251
    update_time_ms: 34.559
  timestamp: 1602381623
  timesteps_since_restore: 0
  timesteps_total: 2426880
  training_iteration: 15
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.8/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 80/80 CPUs, 1/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 RUNNING)
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status   | loc              |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | RUNNING  | 172.17.0.4:18079 |     15 |          588.699 | 2426880 |  228.437 |              281.172 |              125.414 |            816.938 |
+-------------------------+----------+------------------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


Result for PPO_jss_env_21ee9_00000:
  custom_metrics:
    time_step_max: 4228
    time_step_mean: 3538.886962106615
    time_step_min: 3200
  date: 2020-10-11_02-01-02
  done: true
  episode_len_mean: 815.2227880331
  episode_reward_max: 281.1717171717167
  episode_reward_mean: 229.69543300606315
  episode_reward_min: 125.41414141414124
  episodes_this_iter: 298
  episodes_total: 3142
  experiment_id: 7e0abe523acd408cb69250fe839a8f37
  experiment_tag: '0'
  hostname: f85e62b52919
  info:
    learner:
      default_policy:
        allreduce_latency: 0.0
        cur_kl_coeff: 0.20000000000000004
        cur_lr: 5.000000000000001e-05
        entropy: 0.6657386805330004
        entropy_coeff: 0.0
        kl: 0.011011391745081969
        model: {}
        policy_loss: -0.016925643680484166
        total_loss: 2.409372227532523
        vf_explained_var: 0.9964304566383362
        vf_loss: 2.424095630645752
    num_steps_sampled: 2588672
    num_steps_trained: 2588672
  iterations_since_restore: 16
  node_ip: 172.17.0.4
  num_healthy_workers: 79
  off_policy_estimator: {}
  perf:
    cpu_util_percent: 19.157777777777778
    gpu_util_percent0: 0.3404444444444445
    gpu_util_percent1: 0.0
    gpu_util_percent2: 0.0
    ram_util_percent: 6.488888888888892
    vram_util_percent0: 0.20465726467694317
    vram_util_percent1: 0.0009075233687267446
    vram_util_percent2: 0.0009075233687267446
  pid: 18079
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1523299992800189
    mean_env_wait_ms: 1.2287367571858774
    mean_inference_ms: 4.626578586936382
    mean_raw_obs_processing_ms: 0.40222736444938506
  time_since_restore: 627.6844637393951
  time_this_iter_s: 38.98531484603882
  time_total_s: 627.6844637393951
  timers:
    learn_throughput: 5119.812
    learn_time_ms: 31601.159
    sample_throughput: 21804.664
    sample_time_ms: 7420.064
    update_time_ms: 34.103
  timestamp: 1602381662
  timesteps_since_restore: 0
  timesteps_total: 2588672
  training_iteration: 16
  trial_id: 21ee9_00000
  
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | TERMINATED |       |     16 |          627.684 | 2588672 |  229.695 |              281.172 |              125.414 |            815.223 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


[2m[36m(pid=18057)[0m 2020-10-11 02:01:02,367	ERROR worker.py:372 -- SystemExit was raised from the worker
[2m[36m(pid=18057)[0m Traceback (most recent call last):
[2m[36m(pid=18057)[0m   File "python/ray/_raylet.pyx", line 483, in ray._raylet.execute_task
[2m[36m(pid=18057)[0m   File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
[2m[36m(pid=18057)[0m   File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
[2m[36m(pid=18057)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/function_manager.py", line 553, in actor_method_executor
[2m[36m(pid=18057)[0m     return method(actor, *args, **kwargs)
[2m[36m(pid=18057)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/actor.py", line 929, in __ray_terminate__
[2m[36m(pid=18057)[0m     ray.actor.exit_actor()
[2m[36m(pid=18057)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/actor.py", line 996, in exit_actor
[2m[36m(pid=18057)[0m     raise exit
[2m[36m(pid=18057)[0m SystemExit: 0
[2m[36m(pid=18057)[0m 
[2m[36m(pid=18057)[0m During handling of the above exception, another exception occurred:
[2m[36m(pid=18057)[0m 
[2m[36m(pid=18057)[0m Traceback (most recent call last):
[2m[36m(pid=18057)[0m   File "python/ray/_raylet.pyx", line 553, in ray._raylet.task_execution_handler
[2m[36m(pid=18057)[0m   File "python/ray/_raylet.pyx", line 440, in ray._raylet.execute_task
[2m[36m(pid=18057)[0m   File "python/ray/_raylet.pyx", line 479, in ray._raylet.execute_task
[2m[36m(pid=18057)[0m   File "python/ray/includes/libcoreworker.pxi", line 33, in ray._raylet.ProfileEvent.__exit__
[2m[36m(pid=18057)[0m   File "/root/miniconda3/lib/python3.8/traceback.py", line 167, in format_exc
[2m[36m(pid=18057)[0m     return "".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))
[2m[36m(pid=18057)[0m   File "/root/miniconda3/lib/python3.8/traceback.py", line 120, in format_exception
[2m[36m(pid=18057)[0m     return list(TracebackException(
[2m[36m(pid=18057)[0m   File "/root/miniconda3/lib/python3.8/traceback.py", line 613, in format
[2m[36m(pid=18057)[0m     yield from self.stack.format()
[2m[36m(pid=18057)[0m   File "/root/miniconda3/lib/python3.8/traceback.py", line 424, in format
[2m[36m(pid=18057)[0m     frame.filename, frame.lineno, frame.name))
[2m[36m(pid=18057)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/worker.py", line 369, in sigterm_handler
[2m[36m(pid=18057)[0m     sys.exit(1)
[2m[36m(pid=18057)[0m SystemExit: 1
[2m[36m(pid=17998)[0m 2020-10-11 02:01:02,370	ERROR worker.py:372 -- SystemExit was raised from the worker
[2m[36m(pid=17998)[0m Traceback (most recent call last):
[2m[36m(pid=17998)[0m   File "python/ray/_raylet.pyx", line 553, in ray._raylet.task_execution_handler
[2m[36m(pid=17998)[0m   File "python/ray/_raylet.pyx", line 440, in ray._raylet.execute_task
[2m[36m(pid=17998)[0m   File "python/ray/_raylet.pyx", line 479, in ray._raylet.execute_task
[2m[36m(pid=17998)[0m   File "python/ray/_raylet.pyx", line 483, in ray._raylet.execute_task
[2m[36m(pid=17998)[0m   File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
[2m[36m(pid=17998)[0m   File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
[2m[36m(pid=17998)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/function_manager.py", line 553, in actor_method_executor
[2m[36m(pid=17998)[0m     return method(actor, *args, **kwargs)
[2m[36m(pid=17998)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/actor.py", line 929, in __ray_terminate__
[2m[36m(pid=17998)[0m     ray.actor.exit_actor()
[2m[36m(pid=17998)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/actor.py", line 991, in exit_actor
[2m[36m(pid=17998)[0m     ray.state.state.disconnect()
[2m[36m(pid=17998)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/state.py", line 60, in disconnect
[2m[36m(pid=17998)[0m     self.global_state_accessor.disconnect()
2020-10-11 02:01:02,407	WARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff32335d4e01000000.
[2m[36m(pid=17998)[0m   File "/root/miniconda3/lib/python3.8/site-packages/ray/worker.py", line 369, in sigterm_handler
[2m[36m(pid=17998)[0m     sys.exit(1)
[2m[36m(pid=17998)[0m SystemExit: 1
2020-10-11 02:01:02,418	WARNING worker.py:1072 -- A worker died or was killed while executing task ffffffffffffffff452e714401000000.
== Status ==
Memory usage on this node: 48.7/754.6 GiB
Using FIFO scheduling algorithm.
Resources requested: 0/80 CPUs, 0/3 GPUs, 0.0/537.11 GiB heap, 0.0/128.52 GiB objects (0/1.0 accelerator_type:RTX)
Result logdir: /root/ray_results/ppo-jss
Number of trials: 1 (1 TERMINATED)
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+
| Trial name              | status     | loc   |   iter |   total time (s) |      ts |   reward |   episode_reward_max |   episode_reward_min |   episode_len_mean |
|-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------|
| PPO_jss_env_21ee9_00000 | TERMINATED |       |     16 |          627.684 | 2588672 |  229.695 |              281.172 |              125.414 |            815.223 |
+-------------------------+------------+-------+--------+------------------+---------+----------+----------------------+----------------------+--------------------+


